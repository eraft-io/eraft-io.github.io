1
00:00:01,300 --> 00:00:05,129
[Music]

2
00:00:05,200 --> 00:00:05,930
[Applause]

3
00:00:05,930 --> 00:00:08,630
[Music]

4
00:00:08,630 --> 00:00:10,020
[Applause]

5
00:00:10,020 --> 00:00:11,990
[Music]

6
00:00:11,990 --> 00:00:15,750
last lectures it's been a trying

7
00:00:15,750 --> 00:00:17,789
semester but we finally got through it

8
00:00:17,789 --> 00:00:21,689
so for this last discussion we're gonna

9
00:00:21,689 --> 00:00:24,330
talk about databases running on sort of

10
00:00:24,330 --> 00:00:26,460
new emerging hardware or sort of

11
00:00:26,460 --> 00:00:27,900
non-traditional hardware that's slightly

12
00:00:27,900 --> 00:00:29,910
different than everything we talked

13
00:00:29,910 --> 00:00:31,920
about so far before we get into that

14
00:00:31,920 --> 00:00:33,480
material I've quickly want to go over

15
00:00:33,480 --> 00:00:36,660
what's remaining for you guys in you

16
00:00:36,660 --> 00:00:38,010
know from now until the end the semester

17
00:00:38,010 --> 00:00:40,410
of final grades so on Wednesday this

18
00:00:40,410 --> 00:00:42,329
week we'll have a guest speaker from

19
00:00:42,329 --> 00:00:46,050
Amazon come give a talk about the things

20
00:00:46,050 --> 00:00:47,640
he's been working on that redshift so

21
00:00:47,640 --> 00:00:49,410
this will be live this will be on zoom

22
00:00:49,410 --> 00:00:51,780
is unfortunately it's only available for

23
00:00:51,780 --> 00:00:53,789
senior students so I'll post the details

24
00:00:53,789 --> 00:00:57,300
in Piazza on May 4th next week you'll

25
00:00:57,300 --> 00:00:59,070
have your the second round of code

26
00:00:59,070 --> 00:01:01,379
review submissions May 5th go do your

27
00:01:01,379 --> 00:01:05,040
final presentation also unzoom also only

28
00:01:05,040 --> 00:01:07,710
available to CMU students to discuss you

29
00:01:07,710 --> 00:01:10,020
know the butcher group has worked on the

30
00:01:10,020 --> 00:01:12,240
final exam that I gave out last week

31
00:01:12,240 --> 00:01:15,689
will be due on Wednesday May 13th and

32
00:01:15,689 --> 00:01:18,060
then what's missing here is in the code

33
00:01:18,060 --> 00:01:21,150
drop that's posted on the website as

34
00:01:21,150 --> 00:01:22,740
well so when you get those you know

35
00:01:22,740 --> 00:01:24,180
submit all your information to me to say

36
00:01:24,180 --> 00:01:26,310
you're actually done after incorporating

37
00:01:26,310 --> 00:01:28,409
the the second second round of code

38
00:01:28,409 --> 00:01:31,770
review comments and then on May 16th on

39
00:01:31,770 --> 00:01:35,579
Saturday we will have our extra credit

40
00:01:35,579 --> 00:01:37,979
hackathon again this is optional this is

41
00:01:37,979 --> 00:01:39,479
available to those that want to

42
00:01:39,479 --> 00:01:41,310
participate it's actually also going to

43
00:01:41,310 --> 00:01:44,820
be open and potentially for for non CMU

44
00:01:44,820 --> 00:01:47,369
students and so we'll figure out how to

45
00:01:47,369 --> 00:01:49,320
cordate that again the idea is that

46
00:01:49,320 --> 00:01:51,960
you're not gonna work on you know just

47
00:01:51,960 --> 00:01:53,700
keep working on what you worked on for

48
00:01:53,700 --> 00:01:56,030
project number three it would be

49
00:01:56,030 --> 00:01:58,079
something new or sort of adding a new

50
00:01:58,079 --> 00:02:01,710
sequel function or new feature to expand

51
00:02:01,710 --> 00:02:05,430
support of our sequel system for this

52
00:02:05,430 --> 00:02:07,649
okay again I'll post details about this

53
00:02:07,649 --> 00:02:09,669
on on Piazza

54
00:02:09,669 --> 00:02:12,160
one additional thing is I need everyone

55
00:02:12,160 --> 00:02:14,349
also fill out the course evaluations at

56
00:02:14,349 --> 00:02:18,550
this URL here so this is super useful

57
00:02:18,550 --> 00:02:20,560
for me because they I realize that the

58
00:02:20,560 --> 00:02:23,860
last you know last class have half of

59
00:02:23,860 --> 00:02:26,489
the class semester has been online only

60
00:02:26,489 --> 00:02:29,770
so just in general comments about the

61
00:02:29,770 --> 00:02:32,350
projects the reading assignments the

62
00:02:32,350 --> 00:02:34,540
general cadence or the pace of the class

63
00:02:34,540 --> 00:02:36,250
those things are actually very very

64
00:02:36,250 --> 00:02:38,709
useful I actually read them and I

65
00:02:38,709 --> 00:02:39,940
actually take in the consideration of

66
00:02:39,940 --> 00:02:42,400
tweaking the class from one semester to

67
00:02:42,400 --> 00:02:46,690
the next the the University and the

68
00:02:46,690 --> 00:02:47,980
department actually read these things so

69
00:02:47,980 --> 00:02:49,330
this is don't take this lightly and

70
00:02:49,330 --> 00:02:51,459
don't be like most master students often

71
00:02:51,459 --> 00:02:52,750
are where they just click five five oh

72
00:02:52,750 --> 00:02:54,160
five for everything like actually you

73
00:02:54,160 --> 00:02:55,540
know if you want to spend time and give

74
00:02:55,540 --> 00:02:57,970
me sincere feedback please do it's

75
00:02:57,970 --> 00:03:00,160
entirely on anonymous so to give you a

76
00:03:00,160 --> 00:03:02,799
kind of idea a feedback that I often can

77
00:03:02,799 --> 00:03:05,620
get we got this once a year where people

78
00:03:05,620 --> 00:03:08,440
rightly pointed out that I had a body

79
00:03:08,440 --> 00:03:10,569
odor problem this has been since

80
00:03:10,569 --> 00:03:14,320
resolved in subsequent years with sort

81
00:03:14,320 --> 00:03:16,359
of special shampoo so hopefully no one

82
00:03:16,359 --> 00:03:19,989
has been too offended by any odors of my

83
00:03:19,989 --> 00:03:22,180
body emits but again this is super

84
00:03:22,180 --> 00:03:23,769
useful I didn't really know that I had a

85
00:03:23,769 --> 00:03:25,180
body odor issue until this person

86
00:03:25,180 --> 00:03:26,980
pointed it out and then I went to the

87
00:03:26,980 --> 00:03:28,299
doctor and he's like oh yeah this you

88
00:03:28,299 --> 00:03:29,500
have this problem this this medical

89
00:03:29,500 --> 00:03:31,120
condition here's this special shampoo

90
00:03:31,120 --> 00:03:33,280
you should use so this is why I want you

91
00:03:33,280 --> 00:03:35,709
to be candid and open about all your

92
00:03:35,709 --> 00:03:38,410
comments for the course I I do take them

93
00:03:38,410 --> 00:03:42,090
in consideration okay

94
00:03:42,090 --> 00:03:45,100
the as I said the thing where you want

95
00:03:45,100 --> 00:03:47,650
to talk about today is running databases

96
00:03:47,650 --> 00:03:50,850
on you know sort of new hardware

97
00:03:50,850 --> 00:03:52,989
hardware that's not just you know CPU

98
00:03:52,989 --> 00:03:56,590
and SSDs and spinning disk drives and so

99
00:03:56,590 --> 00:03:59,319
this has been a ongoing theme in in

100
00:03:59,319 --> 00:04:01,540
databases for since almost the very

101
00:04:01,540 --> 00:04:03,069
beginning where people have always been

102
00:04:03,069 --> 00:04:06,250
looking to use a specialized hardware or

103
00:04:06,250 --> 00:04:08,739
new hardware to make data systems go

104
00:04:08,739 --> 00:04:10,239
faster

105
00:04:10,239 --> 00:04:13,690
in the in the early days in the 1980s

106
00:04:13,690 --> 00:04:16,180
late 1970s there was this movement

107
00:04:16,180 --> 00:04:18,700
called called database machines where

108
00:04:18,700 --> 00:04:21,190
the idea was you would buy like an

109
00:04:21,190 --> 00:04:22,230
appliance

110
00:04:22,230 --> 00:04:25,740
a specialized server that had custom

111
00:04:25,740 --> 00:04:26,760
hardware Asics

112
00:04:26,760 --> 00:04:29,070
to do splitting of the database

113
00:04:29,070 --> 00:04:31,200
operations so this common one was that

114
00:04:31,200 --> 00:04:32,730
you could buy a database machine that

115
00:04:32,730 --> 00:04:35,130
had specialized hardware to do hash

116
00:04:35,130 --> 00:04:37,830
joins very efficiently so this movement

117
00:04:37,830 --> 00:04:42,750
fizzled out in the 1980s because because

118
00:04:42,750 --> 00:04:44,760
of Moore's law that you know Intel and

119
00:04:44,760 --> 00:04:47,220
Motorola and and Dec we're putting out

120
00:04:47,220 --> 00:04:50,220
new CPUs all the time and so by the time

121
00:04:50,220 --> 00:04:51,900
if you were a databases machine vendor

122
00:04:51,900 --> 00:04:54,210
by the time you went and you know design

123
00:04:54,210 --> 00:04:57,630
and fab and sold your specialized data

124
00:04:57,630 --> 00:04:59,610
as Hardware Intel put out the new

125
00:04:59,610 --> 00:05:02,340
version of x86 that got even faster so

126
00:05:02,340 --> 00:05:05,280
it was you would get diminishing returns

127
00:05:05,280 --> 00:05:06,510
on the amount of effort you had to do to

128
00:05:06,510 --> 00:05:10,500
build these things so in the 1990s for

129
00:05:10,500 --> 00:05:12,380
the most part everybody was running on

130
00:05:12,380 --> 00:05:14,580
commodity hardware and certainly when

131
00:05:14,580 --> 00:05:16,950
the cloud came along in the 2000s this

132
00:05:16,950 --> 00:05:20,640
is even more so in the 2000s though

133
00:05:20,640 --> 00:05:22,890
there was some early attempts to build

134
00:05:22,890 --> 00:05:26,100
FP FPGA databases where the idea was you

135
00:05:26,100 --> 00:05:28,350
would have DJ sit between the CPU and

136
00:05:28,350 --> 00:05:31,560
the disk controller and you just you

137
00:05:31,560 --> 00:05:33,240
push down predicates on that so the

138
00:05:33,240 --> 00:05:34,860
teaser was a famous system that did this

139
00:05:34,860 --> 00:05:36,450
IBM bought them

140
00:05:36,450 --> 00:05:37,950
I think they've sunset of them or killed

141
00:05:37,950 --> 00:05:41,220
them off about a year ago but they you

142
00:05:41,220 --> 00:05:42,630
know they were they were the first FBI

143
00:05:42,630 --> 00:05:44,940
database system and again there was now

144
00:05:44,940 --> 00:05:46,890
also a bunch of appliance databases

145
00:05:46,890 --> 00:05:49,830
where unlike a database machine where it

146
00:05:49,830 --> 00:05:51,300
had specialized hardware just for the

147
00:05:51,300 --> 00:05:53,310
database system the idea of an appliance

148
00:05:53,310 --> 00:05:57,830
was it was commodity hardware but the

149
00:05:57,830 --> 00:06:00,330
system in the operating system the

150
00:06:00,330 --> 00:06:02,370
database system were tuned explicitly

151
00:06:02,370 --> 00:06:04,710
for the for the Harvard that was running

152
00:06:04,710 --> 00:06:07,140
on so you can just buy this one rack

153
00:06:07,140 --> 00:06:09,360
unit that had my sequel running on it

154
00:06:09,360 --> 00:06:11,190
but my sequel was already tuned for that

155
00:06:11,190 --> 00:06:12,630
exact hardware so we sort of achieving

156
00:06:12,630 --> 00:06:15,020
them to the best performance but again

157
00:06:15,020 --> 00:06:17,550
because of the cloud this sort of

158
00:06:17,550 --> 00:06:20,220
fizzled out because everyone just said

159
00:06:20,220 --> 00:06:22,890
it's just cheaper to buy you know

160
00:06:22,890 --> 00:06:24,950
commodity stuff on it from Amazon in

161
00:06:24,950 --> 00:06:29,760
2010 there was a the vinegar the FPGA

162
00:06:29,760 --> 00:06:31,980
czar sort of always been there I think

163
00:06:31,980 --> 00:06:34,289
in recent years they've become

164
00:06:34,289 --> 00:06:37,050
more prevalent but the baking we saw in

165
00:06:37,050 --> 00:06:40,439
the 2010 in the last decade was the rise

166
00:06:40,439 --> 00:06:42,990
of GQ databases and this is where

167
00:06:42,990 --> 00:06:46,740
because of the the big interest in using

168
00:06:46,740 --> 00:06:48,300
GPU computing for machine learning

169
00:06:48,300 --> 00:06:50,819
people correctly identify that oh I can

170
00:06:50,819 --> 00:06:52,080
actually do some database stuff on the

171
00:06:52,080 --> 00:06:54,869
GPUs and take advantage of all the

172
00:06:54,869 --> 00:06:55,979
advancements that the machine learning

173
00:06:55,979 --> 00:06:58,289
guys are are getting and so we'll talk

174
00:06:58,289 --> 00:06:59,819
about a little bit just a little bit at

175
00:06:59,819 --> 00:07:01,889
the end of this lecture there's what

176
00:07:01,889 --> 00:07:03,449
these GPU databases are and what they

177
00:07:03,449 --> 00:07:05,849
look like so now in the current decade

178
00:07:05,849 --> 00:07:08,789
that we're dealing with I'm actually

179
00:07:08,789 --> 00:07:11,939
very excited because I think that I

180
00:07:11,939 --> 00:07:14,219
think it's gonna be the Wild West again

181
00:07:14,219 --> 00:07:17,490
in terms of everybody's gonna be trying

182
00:07:17,490 --> 00:07:19,919
everything I think there's a lot of

183
00:07:19,919 --> 00:07:21,270
interesting things coming out in

184
00:07:21,270 --> 00:07:24,899
hardware that may not be explicitly

185
00:07:24,899 --> 00:07:28,110
designed for database systems but sort

186
00:07:28,110 --> 00:07:29,819
of data intensive applications if you

187
00:07:29,819 --> 00:07:31,020
want to call it that which includes

188
00:07:31,020 --> 00:07:32,490
machine learning or data science things

189
00:07:32,490 --> 00:07:35,699
but databases are a key component in

190
00:07:35,699 --> 00:07:38,399
that kind of stack and I think that

191
00:07:38,399 --> 00:07:39,509
there'll be some things that we can

192
00:07:39,509 --> 00:07:41,069
start incorporating in database systems

193
00:07:41,069 --> 00:07:42,569
and still have that be considered

194
00:07:42,569 --> 00:07:44,999
commodity hardware so the main thing

195
00:07:44,999 --> 00:07:46,439
that we're going to talk about today is

196
00:07:46,439 --> 00:07:49,559
persistent memory and just to be how you

197
00:07:49,559 --> 00:07:51,120
can design a data center to handle this

198
00:07:51,120 --> 00:07:53,399
I think this is gonna be a major change

199
00:07:53,399 --> 00:07:56,639
in this decade FPGA and GPUs are still

200
00:07:56,639 --> 00:08:00,209
be around I think that there's still be

201
00:08:00,209 --> 00:08:04,979
niche players I don't see I don't see

202
00:08:04,979 --> 00:08:07,529
them being like every database systems

203
00:08:07,529 --> 00:08:10,529
gonna have to have a GPU or an FPGA sort

204
00:08:10,529 --> 00:08:14,689
of accelerator component for it its

205
00:08:14,689 --> 00:08:17,509
majority the databases are gonna run on

206
00:08:17,509 --> 00:08:19,709
Davis isms are gonna run on it you know

207
00:08:19,709 --> 00:08:25,169
Intel CPUs going beyond FPGA is are

208
00:08:25,169 --> 00:08:26,819
these things called configurable spatial

209
00:08:26,819 --> 00:08:29,129
accelerators think of this is like an

210
00:08:29,129 --> 00:08:32,578
FPGA there's a programmable hardware

211
00:08:32,578 --> 00:08:35,639
that instead of doing the sort of a

212
00:08:35,639 --> 00:08:38,009
logic that the FPGA is do it's more of a

213
00:08:38,009 --> 00:08:41,009
dataflow thing and again like when I say

214
00:08:41,009 --> 00:08:43,198
more I mean it's hard particulate else

215
00:08:43,198 --> 00:08:47,399
is gonna come out i fabbing costs should

216
00:08:47,399 --> 00:08:48,380
be going down

217
00:08:48,380 --> 00:08:52,530
especially for sort of maybe like 70

218
00:08:52,530 --> 00:08:54,240
nanometers like sort of larger size

219
00:08:54,240 --> 00:08:58,170
transistors so people can start

220
00:08:58,170 --> 00:09:01,200
fattening stuff much more cheaply than

221
00:09:01,200 --> 00:09:02,910
they'd been able to do before

222
00:09:02,910 --> 00:09:04,770
so the economies of scale is good sort

223
00:09:04,770 --> 00:09:06,750
of helped us so again we're gonna focus

224
00:09:06,750 --> 00:09:08,250
on this today we'll talk a little bit

225
00:09:08,250 --> 00:09:12,060
about GPUs but I think in the next 10

226
00:09:12,060 --> 00:09:13,170
years I think a bunch of more things are

227
00:09:13,170 --> 00:09:15,170
gonna come out which I'll be pretty cool

228
00:09:15,170 --> 00:09:18,510
all right so as I said we wanted to spin

229
00:09:18,510 --> 00:09:20,090
us at a talking about persistent memory

230
00:09:20,090 --> 00:09:21,720
we'll talk a little about how to

231
00:09:21,720 --> 00:09:23,790
accelerate things with GPUs and then

232
00:09:23,790 --> 00:09:25,860
we'll finish up talking about Harvard

233
00:09:25,860 --> 00:09:27,270
transactional memory because this one

234
00:09:27,270 --> 00:09:29,250
also often comes up with students asking

235
00:09:29,250 --> 00:09:31,410
about oh you know is this something I

236
00:09:31,410 --> 00:09:32,910
could be using instead of how to do all

237
00:09:32,910 --> 00:09:34,770
the kernel or latching stuff that we

238
00:09:34,770 --> 00:09:37,620
talked about the semester and the answer

239
00:09:37,620 --> 00:09:39,510
is going to be no we still need to do

240
00:09:39,510 --> 00:09:41,460
everything that we've talked about so

241
00:09:41,460 --> 00:09:44,040
far and this may help in in small cases

242
00:09:44,040 --> 00:09:45,950
okay

243
00:09:45,950 --> 00:09:51,000
so persistent memory the persistent

244
00:09:51,000 --> 00:09:53,100
memory the way to think about this is

245
00:09:53,100 --> 00:09:56,670
that you know when we talk about in the

246
00:09:56,670 --> 00:09:59,220
intro class this this dichotomy between

247
00:09:59,220 --> 00:10:01,920
the volatile and the non-volatile

248
00:10:01,920 --> 00:10:05,130
storage and how we had a design or a

249
00:10:05,130 --> 00:10:07,260
disk oriented database system to account

250
00:10:07,260 --> 00:10:08,790
for those differences and certainly

251
00:10:08,790 --> 00:10:10,320
lesson last class when we talked about

252
00:10:10,320 --> 00:10:12,150
larger the memory databases we need to

253
00:10:12,150 --> 00:10:14,040
be aware that our database could have

254
00:10:14,040 --> 00:10:16,950
been writing out to a it's reading data

255
00:10:16,950 --> 00:10:18,660
to a non-volatile block-based storage

256
00:10:18,660 --> 00:10:20,820
device that's much slower so we have to

257
00:10:20,820 --> 00:10:22,710
you know design our algorithms and our

258
00:10:22,710 --> 00:10:24,180
hierarchy to account for that

259
00:10:24,180 --> 00:10:26,610
with non-volatile memory or as

260
00:10:26,610 --> 00:10:29,070
persistent memory the idea is that we're

261
00:10:29,070 --> 00:10:32,340
gonna get almost the speed of DRAM and

262
00:10:32,340 --> 00:10:35,750
have an access interface that is

263
00:10:35,750 --> 00:10:38,060
addressable byte address bold like DRAM

264
00:10:38,060 --> 00:10:42,570
but the hard ler will be able to retain

265
00:10:42,570 --> 00:10:45,930
all our reads and writes even after the

266
00:10:45,930 --> 00:10:48,780
power is lost my sense why it's called

267
00:10:48,780 --> 00:10:50,550
persistent memory so I'm gonna slip up

268
00:10:50,550 --> 00:10:52,740
multiple times during this during this

269
00:10:52,740 --> 00:10:54,720
lecture and keep calling it non-volatile

270
00:10:54,720 --> 00:10:55,860
memory because that's what we were

271
00:10:55,860 --> 00:10:57,000
calling it when we first started doing

272
00:10:57,000 --> 00:11:01,740
this research back in 2013 the industry

273
00:11:01,740 --> 00:11:03,930
standardized on calling this persistent

274
00:11:03,930 --> 00:11:05,370
memory which I actually agree with is a

275
00:11:05,370 --> 00:11:07,290
better term sometimes you also see this

276
00:11:07,290 --> 00:11:07,710
called

277
00:11:07,710 --> 00:11:09,960
storage class memory but they're all

278
00:11:09,960 --> 00:11:11,570
they all essentially mean the same thing

279
00:11:11,570 --> 00:11:15,300
so the first persistent memory devices

280
00:11:15,300 --> 00:11:17,070
that were available which is sort of

281
00:11:17,070 --> 00:11:20,310
confusing because they were like PCI

282
00:11:20,310 --> 00:11:21,600
Express cards that were block

283
00:11:21,600 --> 00:11:24,450
addressable even though the storage

284
00:11:24,450 --> 00:11:27,090
medium inside of it was the same thing

285
00:11:27,090 --> 00:11:28,800
that's gonna be in the precision memory

286
00:11:28,800 --> 00:11:31,140
or talked about here it just provided it

287
00:11:31,140 --> 00:11:35,100
through a you know PCI interface but the

288
00:11:35,100 --> 00:11:36,690
new ones that are actually available now

289
00:11:36,690 --> 00:11:39,150
from Intel are gonna be byte addressable

290
00:11:39,150 --> 00:11:41,160
so it's gonna look and smell exactly

291
00:11:41,160 --> 00:11:45,180
like DRAM to your application but

292
00:11:45,180 --> 00:11:46,920
there's some extra stuff going to need

293
00:11:46,920 --> 00:11:47,940
the covers and make sure that

294
00:11:47,940 --> 00:11:50,730
everything's persistent I have to let

295
00:11:50,730 --> 00:11:55,010
the terrier in so let's talk about the

296
00:11:55,010 --> 00:11:57,390
that's why we got where we are not

297
00:11:57,390 --> 00:11:59,370
because camellias backstory is actually

298
00:11:59,370 --> 00:12:01,050
very interesting and sort of part of the

299
00:12:01,050 --> 00:12:03,750
reason I got you know I spent a few

300
00:12:03,750 --> 00:12:06,000
years researching persistent memory in

301
00:12:06,000 --> 00:12:09,180
databases with with my first PC student

302
00:12:09,180 --> 00:12:13,020
so the if you take if your electrical

303
00:12:13,020 --> 00:12:13,860
engineer and you take off you know

304
00:12:13,860 --> 00:12:16,580
fundamental course on on circuits

305
00:12:16,580 --> 00:12:19,140
they'll describe three types of circuits

306
00:12:19,140 --> 00:12:21,330
right we'll talk about a capacitor which

307
00:12:21,330 --> 00:12:24,060
is invented back in 1745 but this is the

308
00:12:24,060 --> 00:12:26,190
ability to store some charge like a

309
00:12:26,190 --> 00:12:29,430
battery then later on the resistor was

310
00:12:29,430 --> 00:12:32,910
invented to modify the voltage that's

311
00:12:32,910 --> 00:12:35,580
coming in over your circuit and then if

312
00:12:35,580 --> 00:12:37,460
years later they developed the the

313
00:12:37,460 --> 00:12:40,410
inductor which is just a way to convert

314
00:12:40,410 --> 00:12:46,890
the voltage into into heat so after 1831

315
00:12:46,890 --> 00:12:49,230
it was just assumed that these were the

316
00:12:49,230 --> 00:12:51,690
three fundamental circuits there

317
00:12:51,690 --> 00:12:53,610
couldn't be anything else like you the

318
00:12:53,610 --> 00:12:54,720
way to think about this is you can't

319
00:12:54,720 --> 00:12:57,060
build any of these other types of

320
00:12:57,060 --> 00:12:59,700
circuits using other sorry any of these

321
00:12:59,700 --> 00:13:01,650
elements using another element and that

322
00:13:01,650 --> 00:13:02,790
sort of thing there to look at an atomic

323
00:13:02,790 --> 00:13:08,610
element of the circuitry so then in 1971

324
00:13:08,610 --> 00:13:10,920
there was a professor Leon Chua at at

325
00:13:10,920 --> 00:13:14,190
Berkeley who was working through some

326
00:13:14,190 --> 00:13:15,240
equations

327
00:13:15,240 --> 00:13:20,339
and he he did and discovered that there

328
00:13:20,339 --> 00:13:22,200
seems to be that there should be a

329
00:13:22,200 --> 00:13:25,290
fourth type of element because the way

330
00:13:25,290 --> 00:13:28,560
the math worked out is was that there

331
00:13:28,560 --> 00:13:30,240
was like this missing Kapena component

332
00:13:30,240 --> 00:13:31,680
of the equations that you had to have

333
00:13:31,680 --> 00:13:34,980
this other fourth element in order for

334
00:13:34,980 --> 00:13:36,690
the math actually worked out correctly

335
00:13:36,690 --> 00:13:39,600
right and so he hypothesized that there

336
00:13:39,600 --> 00:13:41,790
was a two terminal device where the

337
00:13:41,790 --> 00:13:45,450
resistance of that device depends on the

338
00:13:45,450 --> 00:13:48,060
voltage that's applied to it so it's

339
00:13:48,060 --> 00:13:50,339
like a resistor right but the difference

340
00:13:50,339 --> 00:13:52,350
is that you can actually changed its its

341
00:13:52,350 --> 00:13:54,300
resistance depending what voltage you

342
00:13:54,300 --> 00:13:56,370
give it right and then when you turn off

343
00:13:56,370 --> 00:13:58,310
that voltage it permantly retains

344
00:13:58,310 --> 00:14:01,440
remembers its last resistive state

345
00:14:01,440 --> 00:14:02,310
forever

346
00:14:02,310 --> 00:14:05,610
and so what he hypothesized was that

347
00:14:05,610 --> 00:14:07,290
there was this fourth element called the

348
00:14:07,290 --> 00:14:10,200
mem risker so he wrote a paper about

349
00:14:10,200 --> 00:14:14,250
this in 1971 it was sort of lost to time

350
00:14:14,250 --> 00:14:16,020
because it had a lot of citations it was

351
00:14:16,020 --> 00:14:18,200
very mathematical nobody understood it

352
00:14:18,200 --> 00:14:22,410
and it was essentially forgotten flash

353
00:14:22,410 --> 00:14:26,430
forward now to the early 2000s and there

354
00:14:26,430 --> 00:14:29,910
was this team at HP Labs that was trying

355
00:14:29,910 --> 00:14:33,870
to build sort of self self-configuring

356
00:14:33,870 --> 00:14:37,620
nano devices and what they were finding

357
00:14:37,620 --> 00:14:39,660
in their experiments is that these nano

358
00:14:39,660 --> 00:14:43,050
devices would have certain properties

359
00:14:43,050 --> 00:14:44,579
that they did they couldn't understand

360
00:14:44,579 --> 00:14:45,870
why they were why they were doing

361
00:14:45,870 --> 00:14:48,149
certain things and in particular would

362
00:14:48,149 --> 00:14:49,770
be like when you give them a voltage

363
00:14:49,770 --> 00:14:53,310
they would change the the they would

364
00:14:53,310 --> 00:14:54,600
change the resistance you were seeing in

365
00:14:54,600 --> 00:14:56,700
the in the in the circuit they were

366
00:14:56,700 --> 00:14:59,550
trying to build and so they looked and

367
00:14:59,550 --> 00:15:00,360
they couldn't figure out what it was and

368
00:15:00,360 --> 00:15:01,560
they they've kept looking in the

369
00:15:01,560 --> 00:15:03,060
literature and then they just happened

370
00:15:03,060 --> 00:15:06,420
to stumble upon the the 1971 paper from

371
00:15:06,420 --> 00:15:10,050
Chua that says that oh you know there's

372
00:15:10,050 --> 00:15:11,550
this other fourth have a circuit that

373
00:15:11,550 --> 00:15:13,680
you need actually could exist we just

374
00:15:13,680 --> 00:15:15,240
don't know how to build it yet and then

375
00:15:15,240 --> 00:15:16,910
they determined that it was actually

376
00:15:16,910 --> 00:15:20,490
they they that there that HP Labs

377
00:15:20,490 --> 00:15:22,589
actually and love accidentally building

378
00:15:22,589 --> 00:15:25,380
a memristor or two super interesting and

379
00:15:25,380 --> 00:15:27,150
part of the reason why they figured out

380
00:15:27,150 --> 00:15:28,800
that what they had built was

381
00:15:28,800 --> 00:15:32,310
same thing as what what you hypothesize

382
00:15:32,310 --> 00:15:35,339
is that there's this graph of like the

383
00:15:35,339 --> 00:15:36,480
circuit that shows this sort of

384
00:15:36,480 --> 00:15:39,209
hysteresis loop and what they were

385
00:15:39,209 --> 00:15:41,130
measuring exactly match what he proposed

386
00:15:41,130 --> 00:15:44,190
or in his conjecture that this is what

387
00:15:44,190 --> 00:15:46,230
it should look like so then they went

388
00:15:46,230 --> 00:15:50,040
back and for this for this paper they

389
00:15:50,040 --> 00:15:52,310
wrote how we found the missing memristor

390
00:15:52,310 --> 00:15:55,320
they went back and looked at the last

391
00:15:55,320 --> 00:15:57,510
like 100 years of Electrical Engineering

392
00:15:57,510 --> 00:16:00,570
scientific publications and they found a

393
00:16:00,570 --> 00:16:02,399
bunch of other people reporting the same

394
00:16:02,399 --> 00:16:04,910
hysteresis loop in their in their

395
00:16:04,910 --> 00:16:07,140
experiments but no one could explain

396
00:16:07,140 --> 00:16:08,760
what it was going on so people had been

397
00:16:08,760 --> 00:16:10,410
stumbling upon the memristor for years

398
00:16:10,410 --> 00:16:12,120
and years and years but nobody actually

399
00:16:12,120 --> 00:16:14,720
knew what they were actually building so

400
00:16:14,720 --> 00:16:16,980
HP made this big announcement that they

401
00:16:16,980 --> 00:16:19,170
had they have discovered that mr. that

402
00:16:19,170 --> 00:16:21,029
this is something that they were

403
00:16:21,029 --> 00:16:23,220
reliably able to reproduce in the lab

404
00:16:23,220 --> 00:16:24,630
and that they think they can actually go

405
00:16:24,630 --> 00:16:26,339
ahead and next manufacture it and that

406
00:16:26,339 --> 00:16:28,829
this was gonna be a major game change in

407
00:16:28,829 --> 00:16:33,000
the field of computing so so much so

408
00:16:33,000 --> 00:16:37,350
that like in 2008 they had this big

409
00:16:37,350 --> 00:16:39,899
presentation like I said there whatever

410
00:16:39,899 --> 00:16:41,970
yearly conference that talked about

411
00:16:41,970 --> 00:16:44,880
their their work on memristors and you

412
00:16:44,880 --> 00:16:46,680
can see here that I think this came out

413
00:16:46,680 --> 00:16:49,350
in 2007 so they discovered it in 2006

414
00:16:49,350 --> 00:16:52,470
proved that actually was real 2007 there

415
00:16:52,470 --> 00:16:54,959
at this conference 2008 their claim that

416
00:16:54,959 --> 00:16:56,490
the memristors will be development ready

417
00:16:56,490 --> 00:16:58,980
and then in the near future they were

418
00:16:58,980 --> 00:17:01,380
gonna claim that memristors were going

419
00:17:01,380 --> 00:17:05,040
to replace all DRAM and hard drives and

420
00:17:05,040 --> 00:17:06,480
SSDs and transistors and everything

421
00:17:06,480 --> 00:17:09,630
we're gonna be running off memristors so

422
00:17:09,630 --> 00:17:13,410
this was over 10 years ago deep hims not

423
00:17:13,410 --> 00:17:16,109
gone SSDs aren't gone being his hard

424
00:17:16,109 --> 00:17:21,078
drives aren't gone so what happened well

425
00:17:21,890 --> 00:17:24,150
HP as far as I know has still not

426
00:17:24,150 --> 00:17:27,240
produced a or shipped a memristor

427
00:17:27,240 --> 00:17:32,790
product HP then eventually also split

428
00:17:32,790 --> 00:17:35,010
off between like the consumer side and

429
00:17:35,010 --> 00:17:37,320
the enterprise side they had this ya

430
00:17:37,320 --> 00:17:38,580
have this moonshot project called the

431
00:17:38,580 --> 00:17:40,470
machine that was gonna run entirely off

432
00:17:40,470 --> 00:17:42,929
of memristors as far as I know

433
00:17:42,929 --> 00:17:45,659
that has was was canceled in it and at

434
00:17:45,659 --> 00:17:47,340
this point I don't know whether team

435
00:17:47,340 --> 00:17:48,809
members are going to come out least from

436
00:17:48,809 --> 00:17:53,159
HP so let's talk about other types of

437
00:17:53,159 --> 00:17:54,240
persistent memory or let's not

438
00:17:54,240 --> 00:17:59,070
understand now a little bit about what

439
00:17:59,070 --> 00:18:00,690
we're gonna be talk about today for

440
00:18:00,690 --> 00:18:03,929
Intel's device what the memristor is

441
00:18:03,929 --> 00:18:06,749
what it could have been and what some

442
00:18:06,749 --> 00:18:08,039
future technologies are actually going

443
00:18:08,039 --> 00:18:10,379
to look like so well safety was also

444
00:18:10,379 --> 00:18:12,600
like I drank the kool-aid from HP

445
00:18:12,600 --> 00:18:14,909
although I had no affiliation with them

446
00:18:14,909 --> 00:18:17,789
I thought memristors were a big deal and

447
00:18:17,789 --> 00:18:20,190
I was really excited and I sort of why I

448
00:18:20,190 --> 00:18:21,690
went down this path are doing persistent

449
00:18:21,690 --> 00:18:23,809
memory research here at Carnegie Mellon

450
00:18:23,809 --> 00:18:26,399
and I was always under the impression

451
00:18:26,399 --> 00:18:29,399
that the memristors were always two

452
00:18:29,399 --> 00:18:31,649
years later to our two years away right

453
00:18:31,649 --> 00:18:33,869
so like every time you HP had a press

454
00:18:33,869 --> 00:18:35,340
conference every time HP each system and

455
00:18:35,340 --> 00:18:35,789
publicly

456
00:18:35,789 --> 00:18:37,379
avilés like it's two years later it's

457
00:18:37,379 --> 00:18:38,879
two years two years later and then you

458
00:18:38,879 --> 00:18:40,169
get to the next two years and then come

459
00:18:40,169 --> 00:18:41,279
out say the same thing as two years

460
00:18:41,279 --> 00:18:43,830
later or two years away that it and it

461
00:18:43,830 --> 00:18:47,369
never happened um but Intel actually

462
00:18:47,369 --> 00:18:49,980
shipped shipped shipped a device which

463
00:18:49,980 --> 00:18:51,059
is the first one here at phase-change

464
00:18:51,059 --> 00:18:53,159
memory which is pretty exciting so let's

465
00:18:53,159 --> 00:18:54,029
go through each of these one by one

466
00:18:54,029 --> 00:18:56,429
again this is not specific the databases

467
00:18:56,429 --> 00:18:57,990
is just sort of you get an idea about

468
00:18:57,990 --> 00:19:00,299
what what's going on underneath the

469
00:19:00,299 --> 00:19:03,509
covers with this technology so

470
00:19:03,509 --> 00:19:06,269
phase-change memory the idea is that you

471
00:19:06,269 --> 00:19:10,440
have this storage cell that has two

472
00:19:10,440 --> 00:19:13,559
metal electrodes going into it and what

473
00:19:13,559 --> 00:19:17,450
happens is that you put a charge into

474
00:19:17,840 --> 00:19:20,539
into that this phase change material

475
00:19:20,539 --> 00:19:22,759
that's calcination ID and that

476
00:19:22,759 --> 00:19:28,619
essentially bakes or cooks the material

477
00:19:28,619 --> 00:19:31,440
to be able to change the resistance of

478
00:19:31,440 --> 00:19:34,080
the circuit right so if you give it a

479
00:19:34,080 --> 00:19:36,119
short pulse then that changes the cell

480
00:19:36,119 --> 00:19:37,200
to a zero because that gives you a

481
00:19:37,200 --> 00:19:38,340
different resistance if we changed it to

482
00:19:38,340 --> 00:19:41,009
a long gradual pulse then that'll change

483
00:19:41,009 --> 00:19:43,710
it to a one and again I'm showing this

484
00:19:43,710 --> 00:19:45,419
heater here it's not actually you know

485
00:19:45,419 --> 00:19:47,220
it's not a little match underneath it

486
00:19:47,220 --> 00:19:48,720
but underneath the covers you're giving

487
00:19:48,720 --> 00:19:50,340
it either a short charge or a faster

488
00:19:50,340 --> 00:19:54,419
charge and that changes to be 1 1 0 1 so

489
00:19:54,419 --> 00:19:55,480
the

490
00:19:55,480 --> 00:19:57,400
the idea of a phase change memory has

491
00:19:57,400 --> 00:19:59,410
been around for a while people have

492
00:19:59,410 --> 00:20:00,820
known about them and says nobody's been

493
00:20:00,820 --> 00:20:04,330
able to manufacture them at scale and

494
00:20:04,330 --> 00:20:07,810
the Intel opting DC memory that we'll

495
00:20:07,810 --> 00:20:10,360
talk about is to the best my knowledge

496
00:20:10,360 --> 00:20:12,730
is actually phase change memory it's not

497
00:20:12,730 --> 00:20:14,830
they haven't said it publicly at least I

498
00:20:14,830 --> 00:20:17,080
don't think they have but when the

499
00:20:17,080 --> 00:20:19,150
devices first came out some guy in South

500
00:20:19,150 --> 00:20:21,250
Korea took it out and cut it you know

501
00:20:21,250 --> 00:20:23,440
but busted open the device and looked at

502
00:20:23,440 --> 00:20:25,690
it under electron microscope and saw

503
00:20:25,690 --> 00:20:27,490
that it actually was high during phase

504
00:20:27,490 --> 00:20:31,000
change memory so there's some downsides

505
00:20:31,000 --> 00:20:33,820
of this now because you're actually

506
00:20:33,820 --> 00:20:36,040
having to put a charge in here obviously

507
00:20:36,040 --> 00:20:38,770
this will generate some heat so that

508
00:20:38,770 --> 00:20:41,170
prevents you from potentially storing on

509
00:20:41,170 --> 00:20:46,000
on the on the the CPU itself and I you

510
00:20:46,000 --> 00:20:47,140
know you can only write to it so many

511
00:20:47,140 --> 00:20:49,450
times before it wears out so you know

512
00:20:49,450 --> 00:20:52,270
ehh memory is here it's fast it exists

513
00:20:52,270 --> 00:20:54,930
and you can buy it at large capacities

514
00:20:54,930 --> 00:20:58,570
but you know compared to memory stores I

515
00:20:58,570 --> 00:21:00,580
think I thought this was an inferior

516
00:21:00,580 --> 00:21:02,740
technology but of course this exists you

517
00:21:02,740 --> 00:21:04,630
can buy this today you can't buy memory

518
00:21:04,630 --> 00:21:05,730
stirs

519
00:21:05,730 --> 00:21:09,880
all right so memory stores are a this is

520
00:21:09,880 --> 00:21:11,650
sort of confusing that there's the

521
00:21:11,650 --> 00:21:14,710
memristor to the circuit fundamental the

522
00:21:14,710 --> 00:21:17,140
fundamental circuit element and then and

523
00:21:17,140 --> 00:21:20,260
that actually includes facial memory of

524
00:21:20,260 --> 00:21:22,630
the spintronics but then there's like

525
00:21:22,630 --> 00:21:24,910
the HP marketing what they would call

526
00:21:24,910 --> 00:21:27,870
whatever they were selling the memristor

527
00:21:27,870 --> 00:21:32,260
but these are the these sort of

528
00:21:32,260 --> 00:21:33,550
scientific definition of what they had

529
00:21:33,550 --> 00:21:37,240
built was called resistive Ram and the

530
00:21:37,240 --> 00:21:38,860
way this works is that you have two

531
00:21:38,860 --> 00:21:45,280
layers of titanium dioxide above you

532
00:21:45,280 --> 00:21:47,440
have two titanium dioxide above two

533
00:21:47,440 --> 00:21:48,570
layers of

534
00:21:48,570 --> 00:21:52,060
in between two others are platinum and

535
00:21:52,060 --> 00:21:54,400
the Platinum is gonna carry the charge

536
00:21:54,400 --> 00:21:59,140
and what will happen is if you if you

537
00:21:59,140 --> 00:22:01,600
run the charge in one direction you'll

538
00:22:01,600 --> 00:22:03,400
change the resistive state if you change

539
00:22:03,400 --> 00:22:04,660
around the charge in the other direction

540
00:22:04,660 --> 00:22:06,580
you change you change the resistance

541
00:22:06,580 --> 00:22:08,800
date so the idea is like the

542
00:22:08,800 --> 00:22:11,950
there's floating electrons in between

543
00:22:11,950 --> 00:22:13,720
these two different layers and that's

544
00:22:13,720 --> 00:22:17,980
how you said it'd be a 0 or a 1 so the

545
00:22:17,980 --> 00:22:20,350
cool thing about memristors again why I

546
00:22:20,350 --> 00:22:22,270
was excited about them is like titanium

547
00:22:22,270 --> 00:22:24,670
dioxide is a very common element it's

548
00:22:24,670 --> 00:22:26,530
the same stuff that's in white house

549
00:22:26,530 --> 00:22:28,540
paint or sunscreen that you put on your

550
00:22:28,540 --> 00:22:32,320
face so it's not like some you know some

551
00:22:32,320 --> 00:22:34,630
obscure material that you had to

552
00:22:34,630 --> 00:22:36,640
manufacture the Platinum is obviously

553
00:22:36,640 --> 00:22:40,240
not not super common but but for tiny

554
00:22:40,240 --> 00:22:41,710
dioxide there's you know there's a ton

555
00:22:41,710 --> 00:22:44,110
of it so it was gonna be super cheap and

556
00:22:44,110 --> 00:22:48,760
actually super high density you know

557
00:22:48,760 --> 00:22:50,290
petabytes per square centimeter because

558
00:22:50,290 --> 00:22:52,630
the you know there's the current you're

559
00:22:52,630 --> 00:22:54,100
sending through this is much less than

560
00:22:54,100 --> 00:22:55,870
then the phase change remember to change

561
00:22:55,870 --> 00:22:58,210
the state the other interesting thing

562
00:22:58,210 --> 00:23:00,580
that's really wild about the memory

563
00:23:00,580 --> 00:23:04,180
stirs or was resistive Ram is that HP

564
00:23:04,180 --> 00:23:08,260
was talking about how you could use the

565
00:23:08,260 --> 00:23:11,340
storage fabric or the storage medium for

566
00:23:11,340 --> 00:23:14,410
executable logic so they talked about

567
00:23:14,410 --> 00:23:17,230
how you can actually change the like it

568
00:23:17,230 --> 00:23:20,560
like an FPGA you load a program onto the

569
00:23:20,560 --> 00:23:25,210
onto the memory and have the as data

570
00:23:25,210 --> 00:23:27,940
comes out of the memory it would flow

571
00:23:27,940 --> 00:23:29,920
through your logic gates and do whatever

572
00:23:29,920 --> 00:23:31,420
additional processing that you wanted on

573
00:23:31,420 --> 00:23:33,130
them all right so you think of like I

574
00:23:33,130 --> 00:23:35,350
can do like in memory computing I can do

575
00:23:35,350 --> 00:23:38,050
a scan on a column and have some

576
00:23:38,050 --> 00:23:39,880
executor logic gates to apply the filter

577
00:23:39,880 --> 00:23:44,080
and then the cost of changing that

578
00:23:44,080 --> 00:23:46,870
executed logic on the fly was super

579
00:23:46,870 --> 00:23:51,580
cheap compared to a an FPGA so you like

580
00:23:51,580 --> 00:23:53,680
loaded per query and so there was all

581
00:23:53,680 --> 00:23:54,670
this talk about how they could build

582
00:23:54,670 --> 00:23:56,320
neuro networks and memristors they could

583
00:23:56,320 --> 00:23:59,530
model the brain with memristors that was

584
00:23:59,530 --> 00:24:01,270
about 10 years ago and I haven't heard

585
00:24:01,270 --> 00:24:03,660
anything about it since then

586
00:24:03,660 --> 00:24:09,430
the other thing about the ask you the

587
00:24:09,430 --> 00:24:12,910
logic for members is that it wouldn't

588
00:24:12,910 --> 00:24:14,830
use the traditional NAND based logic

589
00:24:14,830 --> 00:24:18,160
that we use in our CPUs that we have now

590
00:24:18,160 --> 00:24:19,630
it would actually use something called

591
00:24:19,630 --> 00:24:22,500
material implication which was invented

592
00:24:22,500 --> 00:24:24,590
the great philosopher Bertrand Russell

593
00:24:24,590 --> 00:24:27,450
back in like the 1910s so it was a

594
00:24:27,450 --> 00:24:28,860
completely different way of thinking

595
00:24:28,860 --> 00:24:30,480
about computing if you ran on the

596
00:24:30,480 --> 00:24:33,419
memristor of course you know it never

597
00:24:33,419 --> 00:24:38,549
happened yet to happen all right so the

598
00:24:38,549 --> 00:24:40,380
way to think about the three mediums

599
00:24:40,380 --> 00:24:41,429
were talking light also here as well as

600
00:24:41,429 --> 00:24:43,110
like there is a there's the phase change

601
00:24:43,110 --> 00:24:45,210
memory exists now the memristors might

602
00:24:45,210 --> 00:24:47,730
be in the near future and then a little

603
00:24:47,730 --> 00:24:49,770
bit farther out will be this magnetic

604
00:24:49,770 --> 00:24:52,919
resistant RAM or spintronics and for

605
00:24:52,919 --> 00:24:55,730
this one instead of actually storing

606
00:24:55,730 --> 00:24:58,110
instead of actually storing or changing

607
00:24:58,110 --> 00:25:00,840
the the storage medium to record to

608
00:25:00,840 --> 00:25:03,450
record a charge we're going to change

609
00:25:03,450 --> 00:25:08,070
the we're going to move electrons using

610
00:25:08,070 --> 00:25:10,799
magnets okay so the idea is that this

611
00:25:10,799 --> 00:25:12,450
oxide layer is going to move electrons

612
00:25:12,450 --> 00:25:14,340
between them and that's how you're going

613
00:25:14,340 --> 00:25:17,039
to set them to be do you know set the

614
00:25:17,039 --> 00:25:20,970
bit B 0 1 and then supposedly this not

615
00:25:20,970 --> 00:25:23,640
only uses less energy it just has a

616
00:25:23,640 --> 00:25:25,830
smaller scale factor so you can you can

617
00:25:25,830 --> 00:25:27,720
store this at like you can have these be

618
00:25:27,720 --> 00:25:31,530
stored at 10 nanometers per bit and the

619
00:25:31,530 --> 00:25:34,020
speed is almost equivalent to your CPU

620
00:25:34,020 --> 00:25:37,289
caches and like using static Ram SRAM so

621
00:25:37,289 --> 00:25:40,289
you could now replace all your your l1

622
00:25:40,289 --> 00:25:44,580
l2 l3 caches with spintronics have that

623
00:25:44,580 --> 00:25:46,289
be super large because it's a higher

624
00:25:46,289 --> 00:25:48,530
capacity much cheaper to manufacture

625
00:25:48,530 --> 00:25:52,590
sitting on the cpu and you're you know

626
00:25:52,590 --> 00:25:57,210
you basically have persistent l4 it's

627
00:25:57,210 --> 00:25:59,460
like latency is less than D Ram so this

628
00:25:59,460 --> 00:26:01,880
is super amazing right if this exists

629
00:26:01,880 --> 00:26:04,289
this would be a big game-changer

630
00:26:04,289 --> 00:26:06,840
I think for all of these actually Mel

631
00:26:06,840 --> 00:26:08,190
sure what the memory serves I first

632
00:26:08,190 --> 00:26:09,600
spintronics and first patient in your

633
00:26:09,600 --> 00:26:12,360
memory prior to them manufacturing like

634
00:26:12,360 --> 00:26:16,980
your DRAM dam replacements you can buy

635
00:26:16,980 --> 00:26:18,510
them are like small scale factors for

636
00:26:18,510 --> 00:26:20,100
like for like cellphones things like

637
00:26:20,100 --> 00:26:21,780
that so you can get I think now you can

638
00:26:21,780 --> 00:26:24,690
get spintronics DRAM or spintronics Ram

639
00:26:24,690 --> 00:26:27,270
in like 16 mega byte capacities

640
00:26:27,270 --> 00:26:29,700
certainly not enough for what we need

641
00:26:29,700 --> 00:26:31,200
and a database system but like you know

642
00:26:31,200 --> 00:26:33,030
it does actually exist just not at a

643
00:26:33,030 --> 00:26:35,240
large scale

644
00:26:35,240 --> 00:26:39,080
so why is this for real

645
00:26:39,080 --> 00:26:43,440
so four three so three reasons why you

646
00:26:43,440 --> 00:26:45,300
know persistent memory is actually a

647
00:26:45,300 --> 00:26:46,800
thing now we need to consider in our

648
00:26:46,800 --> 00:26:48,630
database system the Stars have sort of

649
00:26:48,630 --> 00:26:51,240
lined such that we need to be cognizant

650
00:26:51,240 --> 00:26:54,180
about about this technology and actually

651
00:26:54,180 --> 00:26:56,210
consider it when we design a new system

652
00:26:56,210 --> 00:26:59,310
so the first of that the industry has

653
00:26:59,310 --> 00:27:02,570
agreed upon a standard technology

654
00:27:02,570 --> 00:27:05,880
nomenclature and form factor for these

655
00:27:05,880 --> 00:27:08,400
devices so there's this thing called j

656
00:27:08,400 --> 00:27:09,780
deck is basically the consortium between

657
00:27:09,780 --> 00:27:11,640
a bunch of manufacturers they said okay

658
00:27:11,640 --> 00:27:13,380
if we're making non-volatile memory

659
00:27:13,380 --> 00:27:15,360
here's what the form factors have to be

660
00:27:15,360 --> 00:27:16,530
right

661
00:27:16,530 --> 00:27:19,440
I sort of like DRAM right you know

662
00:27:19,440 --> 00:27:21,120
there's there's you know there's DRM two

663
00:27:21,120 --> 00:27:22,740
three and four like that's a consortium

664
00:27:22,740 --> 00:27:24,180
that has decided this is what the form

665
00:27:24,180 --> 00:27:26,430
factor is the spec is and then all the

666
00:27:26,430 --> 00:27:28,350
manufacturers can go off go off and make

667
00:27:28,350 --> 00:27:31,140
the same you know sin make devices that

668
00:27:31,140 --> 00:27:34,560
that followed that specification the

669
00:27:34,560 --> 00:27:38,370
next thing that happened in 2018 2017

670
00:27:38,370 --> 00:27:41,730
was that both Microsoft and Linux have

671
00:27:41,730 --> 00:27:44,220
added support for persistent memory in

672
00:27:44,220 --> 00:27:46,020
their kernels and this is something

673
00:27:46,020 --> 00:27:48,540
called Dax is a direct access extensions

674
00:27:48,540 --> 00:27:52,080
this is allows us to write programs that

675
00:27:52,080 --> 00:27:55,650
are that are able to use an API where it

676
00:27:55,650 --> 00:27:57,240
knows it's talking to you persistent

677
00:27:57,240 --> 00:28:00,690
memory right I could space easy sis

678
00:28:00,690 --> 00:28:03,630
calls that we can access this and we and

679
00:28:03,630 --> 00:28:05,340
we had the right instructions we would

680
00:28:05,340 --> 00:28:07,140
need to actually make sure things are

681
00:28:07,140 --> 00:28:11,240
flush which is the next one here so in

682
00:28:11,240 --> 00:28:15,270
2018 2017 Intel refreshed the

683
00:28:15,270 --> 00:28:17,850
instruction set for Zeon's and add

684
00:28:17,850 --> 00:28:20,640
explicit instructions to do cache line

685
00:28:20,640 --> 00:28:24,720
flushes to persistent memory again think

686
00:28:24,720 --> 00:28:27,270
about how you write programs now I when

687
00:28:27,270 --> 00:28:29,520
I do an update to a piece of memory

688
00:28:29,520 --> 00:28:31,830
underneath the covers that's doing a

689
00:28:31,830 --> 00:28:34,980
store operation or stored instruction to

690
00:28:34,980 --> 00:28:39,210
update that that memory but I'm that the

691
00:28:39,210 --> 00:28:41,850
my right is gonna land in my CPU cache

692
00:28:41,850 --> 00:28:44,610
unless I'm doing streaming rights but

693
00:28:44,610 --> 00:28:47,430
you know ignoring that my right lands in

694
00:28:47,430 --> 00:28:47,789
the CP

695
00:28:47,789 --> 00:28:51,359
- but if I if if that CPU cache has now

696
00:28:51,359 --> 00:28:53,369
been backed by persistent memory like

697
00:28:53,369 --> 00:28:55,009
instead of DRAM its persistent memory

698
00:28:55,009 --> 00:28:57,929
but a program needs a way to know that

699
00:28:57,929 --> 00:29:00,479
the things that I wrote that are sitting

700
00:29:00,479 --> 00:29:04,320
in CPU caches have made it out - has

701
00:29:04,320 --> 00:29:07,019
made it actually made it out to - to

702
00:29:07,019 --> 00:29:08,340
persistent memory and therefore I know

703
00:29:08,340 --> 00:29:11,220
that my right is durable when you think

704
00:29:11,220 --> 00:29:13,440
of again a disk based system I'd call F

705
00:29:13,440 --> 00:29:18,090
sink right and that'll move it out of so

706
00:29:18,090 --> 00:29:21,179
whatever buffers that it has and

707
00:29:21,179 --> 00:29:22,769
actually persist it on disk and I don't

708
00:29:22,769 --> 00:29:25,649
get a return call to my application

709
00:29:25,649 --> 00:29:27,059
until I know the disk controller says

710
00:29:27,059 --> 00:29:29,489
that right was successful so we need the

711
00:29:29,489 --> 00:29:31,649
same thing for our cache lines and

712
00:29:31,649 --> 00:29:33,349
that's what these instructions give us

713
00:29:33,349 --> 00:29:36,299
so this is sort of was the state of the

714
00:29:36,299 --> 00:29:41,609
world up until 2019 2018 but then last

715
00:29:41,609 --> 00:29:44,340
year is when this stuff actually became

716
00:29:44,340 --> 00:29:46,259
available so this is what Intel's

717
00:29:46,259 --> 00:29:47,940
shipping now it's called opt Ain DC

718
00:29:47,940 --> 00:29:50,220
persistent memory and as you can see it

719
00:29:50,220 --> 00:29:53,700
looks like DRAM it has a DRM form factor

720
00:29:53,700 --> 00:29:56,009
meaning you can fit right on where demon

721
00:29:56,009 --> 00:29:58,200
exists in the motherboard but instead of

722
00:29:58,200 --> 00:30:01,190
being volatile it's non-volatile storage

723
00:30:01,190 --> 00:30:05,759
now this actually works is a bit

724
00:30:05,759 --> 00:30:07,859
complicated but like there's it's almost

725
00:30:07,859 --> 00:30:09,299
like an SSD where there's there's a

726
00:30:09,299 --> 00:30:11,489
price there's an ASIC on the device

727
00:30:11,489 --> 00:30:14,190
that's doing load balancing or we're

728
00:30:14,190 --> 00:30:15,919
leveling and garbage collection and

729
00:30:15,919 --> 00:30:17,580
encryption and a bunch of other things

730
00:30:17,580 --> 00:30:18,840
so this is this is more than just like

731
00:30:18,840 --> 00:30:20,399
hey I'm just writing just from all bits

732
00:30:20,399 --> 00:30:22,109
this is intercepting the writes and

733
00:30:22,109 --> 00:30:24,720
actually doing something so you as far

734
00:30:24,720 --> 00:30:26,070
as you know you can't go to Amazon

735
00:30:26,070 --> 00:30:28,049
because I tried today you just can't buy

736
00:30:28,049 --> 00:30:29,340
this this is something you have to get

737
00:30:29,340 --> 00:30:31,950
through like a manufacturer so it's nil

738
00:30:31,950 --> 00:30:33,809
still not widely prevalent but it

739
00:30:33,809 --> 00:30:35,879
they're out they are shipping this you

740
00:30:35,879 --> 00:30:37,619
can get access to this today if you have

741
00:30:37,619 --> 00:30:38,970
the money

742
00:30:38,970 --> 00:30:44,090
price wise mean I I'd have to go look I

743
00:30:44,090 --> 00:30:45,450
yeah actually

744
00:30:45,450 --> 00:30:47,009
publicly I don't think I discuss the

745
00:30:47,009 --> 00:30:50,159
prices um I think it's three or four

746
00:30:50,159 --> 00:30:51,899
four times the price of DRM we should

747
00:30:51,899 --> 00:30:55,159
just look that up but but it it exists

748
00:30:55,159 --> 00:30:57,929
which is awesome right so so obviously

749
00:30:57,929 --> 00:30:59,669
over time it ever get cheaper then maybe

750
00:30:59,669 --> 00:31:01,340
other manufacturers of this technology

751
00:31:01,340 --> 00:31:05,860
so this to me this is a big deal

752
00:31:05,860 --> 00:31:07,669
alright so how are we actually going to

753
00:31:07,669 --> 00:31:10,759
use this so from from a databases

754
00:31:10,759 --> 00:31:14,240
perspective there's really two ways and

755
00:31:14,240 --> 00:31:18,259
as far as I know well yeah from a data's

756
00:31:18,259 --> 00:31:19,340
effective there's two ways there's a

757
00:31:19,340 --> 00:31:22,610
there's an additional way to to

758
00:31:22,610 --> 00:31:25,549
configure the the configure that the

759
00:31:25,549 --> 00:31:27,799
device the the opting device to do

760
00:31:27,799 --> 00:31:29,570
writes a certain way but we can ignore

761
00:31:29,570 --> 00:31:31,249
this is what we care about in a database

762
00:31:31,249 --> 00:31:33,769
system so the first is that you just

763
00:31:33,769 --> 00:31:39,619
have DRAM being used as as a Harvard

764
00:31:39,619 --> 00:31:41,840
manage cash so what does that mean so

765
00:31:41,840 --> 00:31:43,850
this is our persistent memory whatever

766
00:31:43,850 --> 00:31:45,409
the size of this is that's what the

767
00:31:45,409 --> 00:31:48,470
operating system thinks it has for for

768
00:31:48,470 --> 00:31:49,369
the total amount of memory that's

769
00:31:49,369 --> 00:31:51,320
available to the database system so now

770
00:31:51,320 --> 00:31:54,110
as I start doing writes for my database

771
00:31:54,110 --> 00:31:56,149
system it'll go through the VM subsystem

772
00:31:56,149 --> 00:31:59,629
the right will first land in DRAM

773
00:31:59,629 --> 00:32:01,820
because that'll be fast and then I can

774
00:32:01,820 --> 00:32:03,649
return back to my application say yeah

775
00:32:03,649 --> 00:32:05,480
we got your got your right in memory and

776
00:32:05,480 --> 00:32:07,879
then eventually this will get pushed out

777
00:32:07,879 --> 00:32:12,379
to do the persistent memory or if I do a

778
00:32:12,379 --> 00:32:13,519
flush then I make sure that that's

779
00:32:13,519 --> 00:32:15,980
actually retained down there but the

780
00:32:15,980 --> 00:32:18,470
idea is that since DRAM is faster than

781
00:32:18,470 --> 00:32:20,179
persistent memory at least as they exist

782
00:32:20,179 --> 00:32:22,519
today I can have them all my ripes

783
00:32:22,519 --> 00:32:24,440
writes absorb this and I don't I don't

784
00:32:24,440 --> 00:32:26,720
experience the slowdown necessarily of

785
00:32:26,720 --> 00:32:29,690
the slower Layton sees for persistent

786
00:32:29,690 --> 00:32:32,450
memory so in for Intel they call this

787
00:32:32,450 --> 00:32:35,419
memory mode where again it's just we're

788
00:32:35,419 --> 00:32:36,919
just using it as if it was D Ram and

789
00:32:36,919 --> 00:32:38,480
there's actually nothing we're doing in

790
00:32:38,480 --> 00:32:40,519
here in our database system for this set

791
00:32:40,519 --> 00:32:43,629
up that is aware that we're writing to

792
00:32:43,629 --> 00:32:47,240
persistent memory and this thinks that

793
00:32:47,240 --> 00:32:48,259
it's just DRAM

794
00:32:48,259 --> 00:32:50,960
it's a larger cheaper potentially DRAM

795
00:32:50,960 --> 00:32:53,570
and so that means that we start the

796
00:32:53,570 --> 00:32:55,070
write a law we said to do much but a

797
00:32:55,070 --> 00:32:57,379
bunch of extra stuff to account for this

798
00:32:57,379 --> 00:32:58,820
because again we think that we're just

799
00:32:58,820 --> 00:33:04,519
writing to to DRM the other approach is

800
00:33:04,519 --> 00:33:08,509
that we would have the the DRAM adjacent

801
00:33:08,509 --> 00:33:11,899
to persistent memory and now our

802
00:33:11,899 --> 00:33:13,960
database system is aware that were right

803
00:33:13,960 --> 00:33:16,270
- persistent memory and that has the

804
00:33:16,270 --> 00:33:19,029
durability properties we didn't want and

805
00:33:19,029 --> 00:33:21,100
so to do this again if I have a right I

806
00:33:21,100 --> 00:33:22,570
can I can declare I want to write it to

807
00:33:22,570 --> 00:33:24,100
some region a memory my address space

808
00:33:24,100 --> 00:33:26,799
that is backed by DRAM or gonna have a

809
00:33:26,799 --> 00:33:28,570
right go to some region of memory that's

810
00:33:28,570 --> 00:33:30,309
backed by persistent memory and I know

811
00:33:30,309 --> 00:33:32,470
that if I do that right the process of

812
00:33:32,470 --> 00:33:34,630
memory and I do my flushes then like my

813
00:33:34,630 --> 00:33:37,899
changes are durable so intel calls this

814
00:33:37,899 --> 00:33:40,090
application mode and the idea here is

815
00:33:40,090 --> 00:33:41,230
that the application meaning our

816
00:33:41,230 --> 00:33:43,210
database system is aware where the

817
00:33:43,210 --> 00:33:44,919
boundaries are or then we've allocated

818
00:33:44,919 --> 00:33:46,330
some memory into our address space

819
00:33:46,330 --> 00:33:48,640
that's in persistent memory versus DRAM

820
00:33:48,640 --> 00:33:53,070
and that we can do flushes as needed so

821
00:33:53,760 --> 00:33:56,950
the as I said beginning these devices

822
00:33:56,950 --> 00:34:00,880
first were arrived on PCI Express cards

823
00:34:00,880 --> 00:34:05,020
and they were block addressable so from

824
00:34:05,020 --> 00:34:06,429
from a database systems perspective

825
00:34:06,429 --> 00:34:09,429
that's not interesting because that's

826
00:34:09,429 --> 00:34:11,168
just we just take our disscourn and

827
00:34:11,168 --> 00:34:13,060
design choices we made from last

828
00:34:13,060 --> 00:34:15,219
semester and build a system to use that

829
00:34:15,219 --> 00:34:19,300
it just looks like a faster faster SSD

830
00:34:19,300 --> 00:34:21,609
and I should when we did benchmarking

831
00:34:21,609 --> 00:34:24,760
against some high-end Samsung devices we

832
00:34:24,760 --> 00:34:27,040
really did see a major difference in

833
00:34:27,040 --> 00:34:29,339
performance for the PCI Express version

834
00:34:29,339 --> 00:34:31,510
you just you saw way more stable

835
00:34:31,510 --> 00:34:33,010
agencies though like if there was less

836
00:34:33,010 --> 00:34:36,429
oscillation and performance the one the

837
00:34:36,429 --> 00:34:38,699
the this set up but we do care about is

838
00:34:38,699 --> 00:34:40,719
the the second one I showed in the last

839
00:34:40,719 --> 00:34:42,280
slide the application mode where I know

840
00:34:42,280 --> 00:34:43,780
I'm ready to the RAM and I know I'm

841
00:34:43,780 --> 00:34:46,270
writing to persistent memory and my dad

842
00:34:46,270 --> 00:34:48,879
listen can manage that right so because

843
00:34:48,879 --> 00:34:51,219
because now we have to go and design our

844
00:34:51,219 --> 00:34:53,320
system to account for that that now I

845
00:34:53,320 --> 00:34:55,119
can actually do byte addressable updates

846
00:34:55,119 --> 00:34:57,129
to some location and memory some data

847
00:34:57,129 --> 00:34:59,440
structure or some table heap that will

848
00:34:59,440 --> 00:35:01,990
be guaranteed to be be durable and then

849
00:35:01,990 --> 00:35:03,940
Intel's device handles the you know

850
00:35:03,940 --> 00:35:05,980
handles of the case where even if I

851
00:35:05,980 --> 00:35:07,180
restore my application I restore my

852
00:35:07,180 --> 00:35:08,980
system I come back and I get access to

853
00:35:08,980 --> 00:35:12,010
my memory that I had it for it's not

854
00:35:12,010 --> 00:35:13,390
gonna restart the program counters for

855
00:35:13,390 --> 00:35:14,500
you so it's not like you can manually

856
00:35:14,500 --> 00:35:16,359
pull the plug and come back and

857
00:35:16,359 --> 00:35:17,410
everything's exactly the way it was

858
00:35:17,410 --> 00:35:19,030
before we still have to do some

859
00:35:19,030 --> 00:35:21,010
potentially some recovery work because

860
00:35:21,010 --> 00:35:23,710
we're processor gonna is gonna start up

861
00:35:23,710 --> 00:35:25,110
all over again

862
00:35:25,110 --> 00:35:28,590
so this is a conjecture of mine I still

863
00:35:28,590 --> 00:35:31,950
think it's true we'll see how it plays

864
00:35:31,950 --> 00:35:34,230
out in the marketplace in the next

865
00:35:34,230 --> 00:35:37,710
couple years but I believe that when

866
00:35:37,710 --> 00:35:39,270
persistent memory come becomes more

867
00:35:39,270 --> 00:35:41,040
widely available and that basically

868
00:35:41,040 --> 00:35:42,960
means like Amazon will give you access

869
00:35:42,960 --> 00:35:44,630
to it

870
00:35:44,630 --> 00:35:48,450
when Itoh ec2 the in-memory database

871
00:35:48,450 --> 00:35:49,440
systems that we've been talking about

872
00:35:49,440 --> 00:35:51,720
this semester they will be in a better

873
00:35:51,720 --> 00:35:54,030
position to accommodate the byte

874
00:35:54,030 --> 00:35:57,450
addressable persistent memory because

875
00:35:57,450 --> 00:35:58,950
they've already written an entire

876
00:35:58,950 --> 00:36:01,080
architecture to assume they can do

877
00:36:01,080 --> 00:36:04,910
random access very quickly to to storage

878
00:36:04,910 --> 00:36:07,350
the image this morning to do systems

879
00:36:07,350 --> 00:36:10,200
what will will probably end up starting

880
00:36:10,200 --> 00:36:11,400
with the second approach I showed before

881
00:36:11,400 --> 00:36:14,250
where you just have the DRAM sit in

882
00:36:14,250 --> 00:36:17,010
front and a Pasiphae is a cheaper more

883
00:36:17,010 --> 00:36:19,290
efficient memory pool or larger capacity

884
00:36:19,290 --> 00:36:21,990
you know memory address space so you

885
00:36:21,990 --> 00:36:23,520
don't the rewrite and your application

886
00:36:23,520 --> 00:36:25,440
you just you're just using more D Ram

887
00:36:25,440 --> 00:36:27,750
but then if you start want to be taking

888
00:36:27,750 --> 00:36:29,670
want to take advantage of persistent

889
00:36:29,670 --> 00:36:32,400
properties of DRAM a persistent memory

890
00:36:32,400 --> 00:36:34,650
then you have to go and reor connect

891
00:36:34,650 --> 00:36:36,690
your system to potentially use a byte

892
00:36:36,690 --> 00:36:38,880
addressable API essentially all the

893
00:36:38,880 --> 00:36:40,320
things that we talked about this entire

894
00:36:40,320 --> 00:36:44,400
semester all right so I want to first

895
00:36:44,400 --> 00:36:47,490
talk about some storage recovery methods

896
00:36:47,490 --> 00:36:50,550
for persistent memory and this is sort

897
00:36:50,550 --> 00:36:53,160
of just get you to think about what what

898
00:36:53,160 --> 00:36:55,830
can change if you design your system to

899
00:36:55,830 --> 00:36:57,780
account for to be aware that you're

900
00:36:57,780 --> 00:37:01,230
writing to byte address well persistent

901
00:37:01,230 --> 00:37:04,200
memory so this is the paper that my PC

902
00:37:04,200 --> 00:37:04,680
soon

903
00:37:04,680 --> 00:37:07,340
joy realized and I wrote a few years ago

904
00:37:07,340 --> 00:37:10,410
on skin can think looking at all the

905
00:37:10,410 --> 00:37:12,210
basic designs you have of a database

906
00:37:12,210 --> 00:37:15,180
system storage architecture and what can

907
00:37:15,180 --> 00:37:17,670
change with with persistent memory so

908
00:37:17,670 --> 00:37:21,540
the back in 2015 we actually did not

909
00:37:21,540 --> 00:37:24,000
have the device the only what we were

910
00:37:24,000 --> 00:37:27,480
using at the time was a harbor emulator

911
00:37:27,480 --> 00:37:29,880
that Intel provided us in Hillsboro

912
00:37:29,880 --> 00:37:34,290
Oregon where they've modified the

913
00:37:34,290 --> 00:37:37,350
the the motherboard for these devices

914
00:37:37,350 --> 00:37:41,280
for the system to introduce some

915
00:37:41,280 --> 00:37:43,410
additional microcode in like debug hooks

916
00:37:43,410 --> 00:37:46,020
for the Zeon so that anytime I did a

917
00:37:46,020 --> 00:37:48,060
load in the store it was basically this

918
00:37:48,060 --> 00:37:50,730
this sophisticated busy loop that would

919
00:37:50,730 --> 00:37:52,710
figure out the timings for how to slow

920
00:37:52,710 --> 00:37:55,170
down the there's loads in store

921
00:37:55,170 --> 00:37:59,420
operations to mimic behavior of

922
00:37:59,540 --> 00:38:01,950
persistent memory when it actually when

923
00:38:01,950 --> 00:38:05,700
it finally came along so this work was

924
00:38:05,700 --> 00:38:08,010
all done in a prototype data system we

925
00:38:08,010 --> 00:38:09,990
were building called n store this is the

926
00:38:09,990 --> 00:38:11,460
first one of the first days system we

927
00:38:11,460 --> 00:38:13,020
were building at Carnegie Mellon when I

928
00:38:13,020 --> 00:38:17,100
started this is actually what the

929
00:38:17,100 --> 00:38:18,780
peloton project came out of so we

930
00:38:18,780 --> 00:38:20,250
started building in store for this paper

931
00:38:20,250 --> 00:38:22,859
the project kind of got bigger and

932
00:38:22,859 --> 00:38:25,530
bigger we renamed it to peloton and then

933
00:38:25,530 --> 00:38:27,150
we eventually killed all peloton and

934
00:38:27,150 --> 00:38:29,280
that became the materia database system

935
00:38:29,280 --> 00:38:30,660
that you guys are working on today we

936
00:38:30,660 --> 00:38:31,920
threw away all the peloton code and

937
00:38:31,920 --> 00:38:34,560
started over so this is you know from n

938
00:38:34,560 --> 00:38:36,180
store to peloton material that's how we

939
00:38:36,180 --> 00:38:37,590
ended up with this but there's nothing

940
00:38:37,590 --> 00:38:40,290
in our current system that uses any of

941
00:38:40,290 --> 00:38:42,359
the code we use we generate and store

942
00:38:42,359 --> 00:38:43,890
because of this a lot of it was was

943
00:38:43,890 --> 00:38:46,920
specific to the Intel emulator device

944
00:38:46,920 --> 00:38:49,770
and it was also before Intel put up put

945
00:38:49,770 --> 00:38:51,990
out a bunch of libraries to do memory

946
00:38:51,990 --> 00:38:53,280
allocation other things you would need

947
00:38:53,280 --> 00:38:55,430
it to write persistent memory programs

948
00:38:55,430 --> 00:39:00,590
nowadays all that stuff exists with the

949
00:39:00,590 --> 00:39:03,510
PMD K from Intel like they provide you

950
00:39:03,510 --> 00:39:05,010
with all the the important constructs

951
00:39:05,010 --> 00:39:06,810
that we had to roll our own backpack

952
00:39:06,810 --> 00:39:10,590
that all right so let's understand how

953
00:39:10,590 --> 00:39:13,460
we reduce synchronization with

954
00:39:13,460 --> 00:39:16,890
persistent memory so again the way we

955
00:39:16,890 --> 00:39:18,960
write programs now when you you allocate

956
00:39:18,960 --> 00:39:21,210
malloc a bunch of memory you do a bunch

957
00:39:21,210 --> 00:39:23,070
of rice to it you assume that it's

958
00:39:23,070 --> 00:39:25,590
volatile and you also assume that's

959
00:39:25,590 --> 00:39:27,750
gonna lend in your CPU caches if the

960
00:39:27,750 --> 00:39:30,270
program crashes you lose everything but

961
00:39:30,270 --> 00:39:32,940
now since we since we want to be able to

962
00:39:32,940 --> 00:39:36,090
write data adorably and have it backed

963
00:39:36,090 --> 00:39:38,520
by persistent memory we need to know how

964
00:39:38,520 --> 00:39:41,210
that actually works at a high level so

965
00:39:41,210 --> 00:39:43,740
again say our pipeline looks like this

966
00:39:43,740 --> 00:39:45,450
this is our process that's running on

967
00:39:45,450 --> 00:39:48,050
the CPU they do a store operation

968
00:39:48,050 --> 00:39:50,810
to update some location in memory but

969
00:39:50,810 --> 00:39:52,190
that store operation is always gonna

970
00:39:52,190 --> 00:39:54,620
land again in our CPU cache all right

971
00:39:54,620 --> 00:39:56,660
guys that's that's the fastest storage

972
00:39:56,660 --> 00:39:57,920
medium and that's available to the CPU

973
00:39:57,920 --> 00:40:01,990
but then now if I want to make sure that

974
00:40:01,990 --> 00:40:06,740
my data my change makes it out to to

975
00:40:06,740 --> 00:40:11,030
persistent memory I could just wait and

976
00:40:11,030 --> 00:40:12,680
hope that eventually it makes it out

977
00:40:12,680 --> 00:40:15,740
because again when my what will happen

978
00:40:15,740 --> 00:40:19,370
is if my cache gets full the the CPU

979
00:40:19,370 --> 00:40:20,780
would then write it back right to change

980
00:40:20,780 --> 00:40:22,280
you actually made out to alton memory

981
00:40:22,280 --> 00:40:24,410
right and then you then fetch in the

982
00:40:24,410 --> 00:40:25,970
next piece that actually needs into the

983
00:40:25,970 --> 00:40:28,910
CPU cache to make space but I I but I

984
00:40:28,910 --> 00:40:31,820
can't I need you know exactly when that

985
00:40:31,820 --> 00:40:33,860
occurs but there's no callback method

986
00:40:33,860 --> 00:40:35,660
for this and when it happens but that

987
00:40:35,660 --> 00:40:37,700
would be too slow so I want to tell it

988
00:40:37,700 --> 00:40:40,220
did I won't tell the CPU hey write this

989
00:40:40,220 --> 00:40:42,350
alpha me so we can use a cache line

990
00:40:42,350 --> 00:40:45,350
right back instruction that then pushes

991
00:40:45,350 --> 00:40:47,540
the the change to a memory controller

992
00:40:47,540 --> 00:40:49,610
and this is sitting on the motherboard

993
00:40:49,610 --> 00:40:51,380
that has the small capacitor to keep it

994
00:40:51,380 --> 00:40:54,830
especially he's battery backed so the

995
00:40:54,830 --> 00:40:57,050
capacitors size such that I lose power

996
00:40:57,050 --> 00:40:58,730
there's enough energy in here to make

997
00:40:58,730 --> 00:40:59,840
sure that everything actually makes it

998
00:40:59,840 --> 00:41:03,710
out to to my persistent memory and then

999
00:41:03,710 --> 00:41:06,290
at this point I'll return control back

1000
00:41:06,290 --> 00:41:08,180
to the program because my right made it

1001
00:41:08,180 --> 00:41:09,320
out to the memory controller and it's

1002
00:41:09,320 --> 00:41:10,790
responsible for making sure it makes it

1003
00:41:10,790 --> 00:41:12,920
on the other side and then this thing

1004
00:41:12,920 --> 00:41:14,600
does what's called an asynchronous data

1005
00:41:14,600 --> 00:41:15,080
refresh

1006
00:41:15,080 --> 00:41:17,570
it's a special instructions I'd said it

1007
00:41:17,570 --> 00:41:20,540
for Intel that prop assist that changes

1008
00:41:20,540 --> 00:41:23,870
to the to the non-volatile memory or

1009
00:41:23,870 --> 00:41:27,200
that the TM device so from our database

1010
00:41:27,200 --> 00:41:28,910
systems perspective we just need to be

1011
00:41:28,910 --> 00:41:31,460
aware of what cache lines or said what

1012
00:41:31,460 --> 00:41:33,050
memory locations we modified that we

1013
00:41:33,050 --> 00:41:34,430
then want to make durable and we use a

1014
00:41:34,430 --> 00:41:36,410
cache line flostor cache line right back

1015
00:41:36,410 --> 00:41:38,920
instruction to make sure that happens

1016
00:41:38,920 --> 00:41:41,240
the next thing we have to deal with is

1017
00:41:41,240 --> 00:41:45,470
if our database system restarts and we

1018
00:41:45,470 --> 00:41:47,690
come back online we have a bunch of

1019
00:41:47,690 --> 00:41:50,480
pointers now to tuples or other

1020
00:41:50,480 --> 00:41:52,420
in-memory data structures that we have

1021
00:41:52,420 --> 00:41:54,470
but how do we actually make sure that

1022
00:41:54,470 --> 00:41:56,840
those pointers are still valid the

1023
00:41:56,840 --> 00:41:59,260
second time to come around because I

1024
00:41:59,260 --> 00:42:01,880
can't guarantee that and when I start

1025
00:42:01,880 --> 00:42:06,410
caning memory that the first time been

1026
00:42:06,410 --> 00:42:08,120
allocated the secretary my program

1027
00:42:08,120 --> 00:42:10,070
starts I'm gonna get the same virtual

1028
00:42:10,070 --> 00:42:12,850
memory addresses that that I had before

1029
00:42:12,850 --> 00:42:15,110
time so the issue is this I have an

1030
00:42:15,110 --> 00:42:17,090
index it has a bunch of pointers to some

1031
00:42:17,090 --> 00:42:20,180
tuples and then let's say if I'm doing a

1032
00:42:20,180 --> 00:42:24,110
pen only I'm doing multi version control

1033
00:42:24,110 --> 00:42:25,910
so I have multiple versions of the tuple

1034
00:42:25,910 --> 00:42:27,560
and this in like in my version chain I

1035
00:42:27,560 --> 00:42:29,750
have a pointer to another tuple here but

1036
00:42:29,750 --> 00:42:32,030
now this my system crashes this gets

1037
00:42:32,030 --> 00:42:35,450
blown away right and my index gets blown

1038
00:42:35,450 --> 00:42:37,070
away all the pointers are now invalid

1039
00:42:37,070 --> 00:42:38,750
what I want to be able to do is come

1040
00:42:38,750 --> 00:42:41,780
back online and have all my pointers

1041
00:42:41,780 --> 00:42:44,270
still be valid so that so if I'm using

1042
00:42:44,270 --> 00:42:45,830
you know virtual memory addresses

1043
00:42:45,830 --> 00:42:50,150
there's no guarantee to do that so what

1044
00:42:50,150 --> 00:42:52,370
you said you need is a memory allocator

1045
00:42:52,370 --> 00:42:55,910
that is aware of of these two issues

1046
00:42:55,910 --> 00:42:57,080
that you need to be able to synchronize

1047
00:42:57,080 --> 00:42:59,150
your data out the disk or try out the

1048
00:42:59,150 --> 00:43:00,830
persistent memory when you call the

1049
00:43:00,830 --> 00:43:03,770
right instructions and then when I come

1050
00:43:03,770 --> 00:43:05,750
back the second time that all my

1051
00:43:05,750 --> 00:43:08,510
addresses steal point to that the

1052
00:43:08,510 --> 00:43:10,790
correct correct memory check locations

1053
00:43:10,790 --> 00:43:13,520
in virtual memory so the first one again

1054
00:43:13,520 --> 00:43:15,530
you're just doing the the cache line

1055
00:43:15,530 --> 00:43:17,570
flush but then you have an S fence

1056
00:43:17,570 --> 00:43:20,510
debate to wait until essentially a

1057
00:43:20,510 --> 00:43:22,160
barrier and junction pipeline to make

1058
00:43:22,160 --> 00:43:23,540
sure that those changes get flushed

1059
00:43:23,540 --> 00:43:25,280
before we start executing the next

1060
00:43:25,280 --> 00:43:27,290
instructions like this is sort of the

1061
00:43:27,290 --> 00:43:30,700
same thing as s ink going to the OS and

1062
00:43:30,700 --> 00:43:33,230
not returning until the the disk

1063
00:43:33,230 --> 00:43:35,780
controller confirms that the flush for

1064
00:43:35,780 --> 00:43:37,340
naming the idea is that the memory

1065
00:43:37,340 --> 00:43:39,650
allocator can you can declare

1066
00:43:39,650 --> 00:43:41,810
specialized pointers that come through

1067
00:43:41,810 --> 00:43:43,550
the memory allocator that are backed by

1068
00:43:43,550 --> 00:43:45,710
persistent memory and that you know that

1069
00:43:45,710 --> 00:43:47,150
anytime you have a pointer to that

1070
00:43:47,150 --> 00:43:49,250
memory location for your application

1071
00:43:49,250 --> 00:43:51,080
when you come back around the second

1072
00:43:51,080 --> 00:43:53,300
time when you restart the program those

1073
00:43:53,300 --> 00:43:54,980
pointers will still be valid for your

1074
00:43:54,980 --> 00:43:58,190
application and so you don't want to

1075
00:43:58,190 --> 00:44:00,110
write all the stuff yourself you want to

1076
00:44:00,110 --> 00:44:01,940
use PMD K from intelligent and they

1077
00:44:01,940 --> 00:44:04,010
provide you the low level primitives to

1078
00:44:04,010 --> 00:44:08,240
do this all right so let's see now how

1079
00:44:08,240 --> 00:44:10,910
we can use these these primitives to

1080
00:44:10,910 --> 00:44:14,150
build a database system so again for

1081
00:44:14,150 --> 00:44:15,650
this paper what we did was we

1082
00:44:15,650 --> 00:44:18,470
looked at the three basic design

1083
00:44:18,470 --> 00:44:20,660
architectures you can have for storage

1084
00:44:20,660 --> 00:44:23,060
manager in a database system and we

1085
00:44:23,060 --> 00:44:26,210
identified where are the bottlenecks or

1086
00:44:26,210 --> 00:44:27,650
what are the issues for when you're

1087
00:44:27,650 --> 00:44:29,810
running on persistent memory and how can

1088
00:44:29,810 --> 00:44:32,060
we do redesign them to be aware that I

1089
00:44:32,060 --> 00:44:34,720
can now write changes that are durable

1090
00:44:34,720 --> 00:44:37,870
so for this one we're gonna assume that

1091
00:44:37,870 --> 00:44:41,510
for simplicity that there's no DRAM that

1092
00:44:41,510 --> 00:44:43,310
everything's in persistent memory and

1093
00:44:43,310 --> 00:44:46,490
therefore if I do the flushes then then

1094
00:44:46,490 --> 00:44:48,230
I can guarantee that my changes are

1095
00:44:48,230 --> 00:44:51,500
durable so this way think about this

1096
00:44:51,500 --> 00:44:53,750
this is like you know maybe fifteen

1097
00:44:53,750 --> 00:44:55,240
years twenty years in the future where

1098
00:44:55,240 --> 00:44:57,620
DRAM goes away and does everything is

1099
00:44:57,620 --> 00:45:00,290
just durable so the first choice to do

1100
00:45:00,290 --> 00:45:01,340
in place update so this is where you

1101
00:45:01,340 --> 00:45:02,570
have a table heat plus a redhead log

1102
00:45:02,570 --> 00:45:05,750
snapshots and this for our example we're

1103
00:45:05,750 --> 00:45:08,060
gonna base base our design on on a volte

1104
00:45:08,060 --> 00:45:10,970
beam the next approach to do

1105
00:45:10,970 --> 00:45:12,070
copy-on-write

1106
00:45:12,070 --> 00:45:14,750
updates and this is just like shadow

1107
00:45:14,750 --> 00:45:17,720
copying or shadow paging where every

1108
00:45:17,720 --> 00:45:19,190
single time I'm gonna update a page I

1109
00:45:19,190 --> 00:45:21,170
make a copy of it and a side side

1110
00:45:21,170 --> 00:45:23,330
location and then when my transaction

1111
00:45:23,330 --> 00:45:25,370
commits I just flip a pointer to say

1112
00:45:25,370 --> 00:45:27,920
here's here's the here's the here's the

1113
00:45:27,920 --> 00:45:31,010
latest version of the database so for

1114
00:45:31,010 --> 00:45:32,840
this one you're making extra copies of

1115
00:45:32,840 --> 00:45:34,310
the table but it doesn't require you to

1116
00:45:34,310 --> 00:45:37,070
have a right ahead log for for

1117
00:45:37,070 --> 00:45:39,830
durability and so our design here would

1118
00:45:39,830 --> 00:45:41,930
be representative of something like LM

1119
00:45:41,930 --> 00:45:45,020
DB which uses this approach the last one

1120
00:45:45,020 --> 00:45:47,810
is a log structured system where you

1121
00:45:47,810 --> 00:45:49,670
don't have a table heap the log is the

1122
00:45:49,670 --> 00:45:51,800
database and we just keep appending to

1123
00:45:51,800 --> 00:45:54,020
the log to do fast writes so this would

1124
00:45:54,020 --> 00:45:57,130
be something like level DB or rocks dB

1125
00:45:57,130 --> 00:45:58,880
so we're gonna go through the each of

1126
00:45:58,880 --> 00:46:00,770
these designs one by one and again the

1127
00:46:00,770 --> 00:46:02,600
idea is that take the textbook

1128
00:46:02,600 --> 00:46:04,280
implementation of these architectures

1129
00:46:04,280 --> 00:46:06,800
run it on persistent memory identify

1130
00:46:06,800 --> 00:46:09,160
where the bottlenecks are or where the

1131
00:46:09,160 --> 00:46:12,470
word that redundant updates are and then

1132
00:46:12,470 --> 00:46:15,050
redesign the architecture to to account

1133
00:46:15,050 --> 00:46:18,380
for persistent memory so again for the

1134
00:46:18,380 --> 00:46:19,970
first one if we have an in-place engine

1135
00:46:19,970 --> 00:46:22,880
the way we do writes is that we follow

1136
00:46:22,880 --> 00:46:24,950
an index that lands to this tuple here

1137
00:46:24,950 --> 00:46:28,020
and then we go ahead and update it

1138
00:46:28,020 --> 00:46:29,730
to make sure when a transaction commits

1139
00:46:29,730 --> 00:46:31,320
that everything's durable we're going to

1140
00:46:31,320 --> 00:46:33,869
write out a Delta record of the change

1141
00:46:33,869 --> 00:46:37,200
that was made to to write a head log and

1142
00:46:37,200 --> 00:46:40,980
then apply our change here and then some

1143
00:46:40,980 --> 00:46:43,560
some later point we when we take a

1144
00:46:43,560 --> 00:46:45,090
snapshot then we make sure that our

1145
00:46:45,090 --> 00:46:47,930
change our change gets persisted there

1146
00:46:47,930 --> 00:46:50,850
so for this one we're an update the

1147
00:46:50,850 --> 00:46:54,000
tuple sort of logically once it's like

1148
00:46:54,000 --> 00:46:55,980
one update query we're applying for this

1149
00:46:55,980 --> 00:46:57,990
one tuple but we end up writing it out

1150
00:46:57,990 --> 00:46:59,850
three times because we have to write out

1151
00:46:59,850 --> 00:47:01,650
the tuple Delta get there right up there

1152
00:47:01,650 --> 00:47:03,600
yeah so two point in the heap and then

1153
00:47:03,600 --> 00:47:04,440
we'll write it out to any additional

1154
00:47:04,440 --> 00:47:07,800
snapshots that we take so again oh this

1155
00:47:07,800 --> 00:47:10,710
is running in persistent memory so

1156
00:47:10,710 --> 00:47:12,830
everything here is considered durable

1157
00:47:12,830 --> 00:47:15,300
and so we have a bunch of duplicate data

1158
00:47:15,300 --> 00:47:17,730
here because again for the same update

1159
00:47:17,730 --> 00:47:20,280
we've read it three times this is also

1160
00:47:20,280 --> 00:47:22,860
gonna have slow latency now because I

1161
00:47:22,860 --> 00:47:26,130
have to do traditional Ares in my my my

1162
00:47:26,130 --> 00:47:28,440
database system where I load the last

1163
00:47:28,440 --> 00:47:30,630
successful snapshot or checkpoint and

1164
00:47:30,630 --> 00:47:34,320
then replay the log with with the you

1165
00:47:34,320 --> 00:47:38,310
know analyze redo and undo phases but

1166
00:47:38,310 --> 00:47:39,840
again everything is persistent

1167
00:47:39,840 --> 00:47:41,460
everything is already durable anyway so

1168
00:47:41,460 --> 00:47:43,650
it may not necessarily need to need to

1169
00:47:43,650 --> 00:47:47,010
do all of that so we can see how we

1170
00:47:47,010 --> 00:47:49,730
actually want to design a system to

1171
00:47:49,730 --> 00:47:52,369
account for the fact that we have

1172
00:47:52,369 --> 00:47:56,369
persistent memory and use the fact that

1173
00:47:56,369 --> 00:47:58,560
we have just pointers that we have

1174
00:47:58,560 --> 00:47:59,910
pointers that can be guaranteed to be

1175
00:47:59,910 --> 00:48:02,220
correct the second time you run our

1176
00:48:02,220 --> 00:48:05,880
system to now only record what was

1177
00:48:05,880 --> 00:48:08,840
changed rather than how it got changed

1178
00:48:08,840 --> 00:48:11,220
so to do this we're going to have to

1179
00:48:11,220 --> 00:48:13,710
maintain a transient undo log in case

1180
00:48:13,710 --> 00:48:15,240
our transaction aborts while while the

1181
00:48:15,240 --> 00:48:17,010
system is online and we have to roll

1182
00:48:17,010 --> 00:48:19,890
things back and we just make sure that

1183
00:48:19,890 --> 00:48:23,609
any changes we make from a we have the

1184
00:48:23,609 --> 00:48:25,560
confidence because there's any change

1185
00:48:25,560 --> 00:48:28,530
that we can't we can't guarantee that

1186
00:48:28,530 --> 00:48:31,800
the CPU will flush out any dirty changes

1187
00:48:31,800 --> 00:48:33,840
to tuples that are sitting in the CPU

1188
00:48:33,840 --> 00:48:37,710
cache out to to memory because that's

1189
00:48:37,710 --> 00:48:39,150
something beyond the control we can't

1190
00:48:39,150 --> 00:48:41,170
tell the CPU not to do that it was

1191
00:48:41,170 --> 00:48:43,150
does it on its own so we need to account

1192
00:48:43,150 --> 00:48:45,849
for that but we know that once our data

1193
00:48:45,849 --> 00:48:50,049
is durable in our tuple then we don't

1194
00:48:50,049 --> 00:48:51,339
need to maintain that we do long for

1195
00:48:51,339 --> 00:48:53,049
that so the two buildings durable out on

1196
00:48:53,049 --> 00:48:56,260
debt or out in the table heap in in a

1197
00:48:56,260 --> 00:48:57,940
persistent memory we don't need to redo

1198
00:48:57,940 --> 00:49:06,190
anything does looking like this so are

1199
00:49:06,190 --> 00:49:08,530
we follow the index everything's in

1200
00:49:08,530 --> 00:49:10,329
persistent memory we get to this tuple

1201
00:49:10,329 --> 00:49:12,760
here we apply the before we apply the

1202
00:49:12,760 --> 00:49:16,329
update we can now put a an entry in our

1203
00:49:16,329 --> 00:49:19,480
log that says here's the pointers to the

1204
00:49:19,480 --> 00:49:21,549
tuples that got modified but that's all

1205
00:49:21,549 --> 00:49:23,940
you need you need to know about it and

1206
00:49:23,940 --> 00:49:26,349
then I can actually now apply my change

1207
00:49:26,349 --> 00:49:31,109
and then if I now you know flush this

1208
00:49:31,109 --> 00:49:35,020
then I know that the change for this

1209
00:49:35,020 --> 00:49:37,869
transaction is durable right this is

1210
00:49:37,869 --> 00:49:39,130
just sort of helping me to say oh by the

1211
00:49:39,130 --> 00:49:40,869
way here's what actually got changed in

1212
00:49:40,869 --> 00:49:42,640
case I need to follow pointers and undo

1213
00:49:42,640 --> 00:49:45,280
things but once this change is flushed

1214
00:49:45,280 --> 00:49:47,349
along with any other changes for it have

1215
00:49:47,349 --> 00:49:49,390
flushed my transaction is considered

1216
00:49:49,390 --> 00:49:53,440
durable alright so let's see how we do a

1217
00:49:53,440 --> 00:49:57,640
copy and write engine for this again so

1218
00:49:57,640 --> 00:49:59,799
this is a hierarchal version of shadow

1219
00:49:59,799 --> 00:50:02,170
paging I'm just using a plus stream and

1220
00:50:02,170 --> 00:50:04,270
the way to think about is that we still

1221
00:50:04,270 --> 00:50:07,089
have the master record that points to

1222
00:50:07,089 --> 00:50:09,520
the master copy of the shadow copy we do

1223
00:50:09,520 --> 00:50:11,589
compare-and-swap to flip that but our

1224
00:50:11,589 --> 00:50:14,230
our pages are just laid out in a

1225
00:50:14,230 --> 00:50:17,650
hierarchy in a tree so let's say I want

1226
00:50:17,650 --> 00:50:20,020
to update this tuple here so I would

1227
00:50:20,020 --> 00:50:24,339
first make a copy of the of that page

1228
00:50:24,339 --> 00:50:27,309
and then the the the entry and the tree

1229
00:50:27,309 --> 00:50:30,819
on the side here then update my

1230
00:50:30,819 --> 00:50:33,880
directory to now point two for the

1231
00:50:33,880 --> 00:50:34,960
second page your still point to the

1232
00:50:34,960 --> 00:50:36,430
original one for the new page over here

1233
00:50:36,430 --> 00:50:38,559
I point to the new one so that's another

1234
00:50:38,559 --> 00:50:40,950
write to do my to my entry to my

1235
00:50:40,950 --> 00:50:44,020
structure then I do a third right now to

1236
00:50:44,020 --> 00:50:48,339
flip the master record to the to the

1237
00:50:48,339 --> 00:50:50,980
dirty record so the first issue with

1238
00:50:50,980 --> 00:50:53,530
this is that these copies are expensive

1239
00:50:53,530 --> 00:50:54,170
because

1240
00:50:54,170 --> 00:50:56,720
again we're taking this entire page even

1241
00:50:56,720 --> 00:50:59,780
though we only update you know one tuple

1242
00:50:59,780 --> 00:51:01,760
inside of it we have to make an entire

1243
00:51:01,760 --> 00:51:03,470
copy we have to update the leaf

1244
00:51:03,470 --> 00:51:05,000
information update the dirt directory

1245
00:51:05,000 --> 00:51:08,420
just to retain this and say what we can

1246
00:51:08,420 --> 00:51:11,240
do because persistent memory is can be

1247
00:51:11,240 --> 00:51:13,190
treated like DRAM instead of having a

1248
00:51:13,190 --> 00:51:15,170
page oriented architecture you can be a

1249
00:51:15,170 --> 00:51:16,849
byte addressable architecture like we

1250
00:51:16,849 --> 00:51:19,520
have now where we just have pointers to

1251
00:51:19,520 --> 00:51:23,180
tuples and then now when I do an update

1252
00:51:23,180 --> 00:51:28,819
I only have to copy pointers over here

1253
00:51:28,819 --> 00:51:32,210
as well as applying the change and then

1254
00:51:32,210 --> 00:51:34,730
I update the dirty directory and and and

1255
00:51:34,730 --> 00:51:36,680
the the master record so the key

1256
00:51:36,680 --> 00:51:37,750
difference here is that the the

1257
00:51:37,750 --> 00:51:39,829
granularity of the change we're making

1258
00:51:39,829 --> 00:51:43,760
because we can read and write two byte

1259
00:51:43,760 --> 00:51:45,829
addressable locations in memory is is

1260
00:51:45,829 --> 00:51:50,329
much smaller all right the last one is a

1261
00:51:50,329 --> 00:51:52,670
log structure Artic architecture and the

1262
00:51:52,670 --> 00:51:55,010
idea here is that sort of classic

1263
00:51:55,010 --> 00:51:56,510
architecture would have is you have an

1264
00:51:56,510 --> 00:51:58,160
in-memory mem table with right ahead log

1265
00:51:58,160 --> 00:52:00,950
and a skip list or some kind of small

1266
00:52:00,950 --> 00:52:02,630
data structure to keep track of what a

1267
00:52:02,630 --> 00:52:05,660
log entries are in memory and then you

1268
00:52:05,660 --> 00:52:07,549
have on on disk you have a bunch of SS

1269
00:52:07,549 --> 00:52:09,380
tables that always have a bloom footer

1270
00:52:09,380 --> 00:52:11,240
in front of it and then index that

1271
00:52:11,240 --> 00:52:15,890
points to locations in the log so when I

1272
00:52:15,890 --> 00:52:17,869
want to update I first apply it into my

1273
00:52:17,869 --> 00:52:19,940
Delta of the change I made to the right

1274
00:52:19,940 --> 00:52:21,680
head log and then at some later point

1275
00:52:21,680 --> 00:52:24,650
I'll I'll flush that out the disk and as

1276
00:52:24,650 --> 00:52:26,180
I'm doing compaction now I'm gonna keep

1277
00:52:26,180 --> 00:52:28,160
I have right amplification where I'm

1278
00:52:28,160 --> 00:52:30,920
keep applying changes or combining log

1279
00:52:30,920 --> 00:52:32,420
records over and over again if they have

1280
00:52:32,420 --> 00:52:35,990
to be retained so the issue with this is

1281
00:52:35,990 --> 00:52:37,940
that we have to pluck data and because

1282
00:52:37,940 --> 00:52:39,200
if we're using a level architecture

1283
00:52:39,200 --> 00:52:41,240
we're going to have expensive

1284
00:52:41,240 --> 00:52:43,190
compactions so if you want to switch to

1285
00:52:43,190 --> 00:52:45,920
this to persistent memory then we can

1286
00:52:45,920 --> 00:52:50,559
get rid of the the ESS table entirely

1287
00:52:50,559 --> 00:52:53,630
because now all of this is persistent

1288
00:52:53,630 --> 00:52:56,059
and therefore we can just have the right

1289
00:52:56,059 --> 00:52:59,240
ahead log and our data for that and we

1290
00:52:59,240 --> 00:53:01,700
don't need to do any any of this we

1291
00:53:01,700 --> 00:53:03,770
still have to do compactions though that

1292
00:53:03,770 --> 00:53:06,690
I think that doesn't go away but

1293
00:53:06,690 --> 00:53:09,119
we don't have to have this you know this

1294
00:53:09,119 --> 00:53:10,890
concept of a mem table and SS table

1295
00:53:10,890 --> 00:53:12,000
which are different different sort of

1296
00:53:12,000 --> 00:53:14,849
layouts of the data in all the examples

1297
00:53:14,849 --> 00:53:18,030
we just looked at as I said those were

1298
00:53:18,030 --> 00:53:20,579
assuming that the computer we were

1299
00:53:20,579 --> 00:53:22,589
running one only had persistent memory

1300
00:53:22,589 --> 00:53:25,109
and there was no DRAM but I guess that's

1301
00:53:25,109 --> 00:53:26,760
not really gonna be realistic for a

1302
00:53:26,760 --> 00:53:29,069
while so let's think about how we acted

1303
00:53:29,069 --> 00:53:31,890
we design a system today using what is

1304
00:53:31,890 --> 00:53:34,140
available from Intel now

1305
00:53:34,140 --> 00:53:38,099
so let's target a way to speed up

1306
00:53:38,099 --> 00:53:40,650
performance and take advantage of

1307
00:53:40,650 --> 00:53:45,810
persistent memory by focusing on the on

1308
00:53:45,810 --> 00:53:47,790
how to sort of take a standard table

1309
00:53:47,790 --> 00:53:49,440
heat plus write a hello implementation

1310
00:53:49,440 --> 00:53:53,040
and speed that up so what is the right

1311
00:53:53,040 --> 00:53:55,800
ahead log doing for us well in a gather

1312
00:53:55,800 --> 00:53:58,020
for a in memory system or dis coordinate

1313
00:53:58,020 --> 00:54:00,270
system the idea is that we're trying to

1314
00:54:00,270 --> 00:54:03,450
avoid random writes disk by replacing

1315
00:54:03,450 --> 00:54:06,000
them with sequential log writes for an

1316
00:54:06,000 --> 00:54:08,400
enemy database we only do special log

1317
00:54:08,400 --> 00:54:09,960
writes because we're writing to the

1318
00:54:09,960 --> 00:54:11,579
table heap in memory for a disk

1319
00:54:11,579 --> 00:54:14,010
coordinate system we do our write

1320
00:54:14,010 --> 00:54:15,750
sequentially to the log and then

1321
00:54:15,750 --> 00:54:16,950
invention in the background will flush

1322
00:54:16,950 --> 00:54:21,119
out dirty pages so that's one advantage

1323
00:54:21,119 --> 00:54:22,650
we'll get the other ones that will also

1324
00:54:22,650 --> 00:54:26,910
get transaction capabilities because now

1325
00:54:26,910 --> 00:54:29,819
if there are changes that are hanging

1326
00:54:29,819 --> 00:54:32,609
out in one disk from a transaction that

1327
00:54:32,609 --> 00:54:35,190
hasn't that did not commit before there

1328
00:54:35,190 --> 00:54:36,450
was a crash before the system shut down

1329
00:54:36,450 --> 00:54:39,390
we can use the log as a way to roll them

1330
00:54:39,390 --> 00:54:42,150
back and reverse any other changes so

1331
00:54:42,150 --> 00:54:44,730
again this design number right ahead log

1332
00:54:44,730 --> 00:54:47,010
of some writing to the tuple first then

1333
00:54:47,010 --> 00:54:50,940
writing to to the started writing to the

1334
00:54:50,940 --> 00:54:54,569
log first before we write to the tuple

1335
00:54:54,569 --> 00:54:57,300
makes sense because again the the log

1336
00:54:57,300 --> 00:55:00,930
right it's gonna be scheduling in a

1337
00:55:00,930 --> 00:55:03,690
persistent memory world though we're

1338
00:55:03,690 --> 00:55:06,030
gonna have fast random writes alright

1339
00:55:06,030 --> 00:55:08,010
we've invited dress will implies that we

1340
00:55:08,010 --> 00:55:09,480
can jump to any location in the

1341
00:55:09,480 --> 00:55:12,390
procession of memory space and that will

1342
00:55:12,390 --> 00:55:15,480
have the access speed that's almost

1343
00:55:15,480 --> 00:55:17,730
equivalent to doing scones access so

1344
00:55:17,730 --> 00:55:19,680
they're huge dichotomy or the

1345
00:55:19,680 --> 00:55:21,480
the difference in performance we had in

1346
00:55:21,480 --> 00:55:22,830
a sequential light versus a random light

1347
00:55:22,830 --> 00:55:25,170
in a spring this hard drive or even SSD

1348
00:55:25,170 --> 00:55:27,900
this will be much less in a in a

1349
00:55:27,900 --> 00:55:31,050
persistent memory system so you wanted

1350
00:55:31,050 --> 00:55:32,430
to find now a logging protocol

1351
00:55:32,430 --> 00:55:34,230
potentially that can take advantage of

1352
00:55:34,230 --> 00:55:35,850
this and the way we're going to do this

1353
00:55:35,850 --> 00:55:40,020
is that the weight the way we're gonna

1354
00:55:40,020 --> 00:55:41,670
do this is maintain a multi version

1355
00:55:41,670 --> 00:55:46,320
database and do copy on writes or make

1356
00:55:46,320 --> 00:55:47,450
sure we don't overwrite existing

1357
00:55:47,450 --> 00:55:51,480
versions and then we'll have in our log

1358
00:55:51,480 --> 00:55:54,240
just the metadata about what was

1359
00:55:54,240 --> 00:55:56,910
committed rather than the actual copies

1360
00:55:56,910 --> 00:55:59,820
of the changes that were made so this is

1361
00:55:59,820 --> 00:56:02,010
the technique that my PhD student

1362
00:56:02,010 --> 00:56:03,660
developed here at Carnegie Mellon called

1363
00:56:03,660 --> 00:56:06,000
right behind logging and the idea here

1364
00:56:06,000 --> 00:56:08,040
is that it's a logging protocol that's

1365
00:56:08,040 --> 00:56:09,780
designed specifically for persistent

1366
00:56:09,780 --> 00:56:11,640
memory but in a world that still has

1367
00:56:11,640 --> 00:56:15,660
DRAM for the table and the idea is that

1368
00:56:15,660 --> 00:56:18,390
we can get instant recovery of the

1369
00:56:18,390 --> 00:56:21,210
database after a crash with minimal

1370
00:56:21,210 --> 00:56:23,250
amount of redundant information being

1371
00:56:23,250 --> 00:56:25,830
stored in the log and so the way we're

1372
00:56:25,830 --> 00:56:29,240
gonna do this is that we only have the

1373
00:56:29,240 --> 00:56:32,190
that we have a copy of the the database

1374
00:56:32,190 --> 00:56:33,960
in persistent memory we make sure that

1375
00:56:33,960 --> 00:56:36,000
we flush changes to that database and

1376
00:56:36,000 --> 00:56:37,950
now our log is only going to change

1377
00:56:37,950 --> 00:56:41,100
contain pointers to the records that got

1378
00:56:41,100 --> 00:56:43,860
changed and then now after a crash or

1379
00:56:43,860 --> 00:56:45,480
anything we need to do is just look in

1380
00:56:45,480 --> 00:56:47,610
the log to figure out what transactions

1381
00:56:47,610 --> 00:56:49,920
are running at the time of the crash of

1382
00:56:49,920 --> 00:56:52,650
the order or the the shutdown and we

1383
00:56:52,650 --> 00:56:53,970
would have pointers to the tuples that

1384
00:56:53,970 --> 00:56:57,230
they modified and we keep track of the

1385
00:56:57,230 --> 00:56:59,610
fact that the the updates that these

1386
00:56:59,610 --> 00:57:01,650
transactions made did not commit and

1387
00:57:01,650 --> 00:57:03,600
therefore we know the pointers to those

1388
00:57:03,600 --> 00:57:05,670
tuples and therefore we want to want to

1389
00:57:05,670 --> 00:57:07,740
reverse them if anybody tries to access

1390
00:57:07,740 --> 00:57:10,920
them so another way to think what this

1391
00:57:10,920 --> 00:57:14,370
is like we unlike an already have log we

1392
00:57:14,370 --> 00:57:16,710
don't need any redo information because

1393
00:57:16,710 --> 00:57:19,500
the changes that our transactions made

1394
00:57:19,500 --> 00:57:21,480
are made durable to persistent memory

1395
00:57:21,480 --> 00:57:24,000
right away and we never have to worry

1396
00:57:24,000 --> 00:57:26,000
about reapplying them from from the log

1397
00:57:26,000 --> 00:57:31,560
so the now in the context of persistent

1398
00:57:31,560 --> 00:57:33,270
memory this protocol is new

1399
00:57:33,270 --> 00:57:35,610
there was one other system that we're

1400
00:57:35,610 --> 00:57:38,040
aware of that did something sort of

1401
00:57:38,040 --> 00:57:40,650
similar to this and this was brought to

1402
00:57:40,650 --> 00:57:42,240
my attention by the great Phil Bernstein

1403
00:57:42,240 --> 00:57:45,060
sort of the Godfather of sort of modern

1404
00:57:45,060 --> 00:57:49,010
concurrent retool and he told us of a

1405
00:57:49,010 --> 00:57:52,770
database for a I think it was a it was a

1406
00:57:52,770 --> 00:57:55,290
Puerto Rican telephone company back in

1407
00:57:55,290 --> 00:57:58,200
the 1970s so at the time Puerto Rico had

1408
00:57:58,200 --> 00:58:00,690
bad power infrastructure and they would

1409
00:58:00,690 --> 00:58:02,490
lose power several times during the day

1410
00:58:02,490 --> 00:58:03,780
so they had to have a database that

1411
00:58:03,780 --> 00:58:05,750
could run that could come back

1412
00:58:05,750 --> 00:58:08,250
instantaneously at any time there was a

1413
00:58:08,250 --> 00:58:10,770
power loss because if you're shutting

1414
00:58:10,770 --> 00:58:12,510
him to me the book shutdowns multiple

1415
00:58:12,510 --> 00:58:14,640
times during the day and if you're if

1416
00:58:14,640 --> 00:58:16,730
you're a recovery time is super long

1417
00:58:16,730 --> 00:58:21,330
then you know by the time it took you to

1418
00:58:21,330 --> 00:58:23,070
go over cover the database the power

1419
00:58:23,070 --> 00:58:25,020
might get shut off again and you're just

1420
00:58:25,020 --> 00:58:26,580
never able to keep up so they had a

1421
00:58:26,580 --> 00:58:29,160
database that sort of did something like

1422
00:58:29,160 --> 00:58:30,900
this obviously it wasn't with persistent

1423
00:58:30,900 --> 00:58:33,420
monitor system memory but it was making

1424
00:58:33,420 --> 00:58:35,730
copies of the database they're paying

1425
00:58:35,730 --> 00:58:37,500
the penalty of doing random random

1426
00:58:37,500 --> 00:58:41,040
writes to disk in exchange for is faster

1427
00:58:41,040 --> 00:58:43,590
recovery times the most modern systems

1428
00:58:43,590 --> 00:58:45,960
don't don't make that choice and in our

1429
00:58:45,960 --> 00:58:47,220
case here with right behind logging

1430
00:58:47,220 --> 00:58:48,870
we'll be able to get good good

1431
00:58:48,870 --> 00:58:50,040
performance at run time and good

1432
00:58:50,040 --> 00:58:53,520
recovery time so again because test

1433
00:58:53,520 --> 00:58:55,170
reactor setup is like this we have a

1434
00:58:55,170 --> 00:58:56,580
table heap so you want to run this query

1435
00:58:56,580 --> 00:58:58,680
there's an update a tuple so the table

1436
00:58:58,680 --> 00:59:01,980
heap will hang out in memory and DRAM

1437
00:59:01,980 --> 00:59:04,290
and then there'll be a second copy on

1438
00:59:04,290 --> 00:59:06,510
persistent memory and then we'll have

1439
00:59:06,510 --> 00:59:08,700
our logon persisting memory as well so

1440
00:59:08,700 --> 00:59:11,160
now when we do an update table we first

1441
00:59:11,160 --> 00:59:13,740
update the tuple in table heap then

1442
00:59:13,740 --> 00:59:16,830
write the change to start in memory then

1443
00:59:16,830 --> 00:59:19,620
we write the change to to nvm but then

1444
00:59:19,620 --> 00:59:21,330
we also Nautilus write some metadata to

1445
00:59:21,330 --> 00:59:24,060
the log to say oh by the way here's the

1446
00:59:24,060 --> 00:59:25,530
pointer to the tuple in persistent

1447
00:59:25,530 --> 00:59:27,510
memory that change so that we know if we

1448
00:59:27,510 --> 00:59:29,670
crash before transaction commits we can

1449
00:59:29,670 --> 00:59:31,530
use this to figure out where do we need

1450
00:59:31,530 --> 00:59:33,300
to go and make sure that those changes

1451
00:59:33,300 --> 00:59:34,650
aren't persisted and when the system

1452
00:59:34,650 --> 00:59:37,380
restarts so how this is all going to

1453
00:59:37,380 --> 00:59:39,780
work is that we're going to rely on

1454
00:59:39,780 --> 00:59:42,030
multi versioning and we're gonna assign

1455
00:59:42,030 --> 00:59:43,920
transactions timestamps there's as we

1456
00:59:43,920 --> 00:59:46,680
normally would and when we go to flush

1457
00:59:46,680 --> 00:59:46,950
out

1458
00:59:46,950 --> 00:59:49,560
changes for transactions the we're gonna

1459
00:59:49,560 --> 00:59:51,660
figure out what is the range of

1460
00:59:51,660 --> 00:59:54,060
transactions in flight transactions that

1461
00:59:54,060 --> 00:59:56,490
are running right now and is record that

1462
00:59:56,490 --> 00:59:59,430
in our editor log wears a red behind log

1463
00:59:59,430 --> 01:00:01,140
along with pointers to the two posts

1464
01:00:01,140 --> 01:00:03,030
that they're modifying and that tells us

1465
01:00:03,030 --> 01:00:04,500
what what are the potential range of

1466
01:00:04,500 --> 01:00:07,380
tuples rent range of transactions that

1467
01:00:07,380 --> 01:00:10,260
should not be persisted after a crash so

1468
01:00:10,260 --> 01:00:11,730
now when after a crash would come back

1469
01:00:11,730 --> 01:00:15,320
again we use this fail group commit rain

1470
01:00:15,320 --> 01:00:18,390
to identify what tuples are not valid so

1471
01:00:18,390 --> 01:00:20,220
we don't have to look at individual

1472
01:00:20,220 --> 01:00:22,320
timestamps we just look at does the is

1473
01:00:22,320 --> 01:00:23,940
the tuple I'm looking at have a

1474
01:00:23,940 --> 01:00:25,859
timestamp that falls in this range and

1475
01:00:25,859 --> 01:00:27,630
therefore I know comes from a failed

1476
01:00:27,630 --> 01:00:30,180
transaction and I can ignore it and so

1477
01:00:30,180 --> 01:00:31,589
what you're essentially getting is like

1478
01:00:31,589 --> 01:00:34,950
the you're getting the undo operation

1479
01:00:34,950 --> 01:00:37,380
sort of free as you're normally doing

1480
01:00:37,380 --> 01:00:39,089
the visibility checks for a multi

1481
01:00:39,089 --> 01:00:42,420
version concurrent role so it made more

1482
01:00:42,420 --> 01:00:45,329
sense more sense in Excel slides so when

1483
01:00:45,329 --> 01:00:47,400
I recover I only have an analyze phase

1484
01:00:47,400 --> 01:00:49,020
the analyze phase looks through the

1485
01:00:49,020 --> 01:00:51,480
right behind log and says here's all the

1486
01:00:51,480 --> 01:00:52,410
here's are the timestamps of the

1487
01:00:52,410 --> 01:00:54,569
transactions that that could that didn't

1488
01:00:54,569 --> 01:00:57,240
commit successfully then I Amelie start

1489
01:00:57,240 --> 01:00:58,770
processing transactions but now I've

1490
01:00:58,770 --> 01:01:00,420
computed this global range that says

1491
01:01:00,420 --> 01:01:03,150
here's the here's the range of

1492
01:01:03,150 --> 01:01:04,440
transactions that if you come across a

1493
01:01:04,440 --> 01:01:06,900
tuple that was modified or created by

1494
01:01:06,900 --> 01:01:08,220
BAM our version that was created by them

1495
01:01:08,220 --> 01:01:09,990
you know we should we should ignore it

1496
01:01:09,990 --> 01:01:11,760
and then reclaim the space so you're

1497
01:01:11,760 --> 01:01:13,500
sort of doing like cooperative garbage

1498
01:01:13,500 --> 01:01:15,930
collection as you're going along and

1499
01:01:15,930 --> 01:01:17,760
identifying tuples that that shouldn't

1500
01:01:17,760 --> 01:01:20,369
exist so let's look at an example so say

1501
01:01:20,369 --> 01:01:22,410
here that this is our timeline of going

1502
01:01:22,410 --> 01:01:24,540
forward in time ever to keep track of as

1503
01:01:24,540 --> 01:01:26,670
transactions get started and and let me

1504
01:01:26,670 --> 01:01:30,359
commit so t1 starts here so for the

1505
01:01:30,359 --> 01:01:32,190
current range of active transactions we

1506
01:01:32,190 --> 01:01:34,710
know it's between t1 and t2 all right

1507
01:01:34,710 --> 01:01:35,849
and there's no failed transactions

1508
01:01:35,849 --> 01:01:37,349
because hey this is the first time we

1509
01:01:37,349 --> 01:01:39,480
turn it on the system so let's say now

1510
01:01:39,480 --> 01:01:43,740
here before t1 commits we crash then

1511
01:01:43,740 --> 01:01:46,319
well when we come back T say the next

1512
01:01:46,319 --> 01:01:48,720
transaction that starts t2 so the only

1513
01:01:48,720 --> 01:01:50,160
thing that we needed to do after the

1514
01:01:50,160 --> 01:01:52,319
crash is when we scan the log we would

1515
01:01:52,319 --> 01:01:54,119
find an entry here to say wheat the last

1516
01:01:54,119 --> 01:01:55,380
range that we knew about from the last

1517
01:01:55,380 --> 01:01:59,040
group commit was between t1 and t2 so

1518
01:01:59,040 --> 01:02:00,190
now

1519
01:02:00,190 --> 01:02:02,470
range factors actions this to t2 to t3

1520
01:02:02,470 --> 01:02:06,520
so now as T 2 runs and access to the

1521
01:02:06,520 --> 01:02:08,800
database if it comes across anything

1522
01:02:08,800 --> 01:02:11,770
that was created by t1 it knows that it

1523
01:02:11,770 --> 01:02:12,900
should be garbage collect and cleaned up

1524
01:02:12,900 --> 01:02:16,839
so it it go has to start cleaning them

1525
01:02:16,839 --> 01:02:20,349
removing those things say t2 commits but

1526
01:02:20,349 --> 01:02:22,390
then t3 starts same thing our active

1527
01:02:22,390 --> 01:02:25,630
transaction is t3 t4 and since we know

1528
01:02:25,630 --> 01:02:28,300
the pointers of the tuples that t1

1529
01:02:28,300 --> 01:02:30,609
modified we would know whether we've

1530
01:02:30,609 --> 01:02:33,849
clean up everything that t1 has touched

1531
01:02:33,849 --> 01:02:35,710
yet and let's say in this case here we

1532
01:02:35,710 --> 01:02:36,730
don't have a transaction that touch is

1533
01:02:36,730 --> 01:02:39,190
what do you want to t2 t it does so we

1534
01:02:39,190 --> 01:02:40,930
could run the background vacuum in a

1535
01:02:40,930 --> 01:02:42,760
separate thread just to scan through and

1536
01:02:42,760 --> 01:02:44,260
find all those things to reverse them so

1537
01:02:44,260 --> 01:02:45,880
that way we're not stuck with with

1538
01:02:45,880 --> 01:02:47,349
versions that nobody wrecks essing in

1539
01:02:47,349 --> 01:02:49,900
its wasting space right and then t4

1540
01:02:49,900 --> 01:02:52,480
starts and at this point here we know

1541
01:02:52,480 --> 01:02:56,380
that we've gotten everything that t1 t1

1542
01:02:56,380 --> 01:02:58,119
modified so we can then remove it from

1543
01:02:58,119 --> 01:03:01,569
our list of failed ranges so I'm going

1544
01:03:01,569 --> 01:03:03,160
to show you now the performance of what

1545
01:03:03,160 --> 01:03:05,170
red behind logging can do but I'm gonna

1546
01:03:05,170 --> 01:03:06,430
do it the opposite of what we normally

1547
01:03:06,430 --> 01:03:08,050
just got how we nearly discuss things

1548
01:03:08,050 --> 01:03:09,880
with transactions I'm gonna show you the

1549
01:03:09,880 --> 01:03:12,430
recovery time first I have no many you

1550
01:03:12,430 --> 01:03:14,369
show performance first before recovery

1551
01:03:14,369 --> 01:03:17,980
so this one it's running replaying right

1552
01:03:17,980 --> 01:03:19,930
behind log right behind log and right

1553
01:03:19,930 --> 01:03:22,510
ahead log of 1 million TPCC transactions

1554
01:03:22,510 --> 01:03:25,119
and this is running on that Intel

1555
01:03:25,119 --> 01:03:26,859
emulator that I mentioned where you

1556
01:03:26,859 --> 01:03:30,460
could to the the latency of persistent

1557
01:03:30,460 --> 01:03:33,310
memory relative to 2d Ram so in this

1558
01:03:33,310 --> 01:03:35,109
care we keep this case here we're making

1559
01:03:35,109 --> 01:03:39,069
the the speed 2x the latency so and also

1560
01:03:39,069 --> 01:03:41,079
to the the the latency here was

1561
01:03:41,079 --> 01:03:43,150
symmetrical so the read and write costs

1562
01:03:43,150 --> 01:03:45,160
were the same and the sequential and

1563
01:03:45,160 --> 01:03:48,160
random writes were this sequential the

1564
01:03:48,160 --> 01:03:50,230
sequential and random access these were

1565
01:03:50,230 --> 01:03:52,030
the same cost and then they reads in the

1566
01:03:52,030 --> 01:03:53,410
right cost were the same as well

1567
01:03:53,410 --> 01:03:55,540
but a real Hardware the reads gonna be

1568
01:03:55,540 --> 01:03:58,240
faster than than the writes so we're

1569
01:03:58,240 --> 01:04:01,990
gonna pair the time it takes to restart

1570
01:04:01,990 --> 01:04:03,670
the system and recover the log put the

1571
01:04:03,670 --> 01:04:05,530
debisch back to a correct state for a

1572
01:04:05,530 --> 01:04:07,780
spankers hard drive a solid-state flash

1573
01:04:07,780 --> 01:04:09,960
drive and the persistent memory emulator

1574
01:04:09,960 --> 01:04:13,060
so what you see is that with right ahead

1575
01:04:13,060 --> 01:04:14,109
log

1576
01:04:14,109 --> 01:04:15,910
the performance of the different

1577
01:04:15,910 --> 01:04:18,460
approaches are roughly the same right

1578
01:04:18,460 --> 01:04:19,960
because this can be the cost of or these

1579
01:04:19,960 --> 01:04:21,700
also unlock scale but it's a couple you

1580
01:04:21,700 --> 01:04:23,619
know it's the cost of accessing disk and

1581
01:04:23,619 --> 01:04:26,019
then replaying the log the combination

1582
01:04:26,019 --> 01:04:28,239
the two of them are about the same the

1583
01:04:28,239 --> 01:04:29,739
difference though now with ripe ahead

1584
01:04:29,739 --> 01:04:33,549
longing the recovery time is a thousand

1585
01:04:33,549 --> 01:04:36,549
X faster because all you do when you

1586
01:04:36,549 --> 01:04:38,950
turn the system on is you just check to

1587
01:04:38,950 --> 01:04:40,930
see that right the the the failed time

1588
01:04:40,930 --> 01:04:42,910
stamps from the right behind log and

1589
01:04:42,910 --> 01:04:45,339
that's all you need to do to say I'm now

1590
01:04:45,339 --> 01:04:47,529
my databases has been fully recovered at

1591
01:04:47,529 --> 01:04:50,049
least at a logical level so what this

1592
01:04:50,049 --> 01:04:52,029
just shown you is that the performance

1593
01:04:52,029 --> 01:04:54,180
benefit are right behind logging for

1594
01:04:54,180 --> 01:04:56,619
persistent memory as well as the older

1595
01:04:56,619 --> 01:04:58,239
storage devices is about the same it's

1596
01:04:58,239 --> 01:05:00,400
about a thousand necks so now you look

1597
01:05:00,400 --> 01:05:02,559
at this and say well sure right behind

1598
01:05:02,559 --> 01:05:03,670
logging is faster than write ahead

1599
01:05:03,670 --> 01:05:05,739
logging but why do I have to do this in

1600
01:05:05,739 --> 01:05:07,720
persistent memory because I'm getting

1601
01:05:07,720 --> 01:05:09,999
amazing performance sorry amazing

1602
01:05:09,999 --> 01:05:11,980
recovery time for these other storage

1603
01:05:11,980 --> 01:05:15,099
devices as well well now if we go look

1604
01:05:15,099 --> 01:05:17,170
at the runtime performance now you see a

1605
01:05:17,170 --> 01:05:19,029
big difference so for the runtime

1606
01:05:19,029 --> 01:05:21,549
performance of the right ahead log you

1607
01:05:21,549 --> 01:05:24,099
see that of course as you add as you

1608
01:05:24,099 --> 01:05:26,680
have a faster storage device you're

1609
01:05:26,680 --> 01:05:27,730
gonna get a better performance so

1610
01:05:27,730 --> 01:05:29,200
persistent memory is faster than the

1611
01:05:29,200 --> 01:05:30,700
solid-state drive with a spinning hard

1612
01:05:30,700 --> 01:05:32,589
drive right and that's the bottleneck of

1613
01:05:32,589 --> 01:05:33,970
when you commit transactions obviously

1614
01:05:33,970 --> 01:05:35,289
in this case here for TPCC

1615
01:05:35,289 --> 01:05:39,009
so that's why persistent there the

1616
01:05:39,009 --> 01:05:40,029
persistent memory gets the best

1617
01:05:40,029 --> 01:05:42,220
performance for right ahead logging but

1618
01:05:42,220 --> 01:05:44,289
now if you do right behind logging now

1619
01:05:44,289 --> 01:05:46,390
you see why you need persistent memory

1620
01:05:46,390 --> 01:05:47,950
because in the case of the spinning disk

1621
01:05:47,950 --> 01:05:49,839
hard drive in the solid-state drive you

1622
01:05:49,839 --> 01:05:52,299
get a temperate 10x reduction in the

1623
01:05:52,299 --> 01:05:53,769
runtime performance when you use right

1624
01:05:53,769 --> 01:05:55,869
behind log but only if you use

1625
01:05:55,869 --> 01:05:56,950
persistent memory

1626
01:05:56,950 --> 01:05:59,410
you're gonna get a one point 2x speed-up

1627
01:05:59,410 --> 01:06:01,539
in performance and this is because in

1628
01:06:01,539 --> 01:06:04,450
with the persistent right behind logging

1629
01:06:04,450 --> 01:06:06,369
with persistent memory because you have

1630
01:06:06,369 --> 01:06:09,880
flat fast random writes to the table

1631
01:06:09,880 --> 01:06:12,609
heap on persistent memory you know

1632
01:06:12,609 --> 01:06:14,650
that's random i/o which is gonna be

1633
01:06:14,650 --> 01:06:17,589
terrible on these these tablets slower

1634
01:06:17,589 --> 01:06:19,900
devices so this is the combination of

1635
01:06:19,900 --> 01:06:23,049
right behind logging and persistent

1636
01:06:23,049 --> 01:06:24,420
memory is the is the right

1637
01:06:24,420 --> 01:06:25,740
combination is to get the best

1638
01:06:25,740 --> 01:06:29,940
performance in this scenario here okay

1639
01:06:29,940 --> 01:06:31,020
so just to summarize what we talked

1640
01:06:31,020 --> 01:06:34,200
about um we talked about how to if you

1641
01:06:34,200 --> 01:06:36,240
if you know you have persistent memory

1642
01:06:36,240 --> 01:06:38,070
that's byte addressable you can

1643
01:06:38,070 --> 01:06:41,160
reorganize your storage architecture to

1644
01:06:41,160 --> 01:06:42,900
take advantage of that and reduce the

1645
01:06:42,900 --> 01:06:44,880
amount of data duplication and redundant

1646
01:06:44,880 --> 01:06:48,210
copies of data during update

1647
01:06:48,210 --> 01:06:50,460
transactions and then we saw in the case

1648
01:06:50,460 --> 01:06:55,950
of right behind ball game is the

1649
01:06:55,950 --> 01:06:57,180
technique allowed you get better

1650
01:06:57,180 --> 01:07:00,390
recovery time because you're taking

1651
01:07:00,390 --> 01:07:01,800
advantage of the fact that you know that

1652
01:07:01,800 --> 01:07:03,720
you have a protocol that's writing to

1653
01:07:03,720 --> 01:07:05,250
persistent memory and therefore you can

1654
01:07:05,250 --> 01:07:06,960
set yourself up the system up so that

1655
01:07:06,960 --> 01:07:09,240
upon recovery you have to do minimal

1656
01:07:09,240 --> 01:07:10,470
amount of work to put the database back

1657
01:07:10,470 --> 01:07:13,200
into the correct state so as I said I

1658
01:07:13,200 --> 01:07:19,680
think for precision memory this hardware

1659
01:07:19,680 --> 01:07:24,060
is available now and I you know once

1660
01:07:24,060 --> 01:07:25,320
becomes more prevalent and more

1661
01:07:25,320 --> 01:07:28,170
commoditized you gonna see a lot of

1662
01:07:28,170 --> 01:07:30,150
database systems coming out to take you

1663
01:07:30,150 --> 01:07:31,920
to take advantages in the very beginning

1664
01:07:31,920 --> 01:07:34,320
they're all just gonna use it as larger

1665
01:07:34,320 --> 01:07:35,490
cheaper memory that's a little bit

1666
01:07:35,490 --> 01:07:39,180
slower and some symptoms of what systems

1667
01:07:39,180 --> 01:07:41,160
will be more sensitive than that but if

1668
01:07:41,160 --> 01:07:43,860
the you know but the prognostications

1669
01:07:43,860 --> 01:07:47,060
about the limitations of scaling DRAM

1670
01:07:47,060 --> 01:07:49,590
you know those turn out to be true then

1671
01:07:49,590 --> 01:07:51,930
the everyone could be switching over to

1672
01:07:51,930 --> 01:07:53,840
something that looks like an opt-in

1673
01:07:53,840 --> 01:07:58,800
obtained in okay so now I want to finish

1674
01:07:58,800 --> 01:08:03,080
up talking about some some computational

1675
01:08:03,080 --> 01:08:05,700
acceleration we can do in our databases

1676
01:08:05,700 --> 01:08:08,540
and explicitly I want to talk about GPUs

1677
01:08:08,540 --> 01:08:11,490
as I said for FPGAs

1678
01:08:11,490 --> 01:08:16,380
they're used in they're becoming a

1679
01:08:16,380 --> 01:08:20,310
little bit more common now sorted

1680
01:08:20,310 --> 01:08:22,290
because you can get them on Amazon high

1681
01:08:22,290 --> 01:08:24,810
you can get ec2 instances with them but

1682
01:08:24,810 --> 01:08:26,819
it as far as I know there's more GPU

1683
01:08:26,819 --> 01:08:29,100
databases around today than there are

1684
01:08:29,100 --> 01:08:31,920
FPGA databases and I think partly is

1685
01:08:31,920 --> 01:08:35,130
that because the overhead or the sort of

1686
01:08:35,130 --> 01:08:37,580
engineering cost of writing FPGA

1687
01:08:37,580 --> 01:08:39,770
code versus writing GPU code or just

1688
01:08:39,770 --> 01:08:42,410
using a GPU and library like the stuff

1689
01:08:42,410 --> 01:08:44,920
that NVIDIA provides like that's much

1690
01:08:44,920 --> 01:08:47,810
the bar entry to get advantage of a new

1691
01:08:47,810 --> 01:08:50,569
hardware or sort of non-traditional

1692
01:08:50,569 --> 01:08:51,830
hardware and your database system is

1693
01:08:51,830 --> 01:08:56,689
lower GPUs than at PJ's ok so if you

1694
01:08:56,689 --> 01:08:58,729
want to use a GPU or in our database

1695
01:08:58,729 --> 01:09:01,250
what do we need to know about well we

1696
01:09:01,250 --> 01:09:02,450
need to know about what what GPUs are

1697
01:09:02,450 --> 01:09:04,899
good for well GPUs are gonna contain

1698
01:09:04,899 --> 01:09:10,310
thousands of cores and but the the type

1699
01:09:10,310 --> 01:09:12,339
of computation or the programs that

1700
01:09:12,339 --> 01:09:17,450
those cores can can execute our going

1701
01:09:17,450 --> 01:09:19,279
have to be less sophisticated and less

1702
01:09:19,279 --> 01:09:20,990
complex than which we'd normally run on

1703
01:09:20,990 --> 01:09:23,630
a full-fledged xeon core this is because

1704
01:09:23,630 --> 01:09:26,060
these cores are designed to do

1705
01:09:26,060 --> 01:09:28,760
relatively simple operations can

1706
01:09:28,760 --> 01:09:32,630
relative to xeon can support on that are

1707
01:09:32,630 --> 01:09:35,960
repetitive on large amounts of data data

1708
01:09:35,960 --> 01:09:38,330
streams right so you like you want to be

1709
01:09:38,330 --> 01:09:40,220
able to say like the best-case scenario

1710
01:09:40,220 --> 01:09:41,630
would be like doing this to furniture

1711
01:09:41,630 --> 01:09:44,630
scan on a bunch of columns or single

1712
01:09:44,630 --> 01:09:46,189
column broken up to different chunks and

1713
01:09:46,189 --> 01:09:47,660
you can blast that out across all the

1714
01:09:47,660 --> 01:09:49,130
cores and all the cores are doing the

1715
01:09:49,130 --> 01:09:53,200
same thing and there's no there's no

1716
01:09:53,200 --> 01:09:54,530
indirection

1717
01:09:54,530 --> 01:09:57,500
there's no conditional branches it just

1718
01:09:57,500 --> 01:09:59,030
says I'm gonna from beginning and I'm

1719
01:09:59,030 --> 01:10:00,530
gonna apply the same filter and over and

1720
01:10:00,530 --> 01:10:04,040
over again so again this basically what

1721
01:10:04,040 --> 01:10:06,500
I was saying but like the kind things we

1722
01:10:06,500 --> 01:10:08,390
want to push down to the GPU or anything

1723
01:10:08,390 --> 01:10:12,620
that don't require a additional input to

1724
01:10:12,620 --> 01:10:14,270
make decision about what to do next or

1725
01:10:14,270 --> 01:10:17,810
require you to the the program to do

1726
01:10:17,810 --> 01:10:19,250
branches like if causes and things like

1727
01:10:19,250 --> 01:10:21,770
that so what's really good for it

1728
01:10:21,770 --> 01:10:24,050
sequential scans what's really bad for B

1729
01:10:24,050 --> 01:10:25,610
plus trees right because that's like

1730
01:10:25,610 --> 01:10:28,550
looking at the the contents of a people

1731
01:10:28,550 --> 01:10:30,470
astray node and make a decision or where

1732
01:10:30,470 --> 01:10:34,760
to go now there are proposals in the

1733
01:10:34,760 --> 01:10:36,410
research literature to build like B plus

1734
01:10:36,410 --> 01:10:37,670
trees or other tree based data

1735
01:10:37,670 --> 01:10:39,860
structures that you can run on GPUs to

1736
01:10:39,860 --> 01:10:41,780
best my knowledge nobody's actually

1737
01:10:41,780 --> 01:10:44,380
using them yet

1738
01:10:44,380 --> 01:10:45,820
and again this is not my area of

1739
01:10:45,820 --> 01:10:47,200
research and I don't know the

1740
01:10:47,200 --> 01:10:49,210
limitations of them are but for the most

1741
01:10:49,210 --> 01:10:51,270
part people aren't doing transactions on

1742
01:10:51,270 --> 01:10:53,500
people aren't doing transactions on GPUs

1743
01:10:53,500 --> 01:10:56,170
they're primarily being used for for

1744
01:10:56,170 --> 01:10:58,900
OLAP workloads the other point thing we

1745
01:10:58,900 --> 01:11:00,460
need to be mindful about is that

1746
01:11:00,460 --> 01:11:02,260
although GPUs are gonna have a lot of

1747
01:11:02,260 --> 01:11:05,800
memory now it's not gonna be cache

1748
01:11:05,800 --> 01:11:09,040
coherent with the CPU so that means that

1749
01:11:09,040 --> 01:11:12,760
if you want to do if you if your

1750
01:11:12,760 --> 01:11:15,610
databases can be updated and it exists

1751
01:11:15,610 --> 01:11:18,400
up in DRAM or even an SSD you either

1752
01:11:18,400 --> 01:11:20,650
need to copy the whole thing down to the

1753
01:11:20,650 --> 01:11:23,050
GPU with all the updates or do like a

1754
01:11:23,050 --> 01:11:24,610
merge operation to apply those changes

1755
01:11:24,610 --> 01:11:26,560
incrementally but it's not like if I

1756
01:11:26,560 --> 01:11:30,310
have you know I have my data's in DRAM

1757
01:11:30,310 --> 01:11:32,800
and I do an update there the GPU is not

1758
01:11:32,800 --> 01:11:34,930
gonna magically see that change we have

1759
01:11:34,930 --> 01:11:36,700
to explicitly send a message down and

1760
01:11:36,700 --> 01:11:40,060
say here's the new data so again the

1761
01:11:40,060 --> 01:11:41,440
idea is here is that we want to figure

1762
01:11:41,440 --> 01:11:43,000
out what computation we can offload to

1763
01:11:43,000 --> 01:11:45,310
to the GPU and it's gonna be mostly

1764
01:11:45,310 --> 01:11:48,670
central scans there are there are

1765
01:11:48,670 --> 01:11:52,030
implementations for pretty much I think

1766
01:11:52,030 --> 01:11:54,220
all relational algebra operators we

1767
01:11:54,220 --> 01:11:56,980
would want to execute in na and you know

1768
01:11:56,980 --> 01:12:00,880
to run queries but sequential scans are

1769
01:12:00,880 --> 01:12:01,810
the sweet spot like those hatrocks

1770
01:12:01,810 --> 01:12:03,010
implementations they're sorting

1771
01:12:03,010 --> 01:12:05,950
algorithms obviously that are designed

1772
01:12:05,950 --> 01:12:07,300
to avoid these conditionals and

1773
01:12:07,300 --> 01:12:09,880
branching so the high-level architecture

1774
01:12:09,880 --> 01:12:12,430
will look like this so say that this is

1775
01:12:12,430 --> 01:12:13,480
this is what we would talk about the

1776
01:12:13,480 --> 01:12:15,340
entire semester so far that then we have

1777
01:12:15,340 --> 01:12:17,830
a CPU or all multi socket system and

1778
01:12:17,830 --> 01:12:19,990
then we have our database hanging out in

1779
01:12:19,990 --> 01:12:22,510
DRAM and we can be aware of the Numa

1780
01:12:22,510 --> 01:12:24,460
regions to recognize what you know what

1781
01:12:24,460 --> 01:12:26,590
what dims are closer closer to a given

1782
01:12:26,590 --> 01:12:30,160
core and so over here now in the PCI

1783
01:12:30,160 --> 01:12:33,240
Express bus is going to be our GPUs and

1784
01:12:33,240 --> 01:12:35,290
we need to sort of think of them as just

1785
01:12:35,290 --> 01:12:39,220
another another socket that has way more

1786
01:12:39,220 --> 01:12:41,740
cores that look a lot different and they

1787
01:12:41,740 --> 01:12:43,840
have their own they own D Ram as well

1788
01:12:43,840 --> 01:12:46,720
and they're not gonna be in sync all

1789
01:12:46,720 --> 01:12:49,230
right so I think like for for GPUs and

1790
01:12:49,230 --> 01:12:52,540
2020 I think you get once only up to 100

1791
01:12:52,540 --> 01:12:54,400
gigs of DRAM

1792
01:12:54,400 --> 01:12:56,560
I probably on the high end ones whereas

1793
01:12:56,560 --> 01:12:58,120
like on the CPU we can get

1794
01:12:58,120 --> 01:13:01,240
and he up to 48 terabytes of DRAM if we

1795
01:13:01,240 --> 01:13:04,150
have a lot of money so the other thing

1796
01:13:04,150 --> 01:13:06,280
we be mindful to is the the bandwidth

1797
01:13:06,280 --> 01:13:10,540
between our compute and storage so to go

1798
01:13:10,540 --> 01:13:14,650
between DRAM and and CPU core with ddr4

1799
01:13:14,650 --> 01:13:16,860
we can do about 40 gigabytes per second

1800
01:13:16,860 --> 01:13:23,050
over the pci-x PCIe bus the best I think

1801
01:13:23,050 --> 01:13:25,810
we can do now is is 16 gigabytes per

1802
01:13:25,810 --> 01:13:28,570
second so it's it's not that far off

1803
01:13:28,570 --> 01:13:30,400
it's not like an order of magnitude but

1804
01:13:30,400 --> 01:13:32,260
it's still significantly slower than

1805
01:13:32,260 --> 01:13:35,170
what we can do over here so that means

1806
01:13:35,170 --> 01:13:38,080
that that's the one of the challenges

1807
01:13:38,080 --> 01:13:39,880
we're gonna face is that you have to run

1808
01:13:39,880 --> 01:13:41,590
a query we have to send a bunch of data

1809
01:13:41,590 --> 01:13:43,480
down here and then be able to crunch on

1810
01:13:43,480 --> 01:13:45,790
and get it back and that's gonna be it

1811
01:13:45,790 --> 01:13:47,680
made it be faster just to run it up up

1812
01:13:47,680 --> 01:13:51,730
here I with the with the CPU I'm not

1813
01:13:51,730 --> 01:13:52,930
gonna have as many cores but this

1814
01:13:52,930 --> 01:13:54,970
bandwidth is gonna be our bottleneck for

1815
01:13:54,970 --> 01:13:55,800
us

1816
01:13:55,800 --> 01:13:58,690
so now NVIDIA has this thing called MV

1817
01:13:58,690 --> 01:14:01,090
link that gives you 25 gigabytes per

1818
01:14:01,090 --> 01:14:04,240
second in between in between two

1819
01:14:04,240 --> 01:14:06,460
different GPUs you could you know you

1820
01:14:06,460 --> 01:14:09,190
message passing in between them you can

1821
01:14:09,190 --> 01:14:12,280
also get MV link to go from the DRAM

1822
01:14:12,280 --> 01:14:16,270
memory up into the CPUs memory at 25

1823
01:14:16,270 --> 01:14:19,930
gigabytes per second that though is this

1824
01:14:19,930 --> 01:14:22,420
MV link technology as far as I know is

1825
01:14:22,420 --> 01:14:24,490
only available on PowerPC machines I

1826
01:14:24,490 --> 01:14:27,070
don't think it's only x86 so you have to

1827
01:14:27,070 --> 01:14:29,290
run on IBM power and in order to get

1828
01:14:29,290 --> 01:14:30,250
advantage of this

1829
01:14:30,250 --> 01:14:33,340
I think Intel has its own fabric but I I

1830
01:14:33,340 --> 01:14:35,680
forget what it's call are a and B might

1831
01:14:35,680 --> 01:14:40,360
have something as well okay so how well

1832
01:14:40,360 --> 01:14:43,840
do you organize our system so there's

1833
01:14:43,840 --> 01:14:45,130
three different approaches we can take

1834
01:14:45,130 --> 01:14:47,260
to how we want to use a GPU in our

1835
01:14:47,260 --> 01:14:49,780
database system so the first is that the

1836
01:14:49,780 --> 01:14:52,300
easiest way is just take our entire

1837
01:14:52,300 --> 01:14:54,910
database and plop it down or copy it

1838
01:14:54,910 --> 01:14:58,360
down to the PCIe bus put it on the GPU

1839
01:14:58,360 --> 01:15:00,340
and now all the queries own if this has

1840
01:15:00,340 --> 01:15:04,090
data that's down on the GPU this

1841
01:15:04,090 --> 01:15:07,150
obviously is limited to the amount of

1842
01:15:07,150 --> 01:15:08,800
VRAM that's available in the GPU if your

1843
01:15:08,800 --> 01:15:11,000
database exceeds that size then this

1844
01:15:11,000 --> 01:15:13,670
work maybe you could daisy chain a bunch

1845
01:15:13,670 --> 01:15:15,470
of GPUs together and have the sepia

1846
01:15:15,470 --> 01:15:16,940
coordinated about what who has what data

1847
01:15:16,940 --> 01:15:18,680
and combine the results up in the cpu

1848
01:15:18,680 --> 01:15:23,960
across the different GPUs but it's best

1849
01:15:23,960 --> 01:15:25,580
my knowledge that I don't think any of

1850
01:15:25,580 --> 01:15:27,080
the major vendors do this anymore so

1851
01:15:27,080 --> 01:15:29,720
this is actually what calm nice I used

1852
01:15:29,720 --> 01:15:31,400
to do when it was called map D and

1853
01:15:31,400 --> 01:15:33,940
they've sensibly architected it to do a

1854
01:15:33,940 --> 01:15:38,510
the third one here so the second

1855
01:15:38,510 --> 01:15:40,660
approach is that you recognize that you

1856
01:15:40,660 --> 01:15:43,430
for some queries or some some databases

1857
01:15:43,430 --> 01:15:45,230
you don't maybe don't need all the

1858
01:15:45,230 --> 01:15:49,730
columns for a table down in the GPU so

1859
01:15:49,730 --> 01:15:52,120
you only copy down the parts of them I

1860
01:15:52,120 --> 01:15:54,560
can now your query planner can recognize

1861
01:15:54,560 --> 01:15:56,570
alright for this part of the query I can

1862
01:15:56,570 --> 01:15:57,860
run on the GPU because those columns are

1863
01:15:57,860 --> 01:16:00,500
down down to the GPU but then I'll get

1864
01:16:00,500 --> 01:16:04,010
back some offsets and I'll you know copy

1865
01:16:04,010 --> 01:16:07,820
the to the the the tuples a bit cover

1866
01:16:07,820 --> 01:16:08,810
the batteries that are needed for those

1867
01:16:08,810 --> 01:16:10,400
two blows based on those offsets for the

1868
01:16:10,400 --> 01:16:11,840
other columns that open my memory and

1869
01:16:11,840 --> 01:16:13,580
then I just made two of those results

1870
01:16:13,580 --> 01:16:15,550
and return them back to the application

1871
01:16:15,550 --> 01:16:19,160
so for this one where I've seen this

1872
01:16:19,160 --> 01:16:20,750
done as usually requires the

1873
01:16:20,750 --> 01:16:22,760
administrator to identify that these

1874
01:16:22,760 --> 01:16:24,530
should be the GPU resident columns and

1875
01:16:24,530 --> 01:16:27,230
these should be up in the CPU and you

1876
01:16:27,230 --> 01:16:28,940
know that has limitations because people

1877
01:16:28,940 --> 01:16:31,190
may not always know how to pick what the

1878
01:16:31,190 --> 01:16:33,290
right approach is there may be some

1879
01:16:33,290 --> 01:16:34,970
other systems that can configure that

1880
01:16:34,970 --> 01:16:38,710
out before you automatically know the

1881
01:16:38,710 --> 01:16:42,560
best approach though is to do support

1882
01:16:42,560 --> 01:16:46,400
streaming algorithms where I can have

1883
01:16:46,400 --> 01:16:49,370
the data to stand on the fly move data

1884
01:16:49,370 --> 01:16:51,500
from the CPU memory down to the GPU

1885
01:16:51,500 --> 01:16:55,340
memory and process it incrementally

1886
01:16:55,340 --> 01:16:57,200
while I'm continuing to send out more

1887
01:16:57,200 --> 01:16:58,820
than you know why send them send down

1888
01:16:58,820 --> 01:17:00,860
the first batch of data the GPU fires

1889
01:17:00,860 --> 01:17:02,780
off starts crunching on it and then the

1890
01:17:02,780 --> 01:17:04,550
background I now start streaming down

1891
01:17:04,550 --> 01:17:07,310
the sort of the next wave of data that

1892
01:17:07,310 --> 01:17:09,320
I'm gonna need and so by the time that

1893
01:17:09,320 --> 01:17:11,030
they finish the GP finishes processing

1894
01:17:11,030 --> 01:17:13,160
the first batch the second batch is

1895
01:17:13,160 --> 01:17:14,510
ready to go and it just keeps on going

1896
01:17:14,510 --> 01:17:16,700
so like the GPUs all be always being

1897
01:17:16,700 --> 01:17:19,040
fully utilized and there's hash join

1898
01:17:19,040 --> 01:17:20,519
there's sort merge-join there's there

1899
01:17:20,519 --> 01:17:24,090
budget of albums that that can their

1900
01:17:24,090 --> 01:17:25,710
implementations of albums that that can

1901
01:17:25,710 --> 01:17:30,119
can do that for you so hard work seller

1902
01:17:30,119 --> 01:17:31,469
databases were something that I was very

1903
01:17:31,469 --> 01:17:33,809
interested in a few years ago we end up

1904
01:17:33,809 --> 01:17:38,699
having a seminar series at CMU on on

1905
01:17:38,699 --> 01:17:41,010
this very topic so I invited most of

1906
01:17:41,010 --> 01:17:42,719
these vendors over here the ah-ha meet I

1907
01:17:42,719 --> 01:17:44,070
went to club map Deacon add a couple is

1908
01:17:44,070 --> 01:17:46,889
in DB scream bright light airy tea bees

1909
01:17:46,889 --> 01:17:49,409
from uber that was that came out after

1910
01:17:49,409 --> 01:17:51,659
we had the seminar series but the point

1911
01:17:51,659 --> 01:17:52,650
I'm trying to make is if you're really

1912
01:17:52,650 --> 01:17:53,789
interested in this topic and want to

1913
01:17:53,789 --> 01:17:56,460
learn more you can go to this URL here

1914
01:17:56,460 --> 01:17:58,499
and I have a whole I think there's eight

1915
01:17:58,499 --> 01:18:00,570
different eight or seven or eight

1916
01:18:00,570 --> 01:18:02,489
different lectures or talks from all

1917
01:18:02,489 --> 01:18:03,960
these major database vendors that are

1918
01:18:03,960 --> 01:18:05,880
building GPU databases and they'll tell

1919
01:18:05,880 --> 01:18:07,320
you you know what makes them interesting

1920
01:18:07,320 --> 01:18:10,889
and how they work but the last thing I

1921
01:18:10,889 --> 01:18:13,110
want to talk about is Harvard transact

1922
01:18:13,110 --> 01:18:17,099
on memory so every year I debate whether

1923
01:18:17,099 --> 01:18:21,570
I want to bring this up because it keeps

1924
01:18:21,570 --> 01:18:23,730
getting turned off by Intel because of

1925
01:18:23,730 --> 01:18:27,059
security leaks so the waiting went over

1926
01:18:27,059 --> 01:18:28,440
transactional memory is that things like

1927
01:18:28,440 --> 01:18:30,719
you have a critical section in your code

1928
01:18:30,719 --> 01:18:33,210
and now I can have a heart our

1929
01:18:33,210 --> 01:18:35,280
transaction managed by the CPU that

1930
01:18:35,280 --> 01:18:37,469
keeps track of the loads and store

1931
01:18:37,469 --> 01:18:39,840
operations into memory for my

1932
01:18:39,840 --> 01:18:42,539
transaction and then if I now if it

1933
01:18:42,539 --> 01:18:44,940
determines that there's a that there was

1934
01:18:44,940 --> 01:18:46,739
another thread that running also a

1935
01:18:46,739 --> 01:18:48,300
transaction that may be read or modified

1936
01:18:48,300 --> 01:18:49,949
the same things I I touched

1937
01:18:49,949 --> 01:18:52,650
then it'll can go ahead and abort me and

1938
01:18:52,650 --> 01:18:54,840
restart be so the way it works is

1939
01:18:54,840 --> 01:18:57,570
basically operates like OCC and it will

1940
01:18:57,570 --> 01:18:59,610
maintain a read rights in a private

1941
01:18:59,610 --> 01:19:02,159
workspace for your transaction and then

1942
01:19:02,159 --> 01:19:04,050
when you go to go ahead and commit they

1943
01:19:04,050 --> 01:19:05,519
check to see whether they do a

1944
01:19:05,519 --> 01:19:07,050
validation to see whether anybody else

1945
01:19:07,050 --> 01:19:08,699
has modified the same location as that I

1946
01:19:08,699 --> 01:19:13,230
read or wrote and it's kind of cool

1947
01:19:13,230 --> 01:19:14,340
because the way basically works is that

1948
01:19:14,340 --> 01:19:17,340
they just piggyback off of the the cache

1949
01:19:17,340 --> 01:19:18,869
coherency protocol it's using any way to

1950
01:19:18,869 --> 01:19:20,760
keep track of to heat the Corazon Singh

1951
01:19:20,760 --> 01:19:22,559
and they're using that to figure out

1952
01:19:22,559 --> 01:19:24,019
when there's conflicts routine

1953
01:19:24,019 --> 01:19:25,980
transactions running at different cores

1954
01:19:25,980 --> 01:19:31,380
so the so for this is this was exactly

1955
01:19:31,380 --> 01:19:32,999
invented by Maurice Herlihy

1956
01:19:32,999 --> 01:19:33,630
who

1957
01:19:33,630 --> 01:19:36,300
the guy invented linearise ability he

1958
01:19:36,300 --> 01:19:38,400
used to be a professor here at CMU but

1959
01:19:38,400 --> 01:19:40,410
now he's a professor at Brown he amended

1960
01:19:40,410 --> 01:19:42,690
this I think in the early 1990s and

1961
01:19:42,690 --> 01:19:44,910
actually Intel put it in their hardware

1962
01:19:44,910 --> 01:19:47,340
I think starting in they now stood in

1963
01:19:47,340 --> 01:19:50,700
2012 and then it came out in 2013 but

1964
01:19:50,700 --> 01:19:53,490
then they found a bug in it in 2014 so

1965
01:19:53,490 --> 01:19:55,740
then they disabled it and then I think

1966
01:19:55,740 --> 01:19:57,360
I'm like 2017 they're like alright

1967
01:19:57,360 --> 01:19:58,890
here's the new CPU as the bug is fixed

1968
01:19:58,890 --> 01:20:01,350
go ahead and rename bêlit and then 20

1969
01:20:01,350 --> 01:20:03,000
million teen I think there's another I

1970
01:20:03,000 --> 01:20:04,530
think it's called vom b-bomb or

1971
01:20:04,530 --> 01:20:06,090
something like rabbits so then another

1972
01:20:06,090 --> 01:20:08,370
bug that can have security leaks when

1973
01:20:08,370 --> 01:20:10,110
you use this so this what I'm saying so

1974
01:20:10,110 --> 01:20:11,610
like I hope you kind of wanted to teach

1975
01:20:11,610 --> 01:20:12,870
us and show this and have you guys use

1976
01:20:12,870 --> 01:20:16,560
this but like I it's unclear whether

1977
01:20:16,560 --> 01:20:18,900
that you know this is actually like you

1978
01:20:18,900 --> 01:20:20,190
could you actually use it today safely

1979
01:20:20,190 --> 01:20:24,120
on on in a modern modern intel cpus i I

1980
01:20:24,120 --> 01:20:26,510
don't know if AMD has has similar issues

1981
01:20:26,510 --> 01:20:30,000
so everything I already said like the

1982
01:20:30,000 --> 01:20:31,320
the way it works is that you keep track

1983
01:20:31,320 --> 01:20:32,910
of every writes that oh the readwrite

1984
01:20:32,910 --> 01:20:34,680
set has to fit in your l1 cache so you

1985
01:20:34,680 --> 01:20:39,450
can't use this for you hug me buddy uses

1986
01:20:39,450 --> 01:20:40,650
for like you know to replace the

1987
01:20:40,650 --> 01:20:41,940
transactional stuff that we talked about

1988
01:20:41,940 --> 01:20:44,040
for concurrent ritual right because a

1989
01:20:44,040 --> 01:20:45,450
lot of times your transaction and

1990
01:20:45,450 --> 01:20:48,270
rewrite set when we large with an l1 and

1991
01:20:48,270 --> 01:20:49,500
certainly if you have multiple threads

1992
01:20:49,500 --> 01:20:51,060
running at the same time you'd be

1993
01:20:51,060 --> 01:20:53,160
thrashing out one and you would have

1994
01:20:53,160 --> 01:21:01,710
problems to this so the reason why we

1995
01:21:01,710 --> 01:21:03,140
might want to use this also too is like

1996
01:21:03,140 --> 01:21:08,300
the this is not just for performance

1997
01:21:08,300 --> 01:21:10,470
this is also useful from a software

1998
01:21:10,470 --> 01:21:12,420
engineering standpoint because now

1999
01:21:12,420 --> 01:21:14,310
instead of doing all the latching and

2000
01:21:14,310 --> 01:21:16,110
crabbing stuff that we talked before you

2001
01:21:16,110 --> 01:21:18,720
could use this as an alternative and

2002
01:21:18,720 --> 01:21:19,920
maybe getting the same performance of

2003
01:21:19,920 --> 01:21:21,900
having software manage latches or

2004
01:21:21,900 --> 01:21:24,540
software manage transactions with lower

2005
01:21:24,540 --> 01:21:26,820
engineering overhead that's purely

2006
01:21:26,820 --> 01:21:28,140
conjecture I don't know what the fact

2007
01:21:28,140 --> 01:21:29,490
that's actually true but that's sort of

2008
01:21:29,490 --> 01:21:31,620
been what the proponents of this of this

2009
01:21:31,620 --> 01:21:35,310
technique have argued so let's see how

2010
01:21:35,310 --> 01:21:36,510
you would actually want to use this so

2011
01:21:36,510 --> 01:21:38,400
with how transactional memory there's

2012
01:21:38,400 --> 01:21:41,100
two programming models that you can use

2013
01:21:41,100 --> 01:21:43,710
the first is called hover lock elysian

2014
01:21:43,710 --> 01:21:47,180
and the way this works is that start my

2015
01:21:47,180 --> 01:21:50,930
transaction and anytime I do a write

2016
01:21:50,930 --> 01:21:52,970
during my transaction I don't actually

2017
01:21:52,970 --> 01:21:55,730
do it I just you know sort of like to do

2018
01:21:55,730 --> 01:21:58,430
a Jedi mind trick I sort of tricked

2019
01:21:58,430 --> 01:21:59,960
myself thinking the night that I did do

2020
01:21:59,960 --> 01:22:05,150
it and what happen is like so too if I

2021
01:22:05,150 --> 01:22:07,190
write to a memory location it's hanging

2022
01:22:07,190 --> 01:22:08,960
out my private workspace if I the

2023
01:22:08,960 --> 01:22:12,830
threads try to read leave that memory

2024
01:22:12,830 --> 01:22:14,270
location they won't see my right and

2025
01:22:14,270 --> 01:22:18,380
then when I go to do a commit the the

2026
01:22:18,380 --> 01:22:19,880
harbor will check to see whether there's

2027
01:22:19,880 --> 01:22:22,010
a conflict with other transactions or

2028
01:22:22,010 --> 01:22:25,430
other threads if there wasn't then I can

2029
01:22:25,430 --> 01:22:26,630
go ahead and apply my changes from the

2030
01:22:26,630 --> 01:22:28,280
private workspace into sort of a global

2031
01:22:28,280 --> 01:22:32,900
memory if there was a conflict then the

2032
01:22:32,900 --> 01:22:35,480
the harbor will roll back roll me back

2033
01:22:35,480 --> 01:22:37,310
to the starting point of my transaction

2034
01:22:37,310 --> 01:22:39,110
almost like a strawberry teacher you

2035
01:22:39,110 --> 01:22:40,970
roll back to its beginning and then re

2036
01:22:40,970 --> 01:22:43,340
execute it but now when the exit of the

2037
01:22:43,340 --> 01:22:44,570
second time I'm actually gonna take

2038
01:22:44,570 --> 01:22:47,000
explicit locks to protect the memory

2039
01:22:47,000 --> 01:22:49,340
regions that I'm writing to them and so

2040
01:22:49,340 --> 01:22:51,080
that way I mean you know I'm guaranteed

2041
01:22:51,080 --> 01:22:54,290
that I can run with that without

2042
01:22:54,290 --> 01:22:56,630
conflicts so it's like again it's

2043
01:22:56,630 --> 01:22:58,960
optimistic first and then if I get it if

2044
01:22:58,960 --> 01:23:02,240
if my if I conflict with somebody else

2045
01:23:02,240 --> 01:23:03,950
then it gets restarted with pessimistic

2046
01:23:03,950 --> 01:23:06,620
locking the other more complicated

2047
01:23:06,620 --> 01:23:08,840
approach is use rtmp restricted

2048
01:23:08,840 --> 01:23:10,940
transaction memory and with this one

2049
01:23:10,940 --> 01:23:12,860
it's like the hardware lock elysian

2050
01:23:12,860 --> 01:23:15,020
where I'm gonna run the first time

2051
01:23:15,020 --> 01:23:18,740
without taking locks but then if there's

2052
01:23:18,740 --> 01:23:21,230
a conflict instead of going back and

2053
01:23:21,230 --> 01:23:24,020
running the transaction again with the

2054
01:23:24,020 --> 01:23:26,540
taking explicit locks you can you

2055
01:23:26,540 --> 01:23:28,910
provide it with a pointer to another

2056
01:23:28,910 --> 01:23:31,580
location in the code to jump to that

2057
01:23:31,580 --> 01:23:34,220
will do something different than this

2058
01:23:34,220 --> 01:23:35,870
the regular code so you still abort the

2059
01:23:35,870 --> 01:23:37,730
transaction and you roll it back but you

2060
01:23:37,730 --> 01:23:39,230
don't jump back to the starting point of

2061
01:23:39,230 --> 01:23:41,420
the transaction and run it again you

2062
01:23:41,420 --> 01:23:43,850
jump to some other memory location for

2063
01:23:43,850 --> 01:23:45,500
the program that can do something

2064
01:23:45,500 --> 01:23:47,900
slightly different so this requires more

2065
01:23:47,900 --> 01:23:49,880
engineering effort on their own outside

2066
01:23:49,880 --> 01:23:52,310
as the data system developer to be

2067
01:23:52,310 --> 01:23:53,510
mindful that we're jumping to another

2068
01:23:53,510 --> 01:23:57,320
location and you know and have sort of a

2069
01:23:57,320 --> 01:23:59,150
an alternative implementation of the

2070
01:23:59,150 --> 01:24:00,260
critical section that we're trying to

2071
01:24:00,260 --> 01:24:01,510
protect

2072
01:24:01,510 --> 01:24:04,369
so let's look an example how we could

2073
01:24:04,369 --> 01:24:06,530
use it so say that we want to do we have

2074
01:24:06,530 --> 01:24:08,389
a B plus tree and we learn when you want

2075
01:24:08,389 --> 01:24:11,090
to insert into key twenty five so if

2076
01:24:11,090 --> 01:24:12,590
we're just doing the latch crabbing that

2077
01:24:12,590 --> 01:24:14,539
we talked about before the optimistic

2078
01:24:14,539 --> 01:24:16,070
latch crabbing I would take real a ch's

2079
01:24:16,070 --> 01:24:18,860
until I get down to here and recognize

2080
01:24:18,860 --> 01:24:20,119
that this is the thing I want to modify

2081
01:24:20,119 --> 01:24:22,579
so I take a right latch or a that's an X

2082
01:24:22,579 --> 01:24:23,570
for exclusive which should be it right

2083
01:24:23,570 --> 01:24:26,119
and then when I have that and go ahead

2084
01:24:26,119 --> 01:24:28,429
and plan my change but now if I'm doing

2085
01:24:28,429 --> 01:24:30,860
this with Howard transactional memory my

2086
01:24:30,860 --> 01:24:32,989
program would look like this I would

2087
01:24:32,989 --> 01:24:34,520
have the boundary from where my

2088
01:24:34,520 --> 01:24:36,020
transaction starts and when I when I

2089
01:24:36,020 --> 01:24:38,480
commit and for this critical section

2090
01:24:38,480 --> 01:24:40,550
here this is just the crabbing portion

2091
01:24:40,550 --> 01:24:44,889
where I'm traversing down into the

2092
01:24:44,889 --> 01:24:47,989
traversing down into the tree till I get

2093
01:24:47,989 --> 01:24:49,849
to this F node and then you take the

2094
01:24:49,849 --> 01:24:51,679
exclusive latch only on me or the right

2095
01:24:51,679 --> 01:24:55,429
latch on F so from the outside it looks

2096
01:24:55,429 --> 01:24:57,380
like that I've magically made it through

2097
01:24:57,380 --> 01:25:00,289
down here transactionally and this would

2098
01:25:00,289 --> 01:25:01,610
automatically detect whether if somebody

2099
01:25:01,610 --> 01:25:03,289
else took a latch at the same time I

2100
01:25:03,289 --> 01:25:05,780
would and so from the outside it looks

2101
01:25:05,780 --> 01:25:07,730
like that I magically warp down here I

2102
01:25:07,730 --> 01:25:09,679
took the correct latches all the way so

2103
01:25:09,679 --> 01:25:12,020
I'm guaranteeing the the integrity of

2104
01:25:12,020 --> 01:25:13,909
the data structure in terms of what were

2105
01:25:13,909 --> 01:25:15,679
their pointers the the pointers are

2106
01:25:15,679 --> 01:25:18,500
pointing to but I didn't have that I

2107
01:25:18,500 --> 01:25:22,280
didn't have to have to you know actually

2108
01:25:22,280 --> 01:25:26,659
apply these rights to you know to in

2109
01:25:26,659 --> 01:25:29,630
memory all that got alighted and I get

2110
01:25:29,630 --> 01:25:31,309
jump down here and get it and do and get

2111
01:25:31,309 --> 01:25:35,679
exactly what I want okay so to finish up

2112
01:25:35,679 --> 01:25:39,110
the as I said we spend most the time

2113
01:25:39,110 --> 01:25:40,250
talking today talk about persistent

2114
01:25:40,250 --> 01:25:43,250
memory because it is my opinion that is

2115
01:25:43,250 --> 01:25:45,590
out now and that when it becomes more

2116
01:25:45,590 --> 01:25:47,420
widespread that this is going to be a

2117
01:25:47,420 --> 01:25:49,460
major change and how we build software

2118
01:25:49,460 --> 01:25:51,889
and especially database systems like I

2119
01:25:51,889 --> 01:25:53,980
could foresee that if persistent memory

2120
01:25:53,980 --> 01:25:56,480
takes off as much as I think it should

2121
01:25:56,480 --> 01:26:01,420
and will then it may be the case that we

2122
01:26:01,420 --> 01:26:04,340
don't you know in the introduction Davis

2123
01:26:04,340 --> 01:26:05,690
class we don't spend time talking about

2124
01:26:05,690 --> 01:26:08,780
things like buffer pools and

2125
01:26:08,780 --> 01:26:10,429
you know how to do right in logging with

2126
01:26:10,429 --> 01:26:12,289
with scrunch why you know maximizing

2127
01:26:12,289 --> 01:26:15,710
cement rely on kids like that think you

2128
01:26:15,710 --> 01:26:17,539
know now memory is just persistent and I

2129
01:26:17,539 --> 01:26:19,190
got right to it I make sure I flush it I

2130
01:26:19,190 --> 01:26:20,780
have to order my rights a little bit but

2131
01:26:20,780 --> 01:26:23,239
like I don't have to do all that page

2132
01:26:23,239 --> 01:26:25,159
latching and all the crap we did in the

2133
01:26:25,159 --> 01:26:28,400
introduction class so it's my conjecture

2134
01:26:28,400 --> 01:26:30,380
also as I said earlier that I think the

2135
01:26:30,380 --> 01:26:31,909
in-memory databases are in a better

2136
01:26:31,909 --> 01:26:33,650
position to take advantage of persistent

2137
01:26:33,650 --> 01:26:34,579
memory because they're already written

2138
01:26:34,579 --> 01:26:37,329
to assume that they're they can talk to

2139
01:26:37,329 --> 01:26:40,789
byte addressable memory and and not deal

2140
01:26:40,789 --> 01:26:42,710
with pages so I think that the

2141
01:26:42,710 --> 01:26:45,170
conversion from a dram or in memory

2142
01:26:45,170 --> 01:26:46,849
system to a persistent memory system

2143
01:26:46,849 --> 01:26:51,130
will be lower for in-memory databases I

2144
01:26:51,130 --> 01:26:55,880
also think that the you know GPU has

2145
01:26:55,880 --> 01:26:57,530
been around for a while FPGA has been

2146
01:26:57,530 --> 01:26:59,510
around for a while but you know like I

2147
01:26:59,510 --> 01:27:01,789
said there's not most databases are not

2148
01:27:01,789 --> 01:27:03,469
database systems are not being written

2149
01:27:03,469 --> 01:27:06,170
assuming you have that hardware it's

2150
01:27:06,170 --> 01:27:08,929
still in my opinion it's a niche you

2151
01:27:08,929 --> 01:27:13,940
know niche market the what could happen

2152
01:27:13,940 --> 01:27:18,530
though is that beyond GPUs and FPGAs you

2153
01:27:18,530 --> 01:27:19,820
may start seeing additional

2154
01:27:19,820 --> 01:27:22,579
computational devices like configure our

2155
01:27:22,579 --> 01:27:24,710
special accelerators something that

2156
01:27:24,710 --> 01:27:28,400
looks like a TPU or you know some kind

2157
01:27:28,400 --> 01:27:31,909
of custom ASIC that could make a bit you

2158
01:27:31,909 --> 01:27:32,809
know big difference in the performance

2159
01:27:32,809 --> 01:27:34,909
of databases the only thing that would

2160
01:27:34,909 --> 01:27:36,619
have to have to overlap pretty heavily

2161
01:27:36,619 --> 01:27:38,420
with the potential machine learning or

2162
01:27:38,420 --> 01:27:40,099
data science the applications more than

2163
01:27:40,099 --> 01:27:41,599
just you know doing sequential scans

2164
01:27:41,599 --> 01:27:43,219
which data science machine learning do

2165
01:27:43,219 --> 01:27:44,929
do a lot of but there's a way for data

2166
01:27:44,929 --> 01:27:46,940
set to take advantage of them I think

2167
01:27:46,940 --> 01:27:50,030
that would be interesting as a sort of

2168
01:27:50,030 --> 01:27:51,590
also another side to eye

2169
01:27:51,590 --> 01:27:56,300
I think matrix databases will have could

2170
01:27:56,300 --> 01:27:57,559
potentially become more important in the

2171
01:27:57,559 --> 01:28:00,199
next decade and in that case you know

2172
01:28:00,199 --> 01:28:03,230
the some of the accelerators that out

2173
01:28:03,230 --> 01:28:04,550
there that are doing computational or

2174
01:28:04,550 --> 01:28:07,039
machine learning on matrices you know

2175
01:28:07,039 --> 01:28:08,630
those databases get to easily take

2176
01:28:08,630 --> 01:28:11,239
advantage of those things but the core

2177
01:28:11,239 --> 01:28:13,340
that the point thing that was like the

2178
01:28:13,340 --> 01:28:14,750
core ideas of the things that we talked

2179
01:28:14,750 --> 01:28:16,639
about this semester and certainly many

2180
01:28:16,639 --> 01:28:17,780
of the algorithms would still be the

2181
01:28:17,780 --> 01:28:18,019
same

2182
01:28:18,019 --> 01:28:20,329
quanto scans the sequential scan

2183
01:28:20,329 --> 01:28:22,250
right evaluating a predicate you know

2184
01:28:22,250 --> 01:28:24,710
coding that or you know traversing the

2185
01:28:24,710 --> 01:28:26,780
tree that is all pretty much still gonna

2186
01:28:26,780 --> 01:28:28,460
be the same and so we do see how to

2187
01:28:28,460 --> 01:28:29,869
think about how we taking the knowledge

2188
01:28:29,869 --> 01:28:31,699
we know about how to bit a bit did his

2189
01:28:31,699 --> 01:28:33,260
some way to be talked about in this

2190
01:28:33,260 --> 01:28:35,980
class and apply it to this new hardware

2191
01:28:35,980 --> 01:28:37,849
and so I think you have the background

2192
01:28:37,849 --> 01:28:43,010
to do this now ok so this is the last

2193
01:28:43,010 --> 01:28:45,500
lecture on Wednesday we're having again

2194
01:28:45,500 --> 01:28:47,059
the guest speaker from Amazon but that

2195
01:28:47,059 --> 01:28:51,619
we closed off to only CMU students so if

2196
01:28:51,619 --> 01:28:53,449
you're watching this from outside of CMU

2197
01:28:53,449 --> 01:28:55,940
I hope you're safe I hope everything is

2198
01:28:55,940 --> 01:28:57,469
doing okay and you know hope you're

2199
01:28:57,469 --> 01:28:58,219
watching this

2200
01:28:58,219 --> 01:29:01,489
well after we passed the the pandemic if

2201
01:29:01,489 --> 01:29:03,290
you made it through the entire semester

2202
01:29:03,290 --> 01:29:04,960
watching the YouTube videos that

2203
01:29:04,960 --> 01:29:09,050
congrats so what what should you be able

2204
01:29:09,050 --> 01:29:12,860
to do now well after going through 25 26

2205
01:29:12,860 --> 01:29:14,860
lectures you should now be able to

2206
01:29:14,860 --> 01:29:17,449
understand and comprehend and reason

2207
01:29:17,449 --> 01:29:20,449
about the major topics that we talked

2208
01:29:20,449 --> 01:29:22,750
about and on how to build a modern

2209
01:29:22,750 --> 01:29:25,130
single node database panel system and

2210
01:29:25,130 --> 01:29:27,020
I'm qualifying when I'm saying my single

2211
01:29:27,020 --> 01:29:29,090
node because going distributed brings up

2212
01:29:29,090 --> 01:29:32,000
a whole other bunch of issues with

2213
01:29:32,000 --> 01:29:34,309
networking and distributed transactions

2214
01:29:34,309 --> 01:29:36,530
that we haven't talked about but at a

2215
01:29:36,530 --> 01:29:38,929
high level there there are many of the

2216
01:29:38,929 --> 01:29:40,280
same issues that we talked about here

2217
01:29:40,280 --> 01:29:41,750
where we care about placement we care

2218
01:29:41,750 --> 01:29:43,520
about partitioning we care about drawing

2219
01:29:43,520 --> 01:29:45,079
algorithms we care about transactions

2220
01:29:45,079 --> 01:29:47,030
all in that environment it's just the

2221
01:29:47,030 --> 01:29:49,340
the communication is slower and more

2222
01:29:49,340 --> 01:29:50,659
unreliable so we have to we have to

2223
01:29:50,659 --> 01:29:54,170
account for that I also hope that you

2224
01:29:54,170 --> 01:29:56,480
now have the reason about the ability of

2225
01:29:56,480 --> 01:29:59,210
a foundation to know reason about the

2226
01:29:59,210 --> 01:30:01,280
claims that people make about their

2227
01:30:01,280 --> 01:30:02,599
database management systems

2228
01:30:02,599 --> 01:30:04,849
and you'll be able to figure out what

2229
01:30:04,849 --> 01:30:07,400
those claims are real or whether they're

2230
01:30:07,400 --> 01:30:09,710
actually implausible or whether it's

2231
01:30:09,710 --> 01:30:12,260
just a bunch of marketing hype because

2232
01:30:12,260 --> 01:30:14,510
databases the Davis market is a lot of

2233
01:30:14,510 --> 01:30:17,630
money there's a lot of startups there's

2234
01:30:17,630 --> 01:30:19,699
a lot of big companies who want to make

2235
01:30:19,699 --> 01:30:22,070
money and sometimes they'll say things

2236
01:30:22,070 --> 01:30:25,369
that you know unless you're sort of

2237
01:30:25,369 --> 01:30:26,840
paying attention go that seems kind of

2238
01:30:26,840 --> 01:30:30,320
cool but if you now using the the the

2239
01:30:30,320 --> 01:30:31,550
knowledge of game right is going to this

2240
01:30:31,550 --> 01:30:32,750
course now should be able to like look

2241
01:30:32,750 --> 01:30:33,449
at this

2242
01:30:33,449 --> 01:30:36,660
is this real or not right so I don't

2243
01:30:36,660 --> 01:30:38,550
mean to pick on these guys but let me

2244
01:30:38,550 --> 01:30:39,870
give one example that came out last week

2245
01:30:39,870 --> 01:30:42,239
so there's this new startup called

2246
01:30:42,239 --> 01:30:45,420
terminus DB and they posted on Hacker

2247
01:30:45,420 --> 01:30:47,730
News hey we've come out we're around you

2248
01:30:47,730 --> 01:30:50,550
know this is what we do so it's a graph

2249
01:30:50,550 --> 01:30:51,719
database and so they're comparing

2250
01:30:51,719 --> 01:30:54,410
themselves against a bunch of other

2251
01:30:54,410 --> 01:30:58,380
other systems in the same space and they

2252
01:30:58,380 --> 01:30:59,760
had this little blip here though what

2253
01:30:59,760 --> 01:31:01,650
that talks about their features that

2254
01:31:01,650 --> 01:31:04,760
they do they do AI cogeneration and

2255
01:31:04,760 --> 01:31:07,530
rightfully so you see this and like what

2256
01:31:07,530 --> 01:31:09,840
does that mean and sure enough somebody

2257
01:31:09,840 --> 01:31:12,300
posted on Hacker News saying hey look AI

2258
01:31:12,300 --> 01:31:15,239
cogeneration what's that what are you

2259
01:31:15,239 --> 01:31:17,070
actually claiming and then these are

2260
01:31:17,070 --> 01:31:19,230
some of their some of the developers

2261
01:31:19,230 --> 01:31:20,969
like oh yeah this is this is incorrect

2262
01:31:20,969 --> 01:31:23,429
this is marketing gone wrong so if

2263
01:31:23,429 --> 01:31:24,989
you're just a casual person looking this

2264
01:31:24,989 --> 01:31:27,300
and go okay I cogeneration well that

2265
01:31:27,300 --> 01:31:28,590
sounds kind of cool what could that be

2266
01:31:28,590 --> 01:31:30,810
but for you guys who have lost at this

2267
01:31:30,810 --> 01:31:33,210
course you know what cogeneration is you

2268
01:31:33,210 --> 01:31:35,340
know there's no AI aspect really to it

2269
01:31:35,340 --> 01:31:37,380
because you're taking a query plan that

2270
01:31:37,380 --> 01:31:40,050
the optimizer spits out that you know

2271
01:31:40,050 --> 01:31:42,030
it's only we're gonna have one way to

2272
01:31:42,030 --> 01:31:44,820
execute it in terms of how you're gonna

2273
01:31:44,820 --> 01:31:47,850
generate the code for it and so there's

2274
01:31:47,850 --> 01:31:51,060
nothing AI to this so again this is sort

2275
01:31:51,060 --> 01:31:53,100
of something I'm hoping you guys can now

2276
01:31:53,100 --> 01:31:55,980
do on your own see things that people

2277
01:31:55,980 --> 01:31:57,810
are saying and use your background you

2278
01:31:57,810 --> 01:31:59,010
gotten from this course to decide

2279
01:31:59,010 --> 01:32:00,270
whether whether they're saying things

2280
01:32:00,270 --> 01:32:03,449
that are plausible okay so again next

2281
01:32:03,449 --> 01:32:05,250
class we'll have a guest speaker from

2282
01:32:05,250 --> 01:32:08,179
Amazon and then for everyone else

2283
01:32:08,179 --> 01:32:11,400
take care Bank it in the side park what

2284
01:32:11,400 --> 01:32:14,170
is this some fools say yo

2285
01:32:14,170 --> 01:32:15,469
[Music]

2286
01:32:15,469 --> 01:32:17,989
especially when they're called the Hokey

2287
01:32:17,989 --> 01:32:21,290
cuz I'm og Ice Cube down with the testy

2288
01:32:21,290 --> 01:32:24,739
hi you look and it was go grab me a 40

2289
01:32:24,739 --> 01:32:27,080
just to get my buzz song cuz I needed

2290
01:32:27,080 --> 01:32:29,360
just a little more kick like a fish

2291
01:32:29,360 --> 01:32:32,739
after just one slipped up to my lips and

2292
01:32:32,739 --> 01:32:37,219
just say nice and my hood won't be to

2293
01:32:37,219 --> 01:32:39,830
say I've diced you take a say I said a

2294
01:32:39,830 --> 01:32:42,130
prayer

