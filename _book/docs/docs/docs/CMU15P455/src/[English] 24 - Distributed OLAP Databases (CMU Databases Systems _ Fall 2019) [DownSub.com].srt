1
00:00:03,640 --> 00:00:13,140
[Music]

2
00:00:14,770 --> 00:00:18,010
let's get started

3
00:00:18,010 --> 00:00:22,070
so DJ drop tables is not here today he

4
00:00:22,070 --> 00:00:24,949
should be here next week he's a bit of

5
00:00:24,949 --> 00:00:28,070
cracking up here so his it's his

6
00:00:28,070 --> 00:00:30,079
girlfriend's birthday this week and he

7
00:00:30,079 --> 00:00:33,440
blew off money last week in Vegas so he

8
00:00:33,440 --> 00:00:35,300
lied and told her that he's going to

9
00:00:35,300 --> 00:00:38,000
visit his family for Thanksgiving so

10
00:00:38,000 --> 00:00:39,320
that's why he's gone this week but

11
00:00:39,320 --> 00:00:40,969
that's just really get out of ruse of

12
00:00:40,969 --> 00:00:43,850
buying him a present so he'll be back

13
00:00:43,850 --> 00:00:45,920
next week alright so again just a

14
00:00:45,920 --> 00:00:47,300
reminder for what's on the docket for

15
00:00:47,300 --> 00:00:50,239
you guys homework 5 is due next week

16
00:00:50,239 --> 00:00:53,269
project 4 we do after that the extra

17
00:00:53,269 --> 00:00:55,129
credit for the feedback submission was

18
00:00:55,129 --> 00:00:56,690
last night

19
00:00:56,690 --> 00:00:59,089
some people emailed about about an error

20
00:00:59,089 --> 00:01:02,239
cuz some funky Unicode issue but

21
00:01:02,239 --> 00:01:04,400
everybody else should have submitted the

22
00:01:04,400 --> 00:01:06,580
final exam will be on December 9th

23
00:01:06,580 --> 00:01:08,510
actually they announced the room but I

24
00:01:08,510 --> 00:01:10,340
have looked to see where it is that has

25
00:01:10,340 --> 00:01:12,890
anybody looked it doesn't matter

26
00:01:12,890 --> 00:01:16,070
we'll figure it out and then for for

27
00:01:16,070 --> 00:01:17,900
next week again the Oracle talk will be

28
00:01:17,900 --> 00:01:20,630
on Monday the assistants popery and the

29
00:01:20,630 --> 00:01:23,750
final review will be on on the Wednesday

30
00:01:23,750 --> 00:01:25,310
so we'll do the final review in the

31
00:01:25,310 --> 00:01:28,009
beginning and then we'll do will cover

32
00:01:28,009 --> 00:01:29,270
three or four different database systems

33
00:01:29,270 --> 00:01:31,430
that you guys voted on and I'll just

34
00:01:31,430 --> 00:01:32,750
sort of give you you know a ten minute

35
00:01:32,750 --> 00:01:34,670
over your what's interesting about it

36
00:01:34,670 --> 00:01:36,350
why it's good why it's bad and so forth

37
00:01:36,350 --> 00:01:37,969
so if you haven't voted yet please

38
00:01:37,969 --> 00:01:40,939
please go in here and vote the numbers

39
00:01:40,939 --> 00:01:45,649
look similar to previous years ah so

40
00:01:45,649 --> 00:01:47,299
again you can go look at the videos and

41
00:01:47,299 --> 00:01:48,020
last year to see what we're gonna

42
00:01:48,020 --> 00:01:50,509
discuss but go vote first then then go

43
00:01:50,509 --> 00:01:53,420
look it up and as I said on Monday

44
00:01:53,420 --> 00:01:54,710
Tuesday next week our friends our Oracle

45
00:01:54,710 --> 00:01:57,049
are coming and there's a gonna be three

46
00:01:57,049 --> 00:01:59,840
different talks so on mondays class in

47
00:01:59,840 --> 00:02:03,229
here they'll be will have Shashank come

48
00:02:03,229 --> 00:02:05,450
and talk about you know there's

49
00:02:05,450 --> 00:02:07,310
something his group is building again

50
00:02:07,310 --> 00:02:08,930
this is not a recruiting talk this is

51
00:02:08,930 --> 00:02:11,270
like a you know a scientific or or

52
00:02:11,270 --> 00:02:13,670
assistant discussion of what they're

53
00:02:13,670 --> 00:02:15,410
building and basically he'll use all the

54
00:02:15,410 --> 00:02:16,760
same key words and buzzwords that I've

55
00:02:16,760 --> 00:02:18,170
used throughout the entire semester so

56
00:02:18,170 --> 00:02:19,800
you realize and I'm not not

57
00:02:19,800 --> 00:02:22,410
is making sure up so he'll come and talk

58
00:02:22,410 --> 00:02:23,700
about their system there's a more

59
00:02:23,700 --> 00:02:25,980
recruiting oriented systems talk will be

60
00:02:25,980 --> 00:02:28,770
Monday at 4:30 in in gates and that one

61
00:02:28,770 --> 00:02:30,780
will be pizza and then a pure research

62
00:02:30,780 --> 00:02:33,360
talk would be on Tuesday December 3rd

63
00:02:33,360 --> 00:02:35,520
the following day at 12 p.m. and the

64
00:02:35,520 --> 00:02:38,870
CICU floor and so the Hideaki Kimura is

65
00:02:38,870 --> 00:02:42,570
as I mentioned on Piazza I went to grad

66
00:02:42,570 --> 00:02:46,110
school with him I he's probably one of

67
00:02:46,110 --> 00:02:48,900
the most hardcore systems programmers

68
00:02:48,900 --> 00:02:50,970
ever met my life he is also the most

69
00:02:50,970 --> 00:02:52,290
stubborn man that I've ever met in my

70
00:02:52,290 --> 00:02:56,100
life when we were building the first the

71
00:02:56,100 --> 00:02:58,230
first summer we were building H store he

72
00:02:58,230 --> 00:03:00,210
wanted we had to build our expression

73
00:03:00,210 --> 00:03:02,310
trees like for the where clauses I had

74
00:03:02,310 --> 00:03:04,110
my way of doing it he had his way we

75
00:03:04,110 --> 00:03:05,730
literally had a four-hour debate in my

76
00:03:05,730 --> 00:03:07,050
office just yelling at each other about

77
00:03:07,050 --> 00:03:08,280
what to do and he just broke me down

78
00:03:08,280 --> 00:03:10,800
said to do it he was wrong and we

79
00:03:10,800 --> 00:03:12,390
removed what he did later on my coats

80
00:03:12,390 --> 00:03:14,520
still there so I was right but in

81
00:03:14,520 --> 00:03:16,440
general he's awesome so he's gonna come

82
00:03:16,440 --> 00:03:19,020
talk about some he's just come talk to

83
00:03:19,020 --> 00:03:20,340
the non-volatile memory stuff that

84
00:03:20,340 --> 00:03:21,660
they've been working on for the system

85
00:03:21,660 --> 00:03:23,520
because he's part of shashank group so

86
00:03:23,520 --> 00:03:24,530
again if you're interested in doing

87
00:03:24,530 --> 00:03:27,000
internships or full-time positions with

88
00:03:27,000 --> 00:03:27,390
them

89
00:03:27,390 --> 00:03:29,040
he will come and tell you the kind of

90
00:03:29,040 --> 00:03:30,750
things you could be working on okay and

91
00:03:30,750 --> 00:03:32,820
I'll some reminders about all these

92
00:03:32,820 --> 00:03:35,250
things on Piazza and the questions about

93
00:03:35,250 --> 00:03:38,970
any of these okay and then I also make

94
00:03:38,970 --> 00:03:39,870
arrangers if you want to eat these guys

95
00:03:39,870 --> 00:03:42,360
one-on-one to talk about internships and

96
00:03:42,360 --> 00:03:43,980
full-time positions as well well I'll

97
00:03:43,980 --> 00:03:47,760
send that email okay so last class was

98
00:03:47,760 --> 00:03:49,680
the second lecture we had on distributed

99
00:03:49,680 --> 00:03:51,450
databases the first class are just

100
00:03:51,450 --> 00:03:53,040
defining what a distributed database

101
00:03:53,040 --> 00:03:54,390
system looks like from architecture

102
00:03:54,390 --> 00:03:56,400
standpoint what are the you know where's

103
00:03:56,400 --> 00:03:58,970
data relative to where the computers

104
00:03:58,970 --> 00:04:00,840
confused actually gonna run on it and

105
00:04:00,840 --> 00:04:02,730
then last class was all about talking

106
00:04:02,730 --> 00:04:04,830
about taking these trip to Stata bases

107
00:04:04,830 --> 00:04:06,180
when you want to do transactions and

108
00:04:06,180 --> 00:04:09,060
making sure that we provide all the

109
00:04:09,060 --> 00:04:11,070
asset guarantees that we'd want on a

110
00:04:11,070 --> 00:04:12,720
single node system but now doing this in

111
00:04:12,720 --> 00:04:14,730
a distribute environment and we spend

112
00:04:14,730 --> 00:04:16,470
most of our time talking about the

113
00:04:16,470 --> 00:04:17,760
atomic commit protocol on replication

114
00:04:17,760 --> 00:04:19,620
because again that's the hard part of

115
00:04:19,620 --> 00:04:20,730
apps you have an issue of your database

116
00:04:20,730 --> 00:04:22,350
when things are split up and now you

117
00:04:22,350 --> 00:04:23,730
have transactions doing rights on a

118
00:04:23,730 --> 00:04:24,780
bunch of different nodes at the same

119
00:04:24,780 --> 00:04:27,120
time how do you keep it all in sync how

120
00:04:27,120 --> 00:04:28,680
do you avoid losing data how do you have

121
00:04:28,680 --> 00:04:30,870
reads not see stale data if you care

122
00:04:30,870 --> 00:04:33,630
about those things so for today

123
00:04:33,630 --> 00:04:35,610
class now we're going to sort up just

124
00:04:35,610 --> 00:04:39,090
leave alone or you know leave all the

125
00:04:39,090 --> 00:04:40,140
transaction stuff we talked about before

126
00:04:40,140 --> 00:04:42,060
and now so I was talking about how to do

127
00:04:42,060 --> 00:04:43,920
analytics where we're not doing a lot of

128
00:04:43,920 --> 00:04:45,390
Rights we're not doing transactions

129
00:04:45,390 --> 00:04:48,150
we're mostly going to be doing reads but

130
00:04:48,150 --> 00:04:49,140
the amount of data we're going to be

131
00:04:49,140 --> 00:04:52,650
reading is much larger than what the old

132
00:04:52,650 --> 00:04:54,360
to be transactions were doing from last

133
00:04:54,360 --> 00:04:57,890
class so I want to show what a sort of a

134
00:04:57,890 --> 00:05:00,960
typical set up would be in a analytical

135
00:05:00,960 --> 00:05:02,220
database and this doesn't does not

136
00:05:02,220 --> 00:05:04,140
necessarily have to be a distributed

137
00:05:04,140 --> 00:05:05,640
database but this is a common

138
00:05:05,640 --> 00:05:07,980
arrangement so on the front end you have

139
00:05:07,980 --> 00:05:09,930
your old to be databases okay this is

140
00:05:09,930 --> 00:05:11,190
where you're ingesting new information

141
00:05:11,190 --> 00:05:14,220
from the outside world and this could be

142
00:05:14,220 --> 00:05:15,330
distributed could be single note it

143
00:05:15,330 --> 00:05:17,370
doesn't matter and then you want to get

144
00:05:17,370 --> 00:05:18,870
all the data from these front-end data

145
00:05:18,870 --> 00:05:21,210
silos into your back-end analytical

146
00:05:21,210 --> 00:05:22,920
database sometimes called a data

147
00:05:22,920 --> 00:05:26,430
warehouse so there's this process called

148
00:05:26,430 --> 00:05:28,650
ETL extract transform the load so

149
00:05:28,650 --> 00:05:30,570
there's tools you can you can buy that

150
00:05:30,570 --> 00:05:32,160
do this we just write Python scripts or

151
00:05:32,160 --> 00:05:34,140
do whatever you do manually but the idea

152
00:05:34,140 --> 00:05:36,210
is that to take all the data from these

153
00:05:36,210 --> 00:05:38,100
different front-end OTP databases and

154
00:05:38,100 --> 00:05:41,970
put it into a universal schema inside

155
00:05:41,970 --> 00:05:44,430
your data warehouse so for example let's

156
00:05:44,430 --> 00:05:47,040
say you have your front-end database one

157
00:05:47,040 --> 00:05:48,600
application has that you know they all

158
00:05:48,600 --> 00:05:50,760
have different customers names but this

159
00:05:50,760 --> 00:05:52,650
one has FM for the first name this one

160
00:05:52,650 --> 00:05:55,170
has first underscore name so you can't

161
00:05:55,170 --> 00:05:56,430
just chuck that all into a single

162
00:05:56,430 --> 00:05:57,720
database because the database doesn't

163
00:05:57,720 --> 00:05:59,820
know that F name equals first name so

164
00:05:59,820 --> 00:06:01,140
this is where you do that cleanup

165
00:06:01,140 --> 00:06:04,710
process here in the ETL world so this is

166
00:06:04,710 --> 00:06:06,600
a very common setup right if you're if

167
00:06:06,600 --> 00:06:08,610
you're gonna build a start up you you

168
00:06:08,610 --> 00:06:10,140
typically start with this because you

169
00:06:10,140 --> 00:06:12,240
need to get data first and then once you

170
00:06:12,240 --> 00:06:13,830
have a lot of data then you want to put

171
00:06:13,830 --> 00:06:15,870
it into your back-end data warehouse and

172
00:06:15,870 --> 00:06:17,040
the idea is that we don't wanna do

173
00:06:17,040 --> 00:06:18,090
analytics on the front end because

174
00:06:18,090 --> 00:06:19,680
that's gonna slow us down or slow down

175
00:06:19,680 --> 00:06:21,330
our transactions so you can put this

176
00:06:21,330 --> 00:06:23,310
into our back-end data warehouse so this

177
00:06:23,310 --> 00:06:24,570
is what we're focusing on today how do

178
00:06:24,570 --> 00:06:29,820
we actually do this so I use the term

179
00:06:29,820 --> 00:06:32,430
OLAP online and local processing

180
00:06:32,430 --> 00:06:34,410
sometimes you'll see see these types of

181
00:06:34,410 --> 00:06:35,850
systems referred to as a data warehouse

182
00:06:35,850 --> 00:06:37,770
or more traditionally sometimes they

183
00:06:37,770 --> 00:06:40,500
call it decision support systems DSS and

184
00:06:40,500 --> 00:06:42,650
again the idea is that these are

185
00:06:42,650 --> 00:06:45,419
applications we're going to right now in

186
00:06:45,419 --> 00:06:47,580
our back-end dip data warehouse

187
00:06:47,580 --> 00:06:51,270
it's gonna analyze the data we have that

188
00:06:51,270 --> 00:06:53,430
we've kept from the OTP side extrapolate

189
00:06:53,430 --> 00:06:55,770
new information and then guide our

190
00:06:55,770 --> 00:06:57,990
decision-making processes for for the

191
00:06:57,990 --> 00:06:59,670
business for the organization or for the

192
00:06:59,670 --> 00:07:02,310
old to be allocations right so very

193
00:07:02,310 --> 00:07:04,080
common set up the one is they've always

194
00:07:04,080 --> 00:07:06,690
like to use is like zinga zinga has all

195
00:07:06,690 --> 00:07:08,460
their stupid farmville games up here

196
00:07:08,460 --> 00:07:09,870
right these are all old to be databases

197
00:07:09,870 --> 00:07:11,580
for every clique in the game that's

198
00:07:11,580 --> 00:07:12,990
another transaction or another update to

199
00:07:12,990 --> 00:07:14,790
the database but then there's a shove

200
00:07:14,790 --> 00:07:18,090
all those clicks into the backend data

201
00:07:18,090 --> 00:07:21,060
warehouse do some analysis on this at

202
00:07:21,060 --> 00:07:22,680
whether your decision support systems or

203
00:07:22,680 --> 00:07:24,330
machine learning to try to figure out

204
00:07:24,330 --> 00:07:25,440
some of how to make you buy

205
00:07:25,440 --> 00:07:28,470
more stuff on the front end right like

206
00:07:28,470 --> 00:07:31,430
the the one example I always heard was

207
00:07:31,430 --> 00:07:34,380
it's the candy crush game if you played

208
00:07:34,380 --> 00:07:36,450
the candy crush game and so you get all

209
00:07:36,450 --> 00:07:38,700
these updates on the OTP side and then

210
00:07:38,700 --> 00:07:40,500
it's a you get a hard puzzle and you

211
00:07:40,500 --> 00:07:42,600
can't beat it right and so you put the

212
00:07:42,600 --> 00:07:44,340
game down so they're gonna collect all

213
00:07:44,340 --> 00:07:45,720
this click stream to see how you played

214
00:07:45,720 --> 00:07:47,820
the game and then they'll learn that oh

215
00:07:47,820 --> 00:07:50,220
if you come back after not having played

216
00:07:50,220 --> 00:07:51,720
the game for like a day because you got

217
00:07:51,720 --> 00:07:53,490
frustrated they make sure you they give

218
00:07:53,490 --> 00:07:54,900
you an easy puzzle that you can solve

219
00:07:54,900 --> 00:07:57,150
right away so you get hooked again right

220
00:07:57,150 --> 00:07:58,380
and then keep playing it because they

221
00:07:58,380 --> 00:07:59,340
know if they give you a hard puzzle

222
00:07:59,340 --> 00:08:00,600
you'll get frustrated and never come

223
00:08:00,600 --> 00:08:01,340
back ever again

224
00:08:01,340 --> 00:08:03,990
right so that extrapolating that

225
00:08:03,990 --> 00:08:05,610
information that oh this is how I give

226
00:08:05,610 --> 00:08:07,980
you know the person you know a game that

227
00:08:07,980 --> 00:08:09,540
they'll be able to beat you figure that

228
00:08:09,540 --> 00:08:12,030
out on this side and then you push the

229
00:08:12,030 --> 00:08:17,520
update to the OTP side so the in general

230
00:08:17,520 --> 00:08:19,170
at high level there's two different ways

231
00:08:19,170 --> 00:08:23,370
you can model a database application on

232
00:08:23,370 --> 00:08:24,960
a back-end data warehouse or analytical

233
00:08:24,960 --> 00:08:27,240
database so you could take the standard

234
00:08:27,240 --> 00:08:29,880
schema that you know your application

235
00:08:29,880 --> 00:08:31,230
would have like typically it's usually a

236
00:08:31,230 --> 00:08:32,130
tree schema because you have this

237
00:08:32,130 --> 00:08:33,929
hierarchy I have customers customers

238
00:08:33,929 --> 00:08:37,770
have orders orders have items but those

239
00:08:37,770 --> 00:08:39,360
schemas can be quite messy and they're

240
00:08:39,360 --> 00:08:41,010
not going to be very efficient for

241
00:08:41,010 --> 00:08:44,490
analytical queries so instead you would

242
00:08:44,490 --> 00:08:46,080
model your database using either what's

243
00:08:46,080 --> 00:08:47,460
called a star schema or a snowflake

244
00:08:47,460 --> 00:08:49,560
schema and sometimes you see analytical

245
00:08:49,560 --> 00:08:52,170
databases that they'll say hey we only

246
00:08:52,170 --> 00:08:53,940
support star schemas you can't do a

247
00:08:53,940 --> 00:08:55,980
snowflake schema you'll see this is

248
00:08:55,980 --> 00:08:58,290
basically a subset of this but you see

249
00:08:58,290 --> 00:09:00,360
why let's discuss why this matching

250
00:09:00,360 --> 00:09:01,270
might be better for it

251
00:09:01,270 --> 00:09:06,670
some analytics so a very common

252
00:09:06,670 --> 00:09:08,560
arrangement would be something like this

253
00:09:08,560 --> 00:09:10,720
so this this is a star schema and you

254
00:09:10,720 --> 00:09:12,040
have two types of tables in a star

255
00:09:12,040 --> 00:09:13,450
schema you have facts tables and

256
00:09:13,450 --> 00:09:15,370
dimension tables so the middle of the

257
00:09:15,370 --> 00:09:17,950
star is the fact table think of this is

258
00:09:17,950 --> 00:09:19,930
like every city event you're trying to

259
00:09:19,930 --> 00:09:22,120
model this is where you store all the

260
00:09:22,120 --> 00:09:23,830
occurrences of them so if you're like

261
00:09:23,830 --> 00:09:26,620
Walmart and your data warehouse keeps

262
00:09:26,620 --> 00:09:28,330
track of every single item that emam I

263
00:09:28,330 --> 00:09:30,670
don't anyone has ever bought at any

264
00:09:30,670 --> 00:09:32,620
Walmart stored at any given time all of

265
00:09:32,620 --> 00:09:34,330
those items getting scanned at the cash

266
00:09:34,330 --> 00:09:36,670
check or the checkout counter that's

267
00:09:36,670 --> 00:09:38,290
another event that we've put in our fact

268
00:09:38,290 --> 00:09:40,510
table so this thing is gonna be massive

269
00:09:40,510 --> 00:09:42,580
like hundreds of billions of records

270
00:09:42,580 --> 00:09:44,560
same thing Amazon every single item that

271
00:09:44,560 --> 00:09:46,270
anyone's ever bought on Amazon goes and

272
00:09:46,270 --> 00:09:48,280
you're in your fact table but we're not

273
00:09:48,280 --> 00:09:50,200
actually going to store any information

274
00:09:50,200 --> 00:09:51,910
about what these items are that someone

275
00:09:51,910 --> 00:09:54,130
bought won't stick and have foreign key

276
00:09:54,130 --> 00:09:57,690
references to our outer dimension tables

277
00:09:57,690 --> 00:09:59,650
where they're going to maintain that

278
00:09:59,650 --> 00:10:02,230
additional information all right cuz can

279
00:10:02,230 --> 00:10:04,120
this is things we massive we want this

280
00:10:04,120 --> 00:10:06,850
to be through as trim as possible

281
00:10:06,850 --> 00:10:08,830
because we have billions of rows so we

282
00:10:08,830 --> 00:10:10,630
put all the actual metadata in the in

283
00:10:10,630 --> 00:10:12,820
the dimension tables but in a scarce in

284
00:10:12,820 --> 00:10:15,910
a star schema you can only have one one

285
00:10:15,910 --> 00:10:18,070
level dimension tables out from the

286
00:10:18,070 --> 00:10:21,310
center of the of the of the star right

287
00:10:21,310 --> 00:10:23,170
so there's no additional tables over

288
00:10:23,170 --> 00:10:25,510
here that these guys can join with right

289
00:10:25,510 --> 00:10:27,040
in this case here I have a category

290
00:10:27,040 --> 00:10:29,830
named a category description so I could

291
00:10:29,830 --> 00:10:31,720
extract that out and normalize that

292
00:10:31,720 --> 00:10:33,220
store that has another dimension table

293
00:10:33,220 --> 00:10:34,480
with another foreign key going from this

294
00:10:34,480 --> 00:10:37,030
to this but under a star schema your

295
00:10:37,030 --> 00:10:38,560
your you know you're not allowed to do

296
00:10:38,560 --> 00:10:48,160
that and we take a guess why yes exactly

297
00:10:48,160 --> 00:10:49,540
so you said the time it takes you to

298
00:10:49,540 --> 00:10:52,210
diverse or join those different tables

299
00:10:52,210 --> 00:10:53,800
is going to be expensive because again

300
00:10:53,800 --> 00:10:55,870
we're not doing like fine ll and ease

301
00:10:55,870 --> 00:10:56,350
items

302
00:10:56,350 --> 00:10:59,500
we're saying find all the items that the

303
00:10:59,500 --> 00:11:01,240
you know that the state of Pennsylvania

304
00:11:01,240 --> 00:11:03,400
has bought within this date range can be

305
00:11:03,400 --> 00:11:05,770
hundreds of millions of rows solely so

306
00:11:05,770 --> 00:11:08,110
we want to avoid as much as doing as

307
00:11:08,110 --> 00:11:11,380
many joins as possible so a snowflake

308
00:11:11,380 --> 00:11:12,760
schema is where you're allowed to do

309
00:11:12,760 --> 00:11:13,560
have multiple dimension

310
00:11:13,560 --> 00:11:15,720
outside of it right so again going back

311
00:11:15,720 --> 00:11:18,029
up here right I have now can break out

312
00:11:18,029 --> 00:11:19,620
my category information I have a foreign

313
00:11:19,620 --> 00:11:21,029
key in the product dimension table and

314
00:11:21,029 --> 00:11:22,830
then I have what is called now a lookup

315
00:11:22,830 --> 00:11:25,380
table which is the things beyond the

316
00:11:25,380 --> 00:11:27,170
mention table where I have that

317
00:11:27,170 --> 00:11:29,930
normalized information as the output and

318
00:11:29,930 --> 00:11:33,750
as I said a some database system some

319
00:11:33,750 --> 00:11:35,580
OLAP systems will say explicitly you

320
00:11:35,580 --> 00:11:37,710
can't have look-up tables you can't have

321
00:11:37,710 --> 00:11:39,450
multiple levels beyond the first

322
00:11:39,450 --> 00:11:45,089
dimension table so the the main sort of

323
00:11:45,089 --> 00:11:46,920
two issues in this world as she sort of

324
00:11:46,920 --> 00:11:49,350
said one of them is performance the

325
00:11:49,350 --> 00:11:51,570
other one is actually going to be the

326
00:11:51,570 --> 00:11:53,430
the integrity of the data that were

327
00:11:53,430 --> 00:11:58,110
storing again so going back here if I if

328
00:11:58,110 --> 00:12:00,180
I collapse down my lookup table into a

329
00:12:00,180 --> 00:12:01,920
single dimension table well I'm gonna be

330
00:12:01,920 --> 00:12:03,660
repeating the category name over and

331
00:12:03,660 --> 00:12:06,089
over again so now if the category name

332
00:12:06,089 --> 00:12:07,710
changes I need to make sure in my

333
00:12:07,710 --> 00:12:10,529
application code that I go update all

334
00:12:10,529 --> 00:12:12,029
the records that have that same category

335
00:12:12,029 --> 00:12:13,920
name so that everything is in sync if

336
00:12:13,920 --> 00:12:16,380
I'm normalized out like this in the

337
00:12:16,380 --> 00:12:17,400
snowflake schema I don't have that

338
00:12:17,400 --> 00:12:18,660
problem because I don't have one entry

339
00:12:18,660 --> 00:12:22,730
for the category right so if you do a

340
00:12:22,730 --> 00:12:24,839
star schema then this extra work that

341
00:12:24,839 --> 00:12:26,460
you have to do in your application to

342
00:12:26,460 --> 00:12:29,160
make sure that your your denormalized

343
00:12:29,160 --> 00:12:32,339
tables are are consistent you now

344
00:12:32,339 --> 00:12:34,020
actually potentially storing more

345
00:12:34,020 --> 00:12:35,490
redundant information that's unnecessary

346
00:12:35,490 --> 00:12:37,770
and so your size your database could be

347
00:12:37,770 --> 00:12:39,810
larger it's not that big of a deal

348
00:12:39,810 --> 00:12:41,790
because again the fact table is the main

349
00:12:41,790 --> 00:12:44,430
is the main juggernaut in this in this

350
00:12:44,430 --> 00:12:47,400
model and we will have ways to compress

351
00:12:47,400 --> 00:12:50,190
that down so the the storage overhead of

352
00:12:50,190 --> 00:12:52,140
denormalized tables is not that big of a

353
00:12:52,140 --> 00:12:53,820
deal it's more the integrity stuff

354
00:12:53,820 --> 00:12:55,710
that's more important and then as she

355
00:12:55,710 --> 00:12:58,830
said the complexity of the queries with

356
00:12:58,830 --> 00:13:02,430
a star schema are gonna be significantly

357
00:13:02,430 --> 00:13:04,170
less than the complexity of the queries

358
00:13:04,170 --> 00:13:06,420
in a snowflake schema because there's

359
00:13:06,420 --> 00:13:09,209
only so many joins I could possibly do I

360
00:13:09,209 --> 00:13:11,120
only have to go sort of one level deep

361
00:13:11,120 --> 00:13:13,050
as we talked about we talked about a

362
00:13:13,050 --> 00:13:15,570
quart apptimize ation the having more

363
00:13:15,570 --> 00:13:17,310
tables or join against just makes

364
00:13:17,310 --> 00:13:18,720
everything super harder when we have to

365
00:13:18,720 --> 00:13:21,420
figure out the joint ordering and so by

366
00:13:21,420 --> 00:13:23,040
restricting ourselves to a star schema

367
00:13:23,040 --> 00:13:25,320
but may end up finding a the optimal

368
00:13:25,320 --> 00:13:27,240
plan whereas the snowflake schema

369
00:13:27,240 --> 00:13:31,290
we may not be able to so again when you

370
00:13:31,290 --> 00:13:32,519
go out in a real world if you come

371
00:13:32,519 --> 00:13:33,959
across data warehouses you're likely to

372
00:13:33,959 --> 00:13:36,929
see either these two approaches because

373
00:13:36,929 --> 00:13:39,360
they're better for analytics and this

374
00:13:39,360 --> 00:13:42,389
this distinction between the dimension

375
00:13:42,389 --> 00:13:43,829
table and the fact table will come up

376
00:13:43,829 --> 00:13:45,569
when we start talking about doing joins

377
00:13:45,569 --> 00:13:47,639
because we need to decide how we're

378
00:13:47,639 --> 00:13:50,040
going to move data between nodes if we

379
00:13:50,040 --> 00:13:51,839
can't do any local joins a town are

380
00:13:51,839 --> 00:13:56,579
machines okay all right so let's talk

381
00:13:56,579 --> 00:13:57,329
about the problem we trying to solve

382
00:13:57,329 --> 00:14:00,959
today and I've already sort of briefly

383
00:14:00,959 --> 00:14:02,850
just mentioned just now so our query

384
00:14:02,850 --> 00:14:04,230
shows up in a master node that wants to

385
00:14:04,230 --> 00:14:07,920
join on our NS and let's say that the

386
00:14:07,920 --> 00:14:10,829
two tables R and s are just split across

387
00:14:10,829 --> 00:14:12,119
the different partitions on the

388
00:14:12,119 --> 00:14:16,139
different nodes uniformly so what's the

389
00:14:16,139 --> 00:14:17,550
stupidest way for me to execute this

390
00:14:17,550 --> 00:14:29,069
query in this set up yes exactly right

391
00:14:29,069 --> 00:14:31,019
the dumbest thing I could do and it

392
00:14:31,019 --> 00:14:32,339
would work it would still be correct is

393
00:14:32,339 --> 00:14:34,529
that I I know I need touch data set

394
00:14:34,529 --> 00:14:36,420
partitions two three and four and so I

395
00:14:36,420 --> 00:14:38,819
just copy them in their entirety up into

396
00:14:38,819 --> 00:14:41,100
the the node where partition one is now

397
00:14:41,100 --> 00:14:43,499
all my data is local I do my joint and

398
00:14:43,499 --> 00:14:47,329
spit back the result why is that stupid

399
00:14:47,329 --> 00:14:51,959
yes he says me you may not need all the

400
00:14:51,959 --> 00:14:54,299
data potentially yes but team Team

401
00:14:54,299 --> 00:15:00,720
stupider yes absolutely yeah you're not

402
00:15:00,720 --> 00:15:01,949
doing any computation on the other nodes

403
00:15:01,949 --> 00:15:04,199
like this defeats the whole purpose of

404
00:15:04,199 --> 00:15:06,420
having your stupid database all right

405
00:15:06,420 --> 00:15:07,589
think about what I did I bought a bunch

406
00:15:07,589 --> 00:15:09,420
of machines I partition my date at my

407
00:15:09,420 --> 00:15:11,249
table across these machines but then my

408
00:15:11,249 --> 00:15:12,779
query shows up and I just copy things

409
00:15:12,779 --> 00:15:14,429
back over to the singing machine anyway

410
00:15:14,429 --> 00:15:16,259
so I bet it would have been better off

411
00:15:16,259 --> 00:15:17,939
just buying this one machine and doing

412
00:15:17,939 --> 00:15:21,660
the join there right so this is the

413
00:15:21,660 --> 00:15:22,649
problem we're trying to solve today

414
00:15:22,649 --> 00:15:24,569
we're trying to say all right if a query

415
00:15:24,569 --> 00:15:26,129
shows up and it wants to do a join we

416
00:15:26,129 --> 00:15:27,689
need access data that's put now across

417
00:15:27,689 --> 00:15:30,929
multiple resources how do we actually

418
00:15:30,929 --> 00:15:31,980
how do we actually do this efficiently

419
00:15:31,980 --> 00:15:33,389
what do we what do we need to be mindful

420
00:15:33,389 --> 00:15:36,089
of when we decide whether we move data

421
00:15:36,089 --> 00:15:38,549
or copy data or push the query or pull

422
00:15:38,549 --> 00:15:40,769
the you know pull the results all right

423
00:15:40,769 --> 00:15:41,500
these are all bit

424
00:15:41,500 --> 00:15:43,300
we have to deal with the threat this

425
00:15:43,300 --> 00:15:45,250
also assumes in this example that my

426
00:15:45,250 --> 00:15:46,780
database can it can fit in on a single

427
00:15:46,780 --> 00:15:49,630
node right again think of like the

428
00:15:49,630 --> 00:15:51,670
Walmart database it's whatever hundreds

429
00:15:51,670 --> 00:15:53,680
of petabytes it's not gonna fit on a

430
00:15:53,680 --> 00:15:55,720
single machine so we're gonna happen run

431
00:15:55,720 --> 00:15:57,040
attribute environment order to get any

432
00:15:57,040 --> 00:15:58,500
any work done

433
00:15:58,500 --> 00:16:00,790
OTP it's not an issue for kids again Oh

434
00:16:00,790 --> 00:16:03,340
an OTP I'm only touching andis data and

435
00:16:03,340 --> 00:16:05,950
E's data is maybe couple hundreds of

436
00:16:05,950 --> 00:16:09,100
kilobytes or megabytes right it's not I

437
00:16:09,100 --> 00:16:10,870
can easily fit that on a single box and

438
00:16:10,870 --> 00:16:12,460
do all my transactions on that one box

439
00:16:12,460 --> 00:16:14,890
in analytics I'm trying to touch the

440
00:16:14,890 --> 00:16:16,600
entire table or large portions of the

441
00:16:16,600 --> 00:16:18,370
table I'm not going to be able to do

442
00:16:18,370 --> 00:16:21,130
everything on a single node so today our

443
00:16:21,130 --> 00:16:22,510
focus is going to be on first discussing

444
00:16:22,510 --> 00:16:24,460
the excuse your models we have in a

445
00:16:24,460 --> 00:16:25,870
distributed database system for

446
00:16:25,870 --> 00:16:26,410
analytics

447
00:16:26,410 --> 00:16:27,940
we've already briefly touched on this a

448
00:16:27,940 --> 00:16:29,260
little bit in the first lecture but now

449
00:16:29,260 --> 00:16:30,910
we'll talk about it more more concretely

450
00:16:30,910 --> 00:16:32,710
and see why it matters then let's

451
00:16:32,710 --> 00:16:34,240
briefly talk about the issues doing

452
00:16:34,240 --> 00:16:35,950
query planning then we'll talk about how

453
00:16:35,950 --> 00:16:38,050
we do distributed joins the spoiler

454
00:16:38,050 --> 00:16:39,520
would be that all the algorithms we

455
00:16:39,520 --> 00:16:40,780
talked about early in the semester are

456
00:16:40,780 --> 00:16:42,550
still still remain we still do them

457
00:16:42,550 --> 00:16:44,890
there's no magic distributed join that

458
00:16:44,890 --> 00:16:47,680
doesn't exist on a single node it's just

459
00:16:47,680 --> 00:16:48,940
the question is again where do we move

460
00:16:48,940 --> 00:16:51,250
data or where did we where do we move

461
00:16:51,250 --> 00:16:53,170
the computation and then I'll finish up

462
00:16:53,170 --> 00:16:56,080
with sort of a quick smattering of what

463
00:16:56,080 --> 00:16:57,370
this sort of state of the art of cloud

464
00:16:57,370 --> 00:16:59,730
databases look like in the world today

465
00:16:59,730 --> 00:17:03,310
and just you know just it again you'll

466
00:17:03,310 --> 00:17:05,140
see how just because it's in the cloud

467
00:17:05,140 --> 00:17:06,760
doesn't mean we still don't care about

468
00:17:06,760 --> 00:17:08,050
all the things we talked about the

469
00:17:08,050 --> 00:17:12,099
entire semester okay all right so as I

470
00:17:12,099 --> 00:17:13,689
said I briefly touch about this first

471
00:17:13,689 --> 00:17:16,510
issue for the execution model or when we

472
00:17:16,510 --> 00:17:18,160
talked about just to the introduction to

473
00:17:18,160 --> 00:17:22,480
distributed databases but the two two

474
00:17:22,480 --> 00:17:23,980
approaches we have to execute a query

475
00:17:23,980 --> 00:17:27,880
are either a push versus a pool so with

476
00:17:27,880 --> 00:17:30,310
a push the idea is that we want to send

477
00:17:30,310 --> 00:17:32,860
the the query or the portion of the

478
00:17:32,860 --> 00:17:35,590
query like the plan fragment to the

479
00:17:35,590 --> 00:17:38,410
location of where the data is located

480
00:17:38,410 --> 00:17:40,780
then run that portion of the query at

481
00:17:40,780 --> 00:17:44,260
that local data and then now just send

482
00:17:44,260 --> 00:17:46,390
back the result to whoever asked for it

483
00:17:46,390 --> 00:17:49,150
like the home node or the base note

484
00:17:49,150 --> 00:17:52,600
that's coordinating the query the idea

485
00:17:52,600 --> 00:17:55,419
here is that we want to just as we

486
00:17:55,419 --> 00:17:57,879
we do projection pushdown or predicate

487
00:17:57,879 --> 00:18:00,009
push down on a single node system we

488
00:18:00,009 --> 00:18:02,289
want to filter out and remove as much

489
00:18:02,289 --> 00:18:06,279
useless data as early as possible before

490
00:18:06,279 --> 00:18:08,950
we send anything over the network so if

491
00:18:08,950 --> 00:18:10,359
we can send a portion of the query to

492
00:18:10,359 --> 00:18:12,940
where the data is located crunch on it

493
00:18:12,940 --> 00:18:14,649
there do some early filtering and then

494
00:18:14,649 --> 00:18:15,969
when we transmit the data back to

495
00:18:15,969 --> 00:18:17,979
another node we're not just blindly

496
00:18:17,979 --> 00:18:20,229
copying all the data that the node has

497
00:18:20,229 --> 00:18:22,359
we're just limiting it to the subset of

498
00:18:22,359 --> 00:18:23,709
that we actually need for this

499
00:18:23,709 --> 00:18:27,549
particular query now we'll see in a

500
00:18:27,549 --> 00:18:30,159
second the lines get blurred and I

501
00:18:30,159 --> 00:18:31,450
shared this system whether you're doing

502
00:18:31,450 --> 00:18:32,649
one of versus another because in a

503
00:18:32,649 --> 00:18:34,869
shared distance to system in general you

504
00:18:34,869 --> 00:18:36,369
can't do any filtering because it's just

505
00:18:36,369 --> 00:18:37,989
a just you know read and write a single

506
00:18:37,989 --> 00:18:40,599
page you can't do anything special but

507
00:18:40,599 --> 00:18:42,669
for shared disk systems again the lines

508
00:18:42,669 --> 00:18:45,369
are blurred the other approach is to

509
00:18:45,369 --> 00:18:46,779
pull the data at the query which is what

510
00:18:46,779 --> 00:18:49,289
I shared this system normally would do

511
00:18:49,289 --> 00:18:52,450
where we grab whatever the data we need

512
00:18:52,450 --> 00:18:54,070
for actually this query we recognize

513
00:18:54,070 --> 00:18:57,039
based on the query plan you know these

514
00:18:57,039 --> 00:18:58,989
are the pages I want to access we pull

515
00:18:58,989 --> 00:19:00,519
the data out make a copy of it

516
00:19:00,519 --> 00:19:02,139
transmitted over the network bring it to

517
00:19:02,139 --> 00:19:04,089
the node where our query is located then

518
00:19:04,089 --> 00:19:05,940
we can then process it and crunch on it

519
00:19:05,940 --> 00:19:08,289
and of course again the dish issue here

520
00:19:08,289 --> 00:19:11,379
is that in an analytical system the the

521
00:19:11,379 --> 00:19:13,779
amount of data the size of the data are

522
00:19:13,779 --> 00:19:15,579
relative to the size of the query is

523
00:19:15,579 --> 00:19:17,889
gonna be quite quite starve equate

524
00:19:17,889 --> 00:19:19,959
different like a query say it's just a

525
00:19:19,959 --> 00:19:23,440
sequel query couple kilobytes the most

526
00:19:23,440 --> 00:19:26,249
I've ever heard from like Google or

527
00:19:26,249 --> 00:19:28,269
Facebook is that sometimes they have

528
00:19:28,269 --> 00:19:29,409
queries that are like like the sequel

529
00:19:29,409 --> 00:19:31,859
text itself is like 10 megabytes right

530
00:19:31,859 --> 00:19:34,299
that's that's a large as query but still

531
00:19:34,299 --> 00:19:36,219
that compared to like reading a terabyte

532
00:19:36,219 --> 00:19:39,519
of data it's nothing so the thing we

533
00:19:39,519 --> 00:19:40,749
have to be mindful whether you want to

534
00:19:40,749 --> 00:19:42,190
one versus the other is you know where's

535
00:19:42,190 --> 00:19:43,899
the data located how can I access it and

536
00:19:43,899 --> 00:19:45,940
is my query going to be larger or

537
00:19:45,940 --> 00:19:48,759
smaller in size to transmit over the

538
00:19:48,759 --> 00:19:50,079
network then the data I'm trying to

539
00:19:50,079 --> 00:19:52,570
access and in analytics it's it's always

540
00:19:52,570 --> 00:19:54,009
the case that the the data you're trying

541
00:19:54,009 --> 00:19:57,039
to crunch on is larger so let's see this

542
00:19:57,039 --> 00:19:59,109
in the context of a shared nothing

543
00:19:59,109 --> 00:20:00,940
system so shared nothing systems are

544
00:20:00,940 --> 00:20:03,249
typically push data to push the query to

545
00:20:03,249 --> 00:20:05,589
the node so my query shows up to this

546
00:20:05,589 --> 00:20:07,179
node here it's in charge of coordinating

547
00:20:07,179 --> 00:20:09,309
with the other node to process

548
00:20:09,309 --> 00:20:11,740
process the join so we're gonna do our

549
00:20:11,740 --> 00:20:15,249
query planner I want to say on this node

550
00:20:15,249 --> 00:20:16,990
if we had recognized oh we need to

551
00:20:16,990 --> 00:20:20,889
access the the ID field for our NS

552
00:20:20,889 --> 00:20:23,289
tables and I know that this node down

553
00:20:23,289 --> 00:20:26,019
here has a partition that I want to

554
00:20:26,019 --> 00:20:27,879
access so I'll just send information

555
00:20:27,879 --> 00:20:30,039
I'll send the query plan fragment down

556
00:20:30,039 --> 00:20:31,960
to this guy and say hey I know you have

557
00:20:31,960 --> 00:20:34,960
this data between 101 and 201 chievous

558
00:20:34,960 --> 00:20:36,999
join and then send me back the result

559
00:20:36,999 --> 00:20:39,669
and the node up above is responsible for

560
00:20:39,669 --> 00:20:42,009
taking the result of that this guy sent

561
00:20:42,009 --> 00:20:44,710
plus it's local result combining them

562
00:20:44,710 --> 00:20:46,450
together to then produce a sing result

563
00:20:46,450 --> 00:20:49,179
back to the application so again we had

564
00:20:49,179 --> 00:20:50,950
this transparency issue or transparency

565
00:20:50,950 --> 00:20:53,619
guarantee where the application doesn't

566
00:20:53,619 --> 00:20:55,779
know doesn't care where the query

567
00:20:55,779 --> 00:20:56,710
actually executed

568
00:20:56,710 --> 00:21:02,019
long as it gets back a single result so

569
00:21:02,019 --> 00:21:03,639
in a shared nothing system it's quite

570
00:21:03,639 --> 00:21:05,919
obvious that you'd want to do push the

571
00:21:05,919 --> 00:21:07,149
courage of the data right because this

572
00:21:07,149 --> 00:21:08,379
makes no sense for us to actually have

573
00:21:08,379 --> 00:21:09,940
to copy this data up and processes it

574
00:21:09,940 --> 00:21:11,919
there it's just better just to send the

575
00:21:11,919 --> 00:21:15,129
query do the crunching locally for this

576
00:21:15,129 --> 00:21:16,419
example we'll see some scenarios where

577
00:21:16,419 --> 00:21:21,840
maybe you do want to do do some copy yes

578
00:21:22,860 --> 00:21:24,999
your question is what if if s is

579
00:21:24,999 --> 00:21:27,730
distributed as well then what well in

580
00:21:27,730 --> 00:21:29,230
this case here it is distribute I'm just

581
00:21:29,230 --> 00:21:30,850
saying like it's partitioned just but

582
00:21:30,850 --> 00:21:31,570
it's partition

583
00:21:31,570 --> 00:21:33,820
well common to your question later on

584
00:21:33,820 --> 00:21:39,009
like correct what we'll come to that

585
00:21:39,009 --> 00:21:40,809
later the in this simple example assume

586
00:21:40,809 --> 00:21:43,570
that R and s are both partition on IDE

587
00:21:43,570 --> 00:21:46,600
the ranges of the values at this

588
00:21:46,600 --> 00:21:48,429
partition are exactly the same so

589
00:21:48,429 --> 00:21:49,899
therefore I know when I'm doing a joint

590
00:21:49,899 --> 00:21:51,820
at this node I don't need to look at any

591
00:21:51,820 --> 00:21:54,009
other other partition in my cluster

592
00:21:54,009 --> 00:21:55,960
everything I need to have computer node

593
00:21:55,960 --> 00:22:00,240
for a single tuple in R is located here

594
00:22:00,240 --> 00:22:02,350
but yeah exactly right I'm joining the

595
00:22:02,350 --> 00:22:03,700
partition key well see those scenarios

596
00:22:03,700 --> 00:22:07,559
in a second yes question

597
00:22:14,169 --> 00:22:18,500
the question is in my example here my

598
00:22:18,500 --> 00:22:21,080
tables are partitioned on my joint key

599
00:22:21,080 --> 00:22:22,669
which is the best case scenario how

600
00:22:22,669 --> 00:22:30,860
often does that happen usually for the

601
00:22:30,860 --> 00:22:36,340
fact table pretty often right like I

602
00:22:36,970 --> 00:22:40,549
would say it's pretty common let me

603
00:22:40,549 --> 00:22:42,169
think about it like in a real system

604
00:22:42,169 --> 00:22:44,500
like so I want to partition I

605
00:22:44,500 --> 00:22:49,970
partitioned on user IDs and you know the

606
00:22:49,970 --> 00:22:52,340
fact table could say here's this this

607
00:22:52,340 --> 00:22:57,409
person bought this item and so it's a

608
00:22:57,409 --> 00:23:00,110
bad example so say I want to do a join

609
00:23:00,110 --> 00:23:02,510
between like here's here's the user IDs

610
00:23:02,510 --> 00:23:03,860
and here's all their items that they

611
00:23:03,860 --> 00:23:05,809
bought and then here's the session of

612
00:23:05,809 --> 00:23:08,539
how they visited the webpage just to

613
00:23:08,539 --> 00:23:09,769
figure out what items I looked at before

614
00:23:09,769 --> 00:23:11,059
I bought something anyone trying to

615
00:23:11,059 --> 00:23:13,220
figure out to learn like oh if they go

616
00:23:13,220 --> 00:23:15,320
look at these much items then they're

617
00:23:15,320 --> 00:23:17,000
more likely to buy something and so in

618
00:23:17,000 --> 00:23:18,470
that case the user ID would be the

619
00:23:18,470 --> 00:23:19,580
partitioning key and that would work out

620
00:23:19,580 --> 00:23:21,350
nicely so it's not always the case but I

621
00:23:21,350 --> 00:23:23,360
would say it's common enough but we'll

622
00:23:23,360 --> 00:23:24,620
see in a second how we handle case where

623
00:23:24,620 --> 00:23:27,049
it's not this like this the main thing I

624
00:23:27,049 --> 00:23:29,630
emphasized here is we can push the query

625
00:23:29,630 --> 00:23:32,690
to the data and that's be better for us

626
00:23:32,690 --> 00:23:34,490
because this this data is gonna be

627
00:23:34,490 --> 00:23:36,769
larger than then this guy here plus we

628
00:23:36,769 --> 00:23:38,450
can also get the the additional benefit

629
00:23:38,450 --> 00:23:39,889
that we paralyzed the computation

630
00:23:39,889 --> 00:23:41,899
because now the top node doesn't have to

631
00:23:41,899 --> 00:23:44,269
do all join this guy can do the join you

632
00:23:44,269 --> 00:23:45,649
know portion the join and this guy can

633
00:23:45,649 --> 00:23:46,940
do the other portion the join and we

634
00:23:46,940 --> 00:23:48,139
just combine it together and the

635
00:23:48,139 --> 00:23:50,149
combined part is cheaper it's cheap

636
00:23:50,149 --> 00:23:54,980
relative to the joint cost so the other

637
00:23:54,980 --> 00:23:56,450
approach is the pool the data to the

638
00:23:56,450 --> 00:23:57,980
query again this is where I'm saying in

639
00:23:57,980 --> 00:23:59,389
a shared disk system the lines are

640
00:23:59,389 --> 00:24:02,750
blurred so we send our query to this

641
00:24:02,750 --> 00:24:05,240
node here this node would recognize that

642
00:24:05,240 --> 00:24:07,279
we've logically partitioned the data

643
00:24:07,279 --> 00:24:08,899
such that this node down here is

644
00:24:08,899 --> 00:24:11,240
responsible for this range that node on

645
00:24:11,240 --> 00:24:13,909
top of that range so then they then go

646
00:24:13,909 --> 00:24:17,360
to the the share disk go access those

647
00:24:17,360 --> 00:24:20,270
pages pull back the results or so pull

648
00:24:20,270 --> 00:24:22,160
back the pages they need

649
00:24:22,160 --> 00:24:23,930
and they compute their local join and

650
00:24:23,930 --> 00:24:26,570
then this guy shows up the result to the

651
00:24:26,570 --> 00:24:30,140
other one so again this step here would

652
00:24:30,140 --> 00:24:34,370
be pulled of data to the query because

653
00:24:34,370 --> 00:24:35,990
I'm just blindly asking for pages where

654
00:24:35,990 --> 00:24:37,910
it's located here and I have to copy it

655
00:24:37,910 --> 00:24:39,890
over here but then certainly this part

656
00:24:39,890 --> 00:24:41,780
here was push the query to the data

657
00:24:41,780 --> 00:24:43,760
because this guy was able to you know

658
00:24:43,760 --> 00:24:45,650
compute the join locally and send the

659
00:24:45,650 --> 00:24:46,310
result up

660
00:24:46,310 --> 00:24:49,160
so would you say that this is a pool

661
00:24:49,160 --> 00:24:55,520
versus a push again it's both well see

662
00:24:55,520 --> 00:25:00,140
it it will I don't think I've a slide

663
00:25:00,140 --> 00:25:03,770
about this but the cloud vendors are

664
00:25:03,770 --> 00:25:06,500
recognizing about having a dumb disks if

665
00:25:06,500 --> 00:25:07,910
you want to call it that

666
00:25:07,910 --> 00:25:09,920
Indy share just databases is a bad idea

667
00:25:09,920 --> 00:25:11,720
because again I'm just always copying

668
00:25:11,720 --> 00:25:13,880
this page without checking to see

669
00:25:13,880 --> 00:25:15,110
whether actually need end the date on

670
00:25:15,110 --> 00:25:16,790
the page I just know that I think I need

671
00:25:16,790 --> 00:25:18,170
to look at it so I just say go give me

672
00:25:18,170 --> 00:25:20,510
this page on like Amazon s3 they now

673
00:25:20,510 --> 00:25:22,070
have a filter command where you actually

674
00:25:22,070 --> 00:25:24,380
can do predicate push down and even when

675
00:25:24,380 --> 00:25:25,850
you say go get this page you can also

676
00:25:25,850 --> 00:25:27,740
say like oh but it also check this

677
00:25:27,740 --> 00:25:28,850
filter for me to see whether everything

678
00:25:28,850 --> 00:25:30,740
actually matches inside the page and if

679
00:25:30,740 --> 00:25:33,220
yes then send it to me if no then don't

680
00:25:33,220 --> 00:25:35,900
write so again that's pushing the query

681
00:25:35,900 --> 00:25:38,870
to the data so again the lines are

682
00:25:38,870 --> 00:25:45,080
blurred okay so one thing we talk about

683
00:25:45,080 --> 00:25:48,950
though is that I said that last class we

684
00:25:48,950 --> 00:25:52,610
made a big deal about if we have a

685
00:25:52,610 --> 00:25:54,500
transaction commit and it touches

686
00:25:54,500 --> 00:25:56,810
multiple nodes I want to make sure that

687
00:25:56,810 --> 00:25:58,730
everyone agrees that all the nodes would

688
00:25:58,730 --> 00:25:59,990
have to agree that this transaction is

689
00:25:59,990 --> 00:26:02,030
allowed to commit before retail the

690
00:26:02,030 --> 00:26:04,190
outside world then it committed all

691
00:26:04,190 --> 00:26:05,060
right because because we're modifying

692
00:26:05,060 --> 00:26:06,410
the database we don't want to lose any

693
00:26:06,410 --> 00:26:10,430
changes but in an OLAP database weird is

694
00:26:10,430 --> 00:26:13,730
doing read-only queries so we're not

695
00:26:13,730 --> 00:26:15,830
really worried about updating the state

696
00:26:15,830 --> 00:26:16,940
of the data to some multiple locations

697
00:26:16,940 --> 00:26:18,680
and keeping those in sync but now we

698
00:26:18,680 --> 00:26:20,420
have to deal with the case where a node

699
00:26:20,420 --> 00:26:22,190
could crash while we're processing the

700
00:26:22,190 --> 00:26:24,050
query and we had to figure out how to

701
00:26:24,050 --> 00:26:27,350
handle that so the important thing to

702
00:26:27,350 --> 00:26:29,840
understand is that when we go request

703
00:26:29,840 --> 00:26:32,570
data from another machine or the shared

704
00:26:32,570 --> 00:26:34,760
disk and it we get we get the copy of

705
00:26:34,760 --> 00:26:35,660
that data when we were

706
00:26:35,660 --> 00:26:37,340
that that's gonna get stored in the

707
00:26:37,340 --> 00:26:39,260
buffer pool just like any other data we

708
00:26:39,260 --> 00:26:42,020
have that we read from disk but it's

709
00:26:42,020 --> 00:26:44,240
stored in like a temporary temporary

710
00:26:44,240 --> 00:26:47,750
buffer space meaning it could get paged

711
00:26:47,750 --> 00:26:49,790
the disk because we run out of space but

712
00:26:49,790 --> 00:26:51,800
if we crash or restart the system to

713
00:26:51,800 --> 00:26:54,140
come back all that temporary displaced

714
00:26:54,140 --> 00:26:55,280
disk is blown away

715
00:26:55,280 --> 00:26:57,770
because the the query or the transaction

716
00:26:57,770 --> 00:26:58,820
that was protected the query that was

717
00:26:58,820 --> 00:27:01,280
that was running that needed that data

718
00:27:01,280 --> 00:27:03,560
is now gone because I crashed and so I

719
00:27:03,560 --> 00:27:05,500
don't need to persist anything

720
00:27:05,500 --> 00:27:10,130
so these OLAP queries for really large

721
00:27:10,130 --> 00:27:13,970
databases can take a long time it's not

722
00:27:13,970 --> 00:27:15,860
unheard of to have queries that could

723
00:27:15,860 --> 00:27:18,530
take hours I've also heard of queries

724
00:27:18,530 --> 00:27:22,850
that take days for column stores that's

725
00:27:22,850 --> 00:27:24,140
gotten much better but back in the old

726
00:27:24,140 --> 00:27:26,180
days it was certainly very common for

727
00:27:26,180 --> 00:27:28,370
like a quarter to take days like you

728
00:27:28,370 --> 00:27:29,870
want you run your reports once a month

729
00:27:29,870 --> 00:27:33,230
and takes like a week to run it so if we

730
00:27:33,230 --> 00:27:34,610
had this long running query and our node

731
00:27:34,610 --> 00:27:38,090
crashes what should we do it's not a

732
00:27:38,090 --> 00:27:39,200
correctness issue because we weren't

733
00:27:39,200 --> 00:27:41,150
updating anything but ideally be nice

734
00:27:41,150 --> 00:27:43,430
may be that we may not have to restart

735
00:27:43,430 --> 00:27:44,600
the whole thing from scratch if it's

736
00:27:44,600 --> 00:27:50,990
gonna take days so the the design

737
00:27:50,990 --> 00:27:54,370
decision that most shared-nothing

738
00:27:54,370 --> 00:27:56,960
distributed databases make is that

739
00:27:56,960 --> 00:27:59,060
they're not gonna actually support query

740
00:27:59,060 --> 00:28:01,370
fault tolerance meaning if your

741
00:28:01,370 --> 00:28:03,380
long-running query crashes if a node

742
00:28:03,380 --> 00:28:04,820
crashes during why your query is running

743
00:28:04,820 --> 00:28:06,560
unless there's a replica that has the

744
00:28:06,560 --> 00:28:09,980
data you need that could you know fill

745
00:28:09,980 --> 00:28:11,330
in some missing piece depending where

746
00:28:11,330 --> 00:28:13,220
you are in the query plan they're just

747
00:28:13,220 --> 00:28:15,080
gonna abort the query and throw back an

748
00:28:15,080 --> 00:28:18,160
error and and tell you to restart it and

749
00:28:18,160 --> 00:28:20,240
we take a guess why they make this

750
00:28:20,240 --> 00:28:22,690
decision

751
00:28:25,530 --> 00:28:27,270
it's expensive right I'm running a long

752
00:28:27,270 --> 00:28:29,400
run in query it starts generating a

753
00:28:29,400 --> 00:28:31,800
bunch of enemy results and now I got to

754
00:28:31,800 --> 00:28:33,330
make sure I flush them all the right to

755
00:28:33,330 --> 00:28:34,350
mount the disk and make sure there's

756
00:28:34,350 --> 00:28:35,700
durable across replicas in case that

757
00:28:35,700 --> 00:28:38,700
there's a crash that's gonna make your

758
00:28:38,700 --> 00:28:39,780
query to run a lot slower because the

759
00:28:39,780 --> 00:28:44,000
disk is super slow so in the

760
00:28:44,000 --> 00:28:46,260
in this sort of traditional data

761
00:28:46,260 --> 00:28:48,420
warehouse world they would say oh you

762
00:28:48,420 --> 00:28:50,880
just pay me ten million dollars to for

763
00:28:50,880 --> 00:28:52,110
this very expensive database system

764
00:28:52,110 --> 00:28:54,150
software I assume you're not running on

765
00:28:54,150 --> 00:28:56,400
machines you found at Goodwill I'm

766
00:28:56,400 --> 00:28:57,330
assuming you're buying on high-end

767
00:28:57,330 --> 00:28:59,280
hardware so the likely that heart that

768
00:28:59,280 --> 00:29:00,210
high-end harbor is gonna have a

769
00:29:00,210 --> 00:29:02,040
catastrophic failure where you know it's

770
00:29:02,040 --> 00:29:03,470
gonna crash in the middle of query is

771
00:29:03,470 --> 00:29:06,120
gonna be low so therefore I'd rather not

772
00:29:06,120 --> 00:29:08,940
pay the penalty of of taking snapshots

773
00:29:08,940 --> 00:29:11,610
or writing me results about the disk as

774
00:29:11,610 --> 00:29:16,020
I run so in general most oh that systems

775
00:29:16,020 --> 00:29:18,240
are going to if a query Fano crashes

776
00:29:18,240 --> 00:29:20,970
during during Cori execution and let's

777
00:29:20,970 --> 00:29:22,590
say it's not just reading from from a

778
00:29:22,590 --> 00:29:23,940
disk where you have copies of like it's

779
00:29:23,940 --> 00:29:25,470
it's some the middle part of the query

780
00:29:25,470 --> 00:29:27,300
we have enemy results that you say the

781
00:29:27,300 --> 00:29:31,140
query fails is when Hadoop came out in

782
00:29:31,140 --> 00:29:33,780
the mid-2000s they were actually taking

783
00:29:33,780 --> 00:29:35,130
snapshots they were actually taking you

784
00:29:35,130 --> 00:29:37,020
know writing at every step of a query

785
00:29:37,020 --> 00:29:38,970
plan writing that out the disk but that

786
00:29:38,970 --> 00:29:41,480
made it super slow right cuz it gives

787
00:29:41,480 --> 00:29:44,580
back in the old days when when even

788
00:29:44,580 --> 00:29:47,010
still now but like when Google was

789
00:29:47,010 --> 00:29:48,750
building that produce they talked about

790
00:29:48,750 --> 00:29:51,210
running on you know cheap hardware where

791
00:29:51,210 --> 00:29:52,500
if you're running a thousand node

792
00:29:52,500 --> 00:29:54,330
cluster and your query is run across

793
00:29:54,330 --> 00:29:55,470
1,000 nodes the likelihood that any

794
00:29:55,470 --> 00:29:56,910
notes gonna crash during that time is

795
00:29:56,910 --> 00:29:58,920
pretty high so and they're well they

796
00:29:58,920 --> 00:30:00,270
would rather take the snapshots to avoid

797
00:30:00,270 --> 00:30:11,010
this yes we're not so much transactions

798
00:30:11,010 --> 00:30:13,860
here which read-only queries analytical

799
00:30:13,860 --> 00:30:19,260
queries right so if it's a if say in

800
00:30:19,260 --> 00:30:20,190
from last class which I went

801
00:30:20,190 --> 00:30:21,600
transactional distributed distributed

802
00:30:21,600 --> 00:30:24,330
datastore transactions if a node fails

803
00:30:24,330 --> 00:30:27,420
that while we're exiting transaction we

804
00:30:27,420 --> 00:30:29,130
just abort that transaction because who

805
00:30:29,130 --> 00:30:31,020
cares so that transaction what ran for

806
00:30:31,020 --> 00:30:34,770
50 milliseconds who cares if now I have

807
00:30:34,770 --> 00:30:36,150
analytical where that's gonna take days

808
00:30:36,150 --> 00:30:38,640
to run if it's take if takes five days

809
00:30:38,640 --> 00:30:39,470
to run I cry

810
00:30:39,470 --> 00:30:40,940
the fourth day the night's wasted four

811
00:30:40,940 --> 00:30:42,950
days of work some people would get

812
00:30:42,950 --> 00:30:44,000
actually pissed about that because now

813
00:30:44,000 --> 00:30:45,500
you gotta you know start it up and run

814
00:30:45,500 --> 00:30:48,350
run all over again and so you could take

815
00:30:48,350 --> 00:30:49,940
a snapshot some systems allow you to

816
00:30:49,940 --> 00:30:51,770
take snapshots as you run the query at

817
00:30:51,770 --> 00:30:53,990
the oleg as the output of one query plan

818
00:30:53,990 --> 00:30:56,059
as gets fed into the next operator I'll

819
00:30:56,059 --> 00:30:57,470
just write all that out to disk as well

820
00:30:57,470 --> 00:30:59,120
so that if I crash at that point I can

821
00:30:59,120 --> 00:31:00,830
bring it back there's ways to turn that

822
00:31:00,830 --> 00:31:02,799
on but by default most systems do not

823
00:31:02,799 --> 00:31:04,280
because they don't want to pay that

824
00:31:04,280 --> 00:31:07,970
performance penalty overhead so again on

825
00:31:07,970 --> 00:31:09,530
a shared your system it's easy to it's

826
00:31:09,530 --> 00:31:11,059
easy to visualize and we're doing that

827
00:31:11,059 --> 00:31:12,799
same join we send the plan timing down

828
00:31:12,799 --> 00:31:15,110
here and then as it computes the join

829
00:31:15,110 --> 00:31:17,030
result it's gonna write that out to the

830
00:31:17,030 --> 00:31:20,059
shared disk there's some notification to

831
00:31:20,059 --> 00:31:21,860
a coordinator to say hey if you're

832
00:31:21,860 --> 00:31:24,200
looking for this join result here's

833
00:31:24,200 --> 00:31:25,580
where to go get it on the shared disk

834
00:31:25,580 --> 00:31:27,620
and that way this guy crashes and goes

835
00:31:27,620 --> 00:31:29,390
away this guy knows he can just pull it

836
00:31:29,390 --> 00:31:31,429
from from there and not worry about you

837
00:31:31,429 --> 00:31:36,110
know how to read good anything so so

838
00:31:36,110 --> 00:31:37,820
again this is an important design

839
00:31:37,820 --> 00:31:39,140
decision that the distributed Avis is

840
00:31:39,140 --> 00:31:41,840
are gonna make their there they're not

841
00:31:41,840 --> 00:31:43,880
gonna provide you what sometimes called

842
00:31:43,880 --> 00:31:46,220
query resiliency or fault tolerance

843
00:31:46,220 --> 00:31:47,240
where the query executes

844
00:31:47,240 --> 00:31:50,360
they maybe restart the query for you but

845
00:31:50,360 --> 00:31:52,370
they're not gonna try to pick up where a

846
00:31:52,370 --> 00:31:54,590
node was running at the Miller at the

847
00:31:54,590 --> 00:32:01,340
crash okay all right so the other thing

848
00:32:01,340 --> 00:32:02,990
you got to worry about now is also have

849
00:32:02,990 --> 00:32:06,470
new query planning so we have all the

850
00:32:06,470 --> 00:32:08,240
same issues that we had before join

851
00:32:08,240 --> 00:32:09,890
orderings how to do predicates pushdowns

852
00:32:09,890 --> 00:32:11,750
or the projections all those same

853
00:32:11,750 --> 00:32:13,760
decisions we had to do on a single node

854
00:32:13,760 --> 00:32:15,530
system we have to do in the distributed

855
00:32:15,530 --> 00:32:17,570
system but now we have a certain extra

856
00:32:17,570 --> 00:32:20,270
level of planning where we need to

857
00:32:20,270 --> 00:32:23,179
reason about where our data is located

858
00:32:23,179 --> 00:32:25,309
how its partitioned or replicated and

859
00:32:25,309 --> 00:32:28,130
now account for the network

860
00:32:28,130 --> 00:32:33,280
communication cost for our algorithms

861
00:32:33,760 --> 00:32:35,990
right and this makes more sense in a

862
00:32:35,990 --> 00:32:37,070
second when we talk about the different

863
00:32:37,070 --> 00:32:40,190
scenarios but like the joint ordering

864
00:32:40,190 --> 00:32:42,740
still matters but now it's also like

865
00:32:42,740 --> 00:32:44,179
alright well I need it should I join

866
00:32:44,179 --> 00:32:46,190
these two tables first because they're

867
00:32:46,190 --> 00:32:47,960
on the same node a partition in the same

868
00:32:47,960 --> 00:32:49,070
way and therefore that can be really

869
00:32:49,070 --> 00:32:51,649
fast even though if I was on a single

870
00:32:51,649 --> 00:32:52,789
node I may not want to join those two

871
00:32:52,789 --> 00:32:53,149
tab

872
00:32:53,149 --> 00:32:55,969
first so that just could now included in

873
00:32:55,969 --> 00:32:57,469
your cost model to have you help me make

874
00:32:57,469 --> 00:32:57,979
a decision

875
00:32:57,979 --> 00:33:00,440
about again what's the right this query

876
00:33:00,440 --> 00:33:01,999
planned a most optimal query plan for

877
00:33:01,999 --> 00:33:04,999
the for the system again just as I said

878
00:33:04,999 --> 00:33:07,399
before doing query optimization on a

879
00:33:07,399 --> 00:33:09,049
single note is hard this is just even

880
00:33:09,049 --> 00:33:16,729
harder okay and like we you know

881
00:33:16,729 --> 00:33:17,989
sometimes you can make a decision on a

882
00:33:17,989 --> 00:33:19,399
single node and centralize the location

883
00:33:19,399 --> 00:33:20,479
sometimes you can make it into

884
00:33:20,479 --> 00:33:22,609
distribute across all the nodes but now

885
00:33:22,609 --> 00:33:24,559
again you had this you have to make sure

886
00:33:24,559 --> 00:33:25,879
all your statistics and all your nodes

887
00:33:25,879 --> 00:33:27,649
are updated as much as possible to help

888
00:33:27,649 --> 00:33:29,149
you make decisions about what the best

889
00:33:29,149 --> 00:33:31,190
plan could be it's just everything just

890
00:33:31,190 --> 00:33:33,489
much much harder when it's distributed

891
00:33:33,489 --> 00:33:37,729
but now same way we have now a query

892
00:33:37,729 --> 00:33:40,369
plan what do we actually want to send to

893
00:33:40,369 --> 00:33:42,109
our different nodes that are that are

894
00:33:42,109 --> 00:33:43,609
going to participate in executing a

895
00:33:43,609 --> 00:33:46,759
joint query so there's two approaches

896
00:33:46,759 --> 00:33:49,099
one is we could actually send the

897
00:33:49,099 --> 00:33:53,779
physical plan or plan fragment to to the

898
00:33:53,779 --> 00:33:57,440
node for it to execute by just taking

899
00:33:57,440 --> 00:33:58,969
the query plan that we've generated on

900
00:33:58,969 --> 00:34:00,379
you know on the base note of the home

901
00:34:00,379 --> 00:34:02,179
node and then carving it up to say well

902
00:34:02,179 --> 00:34:03,649
I know this portion of the query plan

903
00:34:03,649 --> 00:34:05,509
needs to execute on this this node this

904
00:34:05,509 --> 00:34:06,859
other portion the query planner needs

905
00:34:06,859 --> 00:34:08,329
actually on that node you just share

906
00:34:08,329 --> 00:34:09,918
those physical operators to the other

907
00:34:09,918 --> 00:34:11,750
nodes they just take them and

908
00:34:11,750 --> 00:34:12,918
immediately execute them without

909
00:34:12,918 --> 00:34:14,659
reasoning about whether that's the best

910
00:34:14,659 --> 00:34:17,179
thing to do for the local data and then

911
00:34:17,179 --> 00:34:20,089
sending back the results so as far as

912
00:34:20,089 --> 00:34:23,539
they know most most ribbity databases

913
00:34:23,539 --> 00:34:25,159
that are doing analytics do this first

914
00:34:25,159 --> 00:34:27,799
approach well the generate the run the

915
00:34:27,799 --> 00:34:29,059
query plan through an optimizer once

916
00:34:29,059 --> 00:34:31,129
generate a global plan for the entire

917
00:34:31,129 --> 00:34:33,799
cluster for the query then carve it up

918
00:34:33,799 --> 00:34:37,089
into two plan fragments and divide it up

919
00:34:37,089 --> 00:34:40,909
another approach is to actually take the

920
00:34:40,909 --> 00:34:43,489
Seco query that came in and then rewrite

921
00:34:43,489 --> 00:34:46,309
it to have it be on a per partition

922
00:34:46,309 --> 00:34:48,679
basis have a C query each individual

923
00:34:48,679 --> 00:34:52,010
partition and then send that out then

924
00:34:52,010 --> 00:34:54,199
when the when the node that that where

925
00:34:54,199 --> 00:34:55,429
the partition is located it gets that

926
00:34:55,429 --> 00:34:57,200
sequel query then it runs it through its

927
00:34:57,200 --> 00:34:59,480
own query optimizer to generate the

928
00:34:59,480 --> 00:35:01,630
physical plan that it wants to execute

929
00:35:01,630 --> 00:35:05,370
the idea here is that

930
00:35:05,370 --> 00:35:08,550
if we can assume that the if we did a

931
00:35:08,550 --> 00:35:11,220
global plan on a single node the

932
00:35:11,220 --> 00:35:12,930
statistics and information about what's

933
00:35:12,930 --> 00:35:15,570
what's best at each partition is not

934
00:35:15,570 --> 00:35:18,480
going to be up to date or you know or

935
00:35:18,480 --> 00:35:20,850
fresh and therefore rather than me

936
00:35:20,850 --> 00:35:23,340
trying to reason at my home node what

937
00:35:23,340 --> 00:35:24,690
the best thing to do at this other node

938
00:35:24,690 --> 00:35:26,640
I'll just say to this other node hey I

939
00:35:26,640 --> 00:35:28,560
think you need to execute this query or

940
00:35:28,560 --> 00:35:30,120
I need to react to this query for me and

941
00:35:30,120 --> 00:35:32,550
then that that node can then do all the

942
00:35:32,550 --> 00:35:34,080
local optimization and all local

943
00:35:34,080 --> 00:35:37,760
planning when that psycho query arrives

944
00:35:37,760 --> 00:35:40,950
so again look at example here so this is

945
00:35:40,950 --> 00:35:44,400
my query like this and so I could in

946
00:35:44,400 --> 00:35:45,600
this case it there's you know there's

947
00:35:45,600 --> 00:35:49,470
there's no joint odor ah well it's

948
00:35:49,470 --> 00:35:51,630
either RS or SR but I just say alright

949
00:35:51,630 --> 00:35:53,160
well I know me actually the query and

950
00:35:53,160 --> 00:35:54,690
need such data at these three partitions

951
00:35:54,690 --> 00:35:57,780
so I'll rewrite my sequel statement to

952
00:35:57,780 --> 00:35:59,520
now include a where clause that says

953
00:35:59,520 --> 00:36:01,920
here's the here's the portion of the

954
00:36:01,920 --> 00:36:03,870
data you need to look at which matches

955
00:36:03,870 --> 00:36:05,520
what the partition key is or the

956
00:36:05,520 --> 00:36:08,490
partition ranges then the node gets gets

957
00:36:08,490 --> 00:36:10,050
this each each node gets these

958
00:36:10,050 --> 00:36:11,730
individual query plans running through

959
00:36:11,730 --> 00:36:13,140
its own optimizer and then they can

960
00:36:13,140 --> 00:36:15,660
decide Oh based on the data I have here

961
00:36:15,660 --> 00:36:17,730
is it better to join our than SRS then

962
00:36:17,730 --> 00:36:19,920
our shut you a hash join so do a sort

963
00:36:19,920 --> 00:36:22,290
merge join I can make a local decision

964
00:36:22,290 --> 00:36:23,940
here because I have the best view of

965
00:36:23,940 --> 00:36:25,200
what's what date I'm actually storing

966
00:36:25,200 --> 00:36:27,210
whereas the home node again could be out

967
00:36:27,210 --> 00:36:33,810
of date so the only database something

968
00:36:33,810 --> 00:36:34,740
that actually that I'm aware that

969
00:36:34,740 --> 00:36:36,150
actually does something like this is is

970
00:36:36,150 --> 00:36:40,260
mem sequel everybody everybody else

971
00:36:40,260 --> 00:36:44,160
sends the physical plan I don't I mean

972
00:36:44,160 --> 00:36:45,630
to me this seems convincing that you

973
00:36:45,630 --> 00:36:47,400
could do this I think you still have to

974
00:36:47,400 --> 00:36:49,890
make a higher-level decision of the

975
00:36:49,890 --> 00:36:52,650
possible join order at you know if you

976
00:36:52,650 --> 00:36:54,300
have multiple tables more than two like

977
00:36:54,300 --> 00:36:56,970
I 5r s and T should I join

978
00:36:56,970 --> 00:36:59,250
RNs or TNS first like I think there is

979
00:36:59,250 --> 00:37:00,540
some information there that you may have

980
00:37:00,540 --> 00:37:02,370
the reason about at the upper level but

981
00:37:02,370 --> 00:37:04,770
when it comes time for the local node to

982
00:37:04,770 --> 00:37:05,430
make this decision

983
00:37:05,430 --> 00:37:07,620
you know everything it doesn't worry

984
00:37:07,620 --> 00:37:10,280
about communicating with anybody else

985
00:37:10,280 --> 00:37:12,630
I'm not saying one is better than other

986
00:37:12,630 --> 00:37:13,740
I think this has interesting

987
00:37:13,740 --> 00:37:15,750
implications that have not been explored

988
00:37:15,750 --> 00:37:18,320
in the research

989
00:37:18,760 --> 00:37:22,700
okay so now we want talk about joins

990
00:37:22,700 --> 00:37:25,039
again joins are those expensive most

991
00:37:25,039 --> 00:37:26,420
important thing you have to do in a

992
00:37:26,420 --> 00:37:28,309
single node database and just you know

993
00:37:28,309 --> 00:37:31,220
also in a Toshiba database for

994
00:37:31,220 --> 00:37:34,039
analytical workload the large portion of

995
00:37:34,039 --> 00:37:36,049
the time that the system is going to

996
00:37:36,049 --> 00:37:37,880
spend executing a query where I be

997
00:37:37,880 --> 00:37:40,160
reading data from disk or doing doing

998
00:37:40,160 --> 00:37:43,069
our joint as we said reading from data

999
00:37:43,069 --> 00:37:45,170
from disk there's you know there's there

1000
00:37:45,170 --> 00:37:46,490
are some methods you can do to speed

1001
00:37:46,490 --> 00:37:48,289
that up but in the end of the day you're

1002
00:37:48,289 --> 00:37:49,970
usually bound on how fast you can get

1003
00:37:49,970 --> 00:37:52,059
things off off of the physical device

1004
00:37:52,059 --> 00:37:54,950
but for joins we can be smart about

1005
00:37:54,950 --> 00:37:58,730
things so as I showed in the first

1006
00:37:58,730 --> 00:38:01,910
example the easiest way to do a join is

1007
00:38:01,910 --> 00:38:04,700
just get all the data we need to do our

1008
00:38:04,700 --> 00:38:07,069
join put them on a single node and run

1009
00:38:07,069 --> 00:38:09,740
our joint album but as I said you lose

1010
00:38:09,740 --> 00:38:11,539
all the extra parallelism actual

1011
00:38:11,539 --> 00:38:13,099
resources you have by dividing the data

1012
00:38:13,099 --> 00:38:15,200
across multiple nodes you lose all those

1013
00:38:15,200 --> 00:38:18,170
benefits and you also you know you may

1014
00:38:18,170 --> 00:38:19,130
not be able to actually put everything

1015
00:38:19,130 --> 00:38:21,549
in memory to run things fast

1016
00:38:21,549 --> 00:38:24,140
so there's before different approaches

1017
00:38:24,140 --> 00:38:26,480
actually how we actually or affordab it

1018
00:38:26,480 --> 00:38:28,190
scenarios you need to handle when we

1019
00:38:28,190 --> 00:38:30,020
want to do it should be to join and

1020
00:38:30,020 --> 00:38:32,869
again a distributor join is gonna be the

1021
00:38:32,869 --> 00:38:35,210
exact same way we would do a join on a

1022
00:38:35,210 --> 00:38:37,400
single node system but the idea is that

1023
00:38:37,400 --> 00:38:39,230
we need to figure out how to get the

1024
00:38:39,230 --> 00:38:42,440
data we want to join together on and on

1025
00:38:42,440 --> 00:38:44,599
us on a node it could be one node to be

1026
00:38:44,599 --> 00:38:46,910
multiple nodes such that we can do a

1027
00:38:46,910 --> 00:38:48,650
join locally without having to

1028
00:38:48,650 --> 00:38:50,630
coordinate with any other node while

1029
00:38:50,630 --> 00:38:53,809
we're doing the joint so when we do that

1030
00:38:53,809 --> 00:38:55,460
local joint it's all the same algorithms

1031
00:38:55,460 --> 00:38:56,930
the server's join nested loop join the

1032
00:38:56,930 --> 00:38:57,890
hash join that we talked about before

1033
00:38:57,890 --> 00:39:00,470
all the same optimizations apply it's

1034
00:39:00,470 --> 00:39:02,240
the step you have to deal with before

1035
00:39:02,240 --> 00:39:04,250
you do that join of how to get the data

1036
00:39:04,250 --> 00:39:08,599
to a node that that's gonna need it so

1037
00:39:08,599 --> 00:39:09,410
again we're gonna talk about four

1038
00:39:09,410 --> 00:39:10,970
different scenarios if you've already

1039
00:39:10,970 --> 00:39:12,940
sort of come up in our earlier examples

1040
00:39:12,940 --> 00:39:15,319
and we'll see how we actually wanna

1041
00:39:15,319 --> 00:39:17,359
handle them and again the main takeaway

1042
00:39:17,359 --> 00:39:18,770
is that there's no magic here that we

1043
00:39:18,770 --> 00:39:19,940
can actually do there's no magic

1044
00:39:19,940 --> 00:39:21,680
industry to join algorithm that's gonna

1045
00:39:21,680 --> 00:39:24,440
form so much better than a single node

1046
00:39:24,440 --> 00:39:26,660
one it's all about how to get the data

1047
00:39:26,660 --> 00:39:29,559
to where needs to be

1048
00:39:30,170 --> 00:39:31,730
I say the best-case scenario would be

1049
00:39:31,730 --> 00:39:35,930
one where the the table is one of the

1050
00:39:35,930 --> 00:39:37,760
tables for joining us partitioned on the

1051
00:39:37,760 --> 00:39:40,640
join team and then the other table is is

1052
00:39:40,640 --> 00:39:43,940
is replicated in its entirety at every

1053
00:39:43,940 --> 00:39:46,789
single node so in this case here the our

1054
00:39:46,789 --> 00:39:49,519
table is is partitioned on the on the ID

1055
00:39:49,519 --> 00:39:51,289
it's ID field which is in our join

1056
00:39:51,289 --> 00:39:53,420
clause and then the s table is

1057
00:39:53,420 --> 00:39:55,730
replicated in every node again this

1058
00:39:55,730 --> 00:39:57,440
could be the fact table this could be

1059
00:39:57,440 --> 00:39:59,809
the dimension table that this is small

1060
00:39:59,809 --> 00:40:01,190
enough where we could split it up or

1061
00:40:01,190 --> 00:40:02,750
small enough where we could replicate it

1062
00:40:02,750 --> 00:40:05,960
on every single machine so in this case

1063
00:40:05,960 --> 00:40:08,599
here again all we need to do is have

1064
00:40:08,599 --> 00:40:11,630
every single node do a local join to

1065
00:40:11,630 --> 00:40:13,970
produce the result for the data that it

1066
00:40:13,970 --> 00:40:16,369
has you know store and local storage and

1067
00:40:16,369 --> 00:40:19,579
then we just need to transmit the the

1068
00:40:19,579 --> 00:40:22,460
output of one of joining one node to

1069
00:40:22,460 --> 00:40:24,170
some centralized location so that we can

1070
00:40:24,170 --> 00:40:25,279
combine the results that produce a

1071
00:40:25,279 --> 00:40:28,720
single single answer to our application

1072
00:40:28,720 --> 00:40:30,619
all right again this is the best-case

1073
00:40:30,619 --> 00:40:32,750
scenario is this transfer to get the

1074
00:40:32,750 --> 00:40:34,670
join result from this node to that node

1075
00:40:34,670 --> 00:40:37,609
is unavoidable we have to do it but when

1076
00:40:37,609 --> 00:40:38,900
we I should get the join we didn't need

1077
00:40:38,900 --> 00:40:40,099
a coordinator or communicate with any

1078
00:40:40,099 --> 00:40:41,720
other node because everything we needed

1079
00:40:41,720 --> 00:40:44,329
was local to us so this gives us the

1080
00:40:44,329 --> 00:40:45,859
benefit of a distributed database

1081
00:40:45,859 --> 00:40:47,960
because now we can run this join in

1082
00:40:47,960 --> 00:40:50,539
parallel on every single node without

1083
00:40:50,539 --> 00:40:52,880
any coordination and then everyone just

1084
00:40:52,880 --> 00:40:57,880
sends the result back to the head node

1085
00:40:59,990 --> 00:41:03,040
next best-case scenario is where the

1086
00:41:03,040 --> 00:41:06,260
both of the keys are partitioned above

1087
00:41:06,260 --> 00:41:07,550
the tables are partitioned on the join

1088
00:41:07,550 --> 00:41:10,490
key again in this case here the again s

1089
00:41:10,490 --> 00:41:12,650
ID on the last slide it was partitioned

1090
00:41:12,650 --> 00:41:15,770
on today was replicated this one is

1091
00:41:15,770 --> 00:41:17,690
partitioned on the ID field and the

1092
00:41:17,690 --> 00:41:19,610
range that's in this in this partition

1093
00:41:19,610 --> 00:41:22,460
it's the same as the range of sorry the

1094
00:41:22,460 --> 00:41:24,980
range of the partition for s is the same

1095
00:41:24,980 --> 00:41:27,980
as the range for position on R so again

1096
00:41:27,980 --> 00:41:29,660
just like before we compute our local

1097
00:41:29,660 --> 00:41:31,520
join give me a hash going to be nested

1098
00:41:31,520 --> 00:41:32,690
loop could be sort merge it doesn't

1099
00:41:32,690 --> 00:41:35,119
matter and then this guy's transmits the

1100
00:41:35,119 --> 00:41:36,890
result to this other node where we

1101
00:41:36,890 --> 00:41:55,400
combine it together yes so this question

1102
00:41:55,400 --> 00:41:58,910
his question is about data skew so in

1103
00:41:58,910 --> 00:42:01,610
this example here I'm showing you that

1104
00:42:01,610 --> 00:42:03,710
the ranges are the same one to 100 and

1105
00:42:03,710 --> 00:42:06,530
101 to 200 but it doesn't necessarily

1106
00:42:06,530 --> 00:42:10,250
tell you how many tuples exist in this

1107
00:42:10,250 --> 00:42:12,859
range or this partition so like say this

1108
00:42:12,859 --> 00:42:15,140
ID is the primary key for R so there's

1109
00:42:15,140 --> 00:42:17,510
exactly one hundred tuples for R but say

1110
00:42:17,510 --> 00:42:19,510
this is IDs not the primary key for ID

1111
00:42:19,510 --> 00:42:23,330
for s I could have a billion entries

1112
00:42:23,330 --> 00:42:24,980
within this range and then a billion

1113
00:42:24,980 --> 00:42:26,930
entries for that range how do I handle

1114
00:42:26,930 --> 00:42:28,940
that well in that case you've not you

1115
00:42:28,940 --> 00:42:30,890
would not want to have the same range as

1116
00:42:30,890 --> 00:42:32,720
the ID field so in that case you will

1117
00:42:32,720 --> 00:42:34,490
have to shuffle some data around talk

1118
00:42:34,490 --> 00:42:36,800
about in a second there's the best-case

1119
00:42:36,800 --> 00:42:39,710
scenario these are uniform uniformly

1120
00:42:39,710 --> 00:42:41,750
distributed exact same range I don't

1121
00:42:41,750 --> 00:42:45,320
need to corny I'm sure it doesn't

1122
00:42:45,320 --> 00:42:46,640
I agree but it won't have a real-world

1123
00:42:46,640 --> 00:42:49,280
I'm saying best-case of worst-case

1124
00:42:49,280 --> 00:42:50,990
scenario and we'll see how to handle as

1125
00:42:50,990 --> 00:42:58,790
things get worse all right so so related

1126
00:42:58,790 --> 00:43:00,560
to him so so the next issues gonna be

1127
00:43:00,560 --> 00:43:02,960
let's say that one of our tables is not

1128
00:43:02,960 --> 00:43:06,230
partitioned on the the same attribute

1129
00:43:06,230 --> 00:43:07,970
that we want to join on so in this case

1130
00:43:07,970 --> 00:43:10,900
here s is partition on the value field

1131
00:43:10,900 --> 00:43:13,700
so in this case

1132
00:43:13,700 --> 00:43:15,920
can't compute our local join because for

1133
00:43:15,920 --> 00:43:18,440
every single value of our ID here I

1134
00:43:18,440 --> 00:43:22,010
don't know whether it's it's you know a

1135
00:43:22,010 --> 00:43:23,870
matching tuba will exist on my local

1136
00:43:23,870 --> 00:43:25,790
partition then maybe won't over here

1137
00:43:25,790 --> 00:43:29,330
with the same ID so in this one this

1138
00:43:29,330 --> 00:43:31,130
case this is called a broadcast join and

1139
00:43:31,130 --> 00:43:35,210
the basic idea is that you copy the the

1140
00:43:35,210 --> 00:43:37,780
portion of the table that's missing from

1141
00:43:37,780 --> 00:43:41,480
from each partition to every other

1142
00:43:41,480 --> 00:43:44,750
partition so that now this node has a

1143
00:43:44,750 --> 00:43:49,160
complete copy of the table and then now

1144
00:43:49,160 --> 00:43:50,750
you just compute your local join and

1145
00:43:50,750 --> 00:43:52,610
then send the result over to the other

1146
00:43:52,610 --> 00:43:56,240
guy again this assumes that s is small

1147
00:43:56,240 --> 00:43:57,920
enough that it could you reside in

1148
00:43:57,920 --> 00:44:00,230
memory or not to cook not overwhelm this

1149
00:44:00,230 --> 00:44:02,090
machine or does note here you try to

1150
00:44:02,090 --> 00:44:07,550
copy everything here write the broadcast

1151
00:44:07,550 --> 00:44:09,260
means that you're basically generating

1152
00:44:09,260 --> 00:44:10,310
every node would end up with a

1153
00:44:10,310 --> 00:44:13,370
replicated copy of the table sometimes

1154
00:44:13,370 --> 00:44:14,180
just see you ever heard to as a

1155
00:44:14,180 --> 00:44:16,460
broadcaster owned a broadcast broadcast

1156
00:44:16,460 --> 00:44:18,980
partners join it just means they're

1157
00:44:18,980 --> 00:44:21,170
doing this initial step where they

1158
00:44:21,170 --> 00:44:23,000
transmit the data across to different

1159
00:44:23,000 --> 00:44:24,410
notes that everyone has a complete copy

1160
00:44:24,410 --> 00:44:30,710
and then you do the join the last

1161
00:44:30,710 --> 00:44:32,000
scenario is the absolute worst case

1162
00:44:32,000 --> 00:44:34,490
scenario is where both tables are not

1163
00:44:34,490 --> 00:44:36,460
partitioned at all on our join key and

1164
00:44:36,460 --> 00:44:40,250
now we need to reorganize the the layout

1165
00:44:40,250 --> 00:44:42,890
of the data so that we compute our join

1166
00:44:42,890 --> 00:44:45,230
more more efficiently so this will be

1167
00:44:45,230 --> 00:44:47,860
called a shuffle join trouble hash join

1168
00:44:47,860 --> 00:44:50,600
so basically we recognize that we'll

1169
00:44:50,600 --> 00:44:52,190
really want things to be partitioned on

1170
00:44:52,190 --> 00:44:54,260
the ID field so let me just start

1171
00:44:54,260 --> 00:44:56,300
copying the data that I need from these

1172
00:44:56,300 --> 00:44:57,830
two tables to lean these two different

1173
00:44:57,830 --> 00:45:00,710
nodes if this has to spill to disk run

1174
00:45:00,710 --> 00:45:03,170
out of space that's unavoidable so we

1175
00:45:03,170 --> 00:45:04,760
just go ahead and do that and then once

1176
00:45:04,760 --> 00:45:06,110
I know I have everything purchasing the

1177
00:45:06,110 --> 00:45:07,970
way I want to partitioned then I can

1178
00:45:07,970 --> 00:45:10,280
keep my local join and generate the

1179
00:45:10,280 --> 00:45:15,550
results yes

1180
00:45:15,730 --> 00:45:23,060
what so his question is and the space is

1181
00:45:23,060 --> 00:45:23,930
limited what can you do

1182
00:45:23,930 --> 00:45:24,950
so the point I'm trying to make here is

1183
00:45:24,950 --> 00:45:30,050
like Teemo what you end up doing here

1184
00:45:30,050 --> 00:45:31,910
right so I have to now make another copy

1185
00:45:31,910 --> 00:45:35,990
of our on on you know and store it on

1186
00:45:35,990 --> 00:45:38,660
this node and so if it doesn't fit in

1187
00:45:38,660 --> 00:45:40,910
memory just as I said like it's it's it

1188
00:45:40,910 --> 00:45:42,590
gets spilled as a temporary result for

1189
00:45:42,590 --> 00:45:44,300
the query could get spilled a disk

1190
00:45:44,300 --> 00:45:48,440
that's unavoidable right but the more

1191
00:45:48,440 --> 00:45:50,030
important thing is that now when I

1192
00:45:50,030 --> 00:45:51,650
compute the join I want that to be fast

1193
00:45:51,650 --> 00:45:52,670
as possible because that's the most

1194
00:45:52,670 --> 00:45:54,710
expensive thing so by copying data

1195
00:45:54,710 --> 00:45:57,530
around when I do the join everything is

1196
00:45:57,530 --> 00:45:58,790
partitioned nicely the way I want it and

1197
00:45:58,790 --> 00:46:05,540
it's more efficient we this question is

1198
00:46:05,540 --> 00:46:06,680
do we always assume that the disk is

1199
00:46:06,680 --> 00:46:16,190
enough for our class yes in the real

1200
00:46:16,190 --> 00:46:18,860
world no what will happen is the

1201
00:46:18,860 --> 00:46:21,140
database and recognizes that if I get to

1202
00:46:21,140 --> 00:46:25,190
here and I can't copy any more data to

1203
00:46:25,190 --> 00:46:27,260
this node here the query would fail just

1204
00:46:27,260 --> 00:46:29,240
just say I run out of swap stays for 10

1205
00:46:29,240 --> 00:46:31,460
space and you throw an errand the query

1206
00:46:31,460 --> 00:46:35,780
fails and actually related to his

1207
00:46:35,780 --> 00:46:37,010
question but about the dispersion of

1208
00:46:37,010 --> 00:46:41,330
data if say it was partitioned on the ID

1209
00:46:41,330 --> 00:46:43,970
field but the the distribution was

1210
00:46:43,970 --> 00:46:45,230
highly skewed sister that most of the

1211
00:46:45,230 --> 00:46:47,450
data was on this node for s instead of

1212
00:46:47,450 --> 00:46:49,400
that node I can still do this

1213
00:46:49,400 --> 00:46:52,760
reshuffling to to realign my data maybe

1214
00:46:52,760 --> 00:46:54,560
move some data from R and s over here so

1215
00:46:54,560 --> 00:46:57,560
that things even get balanced but still

1216
00:46:57,560 --> 00:46:59,140
it's still called a shuffle process

1217
00:46:59,140 --> 00:47:06,140
question how does a lot more compact oh

1218
00:47:06,140 --> 00:47:08,290
sorry

1219
00:47:13,980 --> 00:47:25,400
yes of course how do you manage what sir

1220
00:47:32,660 --> 00:47:35,099
our question is how do I make a decision

1221
00:47:35,099 --> 00:47:36,990
about what data to send because if

1222
00:47:36,990 --> 00:47:38,310
things are replicated I don't want to

1223
00:47:38,310 --> 00:47:39,180
waste

1224
00:47:39,180 --> 00:47:41,010
you know waste network transmission of

1225
00:47:41,010 --> 00:47:42,570
sending data that's that's that I don't

1226
00:47:42,570 --> 00:47:44,550
need to send you know everything ahead

1227
00:47:44,550 --> 00:47:46,859
of time right sequel is declarative we

1228
00:47:46,859 --> 00:47:48,210
know what the query is we know what data

1229
00:47:48,210 --> 00:47:49,980
are trying to access we then look in our

1230
00:47:49,980 --> 00:47:51,570
system catalog our system Callao is

1231
00:47:51,570 --> 00:47:53,640
gonna tell us how this data is actually

1232
00:47:53,640 --> 00:47:55,410
partitioned we know this ahead of time

1233
00:47:55,410 --> 00:47:57,810
so the query planner can make a decision

1234
00:47:57,810 --> 00:48:00,390
oh well this data partition this way and

1235
00:48:00,390 --> 00:48:02,490
it's this size and it's in on this node

1236
00:48:02,490 --> 00:48:04,260
so therefore and either move or not move

1237
00:48:04,260 --> 00:48:06,329
it or copy here don't copy there I can

1238
00:48:06,329 --> 00:48:07,710
do all that ahead of time it's not like

1239
00:48:07,710 --> 00:48:10,230
as I'm going along I say oh well yeah

1240
00:48:10,230 --> 00:48:12,390
maybe I should copy this you figure out

1241
00:48:12,390 --> 00:48:14,820
everything ahead of time except for the

1242
00:48:14,820 --> 00:48:16,140
issue he brought up or like I ran out of

1243
00:48:16,140 --> 00:48:19,410
disk space you know you just fail

1244
00:48:19,410 --> 00:48:25,980
nothing you can do and then the the how

1245
00:48:25,980 --> 00:48:28,530
efficient the the database system is in

1246
00:48:28,530 --> 00:48:30,270
making those decisions about what the

1247
00:48:30,270 --> 00:48:32,369
copy are not the copy depends on how

1248
00:48:32,369 --> 00:48:34,800
good your query optimizer is which is

1249
00:48:34,800 --> 00:48:36,329
why people pay a lot of money to have

1250
00:48:36,329 --> 00:48:38,270
people like work on query optimizers

1251
00:48:38,270 --> 00:48:43,950
question your question is what if the

1252
00:48:43,950 --> 00:48:45,359
data is sorted on the partition ID

1253
00:48:45,359 --> 00:48:47,369
beforehand but it's partition ID or

1254
00:48:47,369 --> 00:48:53,099
joint ID so if it's sorted for what I'm

1255
00:48:53,099 --> 00:48:56,670
showing here who cares right cuz what I

1256
00:48:56,670 --> 00:48:58,410
care about is the locality of the data I

1257
00:48:58,410 --> 00:49:01,800
need to join our ID on s ID so I want to

1258
00:49:01,800 --> 00:49:03,119
make sure that when I do that join

1259
00:49:03,119 --> 00:49:05,540
locally I have all the data that I need

1260
00:49:05,540 --> 00:49:08,430
to ever you know for you know to join

1261
00:49:08,430 --> 00:49:10,290
the outer table at the inner table is at

1262
00:49:10,290 --> 00:49:12,240
my local node it can't be at some other

1263
00:49:12,240 --> 00:49:13,619
node that I don't know about and that

1264
00:49:13,619 --> 00:49:15,569
could end up with a false negative or

1265
00:49:15,569 --> 00:49:18,900
false positive so sorting doesn't matter

1266
00:49:18,900 --> 00:49:20,880
sorting would matter when we can make a

1267
00:49:20,880 --> 00:49:22,560
decision about do I want to do a cert

1268
00:49:22,560 --> 00:49:25,349
mergers as hash join word like a step

1269
00:49:25,349 --> 00:49:26,849
above this we're designing how do we

1270
00:49:26,849 --> 00:49:27,360
move data

1271
00:49:27,360 --> 00:49:40,260
or not yes okay so question is what if

1272
00:49:40,260 --> 00:49:41,840
what am I actually transmitting here and

1273
00:49:41,840 --> 00:49:44,490
be clear I'm not swapping this I should

1274
00:49:44,490 --> 00:49:46,530
shouldn't have a divider line so this is

1275
00:49:46,530 --> 00:49:48,900
the permanent data on this node it does

1276
00:49:48,900 --> 00:49:50,850
not go anywhere I just make extra copies

1277
00:49:50,850 --> 00:49:52,500
as temporary temporary data to do my

1278
00:49:52,500 --> 00:49:53,760
joint and then I throw it away when my

1279
00:49:53,760 --> 00:49:55,770
queries over so even though I'm

1280
00:49:55,770 --> 00:49:58,770
shuffling here on ID the I'm still going

1281
00:49:58,770 --> 00:50:00,510
at the end of a partition or name and

1282
00:50:00,510 --> 00:50:03,780
value here this this stays but then your

1283
00:50:03,780 --> 00:50:05,610
other question is what am I actually

1284
00:50:05,610 --> 00:50:07,680
transmitting am i transmitting the whole

1285
00:50:07,680 --> 00:50:10,500
tuple or am i transmitting the summit

1286
00:50:10,500 --> 00:50:13,710
some identifiers next slide okay we'll

1287
00:50:13,710 --> 00:50:26,760
get to that yes your question is it on a

1288
00:50:26,760 --> 00:50:29,220
local node if the data is not sorted how

1289
00:50:29,220 --> 00:50:30,210
do I make sure that there's no

1290
00:50:30,210 --> 00:50:34,140
duplicates duplicates of what I want for

1291
00:50:34,140 --> 00:50:43,110
the join ha is a partition ID the

1292
00:50:43,110 --> 00:50:58,070
primary key or a unique ID what the well

1293
00:50:58,070 --> 00:51:01,860
yes all right get to questions that so I

1294
00:51:01,860 --> 00:51:03,510
think what you're asking is actually if

1295
00:51:03,510 --> 00:51:05,400
I have a primary key then I need to

1296
00:51:05,400 --> 00:51:07,260
guarantee it's unique but my my

1297
00:51:07,260 --> 00:51:10,440
partition key is not the primary key how

1298
00:51:10,440 --> 00:51:13,590
do I make sure that I enforce that so

1299
00:51:13,590 --> 00:51:18,060
that that is a transaction right that's

1300
00:51:18,060 --> 00:51:19,620
not us we're just doing analytical

1301
00:51:19,620 --> 00:51:23,040
queries we assume we don't like we

1302
00:51:23,040 --> 00:51:25,170
assume that someone else has solved that

1303
00:51:25,170 --> 00:51:27,150
for us when they inject and stored the

1304
00:51:27,150 --> 00:51:29,520
data as a part of a transaction so in

1305
00:51:29,520 --> 00:51:31,650
your example if I have a partition key

1306
00:51:31,650 --> 00:51:33,030
that's not the same as the primary key

1307
00:51:33,030 --> 00:51:35,340
then I insert a new record

1308
00:51:35,340 --> 00:51:37,350
how do I make sure that's unique while I

1309
00:51:37,350 --> 00:51:40,200
eat IVA need to maintain a sort of

1310
00:51:40,200 --> 00:51:41,339
centralized index that I

1311
00:51:41,339 --> 00:51:42,930
look up and see whether this key does

1312
00:51:42,930 --> 00:51:45,210
party exist or at the broadcast the

1313
00:51:45,210 --> 00:51:46,769
query to every node to say hey I'm

1314
00:51:46,769 --> 00:51:49,349
certain this key do you do you already

1315
00:51:49,349 --> 00:51:54,319
have a copy of it I'm saying you could

1316
00:51:54,319 --> 00:51:57,989
write help me how come in me how could

1317
00:51:57,989 --> 00:52:00,690
how could that be ID there's a node

1318
00:52:00,690 --> 00:52:04,019
here's an index we're building idiots we

1319
00:52:04,019 --> 00:52:07,249
do have every one right we can do this

1320
00:52:09,200 --> 00:52:13,859
again like I don't care about in this

1321
00:52:13,859 --> 00:52:15,329
world for these queries I'm not

1322
00:52:15,329 --> 00:52:18,660
enforcing integrity constraints I'm just

1323
00:52:18,660 --> 00:52:20,460
running this read query is analytical

1324
00:52:20,460 --> 00:52:22,739
queries to figure out you know how to

1325
00:52:22,739 --> 00:52:24,029
compute the joint efficiently on a large

1326
00:52:24,029 --> 00:52:27,690
a large data corpus the transactional

1327
00:52:27,690 --> 00:52:29,519
side it cares about integrity

1328
00:52:29,519 --> 00:52:31,079
constraints when you because you're

1329
00:52:31,079 --> 00:52:32,190
you're modifying the state of the

1330
00:52:32,190 --> 00:52:43,799
database no notice so so going back to

1331
00:52:43,799 --> 00:52:51,779
my initial example here like for this

1332
00:52:51,779 --> 00:52:56,339
ETL thing so this thing of this like

1333
00:52:56,339 --> 00:52:58,410
your bulk loading a bunch of data like

1334
00:52:58,410 --> 00:52:59,969
this is sort of streaming it's not happy

1335
00:52:59,969 --> 00:53:02,160
it's not like all at once here's a bunch

1336
00:53:02,160 --> 00:53:03,210
of data but you're streaming

1337
00:53:03,210 --> 00:53:06,150
incrementally updates from the front end

1338
00:53:06,150 --> 00:53:08,519
to your back end data warehouse and the

1339
00:53:08,519 --> 00:53:10,349
back end data warehouse could choose or

1340
00:53:10,349 --> 00:53:12,119
not choose to enforce those integrity

1341
00:53:12,119 --> 00:53:15,779
strains as it comes in but but it won't

1342
00:53:15,779 --> 00:53:18,869
be on the critical path of when we

1343
00:53:18,869 --> 00:53:20,039
execute our queries because I'm running

1344
00:53:20,039 --> 00:53:21,329
a selects David I'm not checking to see

1345
00:53:21,329 --> 00:53:23,789
whether my primary key is unique so now

1346
00:53:23,789 --> 00:53:25,469
how you enforce that integrity

1347
00:53:25,469 --> 00:53:27,479
constraint as you ingest the data into

1348
00:53:27,479 --> 00:53:29,160
your back into a toe warehouse well

1349
00:53:29,160 --> 00:53:30,479
that's the same thing we talked at last

1350
00:53:30,479 --> 00:53:32,219
class how to do transactions because

1351
00:53:32,219 --> 00:53:34,739
that is a type of transaction you know

1352
00:53:34,739 --> 00:53:36,239
insert something make sure it's unique I

1353
00:53:36,239 --> 00:53:37,799
need to coordinate across multiple nodes

1354
00:53:37,799 --> 00:53:39,660
if I'm not everything's not on a single

1355
00:53:39,660 --> 00:53:42,599
node to make that check it does everyone

1356
00:53:42,599 --> 00:53:43,799
agree that we can go ahead and make this

1357
00:53:43,799 --> 00:53:46,529
change so a lot of times in these

1358
00:53:46,529 --> 00:53:48,599
analytical data warehouses they will

1359
00:53:48,599 --> 00:53:52,229
have they will sort of have a separate

1360
00:53:52,229 --> 00:53:55,230
engine or a poor

1361
00:53:55,230 --> 00:53:57,390
Gorge area that is designed to do

1362
00:53:57,390 --> 00:53:59,100
efficient more are more efficient

1363
00:53:59,100 --> 00:54:01,859
updates than what a you know a

1364
00:54:01,859 --> 00:54:03,990
traditional comm store data system would

1365
00:54:03,990 --> 00:54:07,050
do if you take the advanced class we

1366
00:54:07,050 --> 00:54:08,280
will cover that we didn't cover that

1367
00:54:08,280 --> 00:54:12,210
here right so again for our purpose here

1368
00:54:12,210 --> 00:54:13,890
today we don't care about enforcing that

1369
00:54:13,890 --> 00:54:15,869
integrity train we assumed that it was

1370
00:54:15,869 --> 00:54:18,090
already handled for us some database

1371
00:54:18,090 --> 00:54:20,070
systems I mean some data warehouses they

1372
00:54:20,070 --> 00:54:21,480
just turn all that crap off they turn

1373
00:54:21,480 --> 00:54:23,730
off foreign keys they turn off unique

1374
00:54:23,730 --> 00:54:26,430
keys your data is a little dirty who

1375
00:54:26,430 --> 00:54:46,320
cares for analytics right so this

1376
00:54:46,320 --> 00:54:51,960
question is you have your bank account

1377
00:54:51,960 --> 00:54:54,750
or what it whatever your your your game

1378
00:54:54,750 --> 00:54:57,030
information you you update your user

1379
00:54:57,030 --> 00:54:58,140
account on the front end o to be

1380
00:54:58,140 --> 00:54:59,490
database because that's what that's the

1381
00:54:59,490 --> 00:55:01,260
users are touching this part they don't

1382
00:55:01,260 --> 00:55:02,250
touch the back in data or house they

1383
00:55:02,250 --> 00:55:04,350
make updates here that update gets

1384
00:55:04,350 --> 00:55:05,850
propagated and you want to go update the

1385
00:55:05,850 --> 00:55:08,280
record here has that happen advanced

1386
00:55:08,280 --> 00:55:10,170
class in general what I'll say is like

1387
00:55:10,170 --> 00:55:13,320
you buffer a bunch of changes in a sort

1388
00:55:13,320 --> 00:55:15,180
of right optimized storage layer or

1389
00:55:15,180 --> 00:55:17,010
execution engine in these data warehouse

1390
00:55:17,010 --> 00:55:18,960
and then they periodically merge the

1391
00:55:18,960 --> 00:55:23,070
change into the data warehouse or into

1392
00:55:23,070 --> 00:55:24,990
like the the main column store tables

1393
00:55:24,990 --> 00:55:27,830
for the for that for the new analytics

1394
00:55:27,830 --> 00:55:31,640
different systems do different things

1395
00:55:34,580 --> 00:55:37,580
okay

1396
00:55:39,450 --> 00:55:44,200
so any other questions about about this

1397
00:55:44,200 --> 00:55:44,819
stuff here

1398
00:55:44,819 --> 00:56:02,859
yes go ahead yes her question is I said

1399
00:56:02,859 --> 00:56:05,049
here that if when we go to copy this

1400
00:56:05,049 --> 00:56:07,269
thing here for this particular query if

1401
00:56:07,269 --> 00:56:11,920
we run a disk base and the query crashes

1402
00:56:11,920 --> 00:56:14,619
couldn't the query optimizer figure that

1403
00:56:14,619 --> 00:56:16,119
ahead of time and say oh I'm not gonna

1404
00:56:16,119 --> 00:56:18,670
have a disk space let me let me make

1405
00:56:18,670 --> 00:56:21,309
sure that maybe not run a certain way

1406
00:56:21,309 --> 00:56:24,549
here the query optimizer is usually do

1407
00:56:24,549 --> 00:56:26,920
not reason about what our other queries

1408
00:56:26,920 --> 00:56:29,740
running at the same time it assumed your

1409
00:56:29,740 --> 00:56:36,279
query runs in isolation and that it it

1410
00:56:36,279 --> 00:56:38,549
could reason about certain things like

1411
00:56:38,549 --> 00:56:40,630
some sort of some systems you can

1412
00:56:40,630 --> 00:56:42,789
specify how much temporary buffer space

1413
00:56:42,789 --> 00:56:44,589
or temporary displace the queries

1414
00:56:44,589 --> 00:56:46,299
allowed to use and then if you exceed

1415
00:56:46,299 --> 00:56:47,829
that in your query fails and it throws

1416
00:56:47,829 --> 00:56:49,509
you back hey you know creases parameter

1417
00:56:49,509 --> 00:56:51,970
if you want to keep running so it could

1418
00:56:51,970 --> 00:56:53,859
potentially figure out at planning time

1419
00:56:53,859 --> 00:56:56,380
oh I'm gonna copy over more data than I

1420
00:56:56,380 --> 00:56:57,880
have space for for this particular query

1421
00:56:57,880 --> 00:57:00,640
and throw an error but if like you dis

1422
00:57:00,640 --> 00:57:02,829
physically runs out of space even though

1423
00:57:02,829 --> 00:57:04,890
you're not within that you know you you

1424
00:57:04,890 --> 00:57:07,690
you haven't exceeded that limit on a per

1425
00:57:07,690 --> 00:57:09,609
query basis the query optimizer usually

1426
00:57:09,609 --> 00:57:11,650
does not think about or cannot reason

1427
00:57:11,650 --> 00:57:12,640
about what queries are running the same

1428
00:57:12,640 --> 00:57:13,960
time cuz that just makes your life

1429
00:57:13,960 --> 00:57:16,809
harder cuz like this query first-years

1430
00:57:16,809 --> 00:57:18,160
up I plan it I say all right nothing's

1431
00:57:18,160 --> 00:57:20,559
running now let me go ahead and and

1432
00:57:20,559 --> 00:57:22,089
choose one kind of plan because I'm

1433
00:57:22,089 --> 00:57:23,950
running by myself and start running and

1434
00:57:23,950 --> 00:57:25,299
then this other query now shows up I

1435
00:57:25,299 --> 00:57:27,670
don't want to go back and modify that

1436
00:57:27,670 --> 00:57:28,990
other queries plan to say hey now you're

1437
00:57:28,990 --> 00:57:30,039
also be running another query at the

1438
00:57:30,039 --> 00:57:33,329
same time that's way too hard

1439
00:57:39,280 --> 00:57:43,130
my comment was that sometimes you see in

1440
00:57:43,130 --> 00:57:45,859
data warehouses so the the database

1441
00:57:45,859 --> 00:57:49,040
system itself could support schema

1442
00:57:49,040 --> 00:57:51,170
enforcing integrity constraints foreign

1443
00:57:51,170 --> 00:57:52,820
keys primary keys referential integrity

1444
00:57:52,820 --> 00:57:55,099
and stuff like that it could support

1445
00:57:55,099 --> 00:57:58,760
those but the application developer the

1446
00:57:58,760 --> 00:58:00,530
person building the data warehouse may

1447
00:58:00,530 --> 00:58:02,089
say I don't want to pay the penalty to

1448
00:58:02,089 --> 00:58:03,619
check for foreign keys let me turn all

1449
00:58:03,619 --> 00:58:22,670
that off this question is I said that in

1450
00:58:22,670 --> 00:58:27,530
the previous slide that in general most

1451
00:58:27,530 --> 00:58:32,150
shared-nothing actually shared disk

1452
00:58:32,150 --> 00:58:36,680
notice distributed OLAP databases do not

1453
00:58:36,680 --> 00:58:39,079
support query fault tolerance or query

1454
00:58:39,079 --> 00:58:42,290
query resiliency where if a query if

1455
00:58:42,290 --> 00:58:44,660
they know crashes that's a response for

1456
00:58:44,660 --> 00:58:46,190
executing query halfway through the

1457
00:58:46,190 --> 00:58:50,180
query execution they are not able to

1458
00:58:50,180 --> 00:58:52,460
recover the enemy results of that query

1459
00:58:52,460 --> 00:58:55,700
it was had or computed and then picked

1460
00:58:55,700 --> 00:58:57,020
the query up where it left off in

1461
00:58:57,020 --> 00:58:58,280
general they just killed the whole thing

1462
00:58:58,280 --> 00:58:59,990
through an error or maybe restart it

1463
00:58:59,990 --> 00:59:03,020
silently for you that has nothing to do

1464
00:59:03,020 --> 00:59:05,030
with logging and recovery we absolutely

1465
00:59:05,030 --> 00:59:07,160
still need login recovery and we still

1466
00:59:07,160 --> 00:59:10,369
do that this is this is this is more

1467
00:59:10,369 --> 00:59:12,349
about while the queries running do I can

1468
00:59:12,349 --> 00:59:14,569
I take snapshots as I go along so that I

1469
00:59:14,569 --> 00:59:16,430
can pick up I can pick up midway where

1470
00:59:16,430 --> 00:59:17,540
the query was running if I know Goes

1471
00:59:17,540 --> 00:59:20,060
Down and I'm in the the statement I made

1472
00:59:20,060 --> 00:59:22,220
was that to the best of my knowledge

1473
00:59:22,220 --> 00:59:24,380
most distributed OLAP systems do not

1474
00:59:24,380 --> 00:59:26,480
support that query resiliency because

1475
00:59:26,480 --> 00:59:28,970
taking the check points the snapshots of

1476
00:59:28,970 --> 00:59:37,609
the mediary result is expensive logging

1477
00:59:37,609 --> 00:59:41,500
of what so what logging of what

1478
00:59:41,880 --> 00:59:45,910
the query of the database we're still

1479
00:59:45,910 --> 00:59:50,200
all the fault on all the the D the D and

1480
00:59:50,200 --> 00:59:51,430
acid stuff that we talked about before

1481
00:59:51,430 --> 00:59:54,310
we are still doing that we are still

1482
00:59:54,310 --> 00:59:56,830
making sure that if we ingest data from

1483
00:59:56,830 --> 00:59:58,390
the outside world up to our database we

1484
00:59:58,390 --> 01:00:02,140
don't want to lose that and so what they

1485
01:00:02,140 --> 01:00:03,780
will all provide durability guarantees

1486
01:00:03,780 --> 01:00:06,760
again I am I have a hundred petabytes of

1487
01:00:06,760 --> 01:00:08,620
Walmart they don't want to lose that

1488
01:00:08,620 --> 01:00:10,960
data all right and the days of them will

1489
01:00:10,960 --> 01:00:24,880
guarantee that they won't when you say

1490
01:00:24,880 --> 01:00:26,410
operation again what do you mean like

1491
01:00:26,410 --> 01:00:28,930
the UH nup date to it or we are queer e

1492
01:00:28,930 --> 01:00:38,080
I got like a select query let's take us

1493
01:00:38,080 --> 01:00:40,000
let's go let's sit down afterwards guy

1494
01:00:40,000 --> 01:00:42,670
I'll go through this I think there's

1495
01:00:42,670 --> 01:00:49,300
something you're missing here okay so to

1496
01:00:49,300 --> 01:00:50,830
his question about what am I actually

1497
01:00:50,830 --> 01:00:53,170
sending when I do these to ship it

1498
01:00:53,170 --> 01:00:55,480
adjoins am i sending the whole tuple or

1499
01:00:55,480 --> 01:00:57,670
am i sending them sending sending an

1500
01:00:57,670 --> 01:01:00,040
identifier and I always say the answer

1501
01:01:00,040 --> 01:01:02,890
is that you're sending at the very least

1502
01:01:02,890 --> 01:01:04,450
you're sending the minimum amount of

1503
01:01:04,450 --> 01:01:05,710
information that you need in order to

1504
01:01:05,710 --> 01:01:08,530
compute the join and then the worst-case

1505
01:01:08,530 --> 01:01:10,170
scenario you're sending the entire tuple

1506
01:01:10,170 --> 01:01:13,480
and in general again the the high end

1507
01:01:13,480 --> 01:01:16,030
the good distributed databases that are

1508
01:01:16,030 --> 01:01:18,730
doing analytics will minimize the amount

1509
01:01:18,730 --> 01:01:21,880
that data that you actually need and so

1510
01:01:21,880 --> 01:01:24,580
they're petite have a query would be

1511
01:01:24,580 --> 01:01:26,200
called using what is called a semi joint

1512
01:01:26,200 --> 01:01:30,190
a semi joint is like a regular join but

1513
01:01:30,190 --> 01:01:32,590
the idea is that we're not really gonna

1514
01:01:32,590 --> 01:01:35,980
do a join on the on the right table or

1515
01:01:35,980 --> 01:01:38,590
the inner table we're only gonna check

1516
01:01:38,590 --> 01:01:40,890
to see whether if we dare to join a

1517
01:01:40,890 --> 01:01:44,920
tuple would match so the query optimizer

1518
01:01:44,920 --> 01:01:47,950
can recognize that it may not need all

1519
01:01:47,950 --> 01:01:50,320
the old any inmate may not need any

1520
01:01:50,320 --> 01:01:51,910
values or attributes are from the

1521
01:01:51,910 --> 01:01:54,890
columns of the inner table

1522
01:01:54,890 --> 01:01:57,109
and therefore it can rewrite the query

1523
01:01:57,109 --> 01:01:59,900
just as do an existence check and send

1524
01:01:59,900 --> 01:02:02,240
the middleman information back and forth

1525
01:02:02,240 --> 01:02:04,789
of he knows to do that semi join rather

1526
01:02:04,789 --> 01:02:08,480
than copying the entire tuple again like

1527
01:02:08,480 --> 01:02:09,740
a natural join you would cut you would

1528
01:02:09,740 --> 01:02:11,240
do the join and then the output would be

1529
01:02:11,240 --> 01:02:13,880
all the result in the combination or the

1530
01:02:13,880 --> 01:02:16,099
the concatenated to post on the right

1531
01:02:16,099 --> 01:02:18,680
and the left table and a semi join it's

1532
01:02:18,680 --> 01:02:19,970
just the attributes that needed to

1533
01:02:19,970 --> 01:02:24,410
compute to join from the outer table so

1534
01:02:24,410 --> 01:02:26,569
in this case here say I have a query

1535
01:02:26,569 --> 01:02:29,960
like this select our ID from from are

1536
01:02:29,960 --> 01:02:32,119
doing outer join on s and we'll just

1537
01:02:32,119 --> 01:02:34,490
match my IDE oh and then this is a

1538
01:02:34,490 --> 01:02:35,569
poorly written query because they're

1539
01:02:35,569 --> 01:02:37,160
basically saying where our ID is not

1540
01:02:37,160 --> 01:02:41,809
null then match up with what on s so if

1541
01:02:41,809 --> 01:02:44,029
we didn't do a semi join we either have

1542
01:02:44,029 --> 01:02:48,010
to copy s over here or or R over here

1543
01:02:48,010 --> 01:02:50,000
again we're copying the entire tuple

1544
01:02:50,000 --> 01:02:52,160
that would be expensive but we could

1545
01:02:52,160 --> 01:02:53,720
rewrite this query to be like this where

1546
01:02:53,720 --> 01:02:55,010
we just check to see whether there

1547
01:02:55,010 --> 01:02:58,670
exists a tuple in s that has the same

1548
01:02:58,670 --> 01:03:02,390
ideas our ID and then if that's true

1549
01:03:02,390 --> 01:03:04,549
then we just spit out all our our IDs

1550
01:03:04,549 --> 01:03:06,619
that match so in this case here the only

1551
01:03:06,619 --> 01:03:08,059
thing I need to send over is just maybe

1552
01:03:08,059 --> 01:03:10,160
just the our IDs because that's the bare

1553
01:03:10,160 --> 01:03:11,599
minimum information I need in order to

1554
01:03:11,599 --> 01:03:21,230
compute this join so the some systems

1555
01:03:21,230 --> 01:03:23,059
like Claude hours and Paulo actually has

1556
01:03:23,059 --> 01:03:25,430
an explicit semi join keyword you can

1557
01:03:25,430 --> 01:03:27,829
give it otherwise you can try to fake it

1558
01:03:27,829 --> 01:03:30,500
with it exist the high end systems can

1559
01:03:30,500 --> 01:03:32,480
check to try to rewrite your query into

1560
01:03:32,480 --> 01:03:34,880
a semi join again it's part is figuring

1561
01:03:34,880 --> 01:03:36,049
out what data I need is transmitted

1562
01:03:36,049 --> 01:03:37,160
between between the different notes and

1563
01:03:37,160 --> 01:03:39,170
includes that in its cost calculations

1564
01:03:39,170 --> 01:03:40,579
in the optimizers cost model or to

1565
01:03:40,579 --> 01:03:42,500
decide how much data might transmit in

1566
01:03:42,500 --> 01:03:44,089
between different nodes as one plan

1567
01:03:44,089 --> 01:03:49,970
better than another so like I could have

1568
01:03:49,970 --> 01:03:53,930
I could say select our ID from our semi

1569
01:03:53,930 --> 01:03:58,220
join on s ID explicit sequel that does

1570
01:03:58,220 --> 01:03:59,690
that says hey you're doing a semi join

1571
01:03:59,690 --> 01:04:03,200
or I can rewrite it as this most systems

1572
01:04:03,200 --> 01:04:04,160
you have to do this because they don't

1573
01:04:04,160 --> 01:04:05,420
have I don't think semi joins in the

1574
01:04:05,420 --> 01:04:07,720
sequel standard

1575
01:04:10,890 --> 01:04:12,969
questions who does who does this work

1576
01:04:12,969 --> 01:04:14,049
and this example here this is the

1577
01:04:14,049 --> 01:04:19,420
application programmer the the high-end

1578
01:04:19,420 --> 01:04:21,099
enterprise systems that have good query

1579
01:04:21,099 --> 01:04:22,660
optimizers could figure out how to

1580
01:04:22,660 --> 01:04:24,910
potentially rewrite this for you they

1581
01:04:24,910 --> 01:04:30,160
can do that for you Oh quite your

1582
01:04:30,160 --> 01:04:32,049
question is the query optimizer another

1583
01:04:32,049 --> 01:04:38,489
node another like what do you mind node

1584
01:04:41,099 --> 01:04:43,690
even so this is like a partition that

1585
01:04:43,690 --> 01:04:47,079
you think it doesn't matter doesn't

1586
01:04:47,079 --> 01:04:47,979
matter what the query optimizer is

1587
01:04:47,979 --> 01:04:49,569
running this node here or another node

1588
01:04:49,569 --> 01:04:50,229
doesn't matter

1589
01:04:50,229 --> 01:04:51,849
did for more talked about here this is

1590
01:04:51,849 --> 01:04:54,130
just sort of like the semantics of the

1591
01:04:54,130 --> 01:04:55,529
semi joint

1592
01:04:55,529 --> 01:04:59,769
so from relational algebra standpoint it

1593
01:04:59,769 --> 01:05:01,269
just looks like this I'm joining R and s

1594
01:05:01,269 --> 01:05:04,029
and then the output this is the semi

1595
01:05:04,029 --> 01:05:06,579
joint operator the output would be just

1596
01:05:06,579 --> 01:05:09,700
skin to be a ID be ID that I used to

1597
01:05:09,700 --> 01:05:12,309
compute the joint and nothing from from

1598
01:05:12,309 --> 01:05:18,390
the the inner table so is this clear

1599
01:05:18,390 --> 01:05:23,920
there's a home a question on it all

1600
01:05:23,920 --> 01:05:28,209
right so we have ten minutes so as I

1601
01:05:28,209 --> 01:05:30,130
said this is to sort of crash course on

1602
01:05:30,130 --> 01:05:34,479
on crash course on the main design

1603
01:05:34,479 --> 01:05:38,109
decisions in the issues in tuning and a

1604
01:05:38,109 --> 01:05:40,779
little database if you're not going to

1605
01:05:40,779 --> 01:05:42,400
be building a you know an illiberal

1606
01:05:42,400 --> 01:05:43,599
database min root system actually

1607
01:05:43,599 --> 01:05:44,680
working on the internals of the system

1608
01:05:44,680 --> 01:05:46,630
you just want to be a user of them the

1609
01:05:46,630 --> 01:05:48,039
main issue you're going to deal with is

1610
01:05:48,039 --> 01:05:50,349
that partition key how to pick that in

1611
01:05:50,349 --> 01:05:53,109
such a way that most your joins can

1612
01:05:53,109 --> 01:05:54,819
operate on a local node without having

1613
01:05:54,819 --> 01:05:57,640
to do a broadcast or our shuffle and the

1614
01:05:57,640 --> 01:06:00,160
the the various systems that are out

1615
01:06:00,160 --> 01:06:01,930
there mostly the enterprise guys have

1616
01:06:01,930 --> 01:06:03,190
tools to help you try to figure these

1617
01:06:03,190 --> 01:06:07,959
things out for you okay all right let's

1618
01:06:07,959 --> 01:06:12,459
talk bout Claudius's so the definition

1619
01:06:12,459 --> 01:06:15,390
of comp cloud database is a bit nebulous

1620
01:06:15,390 --> 01:06:18,950
no pun intended the the

1621
01:06:18,950 --> 01:06:21,450
typically what it means is if some

1622
01:06:21,450 --> 01:06:23,070
vendor offering you what is called a

1623
01:06:23,070 --> 01:06:26,010
database as a service from dbaas the

1624
01:06:26,010 --> 01:06:28,170
idea is that you give Amazon whoever

1625
01:06:28,170 --> 01:06:30,090
your credit card and they will say

1626
01:06:30,090 --> 01:06:32,580
here's your JDBC or no DBC connection

1627
01:06:32,580 --> 01:06:35,460
port number and and and hostname that

1628
01:06:35,460 --> 01:06:37,050
you should start shoving queries into it

1629
01:06:37,050 --> 01:06:39,840
and you don't worry about how to manage

1630
01:06:39,840 --> 01:06:41,550
the nodes you don't worry about how to

1631
01:06:41,550 --> 01:06:44,190
do backups they take care of all of that

1632
01:06:44,190 --> 01:06:47,820
for you and so I already sort of

1633
01:06:47,820 --> 01:06:50,790
mentioned this before but the the in

1634
01:06:50,790 --> 01:06:52,800
these some major cloud vendors people

1635
01:06:52,800 --> 01:06:55,050
that control the whole stack like Amazon

1636
01:06:55,050 --> 01:06:57,810
like Google like Microsoft the lines

1637
01:06:57,810 --> 01:07:00,720
between what is a shared disk system

1638
01:07:00,720 --> 01:07:02,430
versus a share nothing system is

1639
01:07:02,430 --> 01:07:04,290
starting to get really blurry because

1640
01:07:04,290 --> 01:07:06,480
they can push down database logic up

1641
01:07:06,480 --> 01:07:08,190
between up and down the different layers

1642
01:07:08,190 --> 01:07:10,800
of the system stack in a way that you

1643
01:07:10,800 --> 01:07:13,200
typically can't do unless you control

1644
01:07:13,200 --> 01:07:16,130
the hardware yourself so for example

1645
01:07:16,130 --> 01:07:18,060
Amazon has something called Aurora

1646
01:07:18,060 --> 01:07:20,820
Aurora is a shared disk version of my

1647
01:07:20,820 --> 01:07:22,920
sequel in Postgres but they actually

1648
01:07:22,920 --> 01:07:25,680
push logic to do transaction management

1649
01:07:25,680 --> 01:07:28,620
down into the storage layer in the EBS

1650
01:07:28,620 --> 01:07:32,160
again at the shared disk level and so

1651
01:07:32,160 --> 01:07:34,410
now it's not pure pure shared disk

1652
01:07:34,410 --> 01:07:36,030
system anymore it starts to look a bit

1653
01:07:36,030 --> 01:07:40,590
more like a shared nothing system so

1654
01:07:40,590 --> 01:07:43,440
alright so I think in the next ten years

1655
01:07:43,440 --> 01:07:45,150
I think the cloud systems will receive

1656
01:07:45,150 --> 01:07:46,440
the mote you see the most innovation in

1657
01:07:46,440 --> 01:07:48,030
the cloud systems and I think it's

1658
01:07:48,030 --> 01:07:49,110
really really interesting what they can

1659
01:07:49,110 --> 01:07:53,310
kind of do alright so I think I've

1660
01:07:53,310 --> 01:07:55,740
really talked about this in general a

1661
01:07:55,740 --> 01:07:58,200
cloud system could either be a managed

1662
01:07:58,200 --> 01:08:00,060
database or a cloud native database so

1663
01:08:00,060 --> 01:08:01,710
managed database would be just taking an

1664
01:08:01,710 --> 01:08:03,450
off-the-shelf database that system that

1665
01:08:03,450 --> 01:08:05,160
was written to run on premise on

1666
01:08:05,160 --> 01:08:07,080
dedicated hardware and now you're just

1667
01:08:07,080 --> 01:08:09,450
running this for you as a service take

1668
01:08:09,450 --> 01:08:12,120
my Seco take Postgres and then you plop

1669
01:08:12,120 --> 01:08:14,550
it into an ec2 instance and then have

1670
01:08:14,550 --> 01:08:16,830
people connect to it and they don't know

1671
01:08:16,830 --> 01:08:19,200
and don't care that you're managing ec2

1672
01:08:19,200 --> 01:08:20,729
for them that they could have done that

1673
01:08:20,729 --> 01:08:23,760
themselves but you're just providing a

1674
01:08:23,760 --> 01:08:24,899
service to do all the backup and other

1675
01:08:24,899 --> 01:08:28,229
management stuff for them so most of the

1676
01:08:28,229 --> 01:08:29,520
times when you see when you get a cloud

1677
01:08:29,520 --> 01:08:31,080
database it's gonna be it's gonna be the

1678
01:08:31,080 --> 01:08:32,290
first one

1679
01:08:32,290 --> 01:08:35,540
now there are some systems where though

1680
01:08:35,540 --> 01:08:36,859
they'll refer to themselves as being a

1681
01:08:36,859 --> 01:08:38,479
cloud native data internet system and

1682
01:08:38,479 --> 01:08:41,139
these are ones where they're designed to

1683
01:08:41,139 --> 01:08:43,279
operate in a cloud environment and

1684
01:08:43,279 --> 01:08:44,599
typically they're going to be a shared

1685
01:08:44,599 --> 01:08:47,089
disk architecture because they don't

1686
01:08:47,089 --> 01:08:48,380
want actually have to build you know

1687
01:08:48,380 --> 01:08:50,960
replicate EBS or s3 so they'll build on

1688
01:08:50,960 --> 01:08:52,929
top of the existing storage

1689
01:08:52,929 --> 01:08:54,859
infrastructure that these cloud vendors

1690
01:08:54,859 --> 01:08:56,540
provide you and they're providing the

1691
01:08:56,540 --> 01:08:58,189
the compute layer on top of it you know

1692
01:08:58,189 --> 01:08:59,630
Stefan do query planning you still have

1693
01:08:59,630 --> 01:09:01,429
to do all the fault tolerant stuff we

1694
01:09:01,429 --> 01:09:03,109
talked about before but they don't worry

1695
01:09:03,109 --> 01:09:04,639
about actually how to you know persist

1696
01:09:04,639 --> 01:09:06,948
things to disk they just let cloud

1697
01:09:06,948 --> 01:09:12,618
vendor provide that for you so there is

1698
01:09:12,618 --> 01:09:14,299
now also a new class of systems that

1699
01:09:14,299 --> 01:09:18,009
label themselves as being serviced yes

1700
01:09:24,399 --> 01:09:27,618
yeah question is what would it like what

1701
01:09:27,618 --> 01:09:28,759
is it what is truly the difference here

1702
01:09:28,759 --> 01:09:30,880
so this would be a manager this would be

1703
01:09:30,880 --> 01:09:34,549
just using my sequence example I take my

1704
01:09:34,549 --> 01:09:36,408
sequel I didn't run it without making

1705
01:09:36,408 --> 01:09:38,149
any changes to it I run it in a

1706
01:09:38,149 --> 01:09:41,658
container or I run it in a VM and it's

1707
01:09:41,658 --> 01:09:43,488
the same software that I would run on my

1708
01:09:43,488 --> 01:09:45,618
local machine but just now I'm running

1709
01:09:45,618 --> 01:09:48,069
it in a you know in a cloud for you

1710
01:09:48,069 --> 01:09:52,279
right and then old and then the the

1711
01:09:52,279 --> 01:09:54,259
service provider will then also do the

1712
01:09:54,259 --> 01:09:55,730
backups and recovery and all the other

1713
01:09:55,730 --> 01:09:57,320
stuff for you this would be like I'm

1714
01:09:57,320 --> 01:09:58,670
building a new database system scratch

1715
01:09:58,670 --> 01:10:00,889
or I take an existing one and I make

1716
01:10:00,889 --> 01:10:03,409
heavy changes to it to be designed to

1717
01:10:03,409 --> 01:10:07,219
work in a cloud environment so up here

1718
01:10:07,219 --> 01:10:08,690
running my cycle my Seco doesn't know

1719
01:10:08,690 --> 01:10:09,710
anything but s3 doesn't know anything

1720
01:10:09,710 --> 01:10:11,690
about the performance implications of

1721
01:10:11,690 --> 01:10:13,250
you know reading PBS and things like

1722
01:10:13,250 --> 01:10:14,690
that just have a disk it has these

1723
01:10:14,690 --> 01:10:16,909
properties this would be like oh I've

1724
01:10:16,909 --> 01:10:18,170
designed the system's explicity to work

1725
01:10:18,170 --> 01:10:19,820
on s/3 s/3 provides me these guarantees

1726
01:10:19,820 --> 01:10:21,679
provide me these properties that

1727
01:10:21,679 --> 01:10:23,420
information now permeates all throughout

1728
01:10:23,420 --> 01:10:25,730
the system like my query optimizers cost

1729
01:10:25,730 --> 01:10:27,469
model can reason about you know what's

1730
01:10:27,469 --> 01:10:28,909
the speed of writing s3 or what you know

1731
01:10:28,909 --> 01:10:30,440
what can you do a nester you can't do on

1732
01:10:30,440 --> 01:10:31,040
EBS

1733
01:10:31,040 --> 01:10:36,230
stuff like that alright so there's a the

1734
01:10:36,230 --> 01:10:37,730
the buzzword going around now is

1735
01:10:37,730 --> 01:10:38,270
serverless

1736
01:10:38,270 --> 01:10:39,980
so of course there's server list

1737
01:10:39,980 --> 01:10:43,340
databases and so it's the same

1738
01:10:43,340 --> 01:10:44,840
everything's the same that we talked

1739
01:10:44,840 --> 01:10:45,650
about before

1740
01:10:45,650 --> 01:10:48,260
it's just that the idea is that when

1741
01:10:48,260 --> 01:10:50,570
your machine goes idle your data has

1742
01:10:50,570 --> 01:10:51,500
connection those idle because your

1743
01:10:51,500 --> 01:10:53,110
application is no longer sending queries

1744
01:10:53,110 --> 01:10:56,020
they will try to then deeper vision or

1745
01:10:56,020 --> 01:10:58,670
have you you know not pay for hardware

1746
01:10:58,670 --> 01:11:01,430
that you're not actually using so let's

1747
01:11:01,430 --> 01:11:04,310
say that I have again a managed database

1748
01:11:04,310 --> 01:11:05,840
system I have a single node it's running

1749
01:11:05,840 --> 01:11:09,320
my sequel and so I pay for I pay for the

1750
01:11:09,320 --> 01:11:11,450
instance I pay for the storage and I

1751
01:11:11,450 --> 01:11:12,860
have to provision it to be running all

1752
01:11:12,860 --> 01:11:14,840
the time so my application sends queries

1753
01:11:14,840 --> 01:11:16,310
to this guy and you know and gets

1754
01:11:16,310 --> 01:11:19,040
results comes back but now if my if my

1755
01:11:19,040 --> 01:11:20,660
application goes to sleep or walks away

1756
01:11:20,660 --> 01:11:24,590
goes the bathroom does whatever then I'm

1757
01:11:24,590 --> 01:11:26,870
paying for these resources I'm not

1758
01:11:26,870 --> 01:11:28,910
actually using right because I have to

1759
01:11:28,910 --> 01:11:30,140
provision the hard right that provision

1760
01:11:30,140 --> 01:11:31,700
the ec2 instance I provisioned the EBS

1761
01:11:31,700 --> 01:11:34,460
storage right so I'm paying for the

1762
01:11:34,460 --> 01:11:35,840
stuff to run and not actually do

1763
01:11:35,840 --> 01:11:39,140
anything so the idea with the serverless

1764
01:11:39,140 --> 01:11:41,510
database is it's almost always a shared

1765
01:11:41,510 --> 01:11:45,500
disk architecture is that I can do my

1766
01:11:45,500 --> 01:11:47,450
all my queries that I had before but now

1767
01:11:47,450 --> 01:11:50,600
when I go to sleep I decommission the

1768
01:11:50,600 --> 01:11:53,360
compute side of things this goes away

1769
01:11:53,360 --> 01:11:55,340
but before I do I basically take a

1770
01:11:55,340 --> 01:11:57,140
snapshot of what pages are my buffer

1771
01:11:57,140 --> 01:11:59,600
pool I take a checkpoint then record all

1772
01:11:59,600 --> 01:12:00,890
the page IDs or what's in my buffer pool

1773
01:12:00,890 --> 01:12:04,130
write that out the shared disk then kill

1774
01:12:04,130 --> 01:12:06,740
off my computer and so now the only

1775
01:12:06,740 --> 01:12:08,990
thing I'm paying for is storage just

1776
01:12:08,990 --> 01:12:11,000
paying for my data to rest at idle on

1777
01:12:11,000 --> 01:12:14,450
disk and then if I ever wake up and come

1778
01:12:14,450 --> 01:12:15,770
back and execute a query the very first

1779
01:12:15,770 --> 01:12:17,150
thing we're gonna do is say alright well

1780
01:12:17,150 --> 01:12:19,250
before I shut down the last time what

1781
01:12:19,250 --> 01:12:21,350
was in my buffer pool and got it trying

1782
01:12:21,350 --> 01:12:23,390
to fetch that in and make it as if I was

1783
01:12:23,390 --> 01:12:26,320
still running all the time

1784
01:12:27,070 --> 01:12:29,090
so this is one way to do it if you

1785
01:12:29,090 --> 01:12:31,250
assume that the there's only one

1786
01:12:31,250 --> 01:12:33,220
customer I'm running on a single node

1787
01:12:33,220 --> 01:12:35,570
another common setup would be you run

1788
01:12:35,570 --> 01:12:36,830
multiple customers or multiple tenants

1789
01:12:36,830 --> 01:12:38,780
on a single node and then you just

1790
01:12:38,780 --> 01:12:40,250
recognize that this customer has not

1791
01:12:40,250 --> 01:12:41,690
sent me to query in a while and then I

1792
01:12:41,690 --> 01:12:43,700
write out its buffer buffer pool page

1793
01:12:43,700 --> 01:12:48,220
contents out the disk before yes

1794
01:12:54,780 --> 01:12:58,330
so this question is why am I doing this

1795
01:12:58,330 --> 01:13:00,610
section chef why am i actually writing

1796
01:13:00,610 --> 01:13:02,200
the buffle blade page contents out to

1797
01:13:02,200 --> 01:13:05,050
disk before you know why do I care about

1798
01:13:05,050 --> 01:13:08,770
this because you want to make it as if

1799
01:13:08,770 --> 01:13:10,330
like the the most expensive thing is

1800
01:13:10,330 --> 01:13:12,820
fetching things from disk so ideally I

1801
01:13:12,820 --> 01:13:15,670
want to have you know my query the next

1802
01:13:15,670 --> 01:13:17,680
query shows up a minute later I don't

1803
01:13:17,680 --> 01:13:19,270
want to have everything all now evicted

1804
01:13:19,270 --> 01:13:21,400
from my buffer pool and I have to pay

1805
01:13:21,400 --> 01:13:24,340
this big upfront cost of warming all my

1806
01:13:24,340 --> 01:13:27,220
data I'm bringing into memory so you you

1807
01:13:27,220 --> 01:13:28,990
record all this information so that when

1808
01:13:28,990 --> 01:13:30,610
you come back again a minute later it

1809
01:13:30,610 --> 01:13:31,960
looks like the thing was still running

1810
01:13:31,960 --> 01:13:33,520
and you don't like you still paid a

1811
01:13:33,520 --> 01:13:35,770
penalty case you have to fetch it in but

1812
01:13:35,770 --> 01:13:36,940
you don't have to wait to like fetch

1813
01:13:36,940 --> 01:13:39,130
everything in you try to maybe prefetch

1814
01:13:39,130 --> 01:13:39,810
some stuff

1815
01:13:39,810 --> 01:13:41,800
you pre-warming with creamer in the

1816
01:13:41,800 --> 01:13:44,050
cache yeah every database system does

1817
01:13:44,050 --> 01:13:45,430
this when you call shut down do it like

1818
01:13:45,430 --> 01:13:46,960
a correct shot down they're already

1819
01:13:46,960 --> 01:14:00,670
doing this correct so his question is if

1820
01:14:00,670 --> 01:14:03,310
I don't do this step well this still

1821
01:14:03,310 --> 01:14:05,620
work yeah it'll be corrective it'll be

1822
01:14:05,620 --> 01:14:07,720
slow right this is this is just an

1823
01:14:07,720 --> 01:14:21,610
optimization to to can warm the cache in

1824
01:14:21,610 --> 01:14:23,170
a cigarette like we're just storing the

1825
01:14:23,170 --> 01:14:24,460
the cotton we're just turning the page

1826
01:14:24,460 --> 01:14:26,320
at ease we had in the buffer pool at the

1827
01:14:26,320 --> 01:14:29,230
time we at the moment did a shutdown so

1828
01:14:29,230 --> 01:14:31,810
then the first query shows up and and

1829
01:14:31,810 --> 01:14:33,130
then say the first query says go give me

1830
01:14:33,130 --> 01:14:35,830
page one two three it says oh I also had

1831
01:14:35,830 --> 01:14:37,330
four five six seven eight nine also in

1832
01:14:37,330 --> 01:14:38,890
there let me go fetch them and fetch the

1833
01:14:38,890 --> 01:14:45,070
Nolan yes this question her question is

1834
01:14:45,070 --> 01:14:46,780
how does it like to be stateless as in

1835
01:14:46,780 --> 01:14:49,840
the server lists it's usually what

1836
01:14:49,840 --> 01:14:52,480
people mean my service is stateless but

1837
01:14:52,480 --> 01:14:57,130
it isn't isn't right so if it's service

1838
01:14:57,130 --> 01:14:59,610
from the perspective of the end user

1839
01:14:59,610 --> 01:15:01,750
meaning like I don't have to say

1840
01:15:01,750 --> 01:15:03,760
provision me this machine so a lot of

1841
01:15:03,760 --> 01:15:05,380
cloud vendors they're not doing a

1842
01:15:05,380 --> 01:15:06,220
service architecture

1843
01:15:06,220 --> 01:15:07,900
you basically say

1844
01:15:07,900 --> 01:15:09,760
I want to be key I wouldn't you know I

1845
01:15:09,760 --> 01:15:11,469
want to pay for this dedicated resources

1846
01:15:11,469 --> 01:15:13,000
to be available for me at all time if

1847
01:15:13,000 --> 01:15:14,020
you're not using them they're so

1848
01:15:14,020 --> 01:15:17,290
charging you they're happy right but if

1849
01:15:17,290 --> 01:15:18,670
my I mean I have one query a minute I

1850
01:15:18,670 --> 01:15:19,659
don't want to me you know I don't want

1851
01:15:19,659 --> 01:15:21,219
to provision a whole machine just to

1852
01:15:21,219 --> 01:15:24,190
send X 60 queries an hour whereas in

1853
01:15:24,190 --> 01:15:25,630
this architecture I can still have my

1854
01:15:25,630 --> 01:15:27,219
database still as if it was running all

1855
01:15:27,219 --> 01:15:28,929
the time but I'm not paying that pending

1856
01:15:28,929 --> 01:15:30,730
so I pay or not I paid on a per query

1857
01:15:30,730 --> 01:15:33,190
basis plus whatever I'm storing over

1858
01:15:33,190 --> 01:15:39,130
here so the main vendors that are in

1859
01:15:39,130 --> 01:15:42,159
this space would be Amazon has a server

1860
01:15:42,159 --> 01:15:44,560
this version of my sequel and then fauna

1861
01:15:44,560 --> 01:15:46,600
DB is a as a separate database startup

1862
01:15:46,600 --> 01:15:49,900
that does so Amazon will try to all

1863
01:15:49,900 --> 01:15:51,070
these guys are doing

1864
01:15:51,070 --> 01:15:52,449
not exactly this where you kill the

1865
01:15:52,449 --> 01:15:54,190
machine they're just recognizing this

1866
01:15:54,190 --> 01:15:55,690
customer has not sent a query while and

1867
01:15:55,690 --> 01:15:58,030
and then they they write everything out

1868
01:15:58,030 --> 01:16:00,640
to disk so Azure can do this and then

1869
01:16:00,640 --> 01:16:04,449
Google I think it's these icons are so

1870
01:16:04,449 --> 01:16:05,500
useless because this like doesn't say

1871
01:16:05,500 --> 01:16:06,520
the name I know and I second what this

1872
01:16:06,520 --> 01:16:08,699
says I think it's the Google fire store

1873
01:16:08,699 --> 01:16:11,560
so not spanner or not the bigquery stuff

1874
01:16:11,560 --> 01:16:15,460
it's only for fire store all right so

1875
01:16:15,460 --> 01:16:16,780
another interesting thing about this is

1876
01:16:16,780 --> 01:16:19,300
that you could potentially build a

1877
01:16:19,300 --> 01:16:22,120
database system without having to write

1878
01:16:22,120 --> 01:16:26,340
every piece of the system yourself so

1879
01:16:26,340 --> 01:16:28,960
there's enough open-source software

1880
01:16:28,960 --> 01:16:31,449
that's out there now or services that

1881
01:16:31,449 --> 01:16:32,739
are out there you can cobble bunch of

1882
01:16:32,739 --> 01:16:34,449
these things together and make a new

1883
01:16:34,449 --> 01:16:36,429
cloud database without having to write

1884
01:16:36,429 --> 01:16:38,560
everything from scratch so we've already

1885
01:16:38,560 --> 01:16:40,390
talked about like as I said her question

1886
01:16:40,390 --> 01:16:41,530
was what is the cloud native database

1887
01:16:41,530 --> 01:16:43,090
well it's one where you assume that you

1888
01:16:43,090 --> 01:16:44,620
can write you know you the sulfur is

1889
01:16:44,620 --> 01:16:46,420
written to assume you're writing to s3

1890
01:16:46,420 --> 01:16:48,520
and you take those it's guarantees or

1891
01:16:48,520 --> 01:16:50,699
performance implications into the design

1892
01:16:50,699 --> 01:16:52,690
so that would be sort of one example

1893
01:16:52,690 --> 01:16:54,010
you're not the write that you know disk

1894
01:16:54,010 --> 01:16:56,320
manager you just let s3 handle that for

1895
01:16:56,320 --> 01:16:57,940
you you may not have to write your

1896
01:16:57,940 --> 01:17:00,040
catalogs right you can get metadata

1897
01:17:00,040 --> 01:17:01,840
service get metadata as a service

1898
01:17:01,840 --> 01:17:03,670
through these bunch of different types

1899
01:17:03,670 --> 01:17:05,739
of software you may not the manage your

1900
01:17:05,739 --> 01:17:07,929
cluster you can relies on kubernetes or

1901
01:17:07,929 --> 01:17:09,640
yarn or these other tools that the

1902
01:17:09,640 --> 01:17:11,650
vendors have to handle all that for you

1903
01:17:11,650 --> 01:17:13,989
and then you may not even have to build

1904
01:17:13,989 --> 01:17:16,270
your own query optimizer so there

1905
01:17:16,270 --> 01:17:18,489
actually are some open source

1906
01:17:18,489 --> 01:17:21,590
sort of optimizers as a service

1907
01:17:21,590 --> 01:17:23,840
where its runs on a separate node you

1908
01:17:23,840 --> 01:17:25,159
just feed it a bunch of XML or JSON

1909
01:17:25,159 --> 01:17:26,780
metadata to say here's what my data

1910
01:17:26,780 --> 01:17:28,340
looks like here's my query plan looks

1911
01:17:28,340 --> 01:17:30,139
like and then the separate machine will

1912
01:17:30,139 --> 01:17:33,219
then crunch on it and spit out a

1913
01:17:33,219 --> 01:17:35,420
potentially optimized plan for you I

1914
01:17:35,420 --> 01:17:36,770
don't know how good these things are

1915
01:17:36,770 --> 01:17:39,170
actually are I'm there has been any

1916
01:17:39,170 --> 01:17:41,570
study actually to evaluate them yet we

1917
01:17:41,570 --> 01:17:42,920
looked at Orca when we were building our

1918
01:17:42,920 --> 01:17:45,170
system and we passed on it because at

1919
01:17:45,170 --> 01:17:47,270
the time the documentation was terrible

1920
01:17:47,270 --> 01:17:49,340
Cal cites written in Java so that was a

1921
01:17:49,340 --> 01:17:52,340
non-starter for us as well all right the

1922
01:17:52,340 --> 01:17:55,480
last thing I briefly talked about is

1923
01:17:55,480 --> 01:18:00,080
file formats so pretty much until very

1924
01:18:00,080 --> 01:18:01,670
recently every single database minute

1925
01:18:01,670 --> 01:18:03,469
system always had their own proprietary

1926
01:18:03,469 --> 01:18:07,699
binary file format meaning like my

1927
01:18:07,699 --> 01:18:09,020
sequel writes a bunch of files a disk

1928
01:18:09,020 --> 01:18:11,090
you can't read those files into Oracle

1929
01:18:11,090 --> 01:18:12,409
well because Oracle has its own file

1930
01:18:12,409 --> 01:18:14,420
format can you do the same thing when

1931
01:18:14,420 --> 01:18:16,280
you built put your projects on bus tub

1932
01:18:16,280 --> 01:18:18,739
bus hub has its own page formats that

1933
01:18:18,739 --> 01:18:21,560
can't be read by anybody else so this is

1934
01:18:21,560 --> 01:18:23,449
problematic now if you're in a cloud

1935
01:18:23,449 --> 01:18:24,619
environment where you have a bunch of

1936
01:18:24,619 --> 01:18:27,050
different services that may want to

1937
01:18:27,050 --> 01:18:29,119
share data like a bunch of data I want

1938
01:18:29,119 --> 01:18:30,710
to generate my old to be databases and

1939
01:18:30,710 --> 01:18:32,210
maybe I want to run that data through

1940
01:18:32,210 --> 01:18:34,130
spark or learn that data through through

1941
01:18:34,130 --> 01:18:36,889
Vertica or some other Shiva database so

1942
01:18:36,889 --> 01:18:38,449
there right now if everything's based on

1943
01:18:38,449 --> 01:18:40,550
a pie chart format the only way you can

1944
01:18:40,550 --> 01:18:42,020
get data out from one system and put

1945
01:18:42,020 --> 01:18:44,239
into another system is to make copies

1946
01:18:44,239 --> 01:18:46,580
and put it into one of these human

1947
01:18:46,580 --> 01:18:49,250
readable text readable formats and so

1948
01:18:49,250 --> 01:18:51,290
now instead is that there's these open

1949
01:18:51,290 --> 01:18:53,239
source binary formats that a bunch of

1950
01:18:53,239 --> 01:18:55,010
cloud vendors or and distributed

1951
01:18:55,010 --> 01:18:57,469
databases or data science ecosystem

1952
01:18:57,469 --> 01:19:00,469
tools are now supporting to that I could

1953
01:19:00,469 --> 01:19:02,630
use right out to s3 or EBS or my

1954
01:19:02,630 --> 01:19:04,429
distributed file system a bunch of these

1955
01:19:04,429 --> 01:19:06,199
files in this format that might get my

1956
01:19:06,199 --> 01:19:08,150
data a system-generated and then I could

1957
01:19:08,150 --> 01:19:09,860
suck them in and read them into another

1958
01:19:09,860 --> 01:19:11,060
database without having to do that any

1959
01:19:11,060 --> 01:19:15,139
destabilization or conversion so some of

1960
01:19:15,139 --> 01:19:16,969
these you may have heard of but these

1961
01:19:16,969 --> 01:19:19,400
are just these are sort of a main ones

1962
01:19:19,400 --> 01:19:21,409
Parkay knork applied two most common

1963
01:19:21,409 --> 01:19:21,770
ones

1964
01:19:21,770 --> 01:19:24,080
Parkay Kemetic ladder and twitter and or

1965
01:19:24,080 --> 01:19:26,719
came out of hive and again think of

1966
01:19:26,719 --> 01:19:28,159
these are like binary column store

1967
01:19:28,159 --> 01:19:30,530
formats that are not tied to any one

1968
01:19:30,530 --> 01:19:32,540
pacific data system like an open

1969
01:19:32,540 --> 01:19:34,159
specification that anybody can modify

1970
01:19:34,159 --> 01:19:35,390
their database system Armada

1971
01:19:35,390 --> 01:19:37,370
by their application to read this data

1972
01:19:37,370 --> 01:19:40,820
natively Carbon data is a newer one

1973
01:19:40,820 --> 01:19:44,210
actually 2016 ish I think that's like

1974
01:19:44,210 --> 01:19:45,710
orc and the parkade that came out of

1975
01:19:45,710 --> 01:19:49,520
Hawaii in China iceberg is another new

1976
01:19:49,520 --> 01:19:52,910
one from from Netflix that I've just

1977
01:19:52,910 --> 01:19:55,430
notified recently by somebody I have

1978
01:19:55,430 --> 01:19:56,960
looked into much into yet but they claim

1979
01:19:56,960 --> 01:19:59,150
that they can support schema evolution

1980
01:19:59,150 --> 01:20:01,370
like I can do change columns and you

1981
01:20:01,370 --> 01:20:02,690
know change memes change column types

1982
01:20:02,690 --> 01:20:04,820
the way these other guys can these other

1983
01:20:04,820 --> 01:20:06,530
guys are read-only like I create the

1984
01:20:06,530 --> 01:20:08,180
file and then I freeze it and I can't go

1985
01:20:08,180 --> 01:20:10,850
back and change them hd5 is not

1986
01:20:10,850 --> 01:20:13,850
typically used in cloud systems or in

1987
01:20:13,850 --> 01:20:15,380
sort of traditional Silicon Valley

1988
01:20:15,380 --> 01:20:17,750
database for tech companies this is

1989
01:20:17,750 --> 01:20:20,270
mostly found in HPC in the scientific

1990
01:20:20,270 --> 01:20:22,610
world this is for like a Rea data like

1991
01:20:22,610 --> 01:20:24,380
you can have your you know your your

1992
01:20:24,380 --> 01:20:26,600
particle collider can can well spit out

1993
01:20:26,600 --> 01:20:27,970
bunch of these files in this type and

1994
01:20:27,970 --> 01:20:31,070
then arrow is an in-memory column format

1995
01:20:31,070 --> 01:20:35,030
that came out of pandas and gem IO that

1996
01:20:35,030 --> 01:20:36,530
think of this is like it's like parkade

1997
01:20:36,530 --> 01:20:39,140
orc but it's for in-memory data so our

1998
01:20:39,140 --> 01:20:40,760
data is more building here at Carnegie

1999
01:20:40,760 --> 01:20:42,950
Mellon our native stored format is

2000
01:20:42,950 --> 01:20:44,960
actually arrow so you could take data

2001
01:20:44,960 --> 01:20:47,210
that our data system generates dump it

2002
01:20:47,210 --> 01:20:49,790
out and feed it into pandas or whatever

2003
01:20:49,790 --> 01:20:51,110
it's I can't learn you want anything

2004
01:20:51,110 --> 01:20:53,570
that reads the arrow format so I think

2005
01:20:53,570 --> 01:20:55,430
this is the right way to go it is sort

2006
01:20:55,430 --> 01:20:56,240
of you get to the lowest common

2007
01:20:56,240 --> 01:20:58,400
denominator like there's you know the

2008
01:20:58,400 --> 01:20:59,900
compression scheme and all these these

2009
01:20:59,900 --> 01:21:03,590
different these formats may not be the

2010
01:21:03,590 --> 01:21:05,240
best for all possible applications and

2011
01:21:05,240 --> 01:21:06,950
certainly if you write a custom one you

2012
01:21:06,950 --> 01:21:07,700
could probably get much better

2013
01:21:07,700 --> 01:21:09,860
compression or better performance but

2014
01:21:09,860 --> 01:21:12,070
this this provides you interoperability

2015
01:21:12,070 --> 01:21:17,380
ok all right so just a finish up overlap

2016
01:21:17,380 --> 01:21:20,180
it means if you if you need analytical

2017
01:21:20,180 --> 01:21:22,280
database that needs to scale then you

2018
01:21:22,280 --> 01:21:24,260
have money because you're getting data

2019
01:21:24,260 --> 01:21:26,270
right people actually using whatever

2020
01:21:26,270 --> 01:21:27,920
application you have and you're actually

2021
01:21:27,920 --> 01:21:29,840
able to process it but the more data you

2022
01:21:29,840 --> 01:21:31,040
get and more problems you're gonna have

2023
01:21:31,040 --> 01:21:32,150
because because these two tivity

2024
01:21:32,150 --> 01:21:34,010
databases are you know all the

2025
01:21:34,010 --> 01:21:35,450
additional management concerns and

2026
01:21:35,450 --> 01:21:36,680
problems that you have with the

2027
01:21:36,680 --> 01:21:38,750
distributed system you do have to

2028
01:21:38,750 --> 01:21:41,540
account for all right so here's question

2029
01:21:41,540 --> 01:21:43,490
last time can I can i names what are

2030
01:21:43,490 --> 01:21:46,390
some interesting or

2031
01:21:46,729 --> 01:21:48,919
now these weren't good but what are the

2032
01:21:48,919 --> 01:21:51,800
main oh that systems you could possibly

2033
01:21:51,800 --> 01:21:54,499
look at well in the cloud red ship and

2034
01:21:54,499 --> 01:21:56,590
snowflake are the key to two players

2035
01:21:56,590 --> 01:21:59,389
Oracle and Microsoft and Google also

2036
01:21:59,389 --> 01:22:01,550
have their own Pacific services I think

2037
01:22:01,550 --> 01:22:03,559
these two are the probably the biggest

2038
01:22:03,559 --> 01:22:06,139
ones so this is run if you're running on

2039
01:22:06,139 --> 01:22:08,139
a cloud if you want to run on premise

2040
01:22:08,139 --> 01:22:10,999
the one that I'm actually super

2041
01:22:10,999 --> 01:22:13,219
interested in is click house so

2042
01:22:13,219 --> 01:22:14,899
distributed in memory column store

2043
01:22:14,899 --> 01:22:16,610
system out of Russia from the Yandex

2044
01:22:16,610 --> 01:22:19,099
guys and when you read their web page

2045
01:22:19,099 --> 01:22:20,329
the list of the things that they support

2046
01:22:20,329 --> 01:22:22,489
it's actually amazing and it's open

2047
01:22:22,489 --> 01:22:27,979
source to presto is runs on top of I

2048
01:22:27,979 --> 01:22:30,709
think SPARC and Hadoop splice machine is

2049
01:22:30,709 --> 01:22:33,320
HBase plus SPARC greenplum is a fourth

2050
01:22:33,320 --> 01:22:36,619
version of Postgres that somebody made

2051
01:22:36,619 --> 01:22:38,389
distributed it was a startup back in the

2052
01:22:38,389 --> 01:22:41,780
2000s they got bought by EMC the EMC

2053
01:22:41,780 --> 01:22:42,979
says we don't wanna be a data based

2054
01:22:42,979 --> 01:22:44,809
company so then they merged with VMware

2055
01:22:44,809 --> 01:22:47,090
became pivotal but in May open sourced

2056
01:22:47,090 --> 01:22:50,570
it Vertica was founded by my advisors

2057
01:22:50,570 --> 01:22:52,880
when I was in back back in New England

2058
01:22:52,880 --> 01:22:55,760
they got bought by HP the guy came gave

2059
01:22:55,760 --> 01:22:58,699
a talk a few weeks ago or the semester

2060
01:22:58,699 --> 01:23:01,429
so the way to think about this is like

2061
01:23:01,429 --> 01:23:04,459
if you have no money start here if you

2062
01:23:04,459 --> 01:23:06,739
have the money you could start over here

2063
01:23:06,739 --> 01:23:08,899
like Oracle data and tear data are super

2064
01:23:08,899 --> 01:23:11,149
super expensive like Exadata I don't

2065
01:23:11,149 --> 01:23:12,289
think you can buy a machine for less

2066
01:23:12,289 --> 01:23:13,550
than like you know two million dollars

2067
01:23:13,550 --> 01:23:16,389
because you're buying custom hardware

2068
01:23:16,389 --> 01:23:22,489
okay alright if you don't want to go

2069
01:23:22,489 --> 01:23:23,780
down this route its setting up a whole

2070
01:23:23,780 --> 01:23:25,760
distribute database there's a newer

2071
01:23:25,760 --> 01:23:27,320
system and I was all very excited about

2072
01:23:27,320 --> 01:23:30,949
called duck DB it's out of Europe think

2073
01:23:30,949 --> 01:23:34,519
of this duck DB as like sequel light for

2074
01:23:34,519 --> 01:23:36,349
analytics so you can run it as an

2075
01:23:36,349 --> 01:23:37,880
embedded database it actually you can

2076
01:23:37,880 --> 01:23:38,989
connect to it through the sequel like

2077
01:23:38,989 --> 01:23:41,179
terminal but it's a column store ranking

2078
01:23:41,179 --> 01:23:43,639
and can do you can do analytics on in

2079
01:23:43,639 --> 01:23:45,139
the same kind of way you can do here so

2080
01:23:45,139 --> 01:23:47,329
if your data can fit on a single node

2081
01:23:47,329 --> 01:23:49,280
duck PD might be the right thing and

2082
01:23:49,280 --> 01:23:53,990
it's open source okay

2083
01:23:53,990 --> 01:23:56,270
so that's it for the the main material

2084
01:23:56,270 --> 01:23:59,930
and the semester the next class after

2085
01:23:59,930 --> 01:24:01,340
the holiday we'll have a guest speaker

2086
01:24:01,340 --> 01:24:02,810
from Oracle and again we'll have the

2087
01:24:02,810 --> 01:24:04,490
final review and the the potpourri

2088
01:24:04,490 --> 01:24:07,130
session on Wednesday so at this point

2089
01:24:07,130 --> 01:24:09,650
again you should be confident enough to

2090
01:24:09,650 --> 01:24:11,060
go out in the real world and either

2091
01:24:11,060 --> 01:24:12,800
manager database or user database and

2092
01:24:12,800 --> 01:24:14,810
know enough about to opine whether you

2093
01:24:14,810 --> 01:24:16,220
know it the system you're working with

2094
01:24:16,220 --> 01:24:18,050
is making good ideas okay

2095
01:24:18,050 --> 01:24:19,790
we've covered a lot and you guys

2096
01:24:19,790 --> 01:25:08,330
hopefully you guys okay okay don't know

2097
01:25:08,330 --> 01:25:11,020
you can't

