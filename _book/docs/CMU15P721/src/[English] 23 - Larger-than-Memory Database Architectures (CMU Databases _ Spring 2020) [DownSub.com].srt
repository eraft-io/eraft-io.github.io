1
00:00:01,300 --> 00:00:05,129
[Music]

2
00:00:05,200 --> 00:00:05,930
[Applause]

3
00:00:05,930 --> 00:00:08,630
[Music]

4
00:00:08,630 --> 00:00:10,020
[Applause]

5
00:00:10,020 --> 00:00:12,200
[Music]

6
00:00:12,200 --> 00:00:15,540
today's lecture is on databases that are

7
00:00:15,540 --> 00:00:16,740
larger than the amount of memory that's

8
00:00:16,740 --> 00:00:19,640
available to the database system so

9
00:00:19,640 --> 00:00:22,550
again still in lockdown here in my house

10
00:00:22,550 --> 00:00:25,230
the carrier's over there it's sort of

11
00:00:25,230 --> 00:00:28,529
asking questions as we go along but it

12
00:00:28,529 --> 00:00:29,970
hasn't been very good before so people

13
00:00:29,970 --> 00:00:31,560
are complaining that like the chair

14
00:00:31,560 --> 00:00:32,640
doesn't ask the questions that they want

15
00:00:32,640 --> 00:00:35,430
to ask them it is one of this so before

16
00:00:35,430 --> 00:00:38,070
we get into today's lecture material I

17
00:00:38,070 --> 00:00:40,350
first wanted to do a quick overview on

18
00:00:40,350 --> 00:00:42,870
what coming up for you for those of you

19
00:00:42,870 --> 00:00:43,920
that are enrolled in the course this

20
00:00:43,920 --> 00:00:46,260
semester like the upcoming deadlines and

21
00:00:46,260 --> 00:00:49,079
dates so on Wednesday this week I will

22
00:00:49,079 --> 00:00:53,699
be releasing the final exam it was

23
00:00:53,699 --> 00:00:56,940
originally due a week from Wednesday so

24
00:00:56,940 --> 00:00:59,940
next week I've now extended that to have

25
00:00:59,940 --> 00:01:02,190
the final exam being due on the on the

26
00:01:02,190 --> 00:01:04,019
13th so everyone's gonna have three

27
00:01:04,019 --> 00:01:10,380
weeks now to actually complete it with

28
00:01:10,380 --> 00:01:16,290
that ok the carriers question is can we

29
00:01:16,290 --> 00:01:17,759
have a you know can the class have a

30
00:01:17,759 --> 00:01:21,000
practice exam before I release this no

31
00:01:21,000 --> 00:01:23,220
because you'll see that it's sort of a

32
00:01:23,220 --> 00:01:25,080
long form question and based on the

33
00:01:25,080 --> 00:01:26,670
material that we discussed this semester

34
00:01:26,670 --> 00:01:28,350
and now that I'm giving you three weeks

35
00:01:28,350 --> 00:01:30,630
to actually do it there's no point of

36
00:01:30,630 --> 00:01:34,020
releasing a practice exam first the next

37
00:01:34,020 --> 00:01:37,170
thing is that on Wednesday next week we

38
00:01:37,170 --> 00:01:39,750
will have a hopefully the guest speaker

39
00:01:39,750 --> 00:01:42,360
from Amazon come and give a talk for

40
00:01:42,360 --> 00:01:45,450
this one because of Amazon restrictions

41
00:01:45,450 --> 00:01:47,100
we're gonna have to make this a live

42
00:01:47,100 --> 00:01:50,030
lecture that will only be accessible to

43
00:01:50,030 --> 00:01:53,220
CMU students and so you'll need to come

44
00:01:53,220 --> 00:01:55,560
at the time that it that that we

45
00:01:55,560 --> 00:01:56,880
normally would have scheduled class

46
00:01:56,880 --> 00:01:59,280
scheduled so be 12:00 12:00 p.m. Eastern

47
00:01:59,280 --> 00:02:02,610
Standard Time because this will not be

48
00:02:02,610 --> 00:02:06,149
recorded so now also in terms of project

49
00:02:06,149 --> 00:02:08,310
3 the second round of reviews will be

50
00:02:08,310 --> 00:02:11,280
due on May 4th and then we'll have now

51
00:02:11,280 --> 00:02:13,370
our final presentations at our

52
00:02:13,370 --> 00:02:17,360
originally scheduled final exam time on

53
00:02:17,360 --> 00:02:20,810
May 5th at 5:30 p.m. and so again we'll

54
00:02:20,810 --> 00:02:22,310
just go to the only zoom channel and

55
00:02:22,310 --> 00:02:24,110
everyone will present as we've done with

56
00:02:24,110 --> 00:02:27,290
the the status updates from before Hey

57
00:02:27,290 --> 00:02:28,790
again and then the final exam will be

58
00:02:28,790 --> 00:02:32,329
due on the 13th so the the main thing

59
00:02:32,329 --> 00:02:35,720
I'll say about this so for the code

60
00:02:35,720 --> 00:02:37,730
reviews Matt and I will go through this

61
00:02:37,730 --> 00:02:39,650
week and give feedback on the first

62
00:02:39,650 --> 00:02:41,390
round of code reviews and that prepare

63
00:02:41,390 --> 00:02:43,519
you for the second round and the idea is

64
00:02:43,519 --> 00:02:44,569
that you want to take all the

65
00:02:44,569 --> 00:02:46,160
suggestions that the other team made

66
00:02:46,160 --> 00:02:47,900
about your project from the first round

67
00:02:47,900 --> 00:02:49,519
and actually apply them to the second

68
00:02:49,519 --> 00:02:51,109
round I don't want to sort of hit make

69
00:02:51,109 --> 00:02:52,489
the same mistakes all over again and

70
00:02:52,489 --> 00:02:56,290
have them just repeating themselves okay

71
00:02:56,290 --> 00:03:00,890
alright so as I said in the very

72
00:03:00,890 --> 00:03:03,170
beginning of the semester which seems

73
00:03:03,170 --> 00:03:04,700
like a long time uh-huh

74
00:03:04,700 --> 00:03:08,810
now back in January was that this class

75
00:03:08,810 --> 00:03:10,870
was focused on in memory databases and

76
00:03:10,870 --> 00:03:15,230
that all of the algorithms and methods

77
00:03:15,230 --> 00:03:17,540
and architectural decisions that we've

78
00:03:17,540 --> 00:03:19,609
talked about this entire semester have

79
00:03:19,609 --> 00:03:21,739
based based on this assumption that the

80
00:03:21,739 --> 00:03:23,870
database resides entirely main memory

81
00:03:23,870 --> 00:03:26,450
meaning we're not writing algorithms or

82
00:03:26,450 --> 00:03:27,380
Rutte not already you know joint

83
00:03:27,380 --> 00:03:30,169
algorithms that can maximize or minimize

84
00:03:30,169 --> 00:03:32,060
the amount of disk i/o that they incur

85
00:03:32,060 --> 00:03:34,549
words assuming that any time we follow a

86
00:03:34,549 --> 00:03:38,989
pointer to a tuple or a buffer region

87
00:03:38,989 --> 00:03:41,260
that that's gonna always be in memory

88
00:03:41,260 --> 00:03:44,239
now the downside of this is like I said

89
00:03:44,239 --> 00:03:45,799
I mean the upside is that as we've seen

90
00:03:45,799 --> 00:03:47,090
throughout the entire semester this

91
00:03:47,090 --> 00:03:49,730
allows you to implement things way more

92
00:03:49,730 --> 00:03:52,310
efficiently because you don't have to

93
00:03:52,310 --> 00:03:56,180
have this all these checks to account

94
00:03:56,180 --> 00:03:58,669
for the fact that like in a disk or any

95
00:03:58,669 --> 00:04:00,889
system anytime you go touch you know

96
00:04:00,889 --> 00:04:02,299
piece of memory that it might actually

97
00:04:02,299 --> 00:04:04,129
be in memory it's me on desk and you

98
00:04:04,129 --> 00:04:05,840
have to get you know go through the

99
00:04:05,840 --> 00:04:07,910
buffle minute ago and get it so we if we

100
00:04:07,910 --> 00:04:10,609
you know we can write our system without

101
00:04:10,609 --> 00:04:12,769
the assumption it's gonna go really fast

102
00:04:12,769 --> 00:04:16,789
the downside is however and what the

103
00:04:16,789 --> 00:04:18,880
in-memory marketplace has sort of shown

104
00:04:18,880 --> 00:04:21,079
in our database marketplace has sort of

105
00:04:21,079 --> 00:04:25,849
shown the last decade is that SSDs and

106
00:04:25,849 --> 00:04:26,630
spinning discs are

107
00:04:26,630 --> 00:04:31,520
drives still provide or still in terms

108
00:04:31,520 --> 00:04:32,840
of price versus performance there's

109
00:04:32,840 --> 00:04:36,230
still a you know still have provide

110
00:04:36,230 --> 00:04:38,000
certain properties that would be

111
00:04:38,000 --> 00:04:41,330
desirable in even from modern a previous

112
00:04:41,330 --> 00:04:44,990
applications and this is because DRAM at

113
00:04:44,990 --> 00:04:48,110
its core is expensive right and it's

114
00:04:48,110 --> 00:04:51,440
expensive both to to buy relative to

115
00:04:51,440 --> 00:04:54,470
DRAM and are sorry to SSDs and and

116
00:04:54,470 --> 00:04:57,140
spinning gears hard drives so roughly in

117
00:04:57,140 --> 00:05:01,550
2020 the price of per gigabyte for a

118
00:05:01,550 --> 00:05:03,890
spinning disc hard drive is around two

119
00:05:03,890 --> 00:05:06,950
to three cents for NAND flash it's it's

120
00:05:06,950 --> 00:05:09,140
less than a dollar and a few years ago I

121
00:05:09,140 --> 00:05:12,710
saw it being you know thirty cents per

122
00:05:12,710 --> 00:05:13,160
gigabyte

123
00:05:13,160 --> 00:05:17,900
whereas in DRAM it's gone down in recent

124
00:05:17,900 --> 00:05:22,370
years because of some lawsuits which we

125
00:05:22,370 --> 00:05:25,760
can take that offline but the it's

126
00:05:25,760 --> 00:05:27,980
roughly maybe like around five to six

127
00:05:27,980 --> 00:05:29,060
dollars per gigabyte

128
00:05:29,060 --> 00:05:30,830
this is assume that you're buying in

129
00:05:30,830 --> 00:05:32,330
bulk I guess I mean your manufacturer

130
00:05:32,330 --> 00:05:33,950
not like you're going to Amazon and

131
00:05:33,950 --> 00:05:38,060
buying you know Dan this for your

132
00:05:38,060 --> 00:05:39,320
machines like you're you're a major

133
00:05:39,320 --> 00:05:41,630
manufacturer they can buy this in bulk

134
00:05:41,630 --> 00:05:45,650
so it's expensive to buy the other thing

135
00:05:45,650 --> 00:05:46,970
we have really talked about too is that

136
00:05:46,970 --> 00:05:48,590
it's expensive to maintain

137
00:05:48,590 --> 00:05:51,740
meaning when I put it in my computer and

138
00:05:51,740 --> 00:05:53,630
I'm on my server and I'm and I'm you

139
00:05:53,630 --> 00:05:54,620
know plug the server in I'm actually

140
00:05:54,620 --> 00:05:57,380
running it the percentage of the

141
00:05:57,380 --> 00:05:59,330
electricity that's being used to power

142
00:05:59,330 --> 00:06:02,720
that machine a sizable portion of it is

143
00:06:02,720 --> 00:06:05,450
going to to be round now this is

144
00:06:05,450 --> 00:06:07,850
ignoring like doing like Bitcoin mining

145
00:06:07,850 --> 00:06:11,390
or you know no net training on GPUs

146
00:06:11,390 --> 00:06:13,100
those things are definitely bigger power

147
00:06:13,100 --> 00:06:15,980
hogs then then DRAM and so that those

148
00:06:15,980 --> 00:06:19,160
are drawl draw most of the power in sort

149
00:06:19,160 --> 00:06:23,120
of a database server that's not doing

150
00:06:23,120 --> 00:06:25,250
stuff on the GPUs it's gonna be a

151
00:06:25,250 --> 00:06:27,380
roughly about 40 percent this was a

152
00:06:27,380 --> 00:06:28,880
survey that was done a few years ago

153
00:06:28,880 --> 00:06:29,840
where they actually went and measured

154
00:06:29,840 --> 00:06:31,700
how much memory was being drawn by the

155
00:06:31,700 --> 00:06:33,500
DIMM slots and they showed it like on

156
00:06:33,500 --> 00:06:35,210
average about was about forty percent so

157
00:06:35,210 --> 00:06:37,550
it means like all the power that you're

158
00:06:37,550 --> 00:06:39,169
paying for to run your machine 40

159
00:06:39,169 --> 00:06:40,659
percent of that is going to

160
00:06:40,659 --> 00:06:44,169
to D Ram so now that means if I'm

161
00:06:44,169 --> 00:06:45,550
running an in-memory database when the

162
00:06:45,550 --> 00:06:49,000
database has to fit entirely in DRAM the

163
00:06:49,000 --> 00:06:51,310
larger my database the more dimalanta by

164
00:06:51,310 --> 00:06:54,099
and then more pockets to use to maintain

165
00:06:54,099 --> 00:06:55,900
him essentially what the motherboard is

166
00:06:55,900 --> 00:06:58,539
doing is like every so often right I

167
00:06:58,539 --> 00:07:00,159
thinks in every couple seconds it's

168
00:07:00,159 --> 00:07:02,650
sending a charge to the dims so that

169
00:07:02,650 --> 00:07:04,569
they can refresh the there's where

170
00:07:04,569 --> 00:07:06,970
they're storing and of course this is

171
00:07:06,970 --> 00:07:08,680
why you if you pull the pull the power

172
00:07:08,680 --> 00:07:10,659
on them you can't do that refresh and

173
00:07:10,659 --> 00:07:14,259
then you lose your data so given that we

174
00:07:14,259 --> 00:07:16,810
spent the entire semester talking about

175
00:07:16,810 --> 00:07:18,550
how to make a really fast in memory

176
00:07:18,550 --> 00:07:21,639
database system it'd be nice if we could

177
00:07:21,639 --> 00:07:24,180
bring back one of these slower

178
00:07:24,180 --> 00:07:26,590
involvement non-volatile storage devices

179
00:07:26,590 --> 00:07:29,289
NAND flash or spinning disk hard drive

180
00:07:29,289 --> 00:07:31,840
and get the benefit of being able to

181
00:07:31,840 --> 00:07:35,979
write out data to to those disks without

182
00:07:35,979 --> 00:07:38,889
having to bring in all the architectural

183
00:07:38,889 --> 00:07:40,590
components that we were avoiding and

184
00:07:40,590 --> 00:07:42,550
algorithms that we were avoiding by

185
00:07:42,550 --> 00:07:44,710
going you know from a disk or any

186
00:07:44,710 --> 00:07:46,479
architecture and pulling that back into

187
00:07:46,479 --> 00:07:48,460
an in-memory system so that we just end

188
00:07:48,460 --> 00:07:50,020
up with that slower disk orient

189
00:07:50,020 --> 00:07:51,669
architecture that we were trying to

190
00:07:51,669 --> 00:07:53,590
avoid in the first place so that's what

191
00:07:53,590 --> 00:07:56,199
the focus on today is so we'll first

192
00:07:56,199 --> 00:07:58,240
talk in the background about the

193
00:07:58,240 --> 00:08:01,719
different choices or we could have why

194
00:08:01,719 --> 00:08:04,990
we want to do this for to support larger

195
00:08:04,990 --> 00:08:06,969
than memory databases in an in-memory

196
00:08:06,969 --> 00:08:08,800
database system then let's talk about

197
00:08:08,800 --> 00:08:09,909
how you actually want to go to implement

198
00:08:09,909 --> 00:08:11,409
this and then we'll finish up talking

199
00:08:11,409 --> 00:08:15,099
about some real implementations of the

200
00:08:15,099 --> 00:08:16,330
various techniques that what we will

201
00:08:16,330 --> 00:08:20,500
talk about today so at a high level as

202
00:08:20,500 --> 00:08:22,389
again I've already said this but just to

203
00:08:22,389 --> 00:08:24,969
repeat it the goal of what we're

204
00:08:24,969 --> 00:08:28,479
discussing today is enabling an

205
00:08:28,479 --> 00:08:31,180
in-memory database minute system to be

206
00:08:31,180 --> 00:08:34,208
able to store and access data that's

207
00:08:34,208 --> 00:08:36,640
been written out the disk but without

208
00:08:36,640 --> 00:08:39,070
having to bring back all of the slow

209
00:08:39,070 --> 00:08:40,479
parts in particular the buffer pool

210
00:08:40,479 --> 00:08:43,839
manager that we got rid of when we went

211
00:08:43,839 --> 00:08:46,480
to an in-memory architecture right and

212
00:08:46,480 --> 00:08:49,839
so another sort of engineering change we

213
00:08:49,839 --> 00:08:52,300
want to try to achieve is that as we

214
00:08:52,300 --> 00:08:53,880
bring back the disk

215
00:08:53,880 --> 00:08:56,430
we don't want to have to go and touch

216
00:08:56,430 --> 00:08:59,970
all our all our components in our

217
00:08:59,970 --> 00:09:01,500
systems to now account for the fact that

218
00:09:01,500 --> 00:09:04,770
data that it could be accessing is is

219
00:09:04,770 --> 00:09:07,290
not an in-memory and it's on disk like

220
00:09:07,290 --> 00:09:09,060
if we bring back a traditional Buffalo

221
00:09:09,060 --> 00:09:10,410
manager this is somewhat the case

222
00:09:10,410 --> 00:09:15,200
because anytime we go access a you know

223
00:09:15,200 --> 00:09:18,030
location we need to know we would have

224
00:09:18,030 --> 00:09:20,340
to know what page are blocking them it's

225
00:09:20,340 --> 00:09:22,830
an univers ID then and go through a

226
00:09:22,830 --> 00:09:24,330
before manager to do this for us so we'd

227
00:09:24,330 --> 00:09:26,130
have to go modify the entire system to

228
00:09:26,130 --> 00:09:27,840
now instead of just go reading a piece

229
00:09:27,840 --> 00:09:29,910
of memory as we did before to now go

230
00:09:29,910 --> 00:09:31,080
through the buffer pool manager and get

231
00:09:31,080 --> 00:09:34,410
a page or get a block of memory that we

232
00:09:34,410 --> 00:09:35,700
can then access and know the offset

233
00:09:35,700 --> 00:09:38,760
within that that's gonna be slow the

234
00:09:38,760 --> 00:09:40,530
algorithms that are designed to minimize

235
00:09:40,530 --> 00:09:42,720
disk i/o there's really much slower than

236
00:09:42,720 --> 00:09:44,280
the random access ones that we've been

237
00:09:44,280 --> 00:09:49,620
talking about today so the the way we're

238
00:09:49,620 --> 00:09:51,030
gonna have to do this or the way you

239
00:09:51,030 --> 00:09:54,510
know though is that we need to be aware

240
00:09:54,510 --> 00:09:58,110
of the the sort of fundamental

241
00:09:58,110 --> 00:10:01,320
differences between the non-volatile

242
00:10:01,320 --> 00:10:02,910
storage like a spinning disk hard drive

243
00:10:02,910 --> 00:10:05,820
and man flash and in memory volatile

244
00:10:05,820 --> 00:10:08,610
storage and the core difference is that

245
00:10:08,610 --> 00:10:10,110
for in memory storage is going to be

246
00:10:10,110 --> 00:10:12,090
tuple oriented essentially byte

247
00:10:12,090 --> 00:10:15,510
addressable that I can go access to jump

248
00:10:15,510 --> 00:10:17,550
to some memory location and that that's

249
00:10:17,550 --> 00:10:22,020
where my tuple will reside in a disk or

250
00:10:22,020 --> 00:10:23,730
any architecture in a disk storage model

251
00:10:23,730 --> 00:10:26,460
it's gonna be block oriented or page

252
00:10:26,460 --> 00:10:28,830
oriented meaning I can't jump to just a

253
00:10:28,830 --> 00:10:31,440
single bytom and memory or in a page and

254
00:10:31,440 --> 00:10:33,810
just get that data and bring it in into

255
00:10:33,810 --> 00:10:34,290
memory

256
00:10:34,290 --> 00:10:36,570
I gotta go fetch the entire four

257
00:10:36,570 --> 00:10:39,750
kilobyte or a kilobyte page that my the

258
00:10:39,750 --> 00:10:41,910
data that I wanted resides in even if I

259
00:10:41,910 --> 00:10:43,440
don't want the other parts I only maybe

260
00:10:43,440 --> 00:10:45,120
want one kilobyte at that for collide

261
00:10:45,120 --> 00:10:46,830
page I'm bringing in the entire four

262
00:10:46,830 --> 00:10:49,980
kilobyte pages right so this this is

263
00:10:49,980 --> 00:10:51,570
what we have to deal with when we design

264
00:10:51,570 --> 00:10:56,250
a capability that allows us to move data

265
00:10:56,250 --> 00:11:00,110
in a disk in our a memory architecture

266
00:11:00,110 --> 00:11:02,010
so the other important thing to discuss

267
00:11:02,010 --> 00:11:05,370
is that the for the entire lecture we're

268
00:11:05,370 --> 00:11:08,030
going to focus on all OLTP work

269
00:11:08,030 --> 00:11:10,880
sooro LTP systems and we can do this in

270
00:11:10,880 --> 00:11:12,560
the context of an H tap system where

271
00:11:12,560 --> 00:11:14,570
we're running the OLAP systems that will

272
00:11:14,570 --> 00:11:16,250
upload it to be workload at the same

273
00:11:16,250 --> 00:11:20,780
time but for the OLAP lab queries there

274
00:11:20,780 --> 00:11:22,340
really isn't gonna be anything special

275
00:11:22,340 --> 00:11:25,100
or magical we can do in M every database

276
00:11:25,100 --> 00:11:28,010
system to make the disk accesses that

277
00:11:28,010 --> 00:11:30,680
they're going to incur go faster because

278
00:11:30,680 --> 00:11:31,550
then in the day

279
00:11:31,550 --> 00:11:34,430
oh that queries are going to do for the

280
00:11:34,430 --> 00:11:38,030
most part large 2000 scans over or those

281
00:11:38,030 --> 00:11:39,590
2000 stands over large segments of at

282
00:11:39,590 --> 00:11:41,120
the table or they or maybe even the

283
00:11:41,120 --> 00:11:43,220
entire table now may be accessing just a

284
00:11:43,220 --> 00:11:45,680
subset of the columns and a column store

285
00:11:45,680 --> 00:11:48,350
could could alleviate the issue of

286
00:11:48,350 --> 00:11:49,730
bringing in data that you don't actually

287
00:11:49,730 --> 00:11:52,700
need and we can do that but that's not

288
00:11:52,700 --> 00:11:54,560
anything special because we're in memory

289
00:11:54,560 --> 00:11:56,090
because the disk scorning the database

290
00:11:56,090 --> 00:11:58,610
system can still be a column store and

291
00:11:58,610 --> 00:12:01,700
still get that same benefit right so

292
00:12:01,700 --> 00:12:03,140
again the main thing I'm trying to point

293
00:12:03,140 --> 00:12:04,370
out here is that there's nothing really

294
00:12:04,370 --> 00:12:06,830
we're gonna do because we ran a memory

295
00:12:06,830 --> 00:12:10,910
system to make disk i/o and for OLAP

296
00:12:10,910 --> 00:12:13,040
queries go better the only thing we can

297
00:12:13,040 --> 00:12:16,120
really do is like say we have a column

298
00:12:16,120 --> 00:12:18,710
that we know in our table that we want

299
00:12:18,710 --> 00:12:21,200
to scan well we can compute a zone map

300
00:12:21,200 --> 00:12:22,940
for it's like a pre computed aggregation

301
00:12:22,940 --> 00:12:25,370
aggregates for the column like the min

302
00:12:25,370 --> 00:12:26,780
the max you know all the things you

303
00:12:26,780 --> 00:12:28,190
would run on want to run an aggregation

304
00:12:28,190 --> 00:12:30,920
stuff on and keep that in memory at all

305
00:12:30,920 --> 00:12:35,300
times and the the rest of the column the

306
00:12:35,300 --> 00:12:37,550
actual data itself we shove out the disk

307
00:12:37,550 --> 00:12:40,220
and so we can use this so map to try to

308
00:12:40,220 --> 00:12:41,630
figure out what whether or not we need

309
00:12:41,630 --> 00:12:43,250
actually need to access that column on

310
00:12:43,250 --> 00:12:45,800
disk or not depending what query we're

311
00:12:45,800 --> 00:12:48,980
trying to do and that's just the data

312
00:12:48,980 --> 00:12:50,750
skipping technique we saw before when we

313
00:12:50,750 --> 00:12:53,420
talked about doing compression in a data

314
00:12:53,420 --> 00:12:57,620
system but again a disk learning system

315
00:12:57,620 --> 00:12:59,480
can still use on maps and there's

316
00:12:59,480 --> 00:13:00,800
nothing special because we're in memory

317
00:13:00,800 --> 00:13:02,720
here so again for this reason there's

318
00:13:02,720 --> 00:13:04,220
not much we can we can do from a good

319
00:13:04,220 --> 00:13:05,750
lab stuff go away all the same

320
00:13:05,750 --> 00:13:06,980
optimizations we would do in a

321
00:13:06,980 --> 00:13:09,140
Discordian system in our buffer pool

322
00:13:09,140 --> 00:13:11,690
like scan sharing or buffer pool bypass

323
00:13:11,690 --> 00:13:16,340
we can still apply them here so the

324
00:13:16,340 --> 00:13:17,720
reason why we're going to focus on the

325
00:13:17,720 --> 00:13:19,460
LTP is because they're going to have

326
00:13:19,460 --> 00:13:20,790
this

327
00:13:20,790 --> 00:13:25,660
this is very common pattern where

328
00:13:25,660 --> 00:13:27,999
there's gonna be this notion of hot data

329
00:13:27,999 --> 00:13:30,459
and cold data in the database and the

330
00:13:30,459 --> 00:13:32,139
idea is that we want to keep the hot

331
00:13:32,139 --> 00:13:33,730
data in memory because that's the data

332
00:13:33,730 --> 00:13:35,079
we're going to be updating or accessing

333
00:13:35,079 --> 00:13:37,480
over and over again more often and then

334
00:13:37,480 --> 00:13:40,149
the cold data we then shove out the disk

335
00:13:40,149 --> 00:13:43,230
and the idea is that we still have a

336
00:13:43,230 --> 00:13:45,579
we're still keeping track of that cold

337
00:13:45,579 --> 00:13:48,040
data in memory so that we know it exists

338
00:13:48,040 --> 00:13:49,589
and we don't have any false negatives

339
00:13:49,589 --> 00:13:51,939
you know we do a lookup for a tuple and

340
00:13:51,939 --> 00:13:53,139
it's on disk and say oh we don't know

341
00:13:53,139 --> 00:13:54,730
anything about it like we're gonna void

342
00:13:54,730 --> 00:13:56,589
that but we're just not gonna pay the

343
00:13:56,589 --> 00:13:59,139
the storage penalty in memory to have

344
00:13:59,139 --> 00:14:03,040
all that cold data around in memory even

345
00:14:03,040 --> 00:14:04,240
though most of the time we're not gonna

346
00:14:04,240 --> 00:14:08,019
need it so the example I always like the

347
00:14:08,019 --> 00:14:09,879
use of understanding hot versus cold

348
00:14:09,879 --> 00:14:12,249
data would be something like reddit for

349
00:14:12,249 --> 00:14:14,319
hacker news right most people are going

350
00:14:14,319 --> 00:14:17,110
to post comments on the latest articles

351
00:14:17,110 --> 00:14:18,430
that been posted on reddit within the

352
00:14:18,430 --> 00:14:20,920
last you know 24 hours or so many days

353
00:14:20,920 --> 00:14:23,379
but few people are going back and

354
00:14:23,379 --> 00:14:26,139
posting comments on you know articles

355
00:14:26,139 --> 00:14:28,800
that were never never uploaded or posted

356
00:14:28,800 --> 00:14:31,569
six months ago right and I actually I

357
00:14:31,569 --> 00:14:33,129
don't think even read even let you do

358
00:14:33,129 --> 00:14:37,269
comments on old articles so again the

359
00:14:37,269 --> 00:14:38,709
ideas that the recent post we want to

360
00:14:38,709 --> 00:14:39,519
keep in memory because those are the

361
00:14:39,519 --> 00:14:41,410
ones everyone's reading and making

362
00:14:41,410 --> 00:14:43,240
updates to the older stuff that you

363
00:14:43,240 --> 00:14:44,920
shell out the disk if everybody comes

364
00:14:44,920 --> 00:14:47,470
and goes looking for it we'll go fetch

365
00:14:47,470 --> 00:14:49,029
it from disk and bring the memory and

366
00:14:49,029 --> 00:14:51,309
serve it to them but most of the time we

367
00:14:51,309 --> 00:14:53,290
don't need that and then the likelihood

368
00:14:53,290 --> 00:14:55,449
that someone who's gonna read that same

369
00:14:55,449 --> 00:14:59,800
article in a cold article immediately

370
00:14:59,800 --> 00:15:02,559
after it was brought back and memory

371
00:15:02,559 --> 00:15:05,920
from the disk it's actually very low so

372
00:15:05,920 --> 00:15:07,420
we can go ahead and shove it back out

373
00:15:07,420 --> 00:15:09,040
the disk later on I didn't save save

374
00:15:09,040 --> 00:15:11,679
space so again some applications like I

375
00:15:11,679 --> 00:15:14,490
said in reddit where they were actually

376
00:15:14,490 --> 00:15:17,040
prevent you from posting on articles

377
00:15:17,040 --> 00:15:20,379
that are that are you become a certain

378
00:15:20,379 --> 00:15:22,899
age that mechanism is actually something

379
00:15:22,899 --> 00:15:24,699
that the application does it's not

380
00:15:24,699 --> 00:15:26,259
something that the data expander system

381
00:15:26,259 --> 00:15:28,120
enforces as far as they know nobody no

382
00:15:28,120 --> 00:15:29,529
database system actually says all right

383
00:15:29,529 --> 00:15:33,220
this stuff is old you know we won't let

384
00:15:33,220 --> 00:15:34,370
you modify because it

385
00:15:34,370 --> 00:15:37,580
it doesn't know that you know you're not

386
00:15:37,580 --> 00:15:40,460
you're inserting into a table like the

387
00:15:40,460 --> 00:15:41,540
comments are giving certain to a

388
00:15:41,540 --> 00:15:42,589
separate table home when the article

389
00:15:42,589 --> 00:15:43,760
secretary post it so it doesn't know you

390
00:15:43,760 --> 00:15:46,610
can't do that as far as I know no system

391
00:15:46,610 --> 00:15:49,160
actually does those so again the purpose

392
00:15:49,160 --> 00:15:50,720
what we're trying to do today is is this

393
00:15:50,720 --> 00:15:52,880
piece here what we need the mechanism to

394
00:15:52,880 --> 00:15:55,250
allow us to identify that we have this

395
00:15:55,250 --> 00:15:58,400
cold data what it is where it is shove

396
00:15:58,400 --> 00:16:00,020
it out the disk and then if never need

397
00:16:00,020 --> 00:16:03,140
it again Brigham back in another way

398
00:16:03,140 --> 00:16:04,460
conceptually think about this too is

399
00:16:04,460 --> 00:16:09,290
that in what we're trying to do is push

400
00:16:09,290 --> 00:16:14,060
cold data atom memory onto disk contrast

401
00:16:14,060 --> 00:16:16,580
this with a disk or nyun system where

402
00:16:16,580 --> 00:16:20,089
you pull hot data from disk and bring it

403
00:16:20,089 --> 00:16:23,330
into memory so this seems like a sort of

404
00:16:23,330 --> 00:16:25,250
semantic difference and hopefully as we

405
00:16:25,250 --> 00:16:26,630
go along with this make more sense but

406
00:16:26,630 --> 00:16:28,190
like the this system is being

407
00:16:28,190 --> 00:16:30,650
architected as such that cold data is

408
00:16:30,650 --> 00:16:32,870
moved out to disk whereas in a different

409
00:16:32,870 --> 00:16:37,100
system hot data is pulled in alright so

410
00:16:37,100 --> 00:16:38,390
let's look at a high-level example here

411
00:16:38,390 --> 00:16:41,180
so we have now we have a database now

412
00:16:41,180 --> 00:16:43,370
that can support writing out data to

413
00:16:43,370 --> 00:16:45,620
cold data storage this is some some

414
00:16:45,620 --> 00:16:47,480
spinning disk hard drive or NAND flash

415
00:16:47,480 --> 00:16:49,700
or EBS whatever you want doesn't matter

416
00:16:49,700 --> 00:16:52,700
for our purposes right now and then in

417
00:16:52,700 --> 00:16:54,100
memory we still have our in memory index

418
00:16:54,100 --> 00:16:56,570
and then we have our in memory table

419
00:16:56,570 --> 00:16:58,430
heap for now assuming everything's fixed

420
00:16:58,430 --> 00:17:02,029
fixed size and it all exists in in this

421
00:17:02,029 --> 00:17:05,780
one space here so the say now we have a

422
00:17:05,780 --> 00:17:09,020
mechanism to look at our tuples and

423
00:17:09,020 --> 00:17:11,540
identify which ones are cold we have a

424
00:17:11,540 --> 00:17:13,400
way to identify that these three tuples

425
00:17:13,400 --> 00:17:17,569
here are haven't been access in in in

426
00:17:17,569 --> 00:17:19,819
the recent recent time unlikely to be

427
00:17:19,819 --> 00:17:21,800
access in the future again how exactly

428
00:17:21,800 --> 00:17:23,599
we do that we'll cover in a second but

429
00:17:23,599 --> 00:17:24,949
for whatever reason we think these three

430
00:17:24,949 --> 00:17:27,949
are our candidates to be evicted so what

431
00:17:27,949 --> 00:17:29,120
we're going to go ahead and do is we're

432
00:17:29,120 --> 00:17:31,000
going to pull them out of our table heap

433
00:17:31,000 --> 00:17:34,610
combine them into a page or a block that

434
00:17:34,610 --> 00:17:36,890
we then write out to disk so this would

435
00:17:36,890 --> 00:17:38,780
now be our victor tuple block there's

436
00:17:38,780 --> 00:17:40,100
some header that's saying here's what

437
00:17:40,100 --> 00:17:41,780
you know here's what's in here and then

438
00:17:41,780 --> 00:17:44,330
we have our tuple data and for this

439
00:17:44,330 --> 00:17:46,520
assume that we're organized as a row

440
00:17:46,520 --> 00:17:47,620
store

441
00:17:47,620 --> 00:17:49,030
store could essentially look the same

442
00:17:49,030 --> 00:17:51,210
way because if you do a pax organized

443
00:17:51,210 --> 00:17:53,710
block right this could be laid out and

444
00:17:53,710 --> 00:17:55,059
in a common store within the page but

445
00:17:55,059 --> 00:17:56,950
all the the values or all the attributes

446
00:17:56,950 --> 00:17:59,320
for a given tuple can be found in this

447
00:17:59,320 --> 00:18:01,990
in this block so now the first question

448
00:18:01,990 --> 00:18:04,360
we have to deal with is what do we do

449
00:18:04,360 --> 00:18:07,090
with the holes that we just made in our

450
00:18:07,090 --> 00:18:09,820
table heap all right we have now empty

451
00:18:09,820 --> 00:18:12,130
space that we could reuse what are we

452
00:18:12,130 --> 00:18:14,050
actually gonna you know when do we

453
00:18:14,050 --> 00:18:15,910
actually put stuff in there because the

454
00:18:15,910 --> 00:18:19,900
issue is that the index now is because

455
00:18:19,900 --> 00:18:22,750
everything is now in our database you

456
00:18:22,750 --> 00:18:24,550
know you're having 64-bit pointers to

457
00:18:24,550 --> 00:18:26,110
two other locations as a memory to

458
00:18:26,110 --> 00:18:28,900
identify tuples it's not a you know page

459
00:18:28,900 --> 00:18:30,910
ID and an offset as you would in a slot

460
00:18:30,910 --> 00:18:32,470
number as you would in a discarding

461
00:18:32,470 --> 00:18:34,570
system these pointers are now pointing

462
00:18:34,570 --> 00:18:35,920
that are still in the index are still

463
00:18:35,920 --> 00:18:38,080
pointing to these empty slots so now if

464
00:18:38,080 --> 00:18:39,550
I could do a lookup and try to find this

465
00:18:39,550 --> 00:18:42,550
tuple that that used to be here I'm

466
00:18:42,550 --> 00:18:45,190
gonna land in you know look at some

467
00:18:45,190 --> 00:18:47,350
empty space now because somebody else

468
00:18:47,350 --> 00:18:49,000
could now be - yeah I could have put

469
00:18:49,000 --> 00:18:52,240
another two boys in this space but now

470
00:18:52,240 --> 00:18:53,320
let's say what this query comes along

471
00:18:53,320 --> 00:18:55,000
and this query now wants to reference

472
00:18:55,000 --> 00:18:57,070
one of the tuples that we just evicted

473
00:18:57,070 --> 00:18:59,650
right so this is accessing tuple 1 but

474
00:18:59,650 --> 00:19:02,200
now tube 1 is somewhere out on disk so

475
00:19:02,200 --> 00:19:03,970
the question is we have to deal with is

476
00:19:03,970 --> 00:19:06,070
well how are we actually gonna find it

477
00:19:06,070 --> 00:19:07,480
how are we actually going to be able to

478
00:19:07,480 --> 00:19:10,450
identify that Oh tuple 0 1 it's not in

479
00:19:10,450 --> 00:19:11,170
memory anymore

480
00:19:11,170 --> 00:19:15,429
right it's it's out on disk then say we

481
00:19:15,429 --> 00:19:17,440
if we can actually identify that it is

482
00:19:17,440 --> 00:19:20,050
on disk we need to bring it back into

483
00:19:20,050 --> 00:19:22,660
memory and now the question is what do

484
00:19:22,660 --> 00:19:26,400
we actually do because as I said the the

485
00:19:26,400 --> 00:19:29,530
cold data storage on our disks is is

486
00:19:29,530 --> 00:19:32,260
block oriented so I can't just go grab 2

487
00:19:32,260 --> 00:19:34,300
+ 0 1 and just copy the the bytes

488
00:19:34,300 --> 00:19:36,520
exactly for that tuple and bringing it

489
00:19:36,520 --> 00:19:38,830
into my my table heap I gotta bring this

490
00:19:38,830 --> 00:19:41,080
whole block in and so now I'm bringing

491
00:19:41,080 --> 00:19:44,140
in tuple 1 also 3 & 4 but I didn't ask

492
00:19:44,140 --> 00:19:47,950
for 3 & 4 I only wanted one so what I

493
00:19:47,950 --> 00:19:50,500
actually do do I merge all three tuples

494
00:19:50,500 --> 00:19:52,929
back in do I just hurt merge one tuple

495
00:19:52,929 --> 00:19:54,880
in and then I'm gonna leave a hole out

496
00:19:54,880 --> 00:19:57,250
on a disk so these are the questions

497
00:19:57,250 --> 00:19:59,110
that were that we're trying to answer

498
00:19:59,110 --> 00:20:00,820
today how we actually want to

499
00:20:00,820 --> 00:20:05,800
orchestrate all of us so the issues we

500
00:20:05,800 --> 00:20:07,930
have to deal with are the following and

501
00:20:07,930 --> 00:20:10,720
again we're focusing on OTP systems

502
00:20:10,720 --> 00:20:13,240
where we assume that actually turns out

503
00:20:13,240 --> 00:20:14,680
you know transactions our query is good

504
00:20:14,680 --> 00:20:17,380
or could try to actually not just access

505
00:20:17,380 --> 00:20:21,190
but also update or modify to pools that

506
00:20:21,190 --> 00:20:24,180
are data that's been shoved out to disk

507
00:20:24,180 --> 00:20:26,110
so the first thing we had to deal with

508
00:20:26,110 --> 00:20:30,160
is for the runtime operations is what

509
00:20:30,160 --> 00:20:32,230
are we actually gonna do while the

510
00:20:32,230 --> 00:20:33,790
transactional videos and runs queries

511
00:20:33,790 --> 00:20:36,100
and transactions to keep track of

512
00:20:36,100 --> 00:20:39,460
whether data is hot or cold like having

513
00:20:39,460 --> 00:20:41,890
to keep track of it and identify oh when

514
00:20:41,890 --> 00:20:43,510
it's time to evict or we wanna take some

515
00:20:43,510 --> 00:20:47,490
data which tuples or which blocks

516
00:20:47,490 --> 00:20:49,450
haven't been accessed in a while and

517
00:20:49,450 --> 00:20:50,470
therefore we want to go ahead and dick

518
00:20:50,470 --> 00:20:53,410
them the next is the eviction policy

519
00:20:53,410 --> 00:20:55,270
this is when the the database system

520
00:20:55,270 --> 00:20:57,040
recognizes that it's running out of

521
00:20:57,040 --> 00:20:59,380
space or running out of memory so says

522
00:20:59,380 --> 00:21:01,960
let's go ahead and let Vic some data so

523
00:21:01,960 --> 00:21:04,480
the first question is when should it

524
00:21:04,480 --> 00:21:08,410
actually fire off the eviction the next

525
00:21:08,410 --> 00:21:09,820
is like what metadata we're going to

526
00:21:09,820 --> 00:21:13,180
keep track of to to record that there

527
00:21:13,180 --> 00:21:15,730
used to be data here in memory but it's

528
00:21:15,730 --> 00:21:17,500
now out on disk and here's how to go

529
00:21:17,500 --> 00:21:21,430
find where it's located on disk and we

530
00:21:21,430 --> 00:21:23,320
need to do this because we need to avoid

531
00:21:23,320 --> 00:21:24,790
false negatives we don't want to write

532
00:21:24,790 --> 00:21:28,950
we only back here and write out tuple 1

533
00:21:28,950 --> 00:21:32,380
to disk then this query comes along and

534
00:21:32,380 --> 00:21:34,630
says oh I want to pull one but we only

535
00:21:34,630 --> 00:21:37,660
consult this portion here of the table

536
00:21:37,660 --> 00:21:38,710
heatman which doesn't have people

537
00:21:38,710 --> 00:21:39,970
wanting more so it would come back and

538
00:21:39,970 --> 00:21:42,040
say up I don't know anything about tuple

539
00:21:42,040 --> 00:21:43,990
0 1 like you what you're asking for it

540
00:21:43,990 --> 00:21:45,610
doesn't exist and therefore this thing

541
00:21:45,610 --> 00:21:48,340
would return incorrect answer so we need

542
00:21:48,340 --> 00:21:51,880
a way to identify that the in memory

543
00:21:51,880 --> 00:21:54,340
that there used to be a tuple 0 1 here

544
00:21:54,340 --> 00:21:56,110
and here's that here's here's the

545
00:21:56,110 --> 00:21:57,070
information you know where to go to find

546
00:21:57,070 --> 00:21:59,530
it on disk so that's the metadata which

547
00:21:59,530 --> 00:22:01,530
kind of keep track out here

548
00:22:01,530 --> 00:22:05,890
then now when we go and and recognize

549
00:22:05,890 --> 00:22:07,360
that we actually do need data on disk

550
00:22:07,360 --> 00:22:10,060
the question is how much data should we

551
00:22:10,060 --> 00:22:12,940
actually bring in what do we actually do

552
00:22:12,940 --> 00:22:14,690
with the query or transaction

553
00:22:14,690 --> 00:22:18,110
that requested that data and where do we

554
00:22:18,110 --> 00:22:20,090
actually put the data that that they've

555
00:22:20,090 --> 00:22:23,180
requested right like where in memory the

556
00:22:23,180 --> 00:22:25,780
table heap or maybe a private buffer I

557
00:22:25,780 --> 00:22:28,190
will cover all of these did these

558
00:22:28,190 --> 00:22:30,470
different design decisions and these all

559
00:22:30,470 --> 00:22:34,010
come from a paper that we wrote in 2016

560
00:22:34,010 --> 00:22:37,670
with one of my PhD students where we

561
00:22:37,670 --> 00:22:39,350
were looking at this idea of again how

562
00:22:39,350 --> 00:22:42,020
do you actually support larger memory

563
00:22:42,020 --> 00:22:45,500
databases in memory database system so

564
00:22:45,500 --> 00:22:47,210
what I'll say though this was based on a

565
00:22:47,210 --> 00:22:48,650
system that I helped build in grad

566
00:22:48,650 --> 00:22:50,810
school called a store which was then

567
00:22:50,810 --> 00:22:55,540
commercialized in 2008 2009 as volte B

568
00:22:55,540 --> 00:22:57,830
most of the mechanisms we'll talk about

569
00:22:57,830 --> 00:23:01,340
here are going to be sort of tuple

570
00:23:01,340 --> 00:23:03,620
oriented likes fine-grain eviction and

571
00:23:03,620 --> 00:23:04,990
fine-grained identification of

572
00:23:04,990 --> 00:23:08,360
individual tuples but the paper I had

573
00:23:08,360 --> 00:23:11,060
you guys read lean store which came much

574
00:23:11,060 --> 00:23:13,490
after this particular paper here was

575
00:23:13,490 --> 00:23:17,720
doing this on at the page level so some

576
00:23:17,720 --> 00:23:18,710
of the things we'll talk about here

577
00:23:18,710 --> 00:23:20,300
don't make sense if you're trying to do

578
00:23:20,300 --> 00:23:22,100
it at a page level because they have a

579
00:23:22,100 --> 00:23:23,780
sort of more coarse graining view of

580
00:23:23,780 --> 00:23:25,940
what data is hot and cold and how they

581
00:23:25,940 --> 00:23:27,170
actually keep track of the metadata of

582
00:23:27,170 --> 00:23:29,690
your when teams get evicted but it's

583
00:23:29,690 --> 00:23:31,790
important to understand you know sort of

584
00:23:31,790 --> 00:23:33,350
the fine grain approach and then you'll

585
00:23:33,350 --> 00:23:35,450
hopefully then appreciate better why the

586
00:23:35,450 --> 00:23:37,850
leads to our idea I actually think is

587
00:23:37,850 --> 00:23:41,180
really good all right plan the first

588
00:23:41,180 --> 00:23:42,710
thing you have to do with how to

589
00:23:42,710 --> 00:23:44,990
identify with what data is called in our

590
00:23:44,990 --> 00:23:48,860
database so the first choice is to do

591
00:23:48,860 --> 00:23:50,590
what I'll call online identification

592
00:23:50,590 --> 00:23:53,780
meaning as the database system is

593
00:23:53,780 --> 00:23:55,310
executing transactions or executing

594
00:23:55,310 --> 00:23:58,100
queries we are keeping track of what

595
00:23:58,100 --> 00:23:59,810
tuples they're accessing what data

596
00:23:59,810 --> 00:24:03,530
they're accessing and then we have to

597
00:24:03,530 --> 00:24:07,250
then maintain some metadata directly in

598
00:24:07,250 --> 00:24:09,260
the tuples of pages themselves that we

599
00:24:09,260 --> 00:24:12,110
then update as our as our queries are

600
00:24:12,110 --> 00:24:14,120
accessing them and the reason why you

601
00:24:14,120 --> 00:24:16,160
want to embed it in the tuple itself is

602
00:24:16,160 --> 00:24:17,900
because you don't want to maybe go then

603
00:24:17,900 --> 00:24:21,740
consult a ugly data structure to say hey

604
00:24:21,740 --> 00:24:24,200
by the way I've updated this tuple all

605
00:24:24,200 --> 00:24:25,790
right if I made the tuple entry in my

606
00:24:25,790 --> 00:24:27,320
tracking data and then up

607
00:24:27,320 --> 00:24:29,780
because in your pain that the storage

608
00:24:29,780 --> 00:24:31,550
penalty of having that extra extra data

609
00:24:31,550 --> 00:24:33,140
structure and then you're also paying

610
00:24:33,140 --> 00:24:35,180
the computational overhead of having to

611
00:24:35,180 --> 00:24:37,580
update it every single time you access a

612
00:24:37,580 --> 00:24:42,740
tubule so for when we did this in H

613
00:24:42,740 --> 00:24:46,580
store the the we would store actually a

614
00:24:46,580 --> 00:24:51,410
64-bit pointer of a tuple to that the

615
00:24:51,410 --> 00:24:52,850
next most recently accessed tuple we

616
00:24:52,850 --> 00:24:55,430
were essentially maintaining a an LRU

617
00:24:55,430 --> 00:24:58,760
chain of all individual tuples so 64

618
00:24:58,760 --> 00:25:02,930
bits per to pool is not ideal and so the

619
00:25:02,930 --> 00:25:05,120
the the tuple is very large if it has a

620
00:25:05,120 --> 00:25:07,130
lot of attributes then the overhead is

621
00:25:07,130 --> 00:25:08,210
kind of small but if it only has like

622
00:25:08,210 --> 00:25:11,180
two attributes like two 32-bit pointers

623
00:25:11,180 --> 00:25:14,090
our sorry 32-bit integers has its

624
00:25:14,090 --> 00:25:17,090
attributes then an additional 64-bit

625
00:25:17,090 --> 00:25:18,770
pointer to keep track of the metadata

626
00:25:18,770 --> 00:25:20,990
it's essentially doubling the size of

627
00:25:20,990 --> 00:25:22,700
the tuple just to keep track of whether

628
00:25:22,700 --> 00:25:27,140
it's hot or not the the second approach

629
00:25:27,140 --> 00:25:29,300
is to go offline and what that means is

630
00:25:29,300 --> 00:25:32,300
that the the database system will record

631
00:25:32,300 --> 00:25:36,080
like an in-memory log of all the angel

632
00:25:36,080 --> 00:25:37,700
accesses that the queries and

633
00:25:37,700 --> 00:25:39,020
transactions make while they're running

634
00:25:39,020 --> 00:25:41,270
but this is just sitting in getting

635
00:25:41,270 --> 00:25:43,160
updated in a private buffer to the

636
00:25:43,160 --> 00:25:44,900
thread doing the access so though

637
00:25:44,900 --> 00:25:46,340
there's no contention on the global data

638
00:25:46,340 --> 00:25:48,710
structure we're not storing for every

639
00:25:48,710 --> 00:25:52,070
single tuple this metadata and payment

640
00:25:52,070 --> 00:25:53,720
penalty as we saw up here so this is

641
00:25:53,720 --> 00:25:56,480
just some some some additional tracking

642
00:25:56,480 --> 00:25:59,450
we're doing that has low overhead at run

643
00:25:59,450 --> 00:26:03,460
time for for queries as the access data

644
00:26:03,460 --> 00:26:07,220
but then now periodically there'll be a

645
00:26:07,220 --> 00:26:08,810
background thread that picks up and

646
00:26:08,810 --> 00:26:10,970
looks at all this log information from

647
00:26:10,970 --> 00:26:12,740
the different threads and then compute

648
00:26:12,740 --> 00:26:15,920
some histograms to to figure out the

649
00:26:15,920 --> 00:26:18,410
access frequencies of individual tuples

650
00:26:18,410 --> 00:26:21,800
so this one is cooperative because all

651
00:26:21,800 --> 00:26:23,120
the threads are sort of helping along

652
00:26:23,120 --> 00:26:26,840
maintaining the metadata this one is is

653
00:26:26,840 --> 00:26:28,670
this separate background thread to go

654
00:26:28,670 --> 00:26:30,200
ahead and combine this information

655
00:26:30,200 --> 00:26:34,070
together all right so the next thing to

656
00:26:34,070 --> 00:26:37,160
do is have basically how to recognize

657
00:26:37,160 --> 00:26:38,860
when the database system is

658
00:26:38,860 --> 00:26:41,830
is running out of memory so a simple

659
00:26:41,830 --> 00:26:43,900
approach is just to have a administrator

660
00:26:43,900 --> 00:26:46,360
defined threshold that says when my

661
00:26:46,360 --> 00:26:49,330
database systems a total memory usage

662
00:26:49,330 --> 00:26:54,190
gets to be about 80% or 90% of the

663
00:26:54,190 --> 00:26:56,230
amount of memory that's allocated to my

664
00:26:56,230 --> 00:26:59,049
database system then I'll fire off my

665
00:26:59,049 --> 00:27:02,890
eviction my fiction policy and go ahead

666
00:27:02,890 --> 00:27:04,900
and start shoving things out the disk

667
00:27:04,900 --> 00:27:07,960
right again in this case the data center

668
00:27:07,960 --> 00:27:10,150
is responsible for removing this data

669
00:27:10,150 --> 00:27:12,400
because there's nothing else that can

670
00:27:12,400 --> 00:27:14,110
control this that's us managing our

671
00:27:14,110 --> 00:27:15,970
memory and therefore we have to do this

672
00:27:15,970 --> 00:27:19,350
we can't rely on the operating system

673
00:27:19,350 --> 00:27:21,580
typically in database system I mean for

674
00:27:21,580 --> 00:27:22,660
everyday pieces of meat whether it's in

675
00:27:22,660 --> 00:27:25,660
memory or not the administrator the data

676
00:27:25,660 --> 00:27:27,790
system has to be told by a human how

677
00:27:27,790 --> 00:27:29,650
much memory they're allowed to use again

678
00:27:29,650 --> 00:27:31,510
whether it's the buffer pool size for

679
00:27:31,510 --> 00:27:33,820
disk warning system or just in memory

680
00:27:33,820 --> 00:27:36,160
size of the heaps for a in-memory

681
00:27:36,160 --> 00:27:37,929
database system it's sent again today

682
00:27:37,929 --> 00:27:39,040
someone has to tell us how much memory

683
00:27:39,040 --> 00:27:41,230
were allowed to use so we DS then set a

684
00:27:41,230 --> 00:27:43,540
threshold and say when I forget to 85%

685
00:27:43,540 --> 00:27:45,730
of that threshold that total upper bound

686
00:27:45,730 --> 00:27:48,940
then I start a victim the other approach

687
00:27:48,940 --> 00:27:51,669
is to do this on demand and this is

688
00:27:51,669 --> 00:27:54,850
where if the database system recognizes

689
00:27:54,850 --> 00:27:56,410
that it doesn't have any more memory to

690
00:27:56,410 --> 00:27:58,540
bring in a new piece of data from disk

691
00:27:58,540 --> 00:28:00,640
that it needs then it runs its

692
00:28:00,640 --> 00:28:03,070
replacement policy which I'll talk about

693
00:28:03,070 --> 00:28:05,860
in a second but I think it is LRU to

694
00:28:05,860 --> 00:28:08,020
identify which pages are no longer

695
00:28:08,020 --> 00:28:11,410
needed or unlikely to be be used in the

696
00:28:11,410 --> 00:28:13,600
future and we can go ahead and shove

697
00:28:13,600 --> 00:28:15,580
them out the disk then reclaim that

698
00:28:15,580 --> 00:28:17,590
space for the new piece of data that we

699
00:28:17,590 --> 00:28:20,860
want to bring in so in you could use LRU

700
00:28:20,860 --> 00:28:23,650
or clock to approximate LRU lean store

701
00:28:23,650 --> 00:28:26,799
uses an approximation of clock which

702
00:28:26,799 --> 00:28:28,330
they call second chance and we'll see

703
00:28:28,330 --> 00:28:32,830
what that looks like in a second all

704
00:28:32,830 --> 00:28:37,240
right so now assuming that we have a way

705
00:28:37,240 --> 00:28:39,520
to fire off the eviction to move data

706
00:28:39,520 --> 00:28:41,440
out to disk we have a way to identify

707
00:28:41,440 --> 00:28:43,780
what our cold data is and we need to

708
00:28:43,780 --> 00:28:45,820
move out to disk now the question we

709
00:28:45,820 --> 00:28:47,530
have to deal with is when it's been

710
00:28:47,530 --> 00:28:49,030
written to disk what do we still

711
00:28:49,030 --> 00:28:49,920
maintain and

712
00:28:49,920 --> 00:28:52,380
to keep track of this data actually

713
00:28:52,380 --> 00:28:54,180
there used to be two placenta that used

714
00:28:54,180 --> 00:28:55,950
to be dated here in memory but if no

715
00:28:55,950 --> 00:28:58,100
longer is and here's where to go find it

716
00:28:58,100 --> 00:29:00,470
so the first approach is to use

717
00:29:00,470 --> 00:29:03,180
tombstones and this is where we will

718
00:29:03,180 --> 00:29:05,370
have a marker or our special kind of

719
00:29:05,370 --> 00:29:07,920
tuple that we have in our table that

720
00:29:07,920 --> 00:29:10,740
says this tuple you're looking for at

721
00:29:10,740 --> 00:29:12,750
this address does not exist but here's

722
00:29:12,750 --> 00:29:14,490
where to go find it here's the block ID

723
00:29:14,490 --> 00:29:17,010
and all set in that block to go get the

724
00:29:17,010 --> 00:29:19,140
data that you're looking for and anytime

725
00:29:19,140 --> 00:29:21,180
that you see you know if you follow a

726
00:29:21,180 --> 00:29:23,190
pointer doing a scan and come across

727
00:29:23,190 --> 00:29:25,530
this tombstone pointer or tombstone a

728
00:29:25,530 --> 00:29:28,350
tuple you could then say all right well

729
00:29:28,350 --> 00:29:29,850
let me go talk to the cold data storage

730
00:29:29,850 --> 00:29:32,460
layer and say go get this data that I'm

731
00:29:32,460 --> 00:29:36,510
looking for so if you Victor tuple that

732
00:29:36,510 --> 00:29:38,610
has showed us a disk and you replaced

733
00:29:38,610 --> 00:29:40,320
with the tombstone then you have to go

734
00:29:40,320 --> 00:29:43,320
update the index now for any or all any

735
00:29:43,320 --> 00:29:44,760
index for that table that's pointing to

736
00:29:44,760 --> 00:29:47,100
the old evicted tuple to now point to

737
00:29:47,100 --> 00:29:49,530
the tombstone tuple writing in that way

738
00:29:49,530 --> 00:29:51,630
there's no false negatives your data is

739
00:29:51,630 --> 00:29:53,810
always there your data is always

740
00:29:53,810 --> 00:29:58,080
identifiable the next approach is to use

741
00:29:58,080 --> 00:30:01,910
bloom filters and this is where you

742
00:30:01,910 --> 00:30:05,670
evict all the data out the disk Victo

743
00:30:05,670 --> 00:30:07,830
clean of tuples at the disk but instead

744
00:30:07,830 --> 00:30:09,270
of maintaining a tombstone

745
00:30:09,270 --> 00:30:11,550
/ - puppets of dictum you just have of

746
00:30:11,550 --> 00:30:12,660
this bloom filter

747
00:30:12,660 --> 00:30:15,090
yeah an approximate data structure that

748
00:30:15,090 --> 00:30:18,030
a set membership that says whether or

749
00:30:18,030 --> 00:30:21,000
not there could exist they tuple for a

750
00:30:21,000 --> 00:30:23,580
given key out on the cold data storage

751
00:30:23,580 --> 00:30:27,420
and so what happens is I if I'm looking

752
00:30:27,420 --> 00:30:30,300
for a particular key on a table I check

753
00:30:30,300 --> 00:30:33,210
the real Mme index if it says is there

754
00:30:33,210 --> 00:30:35,220
then I that's gonna have a pointer to

755
00:30:35,220 --> 00:30:38,700
the real tuple so I'm done in memory if

756
00:30:38,700 --> 00:30:40,530
it says not there then I go check this

757
00:30:40,530 --> 00:30:43,830
bloom filter and if it says it's not

758
00:30:43,830 --> 00:30:45,660
there that I know doesn't exist at all

759
00:30:45,660 --> 00:30:47,460
because a bloom filter would never give

760
00:30:47,460 --> 00:30:49,410
you false puppet false negatives could

761
00:30:49,410 --> 00:30:51,780
give you false positives if it does say

762
00:30:51,780 --> 00:30:53,370
the key exists and it's out and cold

763
00:30:53,370 --> 00:30:55,800
data storage then I go fetch this on

764
00:30:55,800 --> 00:30:59,400
disk index that I bring into memory and

765
00:30:59,400 --> 00:31:01,500
then I find the real location on disk

766
00:31:01,500 --> 00:31:03,500
for the two but I'm looking for

767
00:31:03,500 --> 00:31:06,320
again I'll explain playing these two in

768
00:31:06,320 --> 00:31:07,210
the next slide

769
00:31:07,210 --> 00:31:10,310
the other two approaches are to do

770
00:31:10,310 --> 00:31:12,770
either database system manage memory or

771
00:31:12,770 --> 00:31:14,980
OS manage memory or virtual memory and

772
00:31:14,980 --> 00:31:18,200
the for this one that's the database

773
00:31:18,200 --> 00:31:20,390
system is going to keep track of on a

774
00:31:20,390 --> 00:31:23,630
pad at a page level whether the page

775
00:31:23,630 --> 00:31:25,280
actually exists in the memory or not or

776
00:31:25,280 --> 00:31:27,560
the block level same kind of thing so I

777
00:31:27,560 --> 00:31:30,830
can't tell you whether an image or tuple

778
00:31:30,830 --> 00:31:34,670
exists but if I know that it would exist

779
00:31:34,670 --> 00:31:36,170
in this block and that block have been

780
00:31:36,170 --> 00:31:38,060
written to disk then I know the two

781
00:31:38,060 --> 00:31:42,140
blood i1 is on disk so with OS virtual

782
00:31:42,140 --> 00:31:43,310
memory it's gonna work in the same way

783
00:31:43,310 --> 00:31:45,110
it's just in this case the OS is gonna

784
00:31:45,110 --> 00:31:47,150
track what's in memory are you know what

785
00:31:47,150 --> 00:31:48,680
did memory versus what's on disk and

786
00:31:48,680 --> 00:31:50,290
this is the data systems gonna track it

787
00:31:50,290 --> 00:31:52,760
so we're gonna focus on these two

788
00:31:52,760 --> 00:31:56,660
because these are gonna be the you know

789
00:31:56,660 --> 00:31:58,430
these are using like the fine grain to

790
00:31:58,430 --> 00:31:59,840
pontification approach that we've talked

791
00:31:59,840 --> 00:32:02,420
about we will discuss how to do this one

792
00:32:02,420 --> 00:32:05,810
with least or and Umbra and then we will

793
00:32:05,810 --> 00:32:08,750
see a technique from epfl of doing this

794
00:32:08,750 --> 00:32:13,160
this OS managed memory and I'm using

795
00:32:13,160 --> 00:32:15,110
ball TB and a few more slides well so

796
00:32:15,110 --> 00:32:16,910
recover all of these but I'm gonna first

797
00:32:16,910 --> 00:32:19,430
discuss and show you explicit examples

798
00:32:19,430 --> 00:32:23,540
of these two here alright so again this

799
00:32:23,540 --> 00:32:25,130
is our same setup we had before Mme

800
00:32:25,130 --> 00:32:26,720
index in memory table heap and cold data

801
00:32:26,720 --> 00:32:30,080
storage so again assuming we have some

802
00:32:30,080 --> 00:32:32,510
way to look at how our tuples are being

803
00:32:32,510 --> 00:32:34,910
accessed and we can computer histogram

804
00:32:34,910 --> 00:32:37,010
that says here's the access frequency of

805
00:32:37,010 --> 00:32:39,830
every single individual tuple we can use

806
00:32:39,830 --> 00:32:41,390
this information to identify that these

807
00:32:41,390 --> 00:32:44,000
three tuples here have been are the

808
00:32:44,000 --> 00:32:45,380
least likely to be accessed again

809
00:32:45,380 --> 00:32:47,120
because they didn't access the least

810
00:32:47,120 --> 00:32:49,940
often in my last my you know the last

811
00:32:49,940 --> 00:32:52,070
time I did this check so I'm gonna go

812
00:32:52,070 --> 00:32:53,420
ahead and write those out to my cold

813
00:32:53,420 --> 00:32:57,380
data storage so now in the the indexes

814
00:32:57,380 --> 00:32:59,120
are still pointing to these old oh look

815
00:32:59,120 --> 00:33:03,020
locations here so now what will happen

816
00:33:03,020 --> 00:33:06,590
is if I go and use tombstones then I

817
00:33:06,590 --> 00:33:09,110
will I will have a marker for every

818
00:33:09,110 --> 00:33:11,630
single tuple that I removed with and

819
00:33:11,630 --> 00:33:13,640
have a corresponding to new tuple that's

820
00:33:13,640 --> 00:33:15,230
going to have the block ID and the

821
00:33:15,230 --> 00:33:17,389
offset of where they exist on dead

822
00:33:17,389 --> 00:33:20,119
so now and then I update my MMA index to

823
00:33:20,119 --> 00:33:21,169
now instead of pointing with the old

824
00:33:21,169 --> 00:33:23,059
locations and the table heap they now

825
00:33:23,059 --> 00:33:26,600
point to the the tombstone tuples so if

826
00:33:26,600 --> 00:33:28,549
a query comes along and looks up you

827
00:33:28,549 --> 00:33:31,159
know key XYZ they follow the index and

828
00:33:31,159 --> 00:33:32,869
get one of these pointers I check a flag

829
00:33:32,869 --> 00:33:35,119
that says you're looking at a tombstone

830
00:33:35,119 --> 00:33:37,429
pointer tombstone a tuple pointer or

831
00:33:37,429 --> 00:33:38,659
sorry you're looking at a tombstone

832
00:33:38,659 --> 00:33:40,850
tuple not amount of data to pool and

833
00:33:40,850 --> 00:33:42,860
therefore I know that the my block ID

834
00:33:42,860 --> 00:33:44,690
and offset will tell me where to go

835
00:33:44,690 --> 00:33:46,549
fetch the data that I'm looking for own

836
00:33:46,549 --> 00:33:49,279
desk in this example here I'm showing

837
00:33:49,279 --> 00:33:52,369
the the the tombstone tuple is being

838
00:33:52,369 --> 00:33:55,399
stored in the same data table as the as

839
00:33:55,399 --> 00:33:58,159
the as the regular in-memory tuples in

840
00:33:58,159 --> 00:34:00,080
actuality though you want to store these

841
00:34:00,080 --> 00:34:02,389
as separate separate data tables we'd

842
00:34:02,389 --> 00:34:05,259
have 1 / / you know regular table

843
00:34:05,259 --> 00:34:07,309
because the schemas gonna be different

844
00:34:07,309 --> 00:34:10,549
right in the in the red regular table

845
00:34:10,549 --> 00:34:12,859
you know the the the the tuples can have

846
00:34:12,859 --> 00:34:14,299
any arbitrary number of columns as

847
00:34:14,299 --> 00:34:16,790
defined by the schema when you created

848
00:34:16,790 --> 00:34:18,739
the table in the case of the tombstone

849
00:34:18,739 --> 00:34:20,690
tuples these are gonna be stored these

850
00:34:20,690 --> 00:34:22,489
are only stored storing two 32-bit

851
00:34:22,489 --> 00:34:24,049
values the block ID and the offset

852
00:34:24,049 --> 00:34:26,270
number so I wouldn't actually want to

853
00:34:26,270 --> 00:34:27,619
store these in the same table he because

854
00:34:27,619 --> 00:34:29,299
if I allocate the total amount of space

855
00:34:29,299 --> 00:34:30,980
I would normally have for a regular

856
00:34:30,980 --> 00:34:32,809
tuple for tomb certain people then I get

857
00:34:32,809 --> 00:34:34,159
no benefit from this and I'm just

858
00:34:34,159 --> 00:34:37,609
wasting space so all right so for that

859
00:34:37,609 --> 00:34:38,809
reason that it's stored separately and

860
00:34:38,809 --> 00:34:41,319
the reason why you want to have a

861
00:34:41,319 --> 00:34:44,809
separate tombstone table per data table

862
00:34:44,809 --> 00:34:47,690
instead of one giant tombstone table for

863
00:34:47,690 --> 00:34:49,399
all tables in your database is because

864
00:34:49,399 --> 00:34:52,010
when I do a sequential scan meaning I'm

865
00:34:52,010 --> 00:34:53,510
not going through an index I'm just

866
00:34:53,510 --> 00:34:55,099
scanning through one by one through

867
00:34:55,099 --> 00:34:56,690
continues reaches the memory for my

868
00:34:56,690 --> 00:34:59,660
table after I'm done scanning the

869
00:34:59,660 --> 00:35:01,490
regular table heap the end memory tuples

870
00:35:01,490 --> 00:35:03,559
then I need you started doing scans on

871
00:35:03,559 --> 00:35:07,700
the tombstone tuples now I can't do any

872
00:35:07,700 --> 00:35:10,220
predicate evaluations on on the

873
00:35:10,220 --> 00:35:12,920
tombstones because there's no data in

874
00:35:12,920 --> 00:35:14,450
there all the data is out here on disk

875
00:35:14,450 --> 00:35:16,430
but there are some queries I could

876
00:35:16,430 --> 00:35:19,819
potentially do like count queries where

877
00:35:19,819 --> 00:35:23,599
I could I could you know just count the

878
00:35:23,599 --> 00:35:24,589
number tuples that exist in the entire

879
00:35:24,589 --> 00:35:27,890
table I could apply them on I can run

880
00:35:27,890 --> 00:35:29,869
that kind of query on this and still

881
00:35:29,869 --> 00:35:31,030
have the correct

882
00:35:31,030 --> 00:35:32,080
the mountain without having to go down

883
00:35:32,080 --> 00:35:35,500
or now if I'm also maintaining the a

884
00:35:35,500 --> 00:35:37,390
memory zone map from what the values

885
00:35:37,390 --> 00:35:39,460
actually exist in here and recording

886
00:35:39,460 --> 00:35:41,110
that for a block of tombs from tubal's

887
00:35:41,110 --> 00:35:42,730
I could then still do a scan on there

888
00:35:42,730 --> 00:35:44,890
and be able to compute some answers for

889
00:35:44,890 --> 00:35:46,600
some queries but anytime I need to

890
00:35:46,600 --> 00:35:48,220
actually know what the exact value for

891
00:35:48,220 --> 00:35:51,910
one individual tuple is for one give an

892
00:35:51,910 --> 00:35:53,680
attribute within a tuple then I got to

893
00:35:53,680 --> 00:35:57,220
go out the disk and get it another

894
00:35:57,220 --> 00:35:58,900
optimization you can do with this but we

895
00:35:58,900 --> 00:36:01,150
actually never implemented this in an H

896
00:36:01,150 --> 00:36:04,420
store is that even though this is

897
00:36:04,420 --> 00:36:09,070
Outland disk you could still maybe use

898
00:36:09,070 --> 00:36:11,020
the index as a covering index like if I

899
00:36:11,020 --> 00:36:13,120
know all the ash words that I need to

900
00:36:13,120 --> 00:36:14,530
answer my query can be found in this

901
00:36:14,530 --> 00:36:17,170
index I don't even have to go follow the

902
00:36:17,170 --> 00:36:19,090
the pointers ago can get the data on

903
00:36:19,090 --> 00:36:21,660
disk the index has everything I need

904
00:36:21,660 --> 00:36:23,800
another thing we thought about we never

905
00:36:23,800 --> 00:36:28,030
actually did would be say I have indexes

906
00:36:28,030 --> 00:36:30,550
that for a table that have all the

907
00:36:30,550 --> 00:36:33,520
attributes for my my table like I have

908
00:36:33,520 --> 00:36:34,930
three attributes and there's an index

909
00:36:34,930 --> 00:36:36,730
there's a separate index on each of

910
00:36:36,730 --> 00:36:39,340
those three attributes so now my query

911
00:36:39,340 --> 00:36:40,750
comes along does a lookup on one of

912
00:36:40,750 --> 00:36:42,370
those attributes I would follow along

913
00:36:42,370 --> 00:36:44,200
and then what this tombstone tuple here

914
00:36:44,200 --> 00:36:46,600
but then rather than going up the disk

915
00:36:46,600 --> 00:36:48,970
and getting it I can maybe do a reverse

916
00:36:48,970 --> 00:36:53,040
search in my index and go find the

917
00:36:53,040 --> 00:36:55,330
corresponding key that matches to my

918
00:36:55,330 --> 00:36:57,790
value basically need to scan along the

919
00:36:57,790 --> 00:37:00,310
leaf nodes like this and that actually

920
00:37:00,310 --> 00:37:01,990
might end up being cheaper than having

921
00:37:01,990 --> 00:37:04,690
to go fetch you know some block from

922
00:37:04,690 --> 00:37:06,370
disk and bring it into memory because

923
00:37:06,370 --> 00:37:07,810
this more than just the disk i/o I got

924
00:37:07,810 --> 00:37:08,920
to go bring it into memory and

925
00:37:08,920 --> 00:37:11,500
potentially update indexes as well so

926
00:37:11,500 --> 00:37:13,810
one idea would be if I have enough if I

927
00:37:13,810 --> 00:37:15,070
don't have a single index that could

928
00:37:15,070 --> 00:37:17,200
cover my query but the combination of

929
00:37:17,200 --> 00:37:18,880
them the intersection of them would it

930
00:37:18,880 --> 00:37:21,880
might be cheaper to go back and do you

931
00:37:21,880 --> 00:37:23,680
know do you leave no scans or depending

932
00:37:23,680 --> 00:37:25,480
what data structure I'm using to find

933
00:37:25,480 --> 00:37:28,390
the find all the values finding for the

934
00:37:28,390 --> 00:37:30,250
matching matches for my given tombstone

935
00:37:30,250 --> 00:37:31,990
but we never actually implanted

936
00:37:31,990 --> 00:37:35,290
implemented that all right so the next

937
00:37:35,290 --> 00:37:38,380
one is the the bloom filter approach and

938
00:37:38,380 --> 00:37:40,870
so again the idea here is that we have a

939
00:37:40,870 --> 00:37:42,580
bloom filter for every single index we

940
00:37:42,580 --> 00:37:45,190
have in memory and then add on disk

941
00:37:45,190 --> 00:37:48,700
for the ever every single for every

942
00:37:48,700 --> 00:37:50,230
single block or comment a set of blocks

943
00:37:50,230 --> 00:37:53,200
will have an on disk index just another

944
00:37:53,200 --> 00:37:55,410
B+ treaty that we can use to identify

945
00:37:55,410 --> 00:37:57,730
for the given key that we're looking for

946
00:37:57,730 --> 00:38:00,369
where do we go find it the idea here is

947
00:38:00,369 --> 00:38:02,410
that we want to reduce the size of this

948
00:38:02,410 --> 00:38:05,260
index because in the tombstone case I

949
00:38:05,260 --> 00:38:07,660
would still have all the keys for two

950
00:38:07,660 --> 00:38:10,480
four tuples I've been evicted but with

951
00:38:10,480 --> 00:38:12,400
the bloom filter any key that's been a

952
00:38:12,400 --> 00:38:13,569
victor and the tuba that's been evicted

953
00:38:13,569 --> 00:38:15,880
we removed those keys from the index and

954
00:38:15,880 --> 00:38:18,730
now the index gets reduced in size so if

955
00:38:18,730 --> 00:38:20,740
a query comes along that says does key X

956
00:38:20,740 --> 00:38:21,339
exist

957
00:38:21,339 --> 00:38:23,710
I always check the in memory index first

958
00:38:23,710 --> 00:38:25,839
if it says it's there they don't have a

959
00:38:25,839 --> 00:38:28,150
pointer to the tuple and I'm done if it

960
00:38:28,150 --> 00:38:31,000
says it doesn't exist then I consult its

961
00:38:31,000 --> 00:38:33,609
bloom filter and then again the same

962
00:38:33,609 --> 00:38:35,050
thing the blue input says it doesn't

963
00:38:35,050 --> 00:38:37,210
exist I'm done if it says it does exist

964
00:38:37,210 --> 00:38:40,060
then I go to a lookup on the in memory

965
00:38:40,060 --> 00:38:42,670
and the on disk index and that'll tell

966
00:38:42,670 --> 00:38:45,579
me now where the location is the block

967
00:38:45,579 --> 00:38:47,380
ID and the all set of where the tuple

968
00:38:47,380 --> 00:38:49,000
that is that I'm looking for and then

969
00:38:49,000 --> 00:38:54,640
I'd sort of have a copy back in okay so

970
00:38:54,640 --> 00:38:56,740
now you depending on whether we're using

971
00:38:56,740 --> 00:38:59,020
the tombstones or the bloom filter

972
00:38:59,020 --> 00:39:01,060
approach or a West managed memory or

973
00:39:01,060 --> 00:39:03,010
database system managed memory we now

974
00:39:03,010 --> 00:39:06,130
got to bring bring our data back in so

975
00:39:06,130 --> 00:39:08,700
then we can then have record a run on it

976
00:39:08,700 --> 00:39:12,730
so the question you have to do is what

977
00:39:12,730 --> 00:39:14,050
do we do with the tuples that we brought

978
00:39:14,050 --> 00:39:16,690
in because again in an OTP environment

979
00:39:16,690 --> 00:39:20,260
it's very likely that the for a given

980
00:39:20,260 --> 00:39:22,540
block of data we're only going to need a

981
00:39:22,540 --> 00:39:25,480
subset of the tuples for our query that

982
00:39:25,480 --> 00:39:27,369
are in that block so do we do with all

983
00:39:27,369 --> 00:39:30,099
that all the other ones so the first

984
00:39:30,099 --> 00:39:31,930
choice is that we're just going to merge

985
00:39:31,930 --> 00:39:33,880
all those tuples we find in the blog via

986
00:39:33,880 --> 00:39:36,579
fetch from disk back into our table heap

987
00:39:36,579 --> 00:39:38,530
but regardless of whether they're needed

988
00:39:38,530 --> 00:39:40,750
or not and so what does that mean in the

989
00:39:40,750 --> 00:39:42,310
case the bloom filter kate and bloom put

990
00:39:42,310 --> 00:39:44,680
their arrangement or the the tubes are

991
00:39:44,680 --> 00:39:47,079
tuples now we got to go update the

992
00:39:47,079 --> 00:39:50,680
indexes to now point now to the tuples

993
00:39:50,680 --> 00:39:53,319
we just merged in so if I needed one to

994
00:39:53,319 --> 00:39:55,780
boil my block and my block has a million

995
00:39:55,780 --> 00:39:57,460
tuples now I have to do a million

996
00:39:57,460 --> 00:39:58,510
updates to my

997
00:39:58,510 --> 00:40:00,880
next now to point to the 1 million

998
00:40:00,880 --> 00:40:04,180
tuples that I just brought in and the

999
00:40:04,180 --> 00:40:05,560
downside of this is that it's very

1000
00:40:05,560 --> 00:40:06,700
likely that tuples we just brought

1001
00:40:06,700 --> 00:40:08,650
brought in are gonna be evicted again so

1002
00:40:08,650 --> 00:40:10,180
we sort of have this ping-pong you're

1003
00:40:10,180 --> 00:40:11,950
thrashing effect where we're merging

1004
00:40:11,950 --> 00:40:14,530
data back and front index on our indexes

1005
00:40:14,530 --> 00:40:16,000
and back into our table heap from from

1006
00:40:16,000 --> 00:40:18,190
disk into memory and then we run our

1007
00:40:18,190 --> 00:40:19,330
diction algorithm and then they get

1008
00:40:19,330 --> 00:40:20,680
shoved out to disk right away because

1009
00:40:20,680 --> 00:40:23,200
they're cold all over again the other

1010
00:40:23,200 --> 00:40:27,160
approach is to only merge back the the

1011
00:40:27,160 --> 00:40:29,470
tuples that we need within the block and

1012
00:40:29,470 --> 00:40:32,290
so in this case here we identified just

1013
00:40:32,290 --> 00:40:33,970
what's the minimum amount we need we

1014
00:40:33,970 --> 00:40:35,560
bring that much our table heat we update

1015
00:40:35,560 --> 00:40:37,930
those indexes but now we have this

1016
00:40:37,930 --> 00:40:42,190
problem of the the disk page of the cold

1017
00:40:42,190 --> 00:40:46,660
data if we don't record that we have

1018
00:40:46,660 --> 00:40:50,470
evicted that data sorry then we move

1019
00:40:50,470 --> 00:40:52,990
that data back into memory and therefore

1020
00:40:52,990 --> 00:40:56,110
the the tuple shouldn't be existing on

1021
00:40:56,110 --> 00:40:57,730
that block anymore we could write out

1022
00:40:57,730 --> 00:40:59,260
the new block without that tuple in it

1023
00:40:59,260 --> 00:41:00,640
but that would be expensive because now

1024
00:41:00,640 --> 00:41:03,850
for every single read just to go access

1025
00:41:03,850 --> 00:41:06,340
a tuple I got to do one disk IO to read

1026
00:41:06,340 --> 00:41:08,740
it in I pull it out merge it back to the

1027
00:41:08,740 --> 00:41:10,330
table Eve and then another disk IO to

1028
00:41:10,330 --> 00:41:13,090
write it out and say the tuple doesn't

1029
00:41:13,090 --> 00:41:15,370
exist anymore so you have to maintain

1030
00:41:15,370 --> 00:41:17,110
some of there's some bookkeeping to keep

1031
00:41:17,110 --> 00:41:18,400
track of these holes and you probably

1032
00:41:18,400 --> 00:41:21,250
want to record them in a log rather than

1033
00:41:21,250 --> 00:41:25,780
in the in the addictive block itself and

1034
00:41:25,780 --> 00:41:27,040
then there's some background process you

1035
00:41:27,040 --> 00:41:28,840
could run to do compaction or coalescing

1036
00:41:28,840 --> 00:41:30,760
to combine a bunch of blocks that bunch

1037
00:41:30,760 --> 00:41:32,520
of holes together into a single block

1038
00:41:32,520 --> 00:41:35,080
the reason why you keep track of these

1039
00:41:35,080 --> 00:41:37,270
holes is because what would happen is if

1040
00:41:37,270 --> 00:41:41,020
I fetch a block get a tuple back have

1041
00:41:41,020 --> 00:41:44,320
merchantable back in and then now that

1042
00:41:44,320 --> 00:41:45,970
first block shouldn't have that tuple

1043
00:41:45,970 --> 00:41:47,710
but it's still physically there just but

1044
00:41:47,710 --> 00:41:49,000
I haven't recorded that it shouldn't be

1045
00:41:49,000 --> 00:41:51,070
there if that tuple get the victim again

1046
00:41:51,070 --> 00:41:52,720
now gets written to another block I

1047
00:41:52,720 --> 00:41:54,820
could have the same tuple duplicated

1048
00:41:54,820 --> 00:41:56,560
multiple times in the separate cold data

1049
00:41:56,560 --> 00:41:58,750
blocks and if I crash and come back and

1050
00:41:58,750 --> 00:42:00,160
now I don't know which one is actually

1051
00:42:00,160 --> 00:42:02,290
the the right one I should be I should

1052
00:42:02,290 --> 00:42:04,150
be merging in a bunch amount of work I

1053
00:42:04,150 --> 00:42:06,130
have to do in the recovery side to deal

1054
00:42:06,130 --> 00:42:08,430
with that

1055
00:42:09,040 --> 00:42:15,000
the right the second last issue is is

1056
00:42:15,000 --> 00:42:16,960
what is the threshold we're going to use

1057
00:42:16,960 --> 00:42:18,730
to determine whether to merge something

1058
00:42:18,730 --> 00:42:21,700
in a merger tuple back in so again with

1059
00:42:21,700 --> 00:42:23,680
least or we don't really have this issue

1060
00:42:23,680 --> 00:42:25,900
because everything is controlled by

1061
00:42:25,900 --> 00:42:27,430
pages that we can swap in and out of the

1062
00:42:27,430 --> 00:42:29,020
desk this is most thing and when you're

1063
00:42:29,020 --> 00:42:30,220
doing this is just neat if when you're

1064
00:42:30,220 --> 00:42:31,420
doing the fine-grained tuple based

1065
00:42:31,420 --> 00:42:34,510
identification and eviction so the

1066
00:42:34,510 --> 00:42:36,220
easiest proach is what I said before is

1067
00:42:36,220 --> 00:42:38,200
just always merge it whatever tuples I

1068
00:42:38,200 --> 00:42:40,240
decide I want to merge I'm just gonna

1069
00:42:40,240 --> 00:42:41,380
always put them back in the table heap

1070
00:42:41,380 --> 00:42:44,410
and update the indexes the next approach

1071
00:42:44,410 --> 00:42:46,450
is to only merge them when there's an

1072
00:42:46,450 --> 00:42:49,869
update this means is that if my query

1073
00:42:49,869 --> 00:42:52,530
just wants to read a tuple I will go

1074
00:42:52,530 --> 00:42:56,710
fetch the block that it met at once but

1075
00:42:56,710 --> 00:42:58,900
put it in a temporary buffer allow the

1076
00:42:58,900 --> 00:43:01,180
query to read it and then immediately

1077
00:43:01,180 --> 00:43:03,940
discard the buffer writes in this way I

1078
00:43:03,940 --> 00:43:06,150
don't want the updating in any indexes

1079
00:43:06,150 --> 00:43:10,119
if it is updated then I if the queries

1080
00:43:10,119 --> 00:43:11,350
trying to do an update then I'll go

1081
00:43:11,350 --> 00:43:13,060
ahead and merge it first then allow them

1082
00:43:13,060 --> 00:43:15,940
to do the update and then the last one

1083
00:43:15,940 --> 00:43:18,160
is that we can be a bit clever and

1084
00:43:18,160 --> 00:43:20,230
actually maintain the access frequency

1085
00:43:20,230 --> 00:43:24,910
of of evicted blocks but essentially how

1086
00:43:24,910 --> 00:43:26,410
often that be you know are they being

1087
00:43:26,410 --> 00:43:29,500
retrieved and if my access frequency

1088
00:43:29,500 --> 00:43:31,450
goes above some threshold then I've

1089
00:43:31,450 --> 00:43:33,369
decided that within my current time

1090
00:43:33,369 --> 00:43:35,500
window this block is being accessed all

1091
00:43:35,500 --> 00:43:37,480
the time so it's probably good idea for

1092
00:43:37,480 --> 00:43:39,310
me to keep this around so it's sort of

1093
00:43:39,310 --> 00:43:41,830
like in the same way we would keep track

1094
00:43:41,830 --> 00:43:43,420
of how two poles are being accessed our

1095
00:43:43,420 --> 00:43:44,830
pages are being accessed well 10 memory

1096
00:43:44,830 --> 00:43:46,990
we also can maintain information that

1097
00:43:46,990 --> 00:43:49,720
says how often a page is being accessed

1098
00:43:49,720 --> 00:43:53,320
you know from disk alright so the last

1099
00:43:53,320 --> 00:43:55,600
one I want to talk about is what do we

1100
00:43:55,600 --> 00:43:58,960
do with the query or transaction that

1101
00:43:58,960 --> 00:44:03,730
accessed cold data you know with how

1102
00:44:03,730 --> 00:44:07,330
should we respond to it so the easiest

1103
00:44:07,330 --> 00:44:09,730
thing to do is just abort the

1104
00:44:09,730 --> 00:44:11,650
transaction abort the query and restart

1105
00:44:11,650 --> 00:44:16,090
it and the idea here is that we go to

1106
00:44:16,090 --> 00:44:18,369
access a tuple that's not in memory we

1107
00:44:18,369 --> 00:44:21,430
record what tuple they wanted or what

1108
00:44:21,430 --> 00:44:22,920
data they actually wanted

1109
00:44:22,920 --> 00:44:26,400
and men we abort it a sever background

1110
00:44:26,400 --> 00:44:28,049
thread then kicks off and fetches the

1111
00:44:28,049 --> 00:44:30,690
data that they need that he wanted and

1112
00:44:30,690 --> 00:44:33,089
then merges it based on the policy that

1113
00:44:33,089 --> 00:44:35,970
we just talked about and when the data

1114
00:44:35,970 --> 00:44:37,200
is actually available we have a way of

1115
00:44:37,200 --> 00:44:39,270
either restarting the transaction like

1116
00:44:39,270 --> 00:44:40,799
if it's running as a store by seizure on

1117
00:44:40,799 --> 00:44:41,849
the server side

1118
00:44:41,849 --> 00:44:44,640
or we could potentially notify the

1119
00:44:44,640 --> 00:44:46,140
client said hey the data you want is

1120
00:44:46,140 --> 00:44:50,309
actually now available the that last one

1121
00:44:50,309 --> 00:44:52,200
nobody actually nobody actually supports

1122
00:44:52,200 --> 00:44:54,930
this right so it's basically you abort

1123
00:44:54,930 --> 00:44:56,280
the transaction and can send back an

1124
00:44:56,280 --> 00:44:58,950
exception over ODBC or JDBC and give a

1125
00:44:58,950 --> 00:45:00,599
error code to say the data you want

1126
00:45:00,599 --> 00:45:04,410
something memory please retry there's

1127
00:45:04,410 --> 00:45:05,670
similar once or deadlocks and things

1128
00:45:05,670 --> 00:45:07,890
like that so it's not unfeasible that

1129
00:45:07,890 --> 00:45:10,950
you couldn't do this but no system

1130
00:45:10,950 --> 00:45:13,099
actually does this explicitly for for

1131
00:45:13,099 --> 00:45:15,119
evicted data an in-memory database

1132
00:45:15,119 --> 00:45:21,480
system so the tricky thing what this is

1133
00:45:21,480 --> 00:45:24,750
going to be is that if I have a

1134
00:45:24,750 --> 00:45:27,630
transaction or a query that wants to run

1135
00:45:27,630 --> 00:45:29,910
with a strong isolation level like snaps

1136
00:45:29,910 --> 00:45:34,380
isolation or serialize legislation I had

1137
00:45:34,380 --> 00:45:36,000
to have multi-version concurrency tried

1138
00:45:36,000 --> 00:45:37,530
to use I can have multi versioning in

1139
00:45:37,530 --> 00:45:41,220
order to allow a transaction to get

1140
00:45:41,220 --> 00:45:43,950
restarted multiple times or sort of

1141
00:45:43,950 --> 00:45:49,440
paused and restarted and at least have a

1142
00:45:49,440 --> 00:45:52,859
consistent snapshot of the database so

1143
00:45:52,859 --> 00:45:55,349
with this one it's not really your

1144
00:45:55,349 --> 00:45:57,119
aborting you yes your aborting and

1145
00:45:57,119 --> 00:45:59,549
restarting it but when you come back the

1146
00:45:59,549 --> 00:46:01,530
second time your transaction ID was will

1147
00:46:01,530 --> 00:46:04,619
be still be the same and the idea here

1148
00:46:04,619 --> 00:46:07,859
is that this allows you again you have a

1149
00:46:07,859 --> 00:46:09,599
consistent snapshot of the table or

1150
00:46:09,599 --> 00:46:11,190
whatever you're trying to access even

1151
00:46:11,190 --> 00:46:13,230
though you may be running it at

1152
00:46:13,230 --> 00:46:17,069
different different invocations of the

1153
00:46:17,069 --> 00:46:19,230
query so the way to think about this is

1154
00:46:19,230 --> 00:46:21,540
say I have a query that wants to scan

1155
00:46:21,540 --> 00:46:24,000
the entire team but only half the table

1156
00:46:24,000 --> 00:46:27,990
can exist in memory at a given time what

1157
00:46:27,990 --> 00:46:29,700
would happen is what this approach is I

1158
00:46:29,700 --> 00:46:32,040
would query would start it was begin

1159
00:46:32,040 --> 00:46:33,599
scanning and get through the first half

1160
00:46:33,599 --> 00:46:35,760
of the table and then imma try to access

1161
00:46:35,760 --> 00:46:36,970
the next half

1162
00:46:36,970 --> 00:46:40,400
and then it would it would it would hit

1163
00:46:40,400 --> 00:46:42,110
up either a tombstone tuple or somehow

1164
00:46:42,110 --> 00:46:44,120
identify that the tuple that once is not

1165
00:46:44,120 --> 00:46:47,810
there then there's a it gets aborted the

1166
00:46:47,810 --> 00:46:50,240
background thread fetches the the

1167
00:46:50,240 --> 00:46:54,140
remaining data that actually needs by

1168
00:46:54,140 --> 00:46:56,150
victim the the first half of the table

1169
00:46:56,150 --> 00:46:58,430
and then my transaction of query can get

1170
00:46:58,430 --> 00:47:00,440
restarted but if I'm restarting from the

1171
00:47:00,440 --> 00:47:02,060
beginning then I'm gonna hit the same

1172
00:47:02,060 --> 00:47:04,730
issue where I the first thing I need to

1173
00:47:04,730 --> 00:47:06,590
go fetch is not memory and not to go

1174
00:47:06,590 --> 00:47:08,240
aboard it and now the first half gets

1175
00:47:08,240 --> 00:47:09,890
paid in the second half gets written out

1176
00:47:09,890 --> 00:47:12,200
I never can actually complete or at the

1177
00:47:12,200 --> 00:47:13,940
run with a consistent snapshot where

1178
00:47:13,940 --> 00:47:16,160
transactions could be updating the the

1179
00:47:16,160 --> 00:47:16,880
second half

1180
00:47:16,880 --> 00:47:19,130
while my waiting for a transaction get

1181
00:47:19,130 --> 00:47:21,350
me started or if I have a kiss isn't a

1182
00:47:21,350 --> 00:47:23,120
snapshot then I just should essentially

1183
00:47:23,120 --> 00:47:25,190
pause garbage garbage collection while I

1184
00:47:25,190 --> 00:47:27,890
go flush out the first half bring him

1185
00:47:27,890 --> 00:47:29,270
the second half and I come back and I

1186
00:47:29,270 --> 00:47:31,550
still have a consistent view or

1187
00:47:31,550 --> 00:47:34,460
consistent snapshot of the table as I

1188
00:47:34,460 --> 00:47:37,100
said nobody actually does this one that

1189
00:47:37,100 --> 00:47:40,460
I'm aware of you know for this reason

1190
00:47:40,460 --> 00:47:41,870
because it makes it tricky to guarantee

1191
00:47:41,870 --> 00:47:45,830
consistency the more common approach is

1192
00:47:45,830 --> 00:47:49,010
to do synchronous retrieval and the idea

1193
00:47:49,010 --> 00:47:51,350
here is that it's essentially what a

1194
00:47:51,350 --> 00:47:53,270
disk or native database does now when I

1195
00:47:53,270 --> 00:47:55,130
try to access something that's not in

1196
00:47:55,130 --> 00:47:57,620
memory my transaction gets pause or

1197
00:47:57,620 --> 00:48:00,440
stalled while another thread or my the

1198
00:48:00,440 --> 00:48:04,280
the disk controller or why that's a disk

1199
00:48:04,280 --> 00:48:05,810
manager it fetches the data that I need

1200
00:48:05,810 --> 00:48:07,940
and brings it into memory and once it's

1201
00:48:07,940 --> 00:48:09,710
in the memory then I'm allowed to

1202
00:48:09,710 --> 00:48:12,200
proceed and start running so there's

1203
00:48:12,200 --> 00:48:13,850
some games you can play with some of

1204
00:48:13,850 --> 00:48:18,770
these like I could try to let a query

1205
00:48:18,770 --> 00:48:22,450
keep running for long as it can

1206
00:48:22,450 --> 00:48:28,160
accessing evicted data and I just would

1207
00:48:28,160 --> 00:48:29,570
have to do like a Jedi mind trick that

1208
00:48:29,570 --> 00:48:31,250
says oh I want to read this tuple and

1209
00:48:31,250 --> 00:48:32,900
you pretend that it could actually read

1210
00:48:32,900 --> 00:48:34,640
it some queries can do this some other

1211
00:48:34,640 --> 00:48:37,490
queries can't and there's only when they

1212
00:48:37,490 --> 00:48:39,110
actually try to return results to the

1213
00:48:39,110 --> 00:48:40,370
application or do something with the

1214
00:48:40,370 --> 00:48:42,410
individual attributes on the evicted

1215
00:48:42,410 --> 00:48:44,660
data then you go ahead and pause it or

1216
00:48:44,660 --> 00:48:48,980
abort it the idea here is that you can

1217
00:48:48,980 --> 00:48:50,330
kind of let the query

1218
00:48:50,330 --> 00:48:53,060
as long as possible identify all the the

1219
00:48:53,060 --> 00:48:54,560
two poles are all the pages is gonna

1220
00:48:54,560 --> 00:48:56,810
access and then at some point you say

1221
00:48:56,810 --> 00:48:58,670
alright well I've seen enough let me go

1222
00:48:58,670 --> 00:49:00,170
fetch the big batch of things that you

1223
00:49:00,170 --> 00:49:02,360
need and so that way you're not like

1224
00:49:02,360 --> 00:49:04,370
this run stall run stall over and over

1225
00:49:04,370 --> 00:49:05,810
again you can maybe do a bunch of

1226
00:49:05,810 --> 00:49:07,670
sequential i/o fetch it all in and then

1227
00:49:07,670 --> 00:49:13,370
and let it run more quickly alright so

1228
00:49:13,370 --> 00:49:14,690
now I want to go through a bunch of

1229
00:49:14,690 --> 00:49:17,930
different implementations of systems

1230
00:49:17,930 --> 00:49:19,640
that support larger than memory

1231
00:49:19,640 --> 00:49:21,650
databases and the way this is gonna be

1232
00:49:21,650 --> 00:49:23,660
organized is that the first four here

1233
00:49:23,660 --> 00:49:25,820
we're all gonna be using the the sort of

1234
00:49:25,820 --> 00:49:27,470
fine-grain tuple based approach that we

1235
00:49:27,470 --> 00:49:29,540
talked about before we talked about so

1236
00:49:29,540 --> 00:49:32,750
far and then the these three million

1237
00:49:32,750 --> 00:49:34,160
systems are actually going to be page

1238
00:49:34,160 --> 00:49:36,350
based and at the high level they're all

1239
00:49:36,350 --> 00:49:38,660
going to achieve the same goal that we

1240
00:49:38,660 --> 00:49:40,340
can have a new memory database system

1241
00:49:40,340 --> 00:49:43,280
that can maintain and store databases

1242
00:49:43,280 --> 00:49:44,900
that are larger than the amount of

1243
00:49:44,900 --> 00:49:46,100
memory that's available to the system

1244
00:49:46,100 --> 00:49:49,100
without having to do any rewriting of

1245
00:49:49,100 --> 00:49:53,480
the application to some extent and the

1246
00:49:53,480 --> 00:49:57,020
spoiler that I'll say is that the the

1247
00:49:57,020 --> 00:49:59,270
page based approaches in particular from

1248
00:49:59,270 --> 00:50:01,670
lean store and Umbra I think are the

1249
00:50:01,670 --> 00:50:04,370
right way to go and these two base ones

1250
00:50:04,370 --> 00:50:07,400
are a little bit too fine grain and the

1251
00:50:07,400 --> 00:50:12,230
sort of stores and computational

1252
00:50:12,230 --> 00:50:13,790
overhead you pay or the pen or you pay

1253
00:50:13,790 --> 00:50:15,830
from being a little support this I think

1254
00:50:15,830 --> 00:50:20,180
is it's not worth it so again we'll go

1255
00:50:20,180 --> 00:50:21,800
through each of these one by one but I

1256
00:50:21,800 --> 00:50:23,900
think the leaves for umber one is is

1257
00:50:23,900 --> 00:50:28,160
probably the right way to go so as I

1258
00:50:28,160 --> 00:50:31,370
said before the the paper of all the

1259
00:50:31,370 --> 00:50:32,780
different implementation issues or

1260
00:50:32,780 --> 00:50:36,170
design decisions was based on a system

1261
00:50:36,170 --> 00:50:37,280
that I helped build when I was in grad

1262
00:50:37,280 --> 00:50:38,900
school called eight store that was then

1263
00:50:38,900 --> 00:50:41,960
commercialized as volt EP and over an

1264
00:50:41,960 --> 00:50:45,500
early prototype of of a store that

1265
00:50:45,500 --> 00:50:47,990
supported ready data out the disk was

1266
00:50:47,990 --> 00:50:50,540
this component we call it an T caching

1267
00:50:50,540 --> 00:50:52,580
and again the idea is like it's a

1268
00:50:52,580 --> 00:50:54,710
reverse of a cache instead of fetching

1269
00:50:54,710 --> 00:50:56,510
hot data from disk and pulling into

1270
00:50:56,510 --> 00:51:00,080
memory we push cold data out from from

1271
00:51:00,080 --> 00:51:03,230
memory onto disk so given all the

1272
00:51:03,230 --> 00:51:04,609
different design decisions we talked

1273
00:51:04,609 --> 00:51:06,319
a store here is gonna be doing online

1274
00:51:06,319 --> 00:51:08,450
identification it's gonna maintain an

1275
00:51:08,450 --> 00:51:10,130
LRU chain in the header every single

1276
00:51:10,130 --> 00:51:12,410
tuple we do sampling to make sure that

1277
00:51:12,410 --> 00:51:13,700
we're not updating it every single time

1278
00:51:13,700 --> 00:51:15,829
our transaction runs to avoid too much

1279
00:51:15,829 --> 00:51:19,460
overhead but it's still in 64 bits for

1280
00:51:19,460 --> 00:51:22,099
every single tuple it's gonna have

1281
00:51:22,099 --> 00:51:23,479
administrator defined threshold to

1282
00:51:23,479 --> 00:51:26,559
identify that the data that you need

1283
00:51:26,559 --> 00:51:28,700
when you're running out of space and go

1284
00:51:28,700 --> 00:51:30,289
ahead and kick off the eviction policy

1285
00:51:30,289 --> 00:51:32,150
we're going to use tombstone tuples

1286
00:51:32,150 --> 00:51:33,890
we're gonna do the board and restart

1287
00:51:33,890 --> 00:51:35,569
approach which we can do because all

1288
00:51:35,569 --> 00:51:39,559
transactions in an H store gonna run

1289
00:51:39,559 --> 00:51:42,109
have to run as store procedures it's

1290
00:51:42,109 --> 00:51:44,170
gonna do block level granularity of

1291
00:51:44,170 --> 00:51:47,089
merging and data and then in the

1292
00:51:47,089 --> 00:51:48,619
original implementation it would always

1293
00:51:48,619 --> 00:51:50,839
merge them right the original

1294
00:51:50,839 --> 00:51:52,430
implication couldn't decide oh this is

1295
00:51:52,430 --> 00:51:54,140
the data this data is being updated so

1296
00:51:54,140 --> 00:51:56,239
let me go ahead and emerge that just

1297
00:51:56,239 --> 00:51:58,640
that piece or have it the side buffer it

1298
00:51:58,640 --> 00:52:00,079
just always grab it over the block was

1299
00:52:00,079 --> 00:52:02,499
updated all the indexes that merge it in

1300
00:52:02,499 --> 00:52:05,719
so needless to say that this had a you

1301
00:52:05,719 --> 00:52:07,729
know quite a bit overhead to support

1302
00:52:07,729 --> 00:52:10,819
this the other sort of major

1303
00:52:10,819 --> 00:52:12,880
implementation around this time that

1304
00:52:12,880 --> 00:52:15,769
that supported larger than databases

1305
00:52:15,769 --> 00:52:18,499
came out of it was part of the the

1306
00:52:18,499 --> 00:52:21,890
Hecate on project again Hecate on was

1307
00:52:21,890 --> 00:52:23,749
the a memory storage or execution engine

1308
00:52:23,749 --> 00:52:26,119
that Microsoft build for sequel server I

1309
00:52:26,119 --> 00:52:27,799
think now and they're just called in

1310
00:52:27,799 --> 00:52:29,960
memory tables but the search hackaton

1311
00:52:29,960 --> 00:52:31,999
then it shows up so this was a side

1312
00:52:31,999 --> 00:52:34,190
project or a research project called

1313
00:52:34,190 --> 00:52:36,349
project Siberia that was again looking

1314
00:52:36,349 --> 00:52:39,789
at how to extend Hecate on to support

1315
00:52:39,789 --> 00:52:41,509
databases that exceed the amount of

1316
00:52:41,509 --> 00:52:43,460
memory that's available so the main

1317
00:52:43,460 --> 00:52:44,779
thing about this one was this is what

1318
00:52:44,779 --> 00:52:46,099
we're the bloom filter stuff that we

1319
00:52:46,099 --> 00:52:48,049
talked about came from and the idea is

1320
00:52:48,049 --> 00:52:49,969
that you do the offline identification

1321
00:52:49,969 --> 00:52:52,309
the same threshold as aged or with it

1322
00:52:52,309 --> 00:52:54,229
that's defined by the administrator well

1323
00:52:54,229 --> 00:52:58,640
we'll remove values or keys from evicted

1324
00:52:58,640 --> 00:52:59,839
tuples from the meat from the Mme

1325
00:52:59,839 --> 00:53:02,210
indexes but then update or maintain a

1326
00:53:02,210 --> 00:53:04,099
bloom filter to keep track of whether

1327
00:53:04,099 --> 00:53:06,049
the key actually could exist out on disk

1328
00:53:06,049 --> 00:53:08,539
and then when transactions try to access

1329
00:53:08,539 --> 00:53:10,549
that cold data we would actually pause

1330
00:53:10,549 --> 00:53:13,369
them or stall them and then go fetch it

1331
00:53:13,369 --> 00:53:15,589
and bring it in and they were always

1332
00:53:15,589 --> 00:53:17,509
doing this merging a tuple level

1333
00:53:17,509 --> 00:53:18,210
granularity and

1334
00:53:18,210 --> 00:53:20,070
like in a store they would always merge

1335
00:53:20,070 --> 00:53:23,250
everything so the best my knowledge all

1336
00:53:23,250 --> 00:53:25,980
the Siberia stuff from Microsoft never

1337
00:53:25,980 --> 00:53:27,390
actually made it to production never

1338
00:53:27,390 --> 00:53:29,190
actually made it into the real hackathon

1339
00:53:29,190 --> 00:53:32,460
system and I think a part of this was

1340
00:53:32,460 --> 00:53:33,990
just sort of the the engineering

1341
00:53:33,990 --> 00:53:37,440
complexity of sir maintaining the cold

1342
00:53:37,440 --> 00:53:42,089
data plus the hot data and the sort of

1343
00:53:42,089 --> 00:53:43,589
inconsistent performance you could get

1344
00:53:43,589 --> 00:53:46,830
from you know as sometimes your tuples

1345
00:53:46,830 --> 00:53:48,210
are in memories from them sometimes

1346
00:53:48,210 --> 00:53:49,140
they're not and you don't really know

1347
00:53:49,140 --> 00:53:50,760
that until you act upon them so for

1348
00:53:50,760 --> 00:53:52,500
these reasons I Hecate on never actually

1349
00:53:52,500 --> 00:53:55,140
got this this functionality and likewise

1350
00:53:55,140 --> 00:53:56,970
I don't think both TV ever got the the

1351
00:53:56,970 --> 00:53:58,260
antique ash and stuff that we were doing

1352
00:53:58,260 --> 00:54:02,160
at age 2 either another interesting

1353
00:54:02,160 --> 00:54:06,300
system is came from epfl and this was

1354
00:54:06,300 --> 00:54:08,790
developed by a Natasa alum aki and her

1355
00:54:08,790 --> 00:54:11,310
group in Switzerland the tossa used to

1356
00:54:11,310 --> 00:54:14,130
be the the database professor at CMU

1357
00:54:14,130 --> 00:54:15,540
before I showed up and she actually

1358
00:54:15,540 --> 00:54:19,410
taught the earlier versions of 7:21 13

1359
00:54:19,410 --> 00:54:22,260
years ago so what are they going to do

1360
00:54:22,260 --> 00:54:23,220
so they're gonna do offline

1361
00:54:23,220 --> 00:54:26,400
identification the same with that that

1362
00:54:26,400 --> 00:54:29,490
Siberia did but now they're gonna have

1363
00:54:29,490 --> 00:54:33,750
the OS manage memory and make decisions

1364
00:54:33,750 --> 00:54:36,119
of how to evict things out the disk but

1365
00:54:36,119 --> 00:54:37,050
they're gonna be clever about this

1366
00:54:37,050 --> 00:54:40,410
they're only gonna let the OS evict sort

1367
00:54:40,410 --> 00:54:43,260
of sort of the portions of the table

1368
00:54:43,260 --> 00:54:46,950
heap and they'll have a hot portion that

1369
00:54:46,950 --> 00:54:48,960
they maintain but that never gets

1370
00:54:48,960 --> 00:54:49,920
written out to disk and then we're gonna

1371
00:54:49,920 --> 00:54:52,020
move data to the cold cold portion of

1372
00:54:52,020 --> 00:54:54,750
the heap and let the OS patient's out as

1373
00:54:54,750 --> 00:54:58,619
needed so because it's doing it's using

1374
00:54:58,619 --> 00:55:00,720
em map and the assumed virtual memory

1375
00:55:00,720 --> 00:55:03,060
the OS is swapping things out it's gonna

1376
00:55:03,060 --> 00:55:05,820
do synchronous retrieval because the the

1377
00:55:05,820 --> 00:55:07,230
Dadaism doesn't know actually what's in

1378
00:55:07,230 --> 00:55:10,080
memory versus not remembering it's a new

1379
00:55:10,080 --> 00:55:11,339
page level granularity because that's

1380
00:55:11,339 --> 00:55:13,230
how that works and they're always gonna

1381
00:55:13,230 --> 00:55:16,410
merge things because again that's good

1382
00:55:16,410 --> 00:55:18,780
well the rest of the system doesn't know

1383
00:55:18,780 --> 00:55:20,670
that tuple has been evicted

1384
00:55:20,670 --> 00:55:23,339
he still has a pointer to the the cold

1385
00:55:23,339 --> 00:55:25,619
portion of the heap and then when it

1386
00:55:25,619 --> 00:55:27,330
goes try to access to then it gets then

1387
00:55:27,330 --> 00:55:28,980
it gets there's a page fault and it's

1388
00:55:28,980 --> 00:55:31,710
swapped him right so this is the key

1389
00:55:31,710 --> 00:55:32,040
part

1390
00:55:32,040 --> 00:55:34,950
that's different then then what we seen

1391
00:55:34,950 --> 00:55:36,270
before so let's see how this works so

1392
00:55:36,270 --> 00:55:38,010
here's our a memory table here's our

1393
00:55:38,010 --> 00:55:39,840
cold storage again this is being meant

1394
00:55:39,840 --> 00:55:41,130
this is just swap space that's being

1395
00:55:41,130 --> 00:55:43,620
managed by the operating system so the

1396
00:55:43,620 --> 00:55:45,090
good news is they're gonna divide the

1397
00:55:45,090 --> 00:55:47,340
memory heap into hot tuples and code

1398
00:55:47,340 --> 00:55:49,950
tuples and for the hot portion of the

1399
00:55:49,950 --> 00:55:52,440
heap they're gonna use em lock to pin

1400
00:55:52,440 --> 00:55:55,230
these pages in memory and this is the M

1401
00:55:55,230 --> 00:55:58,380
lock prevents the OS from from writing

1402
00:55:58,380 --> 00:56:00,270
this data out of the disk but the cold

1403
00:56:00,270 --> 00:56:02,490
tuple portion that's not locked or not

1404
00:56:02,490 --> 00:56:05,280
pinned so now that the operators can can

1405
00:56:05,280 --> 00:56:07,260
and any anytime decide to evict this

1406
00:56:07,260 --> 00:56:11,220
data out so let's say now we have this

1407
00:56:11,220 --> 00:56:13,200
offline identification that that the

1408
00:56:13,200 --> 00:56:14,600
database system is going to run

1409
00:56:14,600 --> 00:56:16,950
identifies that this data this tuple

1410
00:56:16,950 --> 00:56:19,110
here is cold so what we're gonna do is

1411
00:56:19,110 --> 00:56:23,250
copy it now into the cold tuple is

1412
00:56:23,250 --> 00:56:24,570
essentially a delete followed by an

1413
00:56:24,570 --> 00:56:26,280
insert like an internal transaction does

1414
00:56:26,280 --> 00:56:27,570
that delete an followed by an insert and

1415
00:56:27,570 --> 00:56:29,190
this will automatically update the index

1416
00:56:29,190 --> 00:56:32,160
is now to point to the new location for

1417
00:56:32,160 --> 00:56:33,900
this the physical location of this tuple

1418
00:56:33,900 --> 00:56:37,410
and then we can put whatever new data we

1419
00:56:37,410 --> 00:56:39,840
want here at some later point at the OS

1420
00:56:39,840 --> 00:56:41,250
decides that it's running out of memory

1421
00:56:41,250 --> 00:56:43,530
it can decide that go ahead and swap any

1422
00:56:43,530 --> 00:56:45,630
of the pages that are in the cold tuple

1423
00:56:45,630 --> 00:56:48,800
region but we have no way to determining

1424
00:56:48,800 --> 00:56:53,100
is this data in memory or not other than

1425
00:56:53,100 --> 00:56:54,990
asking the operating system I would

1426
00:56:54,990 --> 00:56:57,360
which would be a Cisco which are usually

1427
00:56:57,360 --> 00:56:59,760
a bad idea so the tricky thing we have

1428
00:56:59,760 --> 00:57:02,460
to make sure of course and is we want to

1429
00:57:02,460 --> 00:57:04,050
make sure that all our tuples are page

1430
00:57:04,050 --> 00:57:06,060
aligned because we don't have the issue

1431
00:57:06,060 --> 00:57:09,060
where the tube will may may be split

1432
00:57:09,060 --> 00:57:12,390
across multiple multiple pages and now

1433
00:57:12,390 --> 00:57:14,010
things are gonna be tricky to make sure

1434
00:57:14,010 --> 00:57:16,800
that we write out these pages in the

1435
00:57:16,800 --> 00:57:19,290
correct order to make sure that we don't

1436
00:57:19,290 --> 00:57:20,970
see one without the other right we won't

1437
00:57:20,970 --> 00:57:22,440
sort of do this at Tom okay which is not

1438
00:57:22,440 --> 00:57:24,780
something operating system can can

1439
00:57:24,780 --> 00:57:26,910
provide for us because and MF cannot be

1440
00:57:26,910 --> 00:57:28,860
atomic across multiple pages which now

1441
00:57:28,860 --> 00:57:30,360
means that we have to maintain a log

1442
00:57:30,360 --> 00:57:32,730
somewhere to keep track of what's

1443
00:57:32,730 --> 00:57:35,610
happening over here so so I think this

1444
00:57:35,610 --> 00:57:37,290
is an interesting idea because it's it's

1445
00:57:37,290 --> 00:57:39,480
using a map and a clever way for data

1446
00:57:39,480 --> 00:57:44,400
that is read mostly but to handle the

1447
00:57:44,400 --> 00:57:45,480
case for this

1448
00:57:45,480 --> 00:57:47,820
when there's updates you need a log to

1449
00:57:47,820 --> 00:57:50,210
keep track of what's happening here

1450
00:57:50,210 --> 00:57:52,500
all right the last tuple based approach

1451
00:57:52,500 --> 00:57:54,660
I want to talk about comes from Apache

1452
00:57:54,660 --> 00:57:57,930
geode so Apache geode was originally

1453
00:57:57,930 --> 00:57:59,880
this data system Ameri data system

1454
00:57:59,880 --> 00:58:04,200
called called gem fire long story short

1455
00:58:04,200 --> 00:58:06,119
gem fire was developed with another

1456
00:58:06,119 --> 00:58:09,119
company called gemstone and then pivotal

1457
00:58:09,119 --> 00:58:11,580
bought them excuse me and then VMware

1458
00:58:11,580 --> 00:58:14,190
bought them but then VMware decided they

1459
00:58:14,190 --> 00:58:16,230
didn't want to own database companies so

1460
00:58:16,230 --> 00:58:19,170
then they divested it and combined it

1461
00:58:19,170 --> 00:58:20,850
with AMC's greenplum and that became

1462
00:58:20,850 --> 00:58:23,940
pivotal and then I guess pivotal decided

1463
00:58:23,940 --> 00:58:25,260
they didn't want to you know sort of

1464
00:58:25,260 --> 00:58:28,740
actively maintain a gem fire or whatever

1465
00:58:28,740 --> 00:58:32,220
so then they dumped it off to the Apache

1466
00:58:32,220 --> 00:58:35,070
foundation so it's Apache geo so what

1467
00:58:35,070 --> 00:58:36,000
are they doing it's online

1468
00:58:36,000 --> 00:58:38,040
identification like an H door Dumanis

1469
00:58:38,040 --> 00:58:39,420
traitor defined threshold just like

1470
00:58:39,420 --> 00:58:41,670
before as far as I know they're using

1471
00:58:41,670 --> 00:58:44,550
tombstones to identify that tuples have

1472
00:58:44,550 --> 00:58:45,840
been removed from memory and now they

1473
00:58:45,840 --> 00:58:48,480
actually reside on HDFS but this is all

1474
00:58:48,480 --> 00:58:52,350
assuming that you run on HDFS they'll do

1475
00:58:52,350 --> 00:58:53,640
synchronous retrieval because the block

1476
00:58:53,640 --> 00:58:55,740
queries and bringing things in they'll

1477
00:58:55,740 --> 00:58:57,810
do it at a two-base granularity but the

1478
00:58:57,810 --> 00:58:59,460
interesting thing is that they're only

1479
00:58:59,460 --> 00:59:01,410
going to merge tuples and bring them

1480
00:59:01,410 --> 00:59:04,920
back into memory and discard the disk

1481
00:59:04,920 --> 00:59:08,580
based blocks whenever you do updates and

1482
00:59:08,580 --> 00:59:10,430
the reason why they do this is because

1483
00:59:10,430 --> 00:59:15,840
HDFS is append-only so it would be to be

1484
00:59:15,840 --> 00:59:18,480
kind of a pain for them to do in place

1485
00:59:18,480 --> 00:59:21,240
updates to a block that already exists

1486
00:59:21,240 --> 00:59:24,000
you'd have to either write a log message

1487
00:59:24,000 --> 00:59:26,150
from say this old block has been evicted

1488
00:59:26,150 --> 00:59:27,960
sorry it has been pulled back into

1489
00:59:27,960 --> 00:59:29,700
memory and it's no longer considered

1490
00:59:29,700 --> 00:59:35,430
sort of valid or up-to-date I you so in

1491
00:59:35,430 --> 00:59:37,500
their world to avoid that big penalty

1492
00:59:37,500 --> 00:59:39,480
and then also running things out to

1493
00:59:39,480 --> 00:59:41,430
dictator on they'd his update a log

1494
00:59:41,430 --> 00:59:43,350
message to say yes this thing's been

1495
00:59:43,350 --> 00:59:44,970
removed but they only want to do it on

1496
00:59:44,970 --> 00:59:48,390
on an update so as far as I know I mean

1497
00:59:48,390 --> 00:59:49,770
I'm sure people are using this but I

1498
00:59:49,770 --> 00:59:51,960
have not come across anybody in the wild

1499
00:59:51,960 --> 00:59:55,020
that has been using these these overflow

1500
00:59:55,020 --> 00:59:58,130
tables and apache geode

1501
00:59:58,150 --> 01:00:03,489
okay so now as I start alluded to so far

1502
01:00:03,489 --> 01:00:05,359
everything we've talked about at least

1503
01:00:05,359 --> 01:00:09,160
in the a store packet on volt EB and

1504
01:00:09,160 --> 01:00:11,989
Apache geode examples these are all

1505
01:00:11,989 --> 01:00:15,380
doing evictions based on a per tubule

1506
01:00:15,380 --> 01:00:18,049
basis right it means we have to keep

1507
01:00:18,049 --> 01:00:19,519
track of individual tuples how they're

1508
01:00:19,519 --> 01:00:21,109
being read how they're being updated and

1509
01:00:21,109 --> 01:00:26,119
then we make decisions about how to how

1510
01:00:26,119 --> 01:00:27,529
to evict them you know we're making

1511
01:00:27,529 --> 01:00:30,079
those decisions on a per pupil basis to

1512
01:00:30,079 --> 01:00:31,819
combine them into a page or block and

1513
01:00:31,819 --> 01:00:34,579
write them out to disk but with the

1514
01:00:34,579 --> 01:00:41,180
exception of a project Siberia all of

1515
01:00:41,180 --> 01:00:44,059
these wouldn't actually reduce the size

1516
01:00:44,059 --> 01:00:46,999
of indexes and furthermore none of them

1517
01:00:46,999 --> 01:00:48,950
can actually spill the index or write

1518
01:00:48,950 --> 01:00:51,739
portions of the index out the disk so

1519
01:00:51,739 --> 01:00:53,390
only project Siberia would pull the end

1520
01:00:53,390 --> 01:00:55,249
keys out of the index of reduce the size

1521
01:00:55,249 --> 01:00:56,719
of the index and then populate with the

1522
01:00:56,719 --> 01:00:57,710
bloom filter which is gonna be much

1523
01:00:57,710 --> 01:01:00,499
smaller than the than the had the keys

1524
01:01:00,499 --> 01:01:01,670
would have been if they existed in the

1525
01:01:01,670 --> 01:01:05,509
index but other than that they can't

1526
01:01:05,509 --> 01:01:07,519
identify oh well this portion of the

1527
01:01:07,519 --> 01:01:10,039
index of my index is there they're not

1528
01:01:10,039 --> 01:01:12,289
being updated or access very often so

1529
01:01:12,289 --> 01:01:13,579
let me go ahead and show up those things

1530
01:01:13,579 --> 01:01:15,920
out to disk and as we saw when we talked

1531
01:01:15,920 --> 01:01:17,390
about compression I showed at the end

1532
01:01:17,390 --> 01:01:18,650
when we talked about how to do index

1533
01:01:18,650 --> 01:01:21,140
compression for some Ultima databases

1534
01:01:21,140 --> 01:01:23,109
the size of the indexes can be quite

1535
01:01:23,109 --> 01:01:24,979
significant relative to the overall

1536
01:01:24,979 --> 01:01:28,039
overall size of the database right and

1537
01:01:28,039 --> 01:01:29,930
some examples who solved the indexes

1538
01:01:29,930 --> 01:01:32,479
were up to 60% of the total memory size

1539
01:01:32,479 --> 01:01:35,029
of a database so all the things we're

1540
01:01:35,029 --> 01:01:37,009
doing here are not actually targeting

1541
01:01:37,009 --> 01:01:38,450
for those applications are for those

1542
01:01:38,450 --> 01:01:40,729
databases what the bulk of the memory is

1543
01:01:40,729 --> 01:01:43,160
actually being used for so what we

1544
01:01:43,160 --> 01:01:46,549
really want is a unified approach and

1545
01:01:46,549 --> 01:01:50,239
unified model for evicting cold data out

1546
01:01:50,239 --> 01:01:52,849
the disk from either table or from

1547
01:01:52,849 --> 01:01:55,160
either indexes right we shouldn't have

1548
01:01:55,160 --> 01:01:57,380
to have seven policies a separate you

1549
01:01:57,380 --> 01:01:59,569
know separate mechanisms or both of

1550
01:01:59,569 --> 01:02:02,180
these it should just be a single

1551
01:02:02,180 --> 01:02:05,019
approach used across both types of data

1552
01:02:05,019 --> 01:02:07,369
so this is how we ended up with the the

1553
01:02:07,369 --> 01:02:10,770
paper I had you guys read on on leans to

1554
01:02:10,770 --> 01:02:14,100
and so lien store is a was a prototype

1555
01:02:14,100 --> 01:02:15,660
in memory storage manager that was

1556
01:02:15,660 --> 01:02:19,140
developed by the Germans Munich that

1557
01:02:19,140 --> 01:02:21,030
worked on the hyper system but to the

1558
01:02:21,030 --> 01:02:22,110
best of my knowledge this wasn't

1559
01:02:22,110 --> 01:02:23,400
actually part of the hyper project this

1560
01:02:23,400 --> 01:02:25,440
was a this is a standalone separate

1561
01:02:25,440 --> 01:02:27,930
thing and so it's really cool about lean

1562
01:02:27,930 --> 01:02:28,830
strong can do is again it's designed

1563
01:02:28,830 --> 01:02:33,030
from the ground up to evict pages and it

1564
01:02:33,030 --> 01:02:34,440
doesn't know and doesn't care whether

1565
01:02:34,440 --> 01:02:38,490
the pages belong to two parts for data

1566
01:02:38,490 --> 01:02:43,620
tables or they belong to indexes so the

1567
01:02:43,620 --> 01:02:44,910
way to think about what they're doing is

1568
01:02:44,910 --> 01:02:48,080
that lean store is provides a

1569
01:02:48,080 --> 01:02:50,970
decentralized buffer pool manager that

1570
01:02:50,970 --> 01:02:55,080
is based on a page hierarchy meaning

1571
01:02:55,080 --> 01:02:58,200
instead of having instead of having just

1572
01:02:58,200 --> 01:02:59,790
sort of like a regular page table just

1573
01:02:59,790 --> 01:03:03,150
an unordered list of pages it's going to

1574
01:03:03,150 --> 01:03:05,400
be organized as a tree structure the

1575
01:03:05,400 --> 01:03:07,470
idea is going to be that you can't evict

1576
01:03:07,470 --> 01:03:09,870
a the main idea is that you can't evict

1577
01:03:09,870 --> 01:03:14,940
a child page so you can Victorino its

1578
01:03:14,940 --> 01:03:16,590
child pages have been evicted to disk

1579
01:03:16,590 --> 01:03:19,110
either and then also now because they

1580
01:03:19,110 --> 01:03:24,690
are page based the overhead of tracking

1581
01:03:24,690 --> 01:03:26,880
how pages are access is gonna be much

1582
01:03:26,880 --> 01:03:29,370
less than having to do it on a on a per

1583
01:03:29,370 --> 01:03:31,620
pupil basis and in the other systems we

1584
01:03:31,620 --> 01:03:34,740
talked about here so but now the way

1585
01:03:34,740 --> 01:03:36,030
that you can view tracking is

1586
01:03:36,030 --> 01:03:37,740
interesting because they're actually not

1587
01:03:37,740 --> 01:03:39,690
going to track at all most of the time

1588
01:03:39,690 --> 01:03:41,940
and so the way they're going to decide

1589
01:03:41,940 --> 01:03:43,740
what to evict is that there's gonna

1590
01:03:43,740 --> 01:03:47,820
randomly select some pages and then if a

1591
01:03:47,820 --> 01:03:49,560
page is selected then they start

1592
01:03:49,560 --> 01:03:50,940
tracking whether how it's being accessed

1593
01:03:50,940 --> 01:03:53,100
or whether it's being accessed and then

1594
01:03:53,100 --> 01:03:54,570
at some point when we need to free up

1595
01:03:54,570 --> 01:03:56,760
space we go look at that tracking

1596
01:03:56,760 --> 01:03:58,980
information from the rim the last round

1597
01:03:58,980 --> 01:04:01,890
of randomly select the pages and we find

1598
01:04:01,890 --> 01:04:02,880
the ones that haven't been touched

1599
01:04:02,880 --> 01:04:04,860
Jordan been accessed let me go ahead and

1600
01:04:04,860 --> 01:04:10,220
Vic those right so you only turn on the

1601
01:04:10,220 --> 01:04:12,210
tracking identification the page is

1602
01:04:12,210 --> 01:04:15,120
notification when you randomly select a

1603
01:04:15,120 --> 01:04:16,980
page to be evicted so we'll go through

1604
01:04:16,980 --> 01:04:19,370
all these these policies in more detail

1605
01:04:19,370 --> 01:04:23,240
but the key thing they're gonna do

1606
01:04:23,240 --> 01:04:25,290
instead of using the tombstone instead

1607
01:04:25,290 --> 01:04:27,210
of using the bloom filter the key thing

1608
01:04:27,210 --> 01:04:28,440
they're gonna do to figure out whether a

1609
01:04:28,440 --> 01:04:30,740
block or page exists in memory is

1610
01:04:30,740 --> 01:04:32,880
through a technique called pointers

1611
01:04:32,880 --> 01:04:36,290
whistling so I don't think we've covered

1612
01:04:36,290 --> 01:04:39,060
points whizzing that much in the intro

1613
01:04:39,060 --> 01:04:40,530
class but so I'm gonna cover that now in

1614
01:04:40,530 --> 01:04:42,740
the advanced class

1615
01:04:42,740 --> 01:04:45,230
the idea of pointers whistling is that

1616
01:04:45,230 --> 01:04:49,500
we are going to switch the or sort of

1617
01:04:49,500 --> 01:04:53,490
flip the contents of a pointer that one

1618
01:04:53,490 --> 01:04:56,610
object has to another object based on

1619
01:04:56,610 --> 01:04:58,350
whether we know that whether that that

1620
01:04:58,350 --> 01:05:01,620
object that is being pointed to is in

1621
01:05:01,620 --> 01:05:05,720
memory or not so again the idea is that

1622
01:05:05,720 --> 01:05:09,540
and so to figure this out we only need

1623
01:05:09,540 --> 01:05:12,420
to use one bit in the pointer so we'll

1624
01:05:12,420 --> 01:05:15,120
use the first bit to say one that it's

1625
01:05:15,120 --> 01:05:16,980
that it's on disk zero if it's in memory

1626
01:05:16,980 --> 01:05:20,460
and then the rest of the 63 bits and our

1627
01:05:20,460 --> 01:05:22,560
64-bit pointers will actually be used

1628
01:05:22,560 --> 01:05:24,900
for the address that's actually not

1629
01:05:24,900 --> 01:05:29,220
entirely true either because on x86 the

1630
01:05:29,220 --> 01:05:32,400
current architecture only uses 48 bits

1631
01:05:32,400 --> 01:05:36,240
of a 64-bit address to define the memory

1632
01:05:36,240 --> 01:05:38,610
location of something in memory all

1633
01:05:38,610 --> 01:05:39,840
right so they can only actually store up

1634
01:05:39,840 --> 01:05:42,990
to 35 terabytes of memory Intel claims

1635
01:05:42,990 --> 01:05:44,460
they're eventually gonna use the whole

1636
01:05:44,460 --> 01:05:48,710
64 bits I was at a talk that Intel gave

1637
01:05:48,710 --> 01:05:50,970
three or four years ago where they said

1638
01:05:50,970 --> 01:05:53,190
hey don't store anything extra in the

1639
01:05:53,190 --> 01:05:55,290
remaining 16 bits of your pointers

1640
01:05:55,290 --> 01:05:56,760
because eventually Intel's gonna use it

1641
01:05:56,760 --> 01:05:58,440
but like I said that that hasn't

1642
01:05:58,440 --> 01:06:00,660
happened yet and as far as I know it's

1643
01:06:00,660 --> 01:06:02,250
still just 48 bits so you can use the

1644
01:06:02,250 --> 01:06:04,980
upper 16 bits to do whatever you want so

1645
01:06:04,980 --> 01:06:07,500
they say we have here we have two blocks

1646
01:06:07,500 --> 01:06:11,660
and block b1 has a pointer to block b2

1647
01:06:11,660 --> 01:06:16,710
so when the pointer is unsold meaning

1648
01:06:16,710 --> 01:06:19,230
it's pointing to something on disk then

1649
01:06:19,230 --> 01:06:21,600
the bit will be set that where the first

1650
01:06:21,600 --> 01:06:23,190
bit will be set the one saying that it's

1651
01:06:23,190 --> 01:06:26,760
on a Swizzle and then the then we'll

1652
01:06:26,760 --> 01:06:28,590
just have our page ID and offset like 32

1653
01:06:28,590 --> 01:06:32,760
bit page ID 32-bit offset but now if we

1654
01:06:32,760 --> 01:06:36,090
go invisibly 64 bits in total and now if

1655
01:06:36,090 --> 01:06:38,230
we go actually

1656
01:06:38,230 --> 01:06:40,400
Swizzle that address because we brought

1657
01:06:40,400 --> 01:06:43,010
in the block into memory will flip that

1658
01:06:43,010 --> 01:06:45,230
first bit to zero saying that what

1659
01:06:45,230 --> 01:06:47,300
you're looking at is a real in memory

1660
01:06:47,300 --> 01:06:49,400
address not a page ID and offset and

1661
01:06:49,400 --> 01:06:51,410
then the remaining bits would be used to

1662
01:06:51,410 --> 01:06:53,930
actually point to the memory location so

1663
01:06:53,930 --> 01:06:55,550
what happened is when you when you pass

1664
01:06:55,550 --> 01:06:57,170
a memory address you know in your

1665
01:06:57,170 --> 01:06:58,760
program to say go access the thing for

1666
01:06:58,760 --> 01:07:01,130
me to do a load you know this thing's

1667
01:07:01,130 --> 01:07:02,840
not used because this it's not part of

1668
01:07:02,840 --> 01:07:05,420
the 48 bits that the x86 cares about so

1669
01:07:05,420 --> 01:07:07,130
it is just ignored so we don't think we

1670
01:07:07,130 --> 01:07:08,990
do anything special when we do a memory

1671
01:07:08,990 --> 01:07:10,490
you just look up using these Quizlet

1672
01:07:10,490 --> 01:07:13,070
addresses the the harbor just takes care

1673
01:07:13,070 --> 01:07:17,240
of it for us right so the reason why you

1674
01:07:17,240 --> 01:07:19,550
want to do this is because this is gonna

1675
01:07:19,550 --> 01:07:21,950
allow us to have a decentralized way to

1676
01:07:21,950 --> 01:07:23,680
track whether a page is in memory or not

1677
01:07:23,680 --> 01:07:26,690
right this is what a page table would do

1678
01:07:26,690 --> 01:07:29,690
in a disk based system I be this this

1679
01:07:29,690 --> 01:07:33,380
giant map that says page ID 1 2 3 is is

1680
01:07:33,380 --> 01:07:35,780
in disk or owned a score in memory and

1681
01:07:35,780 --> 01:07:37,310
if it's in memory here's the address to

1682
01:07:37,310 --> 01:07:40,970
it the or the mapping table in the B+

1683
01:07:40,970 --> 01:07:42,410
tree or the B Doubletree was essentially

1684
01:07:42,410 --> 01:07:45,020
the same thing so rather than having a

1685
01:07:45,020 --> 01:07:47,930
centralized data structure if we ensure

1686
01:07:47,930 --> 01:07:50,420
that in our in our database system that

1687
01:07:50,420 --> 01:07:53,240
only one block will have a pointer to

1688
01:07:53,240 --> 01:07:55,880
another block then we know that there's

1689
01:07:55,880 --> 01:07:58,010
only one location where there's this

1690
01:07:58,010 --> 01:08:00,020
pointer to this other block so we just

1691
01:08:00,020 --> 01:08:01,550
can do a compare and swap on this to be

1692
01:08:01,550 --> 01:08:03,050
able to flip it to be Swizzle run

1693
01:08:03,050 --> 01:08:04,790
Swizzle because we don't have to worry

1694
01:08:04,790 --> 01:08:06,410
about trying to do atomic updates across

1695
01:08:06,410 --> 01:08:09,140
multiple pointers and so if we think now

1696
01:08:09,140 --> 01:08:13,010
in like a B+ tree I'd know if you ignore

1697
01:08:13,010 --> 01:08:15,170
it 7 pointers you're essentially gonna

1698
01:08:15,170 --> 01:08:16,880
get this for free because that's you

1699
01:08:16,880 --> 01:08:21,560
know it's a it's an acyclic graph I said

1700
01:08:21,560 --> 01:08:22,819
in others do you think interesting about

1701
01:08:22,819 --> 01:08:24,350
lynnster was again the eviction policy

1702
01:08:24,350 --> 01:08:26,600
was it maintaining LRU wasn't doing a

1703
01:08:26,600 --> 01:08:28,430
clock it was just randomly picking some

1704
01:08:28,430 --> 01:08:32,660
some blocks for eviction and then

1705
01:08:32,660 --> 01:08:34,130
figuring out whether they are gonna

1706
01:08:34,130 --> 01:08:36,319
actually be accessed so what's great

1707
01:08:36,319 --> 01:08:37,580
about this is that you don't have to

1708
01:08:37,580 --> 01:08:40,310
maintain any metadata as we did in in

1709
01:08:40,310 --> 01:08:43,100
the other approaches for hot data

1710
01:08:43,100 --> 01:08:45,319
because if it's hot then you don't track

1711
01:08:45,319 --> 01:08:46,939
any information but if it's if it's

1712
01:08:46,939 --> 01:08:49,010
potentially cold then you go ahead and

1713
01:08:49,010 --> 01:08:50,800
track this information so

1714
01:08:50,800 --> 01:08:53,350
what will happen is that I fixed them

1715
01:08:53,350 --> 01:08:55,450
some blocks I select some blocks to be

1716
01:08:55,450 --> 01:08:58,180
evicted and then I'm gonna maintain this

1717
01:08:58,180 --> 01:09:00,670
global hash table that's going to keep

1718
01:09:00,670 --> 01:09:04,569
track of of the tracking info how this

1719
01:09:04,569 --> 01:09:07,450
blocker is being accessed and then if I

1720
01:09:07,450 --> 01:09:09,220
if I determine that when it's time to go

1721
01:09:09,220 --> 01:09:10,540
free some memory I go check that that

1722
01:09:10,540 --> 01:09:12,550
that hash table and I see here's some

1723
01:09:12,550 --> 01:09:13,930
some blocks that haven't been accessed

1724
01:09:13,930 --> 01:09:16,029
then I know it's heading it's safe for

1725
01:09:16,029 --> 01:09:18,550
me to go ahead and evict them so again

1726
01:09:18,550 --> 01:09:20,500
what will happen is I randomly pick some

1727
01:09:20,500 --> 01:09:22,420
blocks I'm gonna unsmooth all their

1728
01:09:22,420 --> 01:09:24,580
pointers meaning it'll revert back to

1729
01:09:24,580 --> 01:09:28,899
the page ID and offset but the I'm not

1730
01:09:28,899 --> 01:09:32,710
actually going to evict the block still

1731
01:09:32,710 --> 01:09:34,510
gonna sit in memory and then what will

1732
01:09:34,510 --> 01:09:37,240
happen is if now a thread comes along or

1733
01:09:37,240 --> 01:09:39,899
query runs and if it comes across a

1734
01:09:39,899 --> 01:09:42,760
unsold pointer with the page ID and

1735
01:09:42,760 --> 01:09:45,490
offset I go check that global hash table

1736
01:09:45,490 --> 01:09:48,819
for the data and my cooling stage and if

1737
01:09:48,819 --> 01:09:50,290
it's in there then I know it's actually

1738
01:09:50,290 --> 01:09:51,819
still in memory and I go find out where

1739
01:09:51,819 --> 01:09:54,910
it is if it's not in there then I know

1740
01:09:54,910 --> 01:09:56,350
it actually is not remembering at all

1741
01:09:56,350 --> 01:09:59,890
and I go out to disk and get it and will

1742
01:09:59,890 --> 01:10:01,390
show an example what this looks like in

1743
01:10:01,390 --> 01:10:06,040
a second so the last thing that's

1744
01:10:06,040 --> 01:10:07,990
important about lean stores that is

1745
01:10:07,990 --> 01:10:10,300
again the block hierarchy again the

1746
01:10:10,300 --> 01:10:13,570
there's no centralized buffer pool table

1747
01:10:13,570 --> 01:10:16,350
so we need a way to and ensure that

1748
01:10:16,350 --> 01:10:19,450
there isn't more than one pointer to a

1749
01:10:19,450 --> 01:10:23,110
to a block in the database so that I can

1750
01:10:23,110 --> 01:10:25,330
just unlock a chanel that I or

1751
01:10:25,330 --> 01:10:26,680
switzerland's was the one location I

1752
01:10:26,680 --> 01:10:28,390
know that that's been covered everywhere

1753
01:10:28,390 --> 01:10:30,610
so they can organize this as a tree

1754
01:10:30,610 --> 01:10:32,920
hierarchy and so every parent can have a

1755
01:10:32,920 --> 01:10:35,380
pointer to a child and that parent is

1756
01:10:35,380 --> 01:10:36,610
the only one with that pointer to that

1757
01:10:36,610 --> 01:10:40,300
given block now so in indexes they're

1758
01:10:40,300 --> 01:10:41,920
already sort of managed like this if you

1759
01:10:41,920 --> 01:10:43,990
can or something pointers again for

1760
01:10:43,990 --> 01:10:46,630
table heaps you have to organize that as

1761
01:10:46,630 --> 01:10:48,280
a hierarchy and then do breadth-first

1762
01:10:48,280 --> 01:10:52,120
search to do scans and think in the lean

1763
01:10:52,120 --> 01:10:53,410
store case there was always index

1764
01:10:53,410 --> 01:10:54,940
organized tables and in the case of I'm

1765
01:10:54,940 --> 01:10:56,470
brother they're gonna do the same thing

1766
01:10:56,470 --> 01:11:00,520
so why do you want to do this well again

1767
01:11:00,520 --> 01:11:04,000
because I know that

1768
01:11:04,000 --> 01:11:06,640
if I want to Victor parent I can't evict

1769
01:11:06,640 --> 01:11:09,700
it to disk unless it children have been

1770
01:11:09,700 --> 01:11:12,790
evicted and this prevents me from having

1771
01:11:12,790 --> 01:11:15,520
the situation where I evict a parent but

1772
01:11:15,520 --> 01:11:16,660
it's children aren't still in memory

1773
01:11:16,660 --> 01:11:18,640
that parent gets written out the disc

1774
01:11:18,640 --> 01:11:21,520
and then now when it gets fetched back

1775
01:11:21,520 --> 01:11:24,700
in its gonna have you know when it was

1776
01:11:24,700 --> 01:11:27,760
written out it would have in memory

1777
01:11:27,760 --> 01:11:29,710
pointers to the children where they

1778
01:11:29,710 --> 01:11:31,240
existed before in memory but now I'm

1779
01:11:31,240 --> 01:11:32,740
gonna come back those memory dresses now

1780
01:11:32,740 --> 01:11:34,990
B might be pointing to frames my buffer

1781
01:11:34,990 --> 01:11:38,320
pool that now have different pages than

1782
01:11:38,320 --> 01:11:40,270
that will over in there before and so

1783
01:11:40,270 --> 01:11:41,830
now I'm pointing to garbage they're not

1784
01:11:41,830 --> 01:11:42,790
pointing they're things I should be

1785
01:11:42,790 --> 01:11:44,590
looking or should be pointing at

1786
01:11:44,590 --> 01:11:46,090
so by ensuring that the children

1787
01:11:46,090 --> 01:11:48,070
Victor's out first the children get

1788
01:11:48,070 --> 01:11:50,440
evicted I update the parent now to have

1789
01:11:50,440 --> 01:11:52,660
to unscrew so pointers to his children

1790
01:11:52,660 --> 01:11:54,820
so that when it gets written out to disk

1791
01:11:54,820 --> 01:11:59,110
and I bring it back in I can then use

1792
01:11:59,110 --> 01:12:00,520
those unsocial pointers to find the

1793
01:12:00,520 --> 01:12:02,080
pages that have the tools I'm looking

1794
01:12:02,080 --> 01:12:04,000
for so just in the same way I can't

1795
01:12:04,000 --> 01:12:04,570
fetch

1796
01:12:04,570 --> 01:12:07,090
I can't evict a parent before it's

1797
01:12:07,090 --> 01:12:08,020
children have been evicted

1798
01:12:08,020 --> 01:12:10,360
I can't fetch children until its parent

1799
01:12:10,360 --> 01:12:12,880
has been fetch which you would you

1800
01:12:12,880 --> 01:12:14,530
guarantee because everything is in this

1801
01:12:14,530 --> 01:12:18,100
tree hierarchy all right so let's look

1802
01:12:18,100 --> 01:12:20,320
an example so the way we're gonna

1803
01:12:20,320 --> 01:12:22,030
organize this again say we have a really

1804
01:12:22,030 --> 01:12:23,770
simple database that only has four pages

1805
01:12:23,770 --> 01:12:27,010
and so we're gonna break the the

1806
01:12:27,010 --> 01:12:29,470
hierarchy up into three stages so we

1807
01:12:29,470 --> 01:12:30,760
have the hot stage where everything is

1808
01:12:30,760 --> 01:12:33,820
in memory and you have a Swizzle

1809
01:12:33,820 --> 01:12:35,710
pointers then you have the cooling stage

1810
01:12:35,710 --> 01:12:37,540
where it still is this in memory but

1811
01:12:37,540 --> 01:12:39,220
you're gonna have unsocial pointers and

1812
01:12:39,220 --> 01:12:41,260
then you have the cold stage where it's

1813
01:12:41,260 --> 01:12:44,710
out on disk with unsocial pointers so

1814
01:12:44,710 --> 01:12:46,960
let's say that I run my eviction

1815
01:12:46,960 --> 01:12:48,700
algorithm that randomly picked some

1816
01:12:48,700 --> 01:12:50,500
blocks to be written out to disk and

1817
01:12:50,500 --> 01:12:53,740
let's say I pick b1 so I'm gonna move it

1818
01:12:53,740 --> 01:12:56,500
down now into the cooling stage and then

1819
01:12:56,500 --> 01:12:58,690
I'm going to add it into my hash table

1820
01:12:58,690 --> 01:13:00,940
over here that that's tracking again the

1821
01:13:00,940 --> 01:13:03,250
access patterns or how often this block

1822
01:13:03,250 --> 01:13:04,360
egg is being accessed

1823
01:13:04,360 --> 01:13:05,890
so this hash table is basically saying

1824
01:13:05,890 --> 01:13:07,930
for b1 here's where to go find it in

1825
01:13:07,930 --> 01:13:09,970
this in this eviction queue and then the

1826
01:13:09,970 --> 01:13:12,550
eviction queue would have the the actual

1827
01:13:12,550 --> 01:13:15,310
memory pointer to two-thirds block so

1828
01:13:15,310 --> 01:13:16,449
now what

1829
01:13:16,449 --> 01:13:20,079
happen is that if if and then of course

1830
01:13:20,079 --> 01:13:22,479
then I have to make sure I update the or

1831
01:13:22,479 --> 01:13:24,489
on so as the pointer from my parent

1832
01:13:24,489 --> 01:13:27,699
block again now if anybody comes along

1833
01:13:27,699 --> 01:13:29,800
and tries to access b1 they would have

1834
01:13:29,800 --> 01:13:31,809
to go through b0 that's in memory then

1835
01:13:31,809 --> 01:13:33,489
they would get this on swizzle pointer

1836
01:13:33,489 --> 01:13:35,590
but then I would always do a lookup in

1837
01:13:35,590 --> 01:13:38,139
my hash table and I would find ng for b1

1838
01:13:38,139 --> 01:13:39,820
find the location in the eviction queue

1839
01:13:39,820 --> 01:13:41,440
and that would give me the real memory

1840
01:13:41,440 --> 01:13:43,780
address so now you're paying a bit of

1841
01:13:43,780 --> 01:13:46,119
penalty now just as you would having an

1842
01:13:46,119 --> 01:13:47,800
indirection layer and a page table in a

1843
01:13:47,800 --> 01:13:50,349
disc or in a database system but it's

1844
01:13:50,349 --> 01:13:53,349
actually not that bad because again if

1845
01:13:53,349 --> 01:13:55,599
this was hot data then the first time

1846
01:13:55,599 --> 01:13:57,070
this would happen I would then bump it

1847
01:13:57,070 --> 01:13:59,050
back up to the hot stage remove it from

1848
01:13:59,050 --> 01:14:01,599
my eviction queue and then dispose of

1849
01:14:01,599 --> 01:14:03,969
the pointer and so only one query would

1850
01:14:03,969 --> 01:14:06,070
ever pay this penalty but if it actually

1851
01:14:06,070 --> 01:14:08,139
really was cold then nobody would

1852
01:14:08,139 --> 01:14:10,269
actually come across this I have to go

1853
01:14:10,269 --> 01:14:11,409
through this hash table and eventually

1854
01:14:11,409 --> 01:14:13,929
get around the disk and you know no harm

1855
01:14:13,929 --> 01:14:16,510
no foul so this is actually really

1856
01:14:16,510 --> 01:14:17,769
interesting right and the idea is also

1857
01:14:17,769 --> 01:14:19,749
to that this eviction cue is keeping

1858
01:14:19,749 --> 01:14:22,389
track of this is essentially is

1859
01:14:22,389 --> 01:14:24,519
naturally ordering the you know which

1860
01:14:24,519 --> 01:14:26,979
was what were the latest the oldest or

1861
01:14:26,979 --> 01:14:29,889
newest paid blocks attitude the queue so

1862
01:14:29,889 --> 01:14:31,420
now if I need to go fetch something

1863
01:14:31,420 --> 01:14:34,239
that's on the cold stage on disk and

1864
01:14:34,239 --> 01:14:36,309
bring it into memory I just go evict

1865
01:14:36,309 --> 01:14:37,630
whatever it is into the front of the

1866
01:14:37,630 --> 01:14:40,809
queue here shove it at the disk and then

1867
01:14:40,809 --> 01:14:42,670
use that space for the tuple or the

1868
01:14:42,670 --> 01:14:45,249
block that I'm that I need so there's

1869
01:14:45,249 --> 01:14:48,550
only one one latch you need in this

1870
01:14:48,550 --> 01:14:50,679
parka texture and that's when you

1871
01:14:50,679 --> 01:14:51,969
actually write things from the cooling

1872
01:14:51,969 --> 01:14:54,190
stage to the cold stage because they

1873
01:14:54,190 --> 01:14:55,630
just need to protect to make sure that

1874
01:14:55,630 --> 01:14:58,059
if you try to evict a page or victim

1875
01:14:58,059 --> 01:14:59,739
block the same time you're trying to

1876
01:14:59,739 --> 01:15:02,889
fetch that block back in you don't want

1877
01:15:02,889 --> 01:15:03,969
to have duplicates in it and get gif

1878
01:15:03,969 --> 01:15:05,949
fouled up so there's only one latch your

1879
01:15:05,949 --> 01:15:08,650
third use to protect for that concurrent

1880
01:15:08,650 --> 01:15:11,979
operation but that's pretty rare so like

1881
01:15:11,979 --> 01:15:14,289
I said this was a prototype system that

1882
01:15:14,289 --> 01:15:16,630
was developed by the Germans I think

1883
01:15:16,630 --> 01:15:18,880
they're continuing to work on it it's

1884
01:15:18,880 --> 01:15:22,719
separate from hyper and it's separate

1885
01:15:22,719 --> 01:15:24,670
from the from the Alma project which

1886
01:15:24,670 --> 01:15:26,389
we'll talk about next

1887
01:15:26,389 --> 01:15:31,460
right so Umbra is a a very new system

1888
01:15:31,460 --> 01:15:32,929
that the Germans have been building

1889
01:15:32,929 --> 01:15:36,350
think of this is like hyper 2.0 and they

1890
01:15:36,350 --> 01:15:38,360
are actually supporting the larger the

1891
01:15:38,360 --> 01:15:42,770
memory database that's a technique that

1892
01:15:42,770 --> 01:15:45,650
that lean store propose of having this

1893
01:15:45,650 --> 01:15:48,770
hierarchy with a randomized the

1894
01:15:48,770 --> 01:15:51,409
randomized eviction album but one of the

1895
01:15:51,409 --> 01:15:52,280
interesting things that there knew

1896
01:15:52,280 --> 01:15:55,219
differently is that they're going to

1897
01:15:55,219 --> 01:15:58,699
support variable sized pages so in the

1898
01:15:58,699 --> 01:16:01,880
case of a lean store and actually of all

1899
01:16:01,880 --> 01:16:04,630
that the architectures we shown before

1900
01:16:04,630 --> 01:16:07,040
the pages that were being organized in

1901
01:16:07,040 --> 01:16:08,330
memory the pages are getting written on

1902
01:16:08,330 --> 01:16:12,469
to disk we're always the same size in

1903
01:16:12,469 --> 01:16:14,210
Umbra what they're gonna do is they're

1904
01:16:14,210 --> 01:16:15,380
gonna they're gonna allow you to

1905
01:16:15,380 --> 01:16:17,750
allocate memory in the same way you

1906
01:16:17,750 --> 01:16:19,760
would in a slab allocator like and like

1907
01:16:19,760 --> 01:16:22,520
je malloc where you can allocate blocks

1908
01:16:22,520 --> 01:16:24,409
that are to be of different sizes

1909
01:16:24,409 --> 01:16:26,810
they're always exponential from the

1910
01:16:26,810 --> 01:16:29,449
previous size and then now you can then

1911
01:16:29,449 --> 01:16:32,500
address the entire block of a given size

1912
01:16:32,500 --> 01:16:35,210
rather than you know individual tuples

1913
01:16:35,210 --> 01:16:36,860
or individual offsets within within a

1914
01:16:36,860 --> 01:16:40,850
block and so the the advantage you're

1915
01:16:40,850 --> 01:16:42,739
gonna get for this is that for databases

1916
01:16:42,739 --> 01:16:45,050
that have large text fields or strings

1917
01:16:45,050 --> 01:16:47,570
or varchars or other internal data

1918
01:16:47,570 --> 01:16:49,100
structures like compression dictionaries

1919
01:16:49,100 --> 01:16:51,920
where you often can't store them in a

1920
01:16:51,920 --> 01:16:56,179
single page you can now avoid overhead

1921
01:16:56,179 --> 01:16:57,650
about having to copy those pages in

1922
01:16:57,650 --> 01:16:59,389
memory and reassemble them whenever you

1923
01:16:59,389 --> 01:17:04,190
go fetch things from disk so the number

1924
01:17:04,190 --> 01:17:05,510
people the Germans make actually a

1925
01:17:05,510 --> 01:17:08,900
really interesting design argument for

1926
01:17:08,900 --> 01:17:11,500
this system and they say that it's

1927
01:17:11,500 --> 01:17:14,030
better we want to support larger than

1928
01:17:14,030 --> 01:17:16,280
memory databases it's better just to

1929
01:17:16,280 --> 01:17:20,179
have a complex buffer pool manager like

1930
01:17:20,179 --> 01:17:21,020
in the case of a supporting a

1931
01:17:21,020 --> 01:17:22,850
variable-length one it's better to make

1932
01:17:22,850 --> 01:17:25,760
that be efficient have that be sort of a

1933
01:17:25,760 --> 01:17:27,770
more complex or difficult to engineer

1934
01:17:27,770 --> 01:17:30,530
component of the system because you only

1935
01:17:30,530 --> 01:17:33,230
have to implement that part once and now

1936
01:17:33,230 --> 01:17:35,060
the rest of the system that's going to

1937
01:17:35,060 --> 01:17:36,409
end up being easier to develop because

1938
01:17:36,409 --> 01:17:39,020
now you have this this flexibility in

1939
01:17:39,020 --> 01:17:39,860
this capability

1940
01:17:39,860 --> 01:17:43,460
the variable size buffle manager and

1941
01:17:43,460 --> 01:17:44,330
it's sort of what we said in the

1942
01:17:44,330 --> 01:17:49,070
beginning about how if you you don't

1943
01:17:49,070 --> 01:17:51,020
want to bring back the Buffalo manager

1944
01:17:51,020 --> 01:17:54,020
and then have to re-architect the entire

1945
01:17:54,020 --> 01:17:57,590
system to account for the fact that you

1946
01:17:57,590 --> 01:17:59,180
could be accessing data that's not on

1947
01:17:59,180 --> 01:18:03,590
disk in this same way here you can not

1948
01:18:03,590 --> 01:18:07,670
have to worry about your packing data in

1949
01:18:07,670 --> 01:18:10,040
all ways exactly into a page that you're

1950
01:18:10,040 --> 01:18:12,170
a fixed page size you can allocate the

1951
01:18:12,170 --> 01:18:13,340
right amount of memory that's needed for

1952
01:18:13,340 --> 01:18:16,370
whatever it is that you're doing and the

1953
01:18:16,370 --> 01:18:18,230
the algorithms of the data structures

1954
01:18:18,230 --> 01:18:20,030
are building on top of that that the

1955
01:18:20,030 --> 01:18:23,000
Buffalo manager don't have to worry

1956
01:18:23,000 --> 01:18:24,680
about the complexity of how that's all

1957
01:18:24,680 --> 01:18:26,780
managed so I think that's actually

1958
01:18:26,780 --> 01:18:29,150
really interesting and - that's my model

1959
01:18:29,150 --> 01:18:30,290
and knowledge this is the only data

1960
01:18:30,290 --> 01:18:31,670
system that's actually doing this which

1961
01:18:31,670 --> 01:18:34,730
is pretty exciting so just like in lean

1962
01:18:34,730 --> 01:18:36,620
store they're gonna store things as

1963
01:18:36,620 --> 01:18:39,350
hierarchy but all the tables are gonna

1964
01:18:39,350 --> 01:18:41,000
be all the relations are sorted index

1965
01:18:41,000 --> 01:18:42,800
organized table so basically all the

1966
01:18:42,800 --> 01:18:44,930
it's sort of like intimacy goes in a DB

1967
01:18:44,930 --> 01:18:46,970
where all the tuples are stored in the

1968
01:18:46,970 --> 01:18:49,610
leaf pages of a B+ tree so you get that

1969
01:18:49,610 --> 01:18:53,300
natural hierarchy that we needed in lean

1970
01:18:53,300 --> 01:18:56,000
store where every child only has there's

1971
01:18:56,000 --> 01:18:57,410
only one parent that has a pointer to

1972
01:18:57,410 --> 01:18:58,810
any one child

1973
01:18:58,810 --> 01:19:01,700
so this is just a high level overview of

1974
01:19:01,700 --> 01:19:03,260
what's going on in the various slides

1975
01:19:03,260 --> 01:19:05,450
buffer pool and again the way it's gonna

1976
01:19:05,450 --> 01:19:08,000
work is that it's like a slab allocator

1977
01:19:08,000 --> 01:19:10,520
will they'll have a bunch of frames in

1978
01:19:10,520 --> 01:19:11,750
the buffer pool for different size

1979
01:19:11,750 --> 01:19:14,120
classes and you'll have more frames for

1980
01:19:14,120 --> 01:19:16,100
the smaller size classes and fewer

1981
01:19:16,100 --> 01:19:17,840
frames for the larger ones because most

1982
01:19:17,840 --> 01:19:19,400
of the most of the chunks of memory

1983
01:19:19,400 --> 01:19:21,230
you're gonna allocate are gonna be quite

1984
01:19:21,230 --> 01:19:24,350
small so the the large size the small

1985
01:19:24,350 --> 01:19:26,120
side would be 64 kilobytes and that'll

1986
01:19:26,120 --> 01:19:30,380
go up to 512 kilobytes so the in the

1987
01:19:30,380 --> 01:19:31,790
buffer frames you would have just sort

1988
01:19:31,790 --> 01:19:34,250
of inactive and active pools everything

1989
01:19:34,250 --> 01:19:35,990
is gonna actually be managed using em

1990
01:19:35,990 --> 01:19:38,270
map use anatomize m map and that gives

1991
01:19:38,270 --> 01:19:40,280
you a virtual memory and so that means

1992
01:19:40,280 --> 01:19:42,350
that I can allocate reserve all this

1993
01:19:42,350 --> 01:19:44,870
space here but it's actually not backed

1994
01:19:44,870 --> 01:19:47,150
by physical memory until I go ahead and

1995
01:19:47,150 --> 01:19:49,820
access it all right so I can allocate

1996
01:19:49,820 --> 01:19:51,050
all the space I would need my buffer

1997
01:19:51,050 --> 01:19:52,820
pool frame for any for the total size

1998
01:19:52,820 --> 01:19:54,230
the database

1999
01:19:54,230 --> 01:19:56,960
but I only you know the OS actually only

2000
01:19:56,960 --> 01:19:59,290
gonna back it when it's actually needed

2001
01:19:59,290 --> 01:20:01,429
so they're also going to do pointers

2002
01:20:01,429 --> 01:20:03,530
whistling the same way you would in in

2003
01:20:03,530 --> 01:20:05,750
lean store and are in other systems but

2004
01:20:05,750 --> 01:20:07,760
what's interesting about it is in a lean

2005
01:20:07,760 --> 01:20:10,730
store case it was just if it's whistled

2006
01:20:10,730 --> 01:20:12,290
it's a memory dress and it's untwisted

2007
01:20:12,290 --> 01:20:15,440
here's the page ID in the offset in this

2008
01:20:15,440 --> 01:20:17,179
case here you don't have all sets

2009
01:20:17,179 --> 01:20:19,550
anymore in pages because you're having a

2010
01:20:19,550 --> 01:20:21,800
fine-grained pointer to the page that

2011
01:20:21,800 --> 01:20:25,070
has exactly the memory that you need you

2012
01:20:25,070 --> 01:20:26,690
know because it's the right size so if I

2013
01:20:26,690 --> 01:20:28,909
only need 64 kilobytes then I have a

2014
01:20:28,909 --> 01:20:30,349
pointer to those 64 kilobytes and

2015
01:20:30,349 --> 01:20:32,840
there's left to whoever is getting that

2016
01:20:32,840 --> 01:20:35,300
64 kilobytes to be able to interpret its

2017
01:20:35,300 --> 01:20:37,550
contents to get the data that is looking

2018
01:20:37,550 --> 01:20:39,290
for but I don't need to record that

2019
01:20:39,290 --> 01:20:42,710
offset in the unsocial pointer but I do

2020
01:20:42,710 --> 01:20:45,469
need to record what size classes in so

2021
01:20:45,469 --> 01:20:47,389
that when I go fetch that block I know

2022
01:20:47,389 --> 01:20:50,119
which category of the data I need to go

2023
01:20:50,119 --> 01:20:52,040
get it from and how big it actually is

2024
01:20:52,040 --> 01:20:53,869
going to be stored out some disk because

2025
01:20:53,869 --> 01:20:56,239
again the OS with virtual memory it

2026
01:20:56,239 --> 01:20:59,570
doesn't know that it's not going to

2027
01:20:59,570 --> 01:21:00,560
allow you to do with these memory

2028
01:21:00,560 --> 01:21:02,690
allocations or page allocations from

2029
01:21:02,690 --> 01:21:04,550
different sizes it's always going to be

2030
01:21:04,550 --> 01:21:07,280
whatever you know four kilobytes as the

2031
01:21:07,280 --> 01:21:09,079
default or you're using huge pages

2032
01:21:09,079 --> 01:21:11,060
whatever the two gigabyte ones it just

2033
01:21:11,060 --> 01:21:12,139
knows that you have some chunk of memory

2034
01:21:12,139 --> 01:21:14,570
so it's up for the the database system

2035
01:21:14,570 --> 01:21:16,429
to be able interpret you know how much

2036
01:21:16,429 --> 01:21:18,949
data do I actually need to read for a

2037
01:21:18,949 --> 01:21:21,949
given page size right and that's based

2038
01:21:21,949 --> 01:21:24,980
on a size class down here right so I

2039
01:21:24,980 --> 01:21:27,020
think this is actually they said I mean

2040
01:21:27,020 --> 01:21:28,699
this is really interesting this you know

2041
01:21:28,699 --> 01:21:31,159
this was the this paper came out only a

2042
01:21:31,159 --> 01:21:33,440
few months ago no other system as far as

2043
01:21:33,440 --> 01:21:35,360
I know actually implements this

2044
01:21:35,360 --> 01:21:38,590
so it's remains to be seen whether the

2045
01:21:38,590 --> 01:21:40,579
you know compared to something like lean

2046
01:21:40,579 --> 01:21:43,790
store that this is the the right

2047
01:21:43,790 --> 01:21:45,650
approach but I definitely it's very

2048
01:21:45,650 --> 01:21:46,760
promising and I think it's better than

2049
01:21:46,760 --> 01:21:49,010
the stuff that we were doing you know

2050
01:21:49,010 --> 01:21:51,250
years ago with with each store or the

2051
01:21:51,250 --> 01:21:54,739
project Siberia stuff and so actually

2052
01:21:54,739 --> 01:21:55,520
last thing to point out too is like

2053
01:21:55,520 --> 01:21:57,290
again these are still 64-bit pointers

2054
01:21:57,290 --> 01:22:00,560
the block ID is now 57 bits and then

2055
01:22:00,560 --> 01:22:05,260
this this size class is is just six bits

2056
01:22:05,260 --> 01:22:07,760
all right so the last approach I want to

2057
01:22:07,760 --> 01:22:10,070
talk about is mem sequel as I'm wearing

2058
01:22:10,070 --> 01:22:14,020
the the old school minima sequel sure so

2059
01:22:14,020 --> 01:22:16,159
traditionally what mem sequel you would

2060
01:22:16,159 --> 01:22:19,520
do is when they brought on the column

2061
01:22:19,520 --> 01:22:22,849
store even now today you can declare

2062
01:22:22,849 --> 01:22:25,909
that you want a table restore as a row

2063
01:22:25,909 --> 01:22:27,889
store and that resides in memory or you

2064
01:22:27,889 --> 01:22:29,869
can have a table exists or you declare a

2065
01:22:29,869 --> 01:22:31,849
table as a column store and that can

2066
01:22:31,849 --> 01:22:34,099
actually be backed by disk but there was

2067
01:22:34,099 --> 01:22:37,940
no way to declare a single logical table

2068
01:22:37,940 --> 01:22:42,889
that could have a but both types but

2069
01:22:42,889 --> 01:22:46,099
then in when they first came out with a

2070
01:22:46,099 --> 01:22:50,389
column store approach up up to 2017 they

2071
01:22:50,389 --> 01:22:52,550
were using em map to manage the pages

2072
01:22:52,550 --> 01:22:54,170
out to disk but they were so blinded is

2073
01:22:54,170 --> 01:22:57,380
using a map and you know it's not being

2074
01:22:57,380 --> 01:22:59,090
an anonymized memory memory virtual

2075
01:22:59,090 --> 01:23:00,679
memory allocation that Humber was doing

2076
01:23:00,679 --> 01:23:03,560
so they quickly found out this was

2077
01:23:03,560 --> 01:23:05,239
actually a bad idea and there's a blog

2078
01:23:05,239 --> 01:23:06,530
article that shows that they were sort

2079
01:23:06,530 --> 01:23:08,989
of abusing a map and getting bad

2080
01:23:08,989 --> 01:23:10,639
performance so then they built their own

2081
01:23:10,639 --> 01:23:15,080
buffer manager where they would take the

2082
01:23:15,080 --> 01:23:17,590
columns and split them up until one one

2083
01:23:17,590 --> 01:23:20,090
segment that had 1 million tuples and

2084
01:23:20,090 --> 01:23:21,650
knew how to fetch in this segments as

2085
01:23:21,650 --> 01:23:26,290
need him but they still had a separate

2086
01:23:26,290 --> 01:23:30,170
sort of separate row store for for

2087
01:23:30,170 --> 01:23:32,750
transactions or OTP workloads in a set

2088
01:23:32,750 --> 01:23:34,790
of is a separate column store for the

2089
01:23:34,790 --> 01:23:37,900
for analytics so what they then now

2090
01:23:37,900 --> 01:23:41,840
announced in 2019 is this that they call

2091
01:23:41,840 --> 01:23:43,940
a new single store architecture where

2092
01:23:43,940 --> 01:23:46,730
you it's like the hyper stuff or the

2093
01:23:46,730 --> 01:23:47,869
stuff we're doing in our own database

2094
01:23:47,869 --> 01:23:50,270
system where you can do transactions on

2095
01:23:50,270 --> 01:23:53,710
top of the on top of a column store

2096
01:23:53,710 --> 01:23:56,659
there's a this blog article makes a

2097
01:23:56,659 --> 01:23:59,480
bunch of claims about you know make a

2098
01:23:59,480 --> 01:24:01,219
sort of seem like that they're the first

2099
01:24:01,219 --> 01:24:04,070
to do this which is not really true and

2100
01:24:04,070 --> 01:24:06,110
then they have some optimizations to

2101
01:24:06,110 --> 01:24:08,719
deal with the large overhead of storing

2102
01:24:08,719 --> 01:24:11,210
nulls that we saw before in the row

2103
01:24:11,210 --> 01:24:13,389
stores when we talked about data types

2104
01:24:13,389 --> 01:24:17,060
but you know this is their sort of

2105
01:24:17,060 --> 01:24:18,560
getting away from having separate

2106
01:24:18,560 --> 01:24:20,960
different in memory roaster and sitter

2107
01:24:20,960 --> 01:24:22,610
separate calm store and now having a

2108
01:24:22,610 --> 01:24:25,640
single single columns for approach that

2109
01:24:25,640 --> 01:24:27,740
can you know have pages written out to

2110
01:24:27,740 --> 01:24:29,690
disk it's unclear how they're deciding

2111
01:24:29,690 --> 01:24:31,220
what pages get written out to disk I

2112
01:24:31,220 --> 01:24:34,010
suspect it's a basic LRU or clock

2113
01:24:34,010 --> 01:24:37,520
approach so now going back to our same

2114
01:24:37,520 --> 01:24:39,410
taxonomy to talk about four they don't

2115
01:24:39,410 --> 01:24:41,600
need any eviction metadata for this

2116
01:24:41,600 --> 01:24:42,830
could just keep me track what pages are

2117
01:24:42,830 --> 01:24:44,600
in and not meant memory or not memory

2118
01:24:44,600 --> 01:24:46,070
they're doing the singham's retrieval

2119
01:24:46,070 --> 01:24:47,320
and then he always has merged things

2120
01:24:47,320 --> 01:24:53,360
okay alright so that was a lot the as I

2121
01:24:53,360 --> 01:24:56,240
said the the what we talked about today

2122
01:24:56,240 --> 01:25:02,300
was just dealing with bringing back in

2123
01:25:02,300 --> 01:25:05,210
the the disk that's me block on in this

2124
01:25:05,210 --> 01:25:06,920
gonna be slow and trying to be clever

2125
01:25:06,920 --> 01:25:09,470
about it to avoid slowing down or in the

2126
01:25:09,470 --> 01:25:11,540
main architecture and as I said multiple

2127
01:25:11,540 --> 01:25:12,080
times

2128
01:25:12,080 --> 01:25:14,300
I think the block base or page brace

2129
01:25:14,300 --> 01:25:16,580
approach used in lean store Umbra is the

2130
01:25:16,580 --> 01:25:18,290
right way to go and the fine-grain to

2131
01:25:18,290 --> 01:25:20,600
pull stuff that we did in in those other

2132
01:25:20,600 --> 01:25:24,410
systems is is it's not the right

2133
01:25:24,410 --> 01:25:25,000
approach

2134
01:25:25,000 --> 01:25:28,010
now the other engine thing about this is

2135
01:25:28,010 --> 01:25:29,830
that everything I talk about here today

2136
01:25:29,830 --> 01:25:33,590
could eventually just all be made null

2137
01:25:33,590 --> 01:25:37,400
and void and and obsolete when we

2138
01:25:37,400 --> 01:25:41,890
actually finally achieve cheap and fast

2139
01:25:41,890 --> 01:25:45,140
byte addressable non-volatile memory so

2140
01:25:45,140 --> 01:25:46,820
that means that memory that goes in the

2141
01:25:46,820 --> 01:25:49,010
dim slot and then you can read and write

2142
01:25:49,010 --> 01:25:50,570
to it as if it's DRAM

2143
01:25:50,570 --> 01:25:53,390
but when you pull the power it persists

2144
01:25:53,390 --> 01:25:57,320
things like like like like an SSD so

2145
01:25:57,320 --> 01:26:00,380
that harbor actually exists we'll cover

2146
01:26:00,380 --> 01:26:02,450
that next week with like talking about

2147
01:26:02,450 --> 01:26:04,880
databases running a new hardware for now

2148
01:26:04,880 --> 01:26:08,000
SSDs or HBO's hard drives are all they

2149
01:26:08,000 --> 01:26:10,310
have for non-volatile storage but in the

2150
01:26:10,310 --> 01:26:13,940
future real persistent memory or real

2151
01:26:13,940 --> 01:26:17,000
non-volatile memory will make everything

2152
01:26:17,000 --> 01:26:18,020
we talked about today I think

2153
01:26:18,020 --> 01:26:21,350
unnecessary all right so next class

2154
01:26:21,350 --> 01:26:24,320
we're going to talk about sort of it

2155
01:26:24,320 --> 01:26:26,510
this is an additional topic that doesn't

2156
01:26:26,510 --> 01:26:28,010
fit exactly in with every we talked

2157
01:26:28,010 --> 01:26:29,160
about but it just

2158
01:26:29,160 --> 01:26:31,920
it's it's another way to get big

2159
01:26:31,920 --> 01:26:33,510
performance improvements in a database

2160
01:26:33,510 --> 01:26:35,010
system if you know what you're doing so

2161
01:26:35,010 --> 01:26:36,450
let's talk about a way to improve

2162
01:26:36,450 --> 01:26:40,260
performance and we'll see two approaches

2163
01:26:40,260 --> 01:26:47,520
from okay all right guys wash your hands

2164
01:26:47,520 --> 01:26:53,390
and what is this

2165
01:26:53,550 --> 01:27:20,790
[Music]

