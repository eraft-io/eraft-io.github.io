1
00:00:01,300 --> 00:00:05,129
[Music]

2
00:00:05,200 --> 00:00:05,930
[Applause]

3
00:00:05,930 --> 00:00:08,630
[Music]

4
00:00:08,630 --> 00:00:10,020
[Applause]

5
00:00:10,020 --> 00:00:13,219
[Music]

6
00:00:13,219 --> 00:00:17,190
this will be the the the last lecture

7
00:00:17,190 --> 00:00:19,410
we're gonna do on on multi version

8
00:00:19,410 --> 00:00:21,420
control and again today we're gonna

9
00:00:21,420 --> 00:00:23,760
focus on garbage questions because

10
00:00:23,760 --> 00:00:27,090
that's super important for an NBC

11
00:00:27,090 --> 00:00:31,349
database system so we've sort of out

12
00:00:31,349 --> 00:00:32,610
recovered this in the last two lectures

13
00:00:32,610 --> 00:00:34,200
but let's go into the Mojo detail what's

14
00:00:34,200 --> 00:00:37,170
what's actually what's going on so the

15
00:00:37,170 --> 00:00:38,969
reason why obviously we need to do

16
00:00:38,969 --> 00:00:41,129
garbage collection in an MVC system is

17
00:00:41,129 --> 00:00:43,620
because we have to identify physical

18
00:00:43,620 --> 00:00:46,530
versions that are reclaim Abul and then

19
00:00:46,530 --> 00:00:48,329
remove them right because otherwise

20
00:00:48,329 --> 00:00:49,920
we'll just run out of space I think I

21
00:00:49,920 --> 00:00:51,870
said in the beginning that with time

22
00:00:51,870 --> 00:00:53,969
travel queries Postgres when I first got

23
00:00:53,969 --> 00:00:56,370
my first words created in 1980s they

24
00:00:56,370 --> 00:00:57,600
didn't do any garbage collection at all

25
00:00:57,600 --> 00:00:59,609
because they said we wanted to support

26
00:00:59,609 --> 00:01:01,649
time travel queries I mean you can go do

27
00:01:01,649 --> 00:01:04,080
queries on status to the database as

28
00:01:04,080 --> 00:01:06,689
they were back in time and of course in

29
00:01:06,689 --> 00:01:08,340
the 1990s when people actually really

30
00:01:08,340 --> 00:01:09,990
started using Postgres also had academia

31
00:01:09,990 --> 00:01:11,970
the first thing they did was add back

32
00:01:11,970 --> 00:01:13,439
garbage collection because you run out

33
00:01:13,439 --> 00:01:15,210
of space pretty quickly if you have a

34
00:01:15,210 --> 00:01:18,720
lot of churn in your database so so it's

35
00:01:18,720 --> 00:01:19,970
sort of obvious why we need to do this

36
00:01:19,970 --> 00:01:22,290
so our definition of a plain Bowl is

37
00:01:22,290 --> 00:01:24,180
going to be a physical version where

38
00:01:24,180 --> 00:01:26,280
there's no active transaction that's

39
00:01:26,280 --> 00:01:30,000
running in the system that can see that

40
00:01:30,000 --> 00:01:31,530
particular physical version meaning it's

41
00:01:31,530 --> 00:01:33,689
not visible to that transaction under

42
00:01:33,689 --> 00:01:37,049
snapshot isolation or obviously if the

43
00:01:37,049 --> 00:01:38,280
version was created by de Borda

44
00:01:38,280 --> 00:01:40,229
transaction we don't want that sitting

45
00:01:40,229 --> 00:01:41,490
around forever and we want to go ahead

46
00:01:41,490 --> 00:01:44,520
and clean that up right so the great

47
00:01:44,520 --> 00:01:45,930
thing about multi version control

48
00:01:45,930 --> 00:01:47,640
because we're recording those timestamps

49
00:01:47,640 --> 00:01:49,770
in order to provide snaps to isolation

50
00:01:49,770 --> 00:01:52,320
that we can just use all those same

51
00:01:52,320 --> 00:01:55,619
timestamps to determine when when tuples

52
00:01:55,619 --> 00:01:57,240
are actually visible or not alright and

53
00:01:57,240 --> 00:01:58,740
the idea here is that the the time

54
00:01:58,740 --> 00:02:00,450
stands for using to assign transactions

55
00:02:00,450 --> 00:02:02,670
to understand they're the global

56
00:02:02,670 --> 00:02:05,130
ordering is the same timestamp so user

57
00:02:05,130 --> 00:02:07,469
to turn you know in in Martin versions

58
00:02:07,469 --> 00:02:10,139
or the lifetime of of physical versions

59
00:02:10,139 --> 00:02:12,150
and we just say all right if nobody can

60
00:02:12,150 --> 00:02:13,490
see this then we go want to go ahead

61
00:02:13,490 --> 00:02:16,940
and remove it right so one thing we need

62
00:02:16,940 --> 00:02:18,920
to talk about though is and what was in

63
00:02:18,920 --> 00:02:20,480
the paper you guys read from the hyper

64
00:02:20,480 --> 00:02:25,160
team is this notion that like the

65
00:02:25,160 --> 00:02:27,230
complications that are on arise if you

66
00:02:27,230 --> 00:02:28,940
now start having transactions or queries

67
00:02:28,940 --> 00:02:31,910
that run for a long time again member I

68
00:02:31,910 --> 00:02:33,440
said in OLTP environment the

69
00:02:33,440 --> 00:02:35,060
transactions are almost always

70
00:02:35,060 --> 00:02:37,760
short-lived right update and E's account

71
00:02:37,760 --> 00:02:39,650
on Amazon commit that transaction and

72
00:02:39,650 --> 00:02:42,410
you're done right and so in that world

73
00:02:42,410 --> 00:02:46,760
updating those versions the transactions

74
00:02:46,760 --> 00:02:47,720
that need to made it read those old

75
00:02:47,720 --> 00:02:50,450
versions they're they're not you know

76
00:02:50,450 --> 00:02:51,500
they're not sitting around for a long

77
00:02:51,500 --> 00:02:53,600
time so it's not like there's a

78
00:02:53,600 --> 00:02:55,490
long-running transaction that needs to

79
00:02:55,490 --> 00:02:57,710
see the version of the database as it

80
00:02:57,710 --> 00:02:59,960
exists at an hour ago in a parallel to

81
00:02:59,960 --> 00:03:01,700
the environment we don't have that issue

82
00:03:01,700 --> 00:03:04,130
but now it's when we start throwing in

83
00:03:04,130 --> 00:03:07,040
the analytic workloads and litical

84
00:03:07,040 --> 00:03:09,080
queries then then we have to care about

85
00:03:09,080 --> 00:03:11,420
this right he's gonna understand an

86
00:03:11,420 --> 00:03:14,330
isolation I need to see only the

87
00:03:14,330 --> 00:03:18,040
versions of the the tuples that existed

88
00:03:18,040 --> 00:03:20,450
by they were created by transactions

89
00:03:20,450 --> 00:03:22,780
that committed before I started so if I

90
00:03:22,780 --> 00:03:25,130
microwaves gonna take an hour then I

91
00:03:25,130 --> 00:03:26,930
need to see the snapshot of the database

92
00:03:26,930 --> 00:03:30,920
as it existed for that entire hour now I

93
00:03:30,920 --> 00:03:33,020
can run under lower isolation levels

94
00:03:33,020 --> 00:03:34,940
like read uncommitted the entry whatever

95
00:03:34,940 --> 00:03:36,650
I want who cares but if you want to

96
00:03:36,650 --> 00:03:38,690
provide snÃ¥sa isolation then you need to

97
00:03:38,690 --> 00:03:42,470
do this all right so again the issues

98
00:03:42,470 --> 00:03:44,060
gonna be what we talked about in the

99
00:03:44,060 --> 00:03:46,040
first lecture about what to call

100
00:03:46,040 --> 00:03:47,630
traditional grabbers question that was

101
00:03:47,630 --> 00:03:48,980
like all right I look at my timestamp

102
00:03:48,980 --> 00:03:51,950
and of all my active transactions and if

103
00:03:51,950 --> 00:03:55,150
anybody if any version is less than the

104
00:03:55,150 --> 00:03:57,440
smallest active transaction time stamp

105
00:03:57,440 --> 00:03:59,270
then I know I know and go ahead and

106
00:03:59,270 --> 00:04:00,800
prune it but now if I had these queries

107
00:04:00,800 --> 00:04:02,450
that are sitting around for an hour then

108
00:04:02,450 --> 00:04:04,850
that's gonna be you know that's gonna be

109
00:04:04,850 --> 00:04:12,940
a longer amount of time yes yeah

110
00:04:14,140 --> 00:04:17,019
Yeah right covered each tap in the in

111
00:04:17,019 --> 00:04:19,360
the intro class

112
00:04:19,360 --> 00:04:23,140
so the lhp and overlap and in the in the

113
00:04:23,140 --> 00:04:25,390
2000s people basically figured out oh

114
00:04:25,390 --> 00:04:27,460
you actually want to have specialized

115
00:04:27,460 --> 00:04:28,990
systems for each of these and then you

116
00:04:28,990 --> 00:04:30,220
can run your OTP queries in this

117
00:04:30,220 --> 00:04:32,140
database and your OLAP queries in this

118
00:04:32,140 --> 00:04:33,580
database and that way they have

119
00:04:33,580 --> 00:04:35,410
different design choices as different

120
00:04:35,410 --> 00:04:37,690
goals and you can build a system that's

121
00:04:37,690 --> 00:04:39,700
optimized for both of them this age tap

122
00:04:39,700 --> 00:04:41,920
stuff is a bit newer concept hybrid

123
00:04:41,920 --> 00:04:44,020
transactional analytical processing and

124
00:04:44,020 --> 00:04:46,420
the idea here is that I want to be able

125
00:04:46,420 --> 00:04:48,310
to run analytical queries as soon as

126
00:04:48,310 --> 00:04:50,380
data arrives so instead of waiting for

127
00:04:50,380 --> 00:04:52,510
me to use some kind of ETL process to

128
00:04:52,510 --> 00:04:54,280
offload it from the the OTP side into

129
00:04:54,280 --> 00:04:55,990
another database system I'm gonna run it

130
00:04:55,990 --> 00:04:58,420
on as immediately as it shows up so that

131
00:04:58,420 --> 00:04:59,890
that's a more common thing now right

132
00:04:59,890 --> 00:05:01,480
because the longer it takes for me to go

133
00:05:01,480 --> 00:05:03,400
figure out like if you're playing a game

134
00:05:03,400 --> 00:05:05,860
and I want to you know trick you to buy

135
00:05:05,860 --> 00:05:08,320
crap if I have to run it and let it to

136
00:05:08,320 --> 00:05:09,760
my back-end machine and it takes a long

137
00:05:09,760 --> 00:05:11,290
time for that data gets transferred over

138
00:05:11,290 --> 00:05:19,360
then I may lose out on the sale yeah so

139
00:05:19,360 --> 00:05:22,510
his he has a perfectly good statement is

140
00:05:22,510 --> 00:05:25,090
like alright well for these analytical

141
00:05:25,090 --> 00:05:27,310
queries do we really need to run under

142
00:05:27,310 --> 00:05:28,870
snapshot isolation coming just run at a

143
00:05:28,870 --> 00:05:31,210
lower isolation level and is that good

144
00:05:31,210 --> 00:05:31,480
enough

145
00:05:31,480 --> 00:05:34,510
in many cases yes and so this is sort of

146
00:05:34,510 --> 00:05:40,290
a this is sort of a have a service um a

147
00:05:40,290 --> 00:05:43,030
perception in academia that is actually

148
00:05:43,030 --> 00:05:44,500
slightly different all right actually

149
00:05:44,500 --> 00:05:45,669
it's quite different than what actually

150
00:05:45,669 --> 00:05:47,470
happens in the real world so in the

151
00:05:47,470 --> 00:05:48,730
academic world will you say oh of course

152
00:05:48,730 --> 00:05:50,200
you want to run a serializable isolation

153
00:05:50,200 --> 00:05:51,850
or snapshot isolation but then in the

154
00:05:51,850 --> 00:05:53,140
real world most people run it like read

155
00:05:53,140 --> 00:05:54,460
committed cuz that's the default you get

156
00:05:54,460 --> 00:05:57,070
in Postgres in my sequel alright so yes

157
00:05:57,070 --> 00:06:00,550
there are there are some cases where yes

158
00:06:00,550 --> 00:06:01,900
you do want synapse isolation you want

159
00:06:01,900 --> 00:06:03,550
sterilizable queries for this analytical

160
00:06:03,550 --> 00:06:05,310
stuff most the time you don't need this

161
00:06:05,310 --> 00:06:08,740
but even then like it does occur enough

162
00:06:08,740 --> 00:06:10,660
that we had to solve the problem all

163
00:06:10,660 --> 00:06:14,919
right yeah we did a survey of DBAs two

164
00:06:14,919 --> 00:06:17,590
three years ago and we basically said

165
00:06:17,590 --> 00:06:19,780
look like 50 there 60 percent of all the

166
00:06:19,780 --> 00:06:22,360
papers in Sigma novio DB they assume

167
00:06:22,360 --> 00:06:23,560
transactions run at serializable

168
00:06:23,560 --> 00:06:25,450
isolation but then you ask real DBA is

169
00:06:25,450 --> 00:06:27,680
in like like 10 percent

170
00:06:27,680 --> 00:06:29,330
transactions run at sterilized isolation

171
00:06:29,330 --> 00:06:30,620
everybody runs re committed cuz that's

172
00:06:30,620 --> 00:06:32,990
the default you get in in in real

173
00:06:32,990 --> 00:06:34,100
database systems and those who don't

174
00:06:34,100 --> 00:06:35,570
bother to change it unless you know what

175
00:06:35,570 --> 00:06:39,320
you're doing so I say that sample

176
00:06:39,320 --> 00:06:42,530
actuation is bearable you would actually

177
00:06:42,530 --> 00:06:45,470
want to have for analytics you probably

178
00:06:45,470 --> 00:06:47,000
almost never want to have like

179
00:06:47,000 --> 00:06:49,130
serializable analytics it doesn't make

180
00:06:49,130 --> 00:06:49,550
sense

181
00:06:49,550 --> 00:06:53,660
exceptions good enough okay actually it

182
00:06:53,660 --> 00:06:54,560
doesn't make sense if it snaps at

183
00:06:54,560 --> 00:06:57,020
insulation then I see everything as

184
00:06:57,020 --> 00:06:58,639
committed that's I can't have any

185
00:06:58,639 --> 00:06:59,900
anomalies because I'm not doing rights

186
00:06:59,900 --> 00:07:00,349
as well

187
00:07:00,349 --> 00:07:02,419
so yes I'm simulation is like the

188
00:07:02,419 --> 00:07:04,990
highest we'd ever want to go yeah okay

189
00:07:04,990 --> 00:07:08,210
all right so I sort of already covered

190
00:07:08,210 --> 00:07:10,280
this but what are the problems of having

191
00:07:10,280 --> 00:07:11,960
these old versions again assuming we

192
00:07:11,960 --> 00:07:13,820
want to achieve samsa isolation for our

193
00:07:13,820 --> 00:07:17,030
analytic queries or obviously we are

194
00:07:17,030 --> 00:07:19,400
increasing our memory usage because now

195
00:07:19,400 --> 00:07:22,610
we're creating new versions and our

196
00:07:22,610 --> 00:07:24,440
version chains are getting longer but we

197
00:07:24,440 --> 00:07:26,270
can't reclaim that memory so that

198
00:07:26,270 --> 00:07:29,360
they're the amount of storage space that

199
00:07:29,360 --> 00:07:32,120
our David says is is consuming or using

200
00:07:32,120 --> 00:07:33,110
just keeps growing and growing

201
00:07:33,110 --> 00:07:36,830
infinitely right but now that also means

202
00:07:36,830 --> 00:07:39,530
that if we have to know if we can't

203
00:07:39,530 --> 00:07:41,659
reuse the memory that from older

204
00:07:41,659 --> 00:07:43,190
versions because we can't recycle the

205
00:07:43,190 --> 00:07:45,229
the space now we're going to go back to

206
00:07:45,229 --> 00:07:46,909
reallocator and potentially go back to

207
00:07:46,909 --> 00:07:49,280
the operating system through malloc and

208
00:07:49,280 --> 00:07:52,820
ask for more memory and that call is not

209
00:07:52,820 --> 00:07:55,310
cheap and is not free like going to

210
00:07:55,310 --> 00:07:58,180
malloc and asking for my memory is

211
00:07:58,180 --> 00:07:59,990
definitely become a bottleneck if you

212
00:07:59,990 --> 00:08:01,340
have a lot of threads doing this at the

213
00:08:01,340 --> 00:08:03,710
same time our verge of changing to be it

214
00:08:03,710 --> 00:08:05,870
longer again that means for transactions

215
00:08:05,870 --> 00:08:08,150
that have to traverse the Virgin chain

216
00:08:08,150 --> 00:08:09,380
to find the right version that they want

217
00:08:09,380 --> 00:08:11,180
that I'm never going to take me longer

218
00:08:11,180 --> 00:08:13,130
now if you're doing news to oldest and

219
00:08:13,130 --> 00:08:14,539
most your OTP transactions are just

220
00:08:14,539 --> 00:08:16,820
touching the newest version right this

221
00:08:16,820 --> 00:08:19,190
is not that big of a deal for the

222
00:08:19,190 --> 00:08:20,509
analytic queries yes they have to

223
00:08:20,509 --> 00:08:21,770
traverse the whole chain but maybe find

224
00:08:21,770 --> 00:08:24,470
the right version the only system that I

225
00:08:24,470 --> 00:08:27,560
know that does oldest to newest is is

226
00:08:27,560 --> 00:08:28,880
Hecate on so they would have this

227
00:08:28,880 --> 00:08:32,990
problem but if you if you notice a

228
00:08:32,990 --> 00:08:34,940
notice then it's a long traversal to put

229
00:08:34,940 --> 00:08:36,559
the new one at the m that's only a

230
00:08:36,559 --> 00:08:38,240
problem Hecate on but for analytical

231
00:08:38,240 --> 00:08:39,679
queries it takes longer for them to find

232
00:08:39,679 --> 00:08:41,520
the right versions they want

233
00:08:41,520 --> 00:08:43,860
another big issue which we haven't

234
00:08:43,860 --> 00:08:45,360
really talked about so much is this

235
00:08:45,360 --> 00:08:47,880
notion of having consistent performance

236
00:08:47,880 --> 00:08:50,399
and stability in in your database system

237
00:08:50,399 --> 00:08:54,330
in terms of performance if now you have

238
00:08:54,330 --> 00:08:56,339
like these long-running queries for an

239
00:08:56,339 --> 00:08:58,709
hour and then the hour the queries done

240
00:08:58,709 --> 00:09:00,540
and now I need to go back and clean up

241
00:09:00,540 --> 00:09:01,830
all the old versions that are finally

242
00:09:01,830 --> 00:09:03,930
finally reclaim Abul we're now gonna

243
00:09:03,930 --> 00:09:06,300
have this huge spike in the CPU usage

244
00:09:06,300 --> 00:09:07,320
for your garbage collection threads

245
00:09:07,320 --> 00:09:08,430
because they're gonna say oh look at all

246
00:09:08,430 --> 00:09:10,080
these versions I can go clean up let me

247
00:09:10,080 --> 00:09:13,230
rip through that and and you know start

248
00:09:13,230 --> 00:09:15,089
throwing them away and now queries that

249
00:09:15,089 --> 00:09:16,500
are running the same time they might not

250
00:09:16,500 --> 00:09:17,910
have a dip in performance because now

251
00:09:17,910 --> 00:09:19,830
there's contention on the CPU for

252
00:09:19,830 --> 00:09:21,750
resources because because you're doing

253
00:09:21,750 --> 00:09:25,410
garbage collection all right so again

254
00:09:25,410 --> 00:09:27,600
like a lot of times in in the real world

255
00:09:27,600 --> 00:09:30,380
a lot of companies or organizations

256
00:09:30,380 --> 00:09:32,990
they're they're very conservative with

257
00:09:32,990 --> 00:09:35,610
taking one news new technology for

258
00:09:35,610 --> 00:09:37,800
databases because they want to have

259
00:09:37,800 --> 00:09:39,420
consistent performance it doesn't help

260
00:09:39,420 --> 00:09:40,800
you to say like alright here's the

261
00:09:40,800 --> 00:09:41,910
latest greatest version of a new

262
00:09:41,910 --> 00:09:44,040
database system and it's gonna make 95%

263
00:09:44,040 --> 00:09:45,720
of my queries go go much faster but then

264
00:09:45,720 --> 00:09:47,420
the 5% I'm gonna be like randomly slow

265
00:09:47,420 --> 00:09:50,070
people aren't going to want that they'll

266
00:09:50,070 --> 00:09:50,970
stick with the old stuff that they

267
00:09:50,970 --> 00:09:53,610
actually know all right and the last one

268
00:09:53,610 --> 00:09:55,730
is gonna be an issue when we start doing

269
00:09:55,730 --> 00:09:58,380
we talk more about cache locality and

270
00:09:58,380 --> 00:10:01,920
other things so I'm compression so if I

271
00:10:01,920 --> 00:10:03,600
now have all these old versions

272
00:10:03,600 --> 00:10:06,390
scattered around in my my tablespace

273
00:10:06,390 --> 00:10:10,410
then when I start doing if I'm doing

274
00:10:10,410 --> 00:10:12,870
this the garbage section all at once now

275
00:10:12,870 --> 00:10:15,029
I have a bunch of holes in my in my

276
00:10:15,029 --> 00:10:16,500
table that I can refill with other other

277
00:10:16,500 --> 00:10:19,380
objects but when I want to do

278
00:10:19,380 --> 00:10:20,850
compression I want to basically get a

279
00:10:20,850 --> 00:10:22,890
bunch of old data and compress it down

280
00:10:22,890 --> 00:10:26,850
because it's it's read-only if my all

281
00:10:26,850 --> 00:10:28,470
the virgins are sort of scattered around

282
00:10:28,470 --> 00:10:30,480
because I can't keep reusing the same

283
00:10:30,480 --> 00:10:32,430
space over and over again then I lose

284
00:10:32,430 --> 00:10:34,020
this locality and I have to do a bunch

285
00:10:34,020 --> 00:10:36,810
of extra work to combine together

286
00:10:36,810 --> 00:10:38,279
objects that are related to each other

287
00:10:38,279 --> 00:10:41,250
within time and that way they can be

288
00:10:41,250 --> 00:10:43,620
compressed this won't make sense right

289
00:10:43,620 --> 00:10:45,480
now I'll cover this event at the end of

290
00:10:45,480 --> 00:10:50,010
election okay all right so for today I

291
00:10:50,010 --> 00:10:51,240
want to spend a little time at beginning

292
00:10:51,240 --> 00:10:52,290
to talk about we talked about the issue

293
00:10:52,290 --> 00:10:53,490
about delete so this is something we

294
00:10:53,490 --> 00:10:55,500
didn't cover

295
00:10:55,500 --> 00:10:57,000
in the last few lectures I should have

296
00:10:57,000 --> 00:10:59,040
but it's it's in here now and then we'll

297
00:10:59,040 --> 00:11:01,110
focus on the different design decisions

298
00:11:01,110 --> 00:11:02,160
you have for garbage collection which

299
00:11:02,160 --> 00:11:03,540
was in the hyper paper you guys read and

300
00:11:03,540 --> 00:11:06,120
then what's a rock block compaction

301
00:11:06,120 --> 00:11:07,530
which is the thing I was saying about

302
00:11:07,530 --> 00:11:10,800
combining together unused space across

303
00:11:10,800 --> 00:11:13,170
the the data tables in order to you know

304
00:11:13,170 --> 00:11:15,300
compactor will combine them together and

305
00:11:15,300 --> 00:11:16,920
forget memory and then I'm missing the

306
00:11:16,920 --> 00:11:18,060
the bullet point here but I'll finish

307
00:11:18,060 --> 00:11:20,790
off and doing a tutorial on perf which

308
00:11:20,790 --> 00:11:22,860
is what you need to do for project one

309
00:11:22,860 --> 00:11:28,800
okay alright so we've talked about it

310
00:11:28,800 --> 00:11:29,880
doing inserts or talked about doing

311
00:11:29,880 --> 00:11:31,260
updates we didn't really talk about how

312
00:11:31,260 --> 00:11:34,170
to do deletes so in such your easy right

313
00:11:34,170 --> 00:11:36,450
it's it's the first physical version of

314
00:11:36,450 --> 00:11:39,330
a tuple I find a free slot in my in my

315
00:11:39,330 --> 00:11:40,950
night data table and I just insert it

316
00:11:40,950 --> 00:11:43,110
right no big deal and then updates we

317
00:11:43,110 --> 00:11:43,920
already know that a handle right

318
00:11:43,920 --> 00:11:45,270
depending on what version scheme are

319
00:11:45,270 --> 00:11:47,340
using right whether we do Delta records

320
00:11:47,340 --> 00:11:49,230
would be pen only whether do you know

321
00:11:49,230 --> 00:11:50,730
what direction the version chain is we

322
00:11:50,730 --> 00:11:52,680
know how to handle that deletes a little

323
00:11:52,680 --> 00:11:57,930
bit tricky now because you need to

324
00:11:57,930 --> 00:12:00,630
basically record now that this this fist

325
00:12:00,630 --> 00:12:02,340
of this logical tuple has been deleted

326
00:12:02,340 --> 00:12:04,920
and that even though someone may come

327
00:12:04,920 --> 00:12:07,230
along and insert that same tuple all

328
00:12:07,230 --> 00:12:09,210
over again that's technically now in

329
00:12:09,210 --> 00:12:10,740
another snapshot and you don't want to

330
00:12:10,740 --> 00:12:13,770
reuse the Virgin chain and so basically

331
00:12:13,770 --> 00:12:15,330
you need a way to record to say all

332
00:12:15,330 --> 00:12:19,920
right well this thing is now deleted no

333
00:12:19,920 --> 00:12:21,510
other version ship should come behind it

334
00:12:21,510 --> 00:12:24,960
right so again we can't have any right

335
00:12:24,960 --> 00:12:26,070
right complex this is only the first

336
00:12:26,070 --> 00:12:28,140
writer wins so if my transaction deletes

337
00:12:28,140 --> 00:12:29,700
this tuple before I could before I

338
00:12:29,700 --> 00:12:31,860
commit you try to update it I'll beat

339
00:12:31,860 --> 00:12:33,540
you so we need to have the same sort of

340
00:12:33,540 --> 00:12:36,510
correct correctness semantics as before

341
00:12:36,510 --> 00:12:39,900
right so the question is now how are we

342
00:12:39,900 --> 00:12:42,330
actually going to record that our tuple

343
00:12:42,330 --> 00:12:44,130
was logically deleted at some point in

344
00:12:44,130 --> 00:12:46,410
time because we can't delete the version

345
00:12:46,410 --> 00:12:48,510
chain because that's you know then the

346
00:12:48,510 --> 00:12:53,070
existence is gone right so there's two

347
00:12:53,070 --> 00:12:55,620
basic approaches to do this the one is

348
00:12:55,620 --> 00:12:57,360
you maintain a separate flag somewhere

349
00:12:57,360 --> 00:12:59,730
that says that this logical tuple has

350
00:12:59,730 --> 00:13:02,730
been deleted and so you can either just

351
00:13:02,730 --> 00:13:04,650
store this now in like the tuple header

352
00:13:04,650 --> 00:13:06,510
that we talked about before we record

353
00:13:06,510 --> 00:13:08,790
all this timestamps or you can just have

354
00:13:08,790 --> 00:13:09,000
a

355
00:13:09,000 --> 00:13:11,700
per column that's just a bitmap field

356
00:13:11,700 --> 00:13:14,210
that says the the tuple within our block

357
00:13:14,210 --> 00:13:17,820
at this all set has been deleted so that

358
00:13:17,820 --> 00:13:19,740
means now when I start scanning or my

359
00:13:19,740 --> 00:13:21,120
transaction starts reading the database

360
00:13:21,120 --> 00:13:23,580
I always have to check this thing first

361
00:13:23,580 --> 00:13:25,680
to see whether it's actually you know

362
00:13:25,680 --> 00:13:26,940
whether I'm going down a path that

363
00:13:26,940 --> 00:13:28,670
that's it's not believe it or not

364
00:13:28,670 --> 00:13:32,610
alright so in our system we store it as

365
00:13:32,610 --> 00:13:33,840
a separate column that's a separate

366
00:13:33,840 --> 00:13:36,750
bitmap field all right the other

367
00:13:36,750 --> 00:13:38,610
approach is to do a tombstone tuple and

368
00:13:38,610 --> 00:13:42,690
the idea here is that we store a new

369
00:13:42,690 --> 00:13:44,490
physical version a special physical

370
00:13:44,490 --> 00:13:46,410
version at the end of the version chain

371
00:13:46,410 --> 00:13:48,420
or at beginning the end depending what

372
00:13:48,420 --> 00:13:51,450
direction we're doing and then the

373
00:13:51,450 --> 00:13:54,210
somehow to indicate in that in this

374
00:13:54,210 --> 00:13:56,160
special version that it's representing

375
00:13:56,160 --> 00:13:59,400
that this tuple was deleted and then

376
00:13:59,400 --> 00:14:00,930
that per to destroy all the time stamps

377
00:14:00,930 --> 00:14:02,100
and everything you would do before and

378
00:14:02,100 --> 00:14:03,300
that gives you no information about say

379
00:14:03,300 --> 00:14:04,770
when this when this tuple was actually

380
00:14:04,770 --> 00:14:07,110
deleted so anybody that comes prior to

381
00:14:07,110 --> 00:14:08,820
that and earlier snapshot please still

382
00:14:08,820 --> 00:14:13,170
see the older versions so one way to

383
00:14:13,170 --> 00:14:14,670
sort of improve this and make make this

384
00:14:14,670 --> 00:14:16,740
work nicely instead of having sort of

385
00:14:16,740 --> 00:14:20,280
polluting all of the extended wasting

386
00:14:20,280 --> 00:14:22,260
space in their fixed data pool you could

387
00:14:22,260 --> 00:14:25,740
have a separate data pool to store these

388
00:14:25,740 --> 00:14:26,730
two Serna to blows because you don't

389
00:14:26,730 --> 00:14:28,620
actually need to restore the whole tuple

390
00:14:28,620 --> 00:14:30,600
and then the version chain now this

391
00:14:30,600 --> 00:14:31,800
points points to this thing and you

392
00:14:31,800 --> 00:14:33,800
would look and say oh with this bit set

393
00:14:33,800 --> 00:14:36,030
there's some bit pattern inside it says

394
00:14:36,030 --> 00:14:37,920
oh this is actually tombstones tuple not

395
00:14:37,920 --> 00:14:39,960
a regular tube wall this is only really

396
00:14:39,960 --> 00:14:41,100
the issue if you're doing append only

397
00:14:41,100 --> 00:14:43,140
alright so again think about this if I

398
00:14:43,140 --> 00:14:46,200
am doing a pendulum and I have a

399
00:14:46,200 --> 00:14:49,320
thousand columns if I delete that tuple

400
00:14:49,320 --> 00:14:50,670
and I want to create a tombstone to pool

401
00:14:50,670 --> 00:14:52,680
well one approach is I now make a

402
00:14:52,680 --> 00:14:54,930
special tuple in my same table with all

403
00:14:54,930 --> 00:14:57,360
my other tuples for that table that has

404
00:14:57,360 --> 00:14:59,760
a thousand attributes so that's wasted

405
00:14:59,760 --> 00:15:01,320
space just a record that that thing was

406
00:15:01,320 --> 00:15:03,720
actually deleted or it can have a marker

407
00:15:03,720 --> 00:15:05,880
that says hey you know or have a special

408
00:15:05,880 --> 00:15:07,740
tuple space to say this represents a

409
00:15:07,740 --> 00:15:09,660
deleted tuple and that means shared

410
00:15:09,660 --> 00:15:11,370
across different tables because we're

411
00:15:11,370 --> 00:15:12,930
not storing any attributes in the

412
00:15:12,930 --> 00:15:14,250
tombstone and tuple we're just it's a

413
00:15:14,250 --> 00:15:16,040
marker to say this thing was deleted

414
00:15:16,040 --> 00:15:19,440
so in peloton in our I would say not but

415
00:15:19,440 --> 00:15:21,120
loved but whatever the old system we

416
00:15:21,120 --> 00:15:22,920
killed we did it this way

417
00:15:22,920 --> 00:15:24,149
and we would use this special pool

418
00:15:24,149 --> 00:15:25,740
because we were doing a pen only licking

419
00:15:25,740 --> 00:15:28,529
Hecate on and therefore if we now create

420
00:15:28,529 --> 00:15:30,660
a tombstone to pool if we put it in the

421
00:15:30,660 --> 00:15:32,220
same data table would be a big waste of

422
00:15:32,220 --> 00:15:34,920
space and the newer system we use we use

423
00:15:34,920 --> 00:15:39,470
a separate column as a deleted flag yes

424
00:15:40,579 --> 00:15:42,660
this question is why doesn't there need

425
00:15:42,660 --> 00:15:46,680
to be a Oh starting different to sent

426
00:15:46,680 --> 00:15:48,420
ripples for deleted tuples or for

427
00:15:48,420 --> 00:15:59,490
different tables okay is if I delete

428
00:15:59,490 --> 00:16:01,560
three tuples from the same table why do

429
00:16:01,560 --> 00:16:02,940
I need a separate room center table for

430
00:16:02,940 --> 00:16:04,800
each of them because in the tombstone to

431
00:16:04,800 --> 00:16:06,300
boil you're recording the begin and end

432
00:16:06,300 --> 00:16:08,610
time stamp because I need to know when

433
00:16:08,610 --> 00:16:10,680
was this thing delete it now yeah I

434
00:16:10,680 --> 00:16:11,970
think your other question too was well

435
00:16:11,970 --> 00:16:15,230
why do I need to have why can I have as

436
00:16:15,230 --> 00:16:19,139
why can I have a same tombstone table

437
00:16:19,139 --> 00:16:21,360
special table that can be shared across

438
00:16:21,360 --> 00:16:23,610
multiple data tables because we are not

439
00:16:23,610 --> 00:16:25,320
storing any attributes in the tombstone

440
00:16:25,320 --> 00:16:27,630
the tombstone just says hey you're dead

441
00:16:27,630 --> 00:16:30,180
at this time so it doesn't matter what

442
00:16:30,180 --> 00:16:50,010
table it corresponds to but you need you

443
00:16:50,010 --> 00:16:54,000
know the timestamp back on that yeah

444
00:16:54,000 --> 00:16:56,149
yeah

445
00:16:59,410 --> 00:17:02,649
I think I think I think part of the

446
00:17:02,649 --> 00:17:06,490
issue is gonna be that first rider would

447
00:17:06,490 --> 00:17:08,730
win so who cares your market is leading

448
00:17:08,730 --> 00:17:10,839
there might be some ordering issue of

449
00:17:10,839 --> 00:17:14,559
like can I record that's been deleted

450
00:17:14,559 --> 00:17:19,119
and then I stop to go yeah if I do that

451
00:17:19,119 --> 00:17:21,099
then if my transaction that deleted that

452
00:17:21,099 --> 00:17:23,199
tuple aborts then I gotta go make sure I

453
00:17:23,199 --> 00:17:26,829
go back and remove that if I don't

454
00:17:26,829 --> 00:17:30,669
modify the previous tuple other than

455
00:17:30,669 --> 00:17:32,289
maybe the pointer then when I when I

456
00:17:32,289 --> 00:17:35,049
when I bought I stopped update the

457
00:17:35,049 --> 00:17:37,539
pointer yeah you might be able get away

458
00:17:37,539 --> 00:17:38,379
with something like that I have to think

459
00:17:38,379 --> 00:17:44,500
about that oh yeah if it was it was the

460
00:17:44,500 --> 00:17:45,909
student that built this piece of the

461
00:17:45,909 --> 00:17:48,789
system it's not that he liked to cut

462
00:17:48,789 --> 00:17:50,049
corners but he basically did everything

463
00:17:50,049 --> 00:17:52,960
in the most efficient way but possible

464
00:17:52,960 --> 00:17:54,429
which is always not the best engineering

465
00:17:54,429 --> 00:17:56,590
approach so if there's a way to make

466
00:17:56,590 --> 00:17:59,500
that work I would and like do that hack

467
00:17:59,500 --> 00:18:00,070
you're proposing

468
00:18:00,070 --> 00:18:02,350
I suspect you would have done it but we

469
00:18:02,350 --> 00:18:04,179
can take it offline maybe do on the

470
00:18:04,179 --> 00:18:05,080
board and figure out why that would

471
00:18:05,080 --> 00:18:08,139
would not work okay again so again for

472
00:18:08,139 --> 00:18:10,649
this one I don't think anybody does this

473
00:18:10,649 --> 00:18:13,149
other than us because if you're doing

474
00:18:13,149 --> 00:18:16,120
Delta store and if it doesn't store

475
00:18:16,120 --> 00:18:17,649
would do the same thing but he was doing

476
00:18:17,649 --> 00:18:23,110
newest to oldest with a delta store then

477
00:18:23,110 --> 00:18:24,639
this doesn't buy you anything because

478
00:18:24,639 --> 00:18:27,070
you do store in the in the the header

479
00:18:27,070 --> 00:18:28,899
for that tube other things been deleted

480
00:18:28,899 --> 00:18:34,240
yes but that was his state question is

481
00:18:34,240 --> 00:18:35,169
like what about his update the end

482
00:18:35,169 --> 00:18:37,179
timestamp would that be enough to denote

483
00:18:37,179 --> 00:18:38,590
that it was deleted I start to have a

484
00:18:38,590 --> 00:18:40,149
flag somewhere that said the thing was

485
00:18:40,149 --> 00:18:49,509
deleted right but he it's it you need it

486
00:18:49,509 --> 00:18:52,990
end timestamp to represent that there

487
00:18:52,990 --> 00:18:54,460
was a special delete like maybe put you

488
00:18:54,460 --> 00:18:56,559
take the first bit and had that

489
00:18:56,559 --> 00:18:59,070
represent it was deleted you can do that

490
00:18:59,070 --> 00:19:01,210
the I just put an end timestamp in there

491
00:19:01,210 --> 00:19:02,529
I don't know whether that's a delete or

492
00:19:02,529 --> 00:19:03,490
not or whether it's actually a new

493
00:19:03,490 --> 00:19:05,820
version

494
00:19:10,549 --> 00:19:17,249
yeah yeah okay alright so alright let's

495
00:19:17,249 --> 00:19:18,869
now talk about different design

496
00:19:18,869 --> 00:19:21,269
decisions so I wanted this part wasn't

497
00:19:21,269 --> 00:19:22,499
in the paper but I want to talk about

498
00:19:22,499 --> 00:19:25,710
how we actually do clean up keys from

499
00:19:25,710 --> 00:19:29,580
indexes and then the there's only really

500
00:19:29,580 --> 00:19:31,169
two papers on garbage collection for

501
00:19:31,169 --> 00:19:33,389
MVCC systems I had you read the guy's

502
00:19:33,389 --> 00:19:35,460
the one from hyper which actually just

503
00:19:35,460 --> 00:19:37,320
came out a few months ago there's

504
00:19:37,320 --> 00:19:39,119
another paper from 2016 that I had the

505
00:19:39,119 --> 00:19:40,679
students read last year from the SA P

506
00:19:40,679 --> 00:19:45,269
team they're not but they're they're

507
00:19:45,269 --> 00:19:48,330
both okay papers the what I don't like

508
00:19:48,330 --> 00:19:50,789
is that they sort of define the same

509
00:19:50,789 --> 00:19:53,100
define the same concepts but using

510
00:19:53,100 --> 00:19:55,049
different terms like I think like the

511
00:19:55,049 --> 00:19:56,940
hyper guys calls things like precision

512
00:19:56,940 --> 00:19:59,730
and frequency but they you know these

513
00:19:59,730 --> 00:20:01,379
guys called like identification and

514
00:20:01,379 --> 00:20:03,570
things like that like so the concepts at

515
00:20:03,570 --> 00:20:05,100
a high level are the same just the the

516
00:20:05,100 --> 00:20:06,450
the nomenclature they're using to

517
00:20:06,450 --> 00:20:08,009
describe these things will be slightly

518
00:20:08,009 --> 00:20:10,200
different so I'm a mix up as we go along

519
00:20:10,200 --> 00:20:12,059
some bit some Hana the hotter paper and

520
00:20:12,059 --> 00:20:13,499
the hyper paper but hopefully it should

521
00:20:13,499 --> 00:20:15,119
all sort of make sense so let's talk

522
00:20:15,119 --> 00:20:16,679
about how we're gonna track versions the

523
00:20:16,679 --> 00:20:17,999
frequency which we invoke the carbon

524
00:20:17,999 --> 00:20:20,070
Scotch and the granularity we're going

525
00:20:20,070 --> 00:20:22,590
to look at potential versions we can

526
00:20:22,590 --> 00:20:25,259
remove and had a compare of whether it's

527
00:20:25,259 --> 00:20:28,590
okay to put in them or not okay all

528
00:20:28,590 --> 00:20:32,789
right so four indexes again what's gonna

529
00:20:32,789 --> 00:20:35,720
happen is that as my transaction runs

530
00:20:35,720 --> 00:20:39,480
and I'm creating new you know I'm

531
00:20:39,480 --> 00:20:40,830
creating new tuples and putting new

532
00:20:40,830 --> 00:20:44,279
versions I have to store that in an

533
00:20:44,279 --> 00:20:47,100
index because now if I try to go back

534
00:20:47,100 --> 00:20:48,720
and read that same thing that I just

535
00:20:48,720 --> 00:20:50,129
wrote I want to be able to go through

536
00:20:50,129 --> 00:20:52,320
the index and see my own rights if

537
00:20:52,320 --> 00:20:53,879
you're doing OCC was a private workspace

538
00:20:53,879 --> 00:20:55,710
you don't do this cuz you staged all the

539
00:20:55,710 --> 00:20:58,320
rights at the end but the what we've

540
00:20:58,320 --> 00:20:59,129
been talking about is doing the

541
00:20:59,129 --> 00:21:00,720
timestamp ordering approach where you

542
00:21:00,720 --> 00:21:02,279
apply the rights in that in that global

543
00:21:02,279 --> 00:21:03,450
space because that allows you to do

544
00:21:03,450 --> 00:21:05,549
spected reads for other transactions

545
00:21:05,549 --> 00:21:07,950
that are ahead of you in in sort of

546
00:21:07,950 --> 00:21:10,350
logical time so now the problems going

547
00:21:10,350 --> 00:21:13,679
to be is that if i need to abort or if i

548
00:21:13,679 --> 00:21:15,509
need to go clean up versions i need to

549
00:21:15,509 --> 00:21:18,149
make sure that i remove any keys that

550
00:21:18,149 --> 00:21:20,850
correspond to older versions that that I

551
00:21:20,850 --> 00:21:22,980
need to remove right

552
00:21:22,980 --> 00:21:24,720
so the way any basically do this is that

553
00:21:24,720 --> 00:21:27,090
wall transactions running and it's

554
00:21:27,090 --> 00:21:29,730
updating the indexes we just need to

555
00:21:29,730 --> 00:21:31,800
record you know what keys did we insert

556
00:21:31,800 --> 00:21:38,640
or do we do ease to be invalidate from

557
00:21:38,640 --> 00:21:40,080
our index because we're making changes

558
00:21:40,080 --> 00:21:42,540
and then when we go to commit or a

559
00:21:42,540 --> 00:21:44,790
border transaction we have to have the

560
00:21:44,790 --> 00:21:45,930
garbage collector kick in and say

561
00:21:45,930 --> 00:21:49,290
alright well let me go clean up the let

562
00:21:49,290 --> 00:21:51,780
me go clean up the the the indexes

563
00:21:51,780 --> 00:21:52,800
because these are things that people

564
00:21:52,800 --> 00:21:56,190
shouldn't see right so the way hyper got

565
00:21:56,190 --> 00:22:00,480
around this was anytime you would you

566
00:22:00,480 --> 00:22:03,870
modify an attribute that's indexed then

567
00:22:03,870 --> 00:22:05,490
you treat that as a delete followed by

568
00:22:05,490 --> 00:22:07,710
an insert for that for that transaction

569
00:22:07,710 --> 00:22:09,360
because then you don't have to worry

570
00:22:09,360 --> 00:22:11,250
about going and finding the key and

571
00:22:11,250 --> 00:22:13,560
updating the pointer right you just say

572
00:22:13,560 --> 00:22:15,090
this here's the old version from the key

573
00:22:15,090 --> 00:22:17,040
and the index you remove it they let me

574
00:22:17,040 --> 00:22:20,280
insert a new one so we did not do this

575
00:22:20,280 --> 00:22:22,620
in in peloton we did something really

576
00:22:22,620 --> 00:22:24,450
really stupid like we're totally stupid

577
00:22:24,450 --> 00:22:25,980
I don't know why this is one of those

578
00:22:25,980 --> 00:22:26,970
things were like the student did it this

579
00:22:26,970 --> 00:22:28,350
way because it because it looked like it

580
00:22:28,350 --> 00:22:29,700
made performance go better for our

581
00:22:29,700 --> 00:22:31,320
benchmarks and it wasn't till with like

582
00:22:31,320 --> 00:22:32,730
later on we're like oh we gotta go

583
00:22:32,730 --> 00:22:34,020
modify this to could fix some things

584
00:22:34,020 --> 00:22:36,450
like oh my gosh they did something bad

585
00:22:36,450 --> 00:22:38,550
we shouldn't have done this right so

586
00:22:38,550 --> 00:22:39,690
here's what we did in Palestine so again

587
00:22:39,690 --> 00:22:43,530
we were doing append only oldest to

588
00:22:43,530 --> 00:22:46,980
newest that true yes and what would

589
00:22:46,980 --> 00:22:48,600
happen is if I have a transaction comes

590
00:22:48,600 --> 00:22:51,900
along and say they update a right and we

591
00:22:51,900 --> 00:22:54,810
set this key now to 22 well I would do

592
00:22:54,810 --> 00:22:59,100
an append only a pendant new to point to

593
00:22:59,100 --> 00:23:01,170
my tablespace but then I would add a new

594
00:23:01,170 --> 00:23:05,010
entry in my index to say for for key 20

595
00:23:05,010 --> 00:23:07,170
- 2 - here's the version of it so even

596
00:23:07,170 --> 00:23:10,260
though logically they're the same tuple

597
00:23:10,260 --> 00:23:12,150
from the indexes perspective they look

598
00:23:12,150 --> 00:23:13,220
like separate things

599
00:23:13,220 --> 00:23:16,650
alright so then we got into trouble was

600
00:23:16,650 --> 00:23:18,750
way if you try to update the same key

601
00:23:18,750 --> 00:23:21,510
again on the same tuple instead of

602
00:23:21,510 --> 00:23:24,150
making a new entry in the index we would

603
00:23:24,150 --> 00:23:26,550
actually go and overwrite the the

604
00:23:26,550 --> 00:23:29,100
previous version that we created so in

605
00:23:29,100 --> 00:23:30,660
this case here I would replace 2 - 2

606
00:23:30,660 --> 00:23:34,200
with now 33 our 3 3 3 and then now I

607
00:23:34,200 --> 00:23:36,710
would also have update my index and

608
00:23:36,710 --> 00:23:39,020
point to it as well and I kept doing

609
00:23:39,020 --> 00:23:40,850
this every single time I did an update

610
00:23:40,850 --> 00:23:42,440
right so this that's it two four four

611
00:23:42,440 --> 00:23:45,320
and I have an update entry to point two

612
00:23:45,320 --> 00:23:47,510
here so now the problem is when we go

613
00:23:47,510 --> 00:23:49,340
ahead and and how to abort this

614
00:23:49,340 --> 00:23:51,919
transaction we had no idea what was the

615
00:23:51,919 --> 00:23:54,289
other you know 2:00 to 2:30 3:00 that we

616
00:23:54,289 --> 00:23:57,380
inserted and so we could go delete 4 4 4

617
00:23:57,380 --> 00:23:58,760
because we know this is the version we

618
00:23:58,760 --> 00:23:59,809
need to clean up because that's what

619
00:23:59,809 --> 00:24:02,149
we're seeing in you know you know dirty

620
00:24:02,149 --> 00:24:04,669
table space or dirty dirty tuple list

621
00:24:04,669 --> 00:24:06,289
for our transaction but we had no idea

622
00:24:06,289 --> 00:24:07,909
that we've left there's other keys

623
00:24:07,909 --> 00:24:10,340
inside here so we would run this for a

624
00:24:10,340 --> 00:24:11,690
while run some benchmarks and all sudden

625
00:24:11,690 --> 00:24:13,820
you'd get it was a unique index you

626
00:24:13,820 --> 00:24:14,929
would get back an error and say that a

627
00:24:14,929 --> 00:24:16,610
key already existed even though the

628
00:24:16,610 --> 00:24:17,929
digits in the table because we were

629
00:24:17,929 --> 00:24:21,200
leaking these keys from you know from

630
00:24:21,200 --> 00:24:24,919
aborted transactions so you know this is

631
00:24:24,919 --> 00:24:28,250
embarrassing this is stupid you know

632
00:24:28,250 --> 00:24:29,990
this is not really anything specific

633
00:24:29,990 --> 00:24:33,049
about you know paper you guys read this

634
00:24:33,049 --> 00:24:34,399
is just showing that like it's hard to

635
00:24:34,399 --> 00:24:36,380
get these things right even if you have

636
00:24:36,380 --> 00:24:40,429
the best intentions and just not keeping

637
00:24:40,429 --> 00:24:41,960
track of all the keys that you updated

638
00:24:41,960 --> 00:24:43,820
as you know or all the case you you

639
00:24:43,820 --> 00:24:45,230
modify in the index as you're going

640
00:24:45,230 --> 00:24:49,490
along can end up end up losing things so

641
00:24:49,490 --> 00:24:50,539
again we don't do this anymore

642
00:24:50,539 --> 00:24:54,380
this is good ok so let's talk about now

643
00:24:54,380 --> 00:24:56,059
how we're actually going to keep find a

644
00:24:56,059 --> 00:24:58,450
keep track of the versions that

645
00:24:58,450 --> 00:25:01,190
transactions are gonna create there's a

646
00:25:01,190 --> 00:25:04,190
typo here sorry so the the first

647
00:25:04,190 --> 00:25:05,630
approach we sort of talked about we

648
00:25:05,630 --> 00:25:08,720
first talked to these two in the first

649
00:25:08,720 --> 00:25:08,990
lecture

650
00:25:08,990 --> 00:25:11,740
MVCC right this is where we just have

651
00:25:11,740 --> 00:25:15,830
some mechanism where a transaction

652
00:25:15,830 --> 00:25:17,960
threads or a separate garbage touchin

653
00:25:17,960 --> 00:25:20,029
thread can go through our tables and

654
00:25:20,029 --> 00:25:23,480
identify versions that we need to prune

655
00:25:23,480 --> 00:25:25,370
up right the background vacuuming was it

656
00:25:25,370 --> 00:25:26,809
was a separate thread the proper

657
00:25:26,809 --> 00:25:28,820
cleaning technique was where the

658
00:25:28,820 --> 00:25:30,529
transactions or the queries as they were

659
00:25:30,529 --> 00:25:32,270
running if they noticed they had a

660
00:25:32,270 --> 00:25:34,490
version that was not visible to any

661
00:25:34,490 --> 00:25:36,169
transaction then they would go ahead and

662
00:25:36,169 --> 00:25:38,600
clean that so hackathon did this because

663
00:25:38,600 --> 00:25:40,070
they were doing oldest to newest so as

664
00:25:40,070 --> 00:25:42,020
transactions ran and had to traverse the

665
00:25:42,020 --> 00:25:42,980
virgin chain to get to the newest

666
00:25:42,980 --> 00:25:44,960
version along the way they would see a

667
00:25:44,960 --> 00:25:46,370
bunch of old versions that they knew

668
00:25:46,370 --> 00:25:47,960
were reclaim a bowl and they'd go ahead

669
00:25:47,960 --> 00:25:48,659
and remove them

670
00:25:48,659 --> 00:25:52,499
there all right the transaction level

671
00:25:52,499 --> 00:25:53,820
approach is what we used to do in

672
00:25:53,820 --> 00:25:55,979
peloton and this is where transactions

673
00:25:55,979 --> 00:25:57,149
would keep track of all the versions

674
00:25:57,149 --> 00:25:59,940
that they created and then when they

675
00:25:59,940 --> 00:26:01,710
commit they handed off this information

676
00:26:01,710 --> 00:26:04,769
to the garbage collector who then had a

677
00:26:04,769 --> 00:26:06,989
view on what transactions are running

678
00:26:06,989 --> 00:26:08,690
what are their time stamps okay and

679
00:26:08,690 --> 00:26:11,909
excuse me and they can identify which

680
00:26:11,909 --> 00:26:14,190
which you know which versions that were

681
00:26:14,190 --> 00:26:15,989
invalidated by these transactions are

682
00:26:15,989 --> 00:26:19,919
now are now printable the last approach

683
00:26:19,919 --> 00:26:21,960
is an epoch based approach and this is

684
00:26:21,960 --> 00:26:23,399
basically the same thing as transaction

685
00:26:23,399 --> 00:26:25,019
level the idea here is you're gonna ask

686
00:26:25,019 --> 00:26:27,299
you a bunch of transactions and and not

687
00:26:27,299 --> 00:26:28,979
as a batch meeting all exact same time

688
00:26:28,979 --> 00:26:30,509
but you put them under this the same

689
00:26:30,509 --> 00:26:32,940
epoch and this will make well we'll see

690
00:26:32,940 --> 00:26:34,080
this again on Monday when we talk about

691
00:26:34,080 --> 00:26:36,179
the beta retreat but basically it's like

692
00:26:36,179 --> 00:26:37,619
this other counter that's always going

693
00:26:37,619 --> 00:26:39,450
for at a time and we would know that

694
00:26:39,450 --> 00:26:41,970
when we go from one epoch to the next we

695
00:26:41,970 --> 00:26:43,320
would know whether there's any

696
00:26:43,320 --> 00:26:44,940
transactions that could still be seeing

697
00:26:44,940 --> 00:26:47,099
something in the previous epoch and then

698
00:26:47,099 --> 00:26:48,690
if not then we know that anything that

699
00:26:48,690 --> 00:26:50,190
was that was invalidated in that epoch

700
00:26:50,190 --> 00:26:53,729
can be reclaimed well seem again this

701
00:26:53,729 --> 00:26:56,009
more we'll see more about seed this

702
00:26:56,009 --> 00:26:58,320
approach or technique used in the the

703
00:26:58,320 --> 00:26:59,609
beat of a tree on Monday when you read

704
00:26:59,609 --> 00:27:01,619
that paper all right so let's had to be

705
00:27:01,619 --> 00:27:03,299
the verge of tracking at the transaction

706
00:27:03,299 --> 00:27:04,979
level again so my transaction comes

707
00:27:04,979 --> 00:27:07,710
along it's time Sam 10 I'll do an update

708
00:27:07,710 --> 00:27:10,499
on a I create a new version right and

709
00:27:10,499 --> 00:27:13,710
then now because I know that I had this

710
00:27:13,710 --> 00:27:15,899
was the the version that the latest

711
00:27:15,899 --> 00:27:17,879
version that I saw and then I created my

712
00:27:17,879 --> 00:27:20,249
new version so therefore I know for this

713
00:27:20,249 --> 00:27:23,700
transaction a 2 is now potentially

714
00:27:23,700 --> 00:27:25,379
reclaim below so if my transaction

715
00:27:25,379 --> 00:27:27,419
commits then I know I can go ahead and

716
00:27:27,419 --> 00:27:30,259
clean up a two sides record that in my

717
00:27:30,259 --> 00:27:32,220
transaction local space for my old

718
00:27:32,220 --> 00:27:33,690
versions and this is just a pointer to

719
00:27:33,690 --> 00:27:36,690
this location here and this can work

720
00:27:36,690 --> 00:27:38,729
these pointers can use these pointers

721
00:27:38,729 --> 00:27:40,859
because we're not gonna end up we're not

722
00:27:40,859 --> 00:27:42,659
moving this thing around right we're not

723
00:27:42,659 --> 00:27:43,919
doing compaction where we can be moving

724
00:27:43,919 --> 00:27:45,779
it from one block to nuts we just say

725
00:27:45,779 --> 00:27:49,080
that this thing has to stay there now I

726
00:27:49,080 --> 00:27:52,559
do a an update on B same thing I had the

727
00:27:52,559 --> 00:27:54,840
old version that I know that I created I

728
00:27:54,840 --> 00:27:56,700
create my new version after the previous

729
00:27:56,700 --> 00:27:59,190
old version I update that now in my old

730
00:27:59,190 --> 00:28:01,529
version list then when my transaction

731
00:28:01,529 --> 00:28:02,309
goes ahead and commit

732
00:28:02,309 --> 00:28:04,169
I just pass this information along to

733
00:28:04,169 --> 00:28:05,849
the garbage collector we then look at

734
00:28:05,849 --> 00:28:09,330
and say well the commit time stamp for

735
00:28:09,330 --> 00:28:11,399
this is 15 so I know for these versions

736
00:28:11,399 --> 00:28:15,509
here anybody that's less than 15 its

737
00:28:15,509 --> 00:28:19,080
highest time stamp less than 15 should

738
00:28:19,080 --> 00:28:22,259
be able to see them right so if now

739
00:28:22,259 --> 00:28:24,479
there is no transaction that has a time

740
00:28:24,479 --> 00:28:26,609
stamp less than 15 but I know that these

741
00:28:26,609 --> 00:28:28,169
versions are removable

742
00:28:28,169 --> 00:28:31,739
I say this is called I think the the

743
00:28:31,739 --> 00:28:33,389
low-water mark of high-water mark in the

744
00:28:33,389 --> 00:28:36,509
paper basically IDs need to know for for

745
00:28:36,509 --> 00:28:39,149
these tuples what's the lowest time

746
00:28:39,149 --> 00:28:40,619
stamp I could have where someone could

747
00:28:40,619 --> 00:28:41,729
actually still see this so if no

748
00:28:41,729 --> 00:28:43,109
transaction has something below that

749
00:28:43,109 --> 00:28:53,119
time stamp then I can remove it yes yes

750
00:28:56,210 --> 00:28:58,049
this question is if I have another

751
00:28:58,049 --> 00:28:59,580
transaction that's running that has a

752
00:28:59,580 --> 00:29:02,099
begin time stamp of what you can't cuz

753
00:29:02,099 --> 00:29:05,519
this guy already has ten so nine okay so

754
00:29:05,519 --> 00:29:08,429
he comes along and he's gonna read a he

755
00:29:08,429 --> 00:29:09,509
would read this one right because nine

756
00:29:09,509 --> 00:29:12,269
is it isn't in between 1 and 15 right so

757
00:29:12,269 --> 00:29:18,450
yeah he read a - you know so again the

758
00:29:18,450 --> 00:29:21,119
garbage doctor knows like it knows what

759
00:29:21,119 --> 00:29:22,139
other it has you have to know what

760
00:29:22,139 --> 00:29:23,879
transactions are running so in the hypo

761
00:29:23,879 --> 00:29:25,049
favorite they talk about how the hell is

762
00:29:25,049 --> 00:29:26,249
this linked list that's sort of my

763
00:29:26,249 --> 00:29:27,570
transaction ID and you can just look at

764
00:29:27,570 --> 00:29:29,249
the head or a depend what order is to

765
00:29:29,249 --> 00:29:30,659
find out what the lowest one is that's

766
00:29:30,659 --> 00:29:32,519
like that's both the low-water mark or

767
00:29:32,519 --> 00:29:33,690
the high more depending what you're

768
00:29:33,690 --> 00:29:35,700
looking at and the idea is that I know

769
00:29:35,700 --> 00:29:36,929
which ones actually running so if

770
00:29:36,929 --> 00:29:38,219
there's a transaction that's running

771
00:29:38,219 --> 00:29:41,580
with timestamp 9 then 9 is less than 15

772
00:29:41,580 --> 00:29:43,769
so therefore it could potentially still

773
00:29:43,769 --> 00:29:46,139
read these things and therefore I can't

774
00:29:46,139 --> 00:29:49,259
reclaim them it may never read B but I

775
00:29:49,259 --> 00:29:50,399
don't know that because I don't know

776
00:29:50,399 --> 00:29:51,389
what the transaction is actually going

777
00:29:51,389 --> 00:29:53,609
to do so I have to be conservative and

778
00:29:53,609 --> 00:29:57,619
lead everything you know leave it around

779
00:29:59,089 --> 00:30:02,159
correct like and again you could use the

780
00:30:02,159 --> 00:30:03,570
the sorted linked list that the hyper

781
00:30:03,570 --> 00:30:04,889
does you could just record a single

782
00:30:04,889 --> 00:30:08,779
value there are different ways I did it

783
00:30:08,779 --> 00:30:11,300
okay

784
00:30:11,300 --> 00:30:13,790
so the next question is how often are we

785
00:30:13,790 --> 00:30:15,700
going to invoke the garbage collector

786
00:30:15,700 --> 00:30:19,040
and again is this trade-off between if

787
00:30:19,040 --> 00:30:20,840
we're very aggressive in our garbage

788
00:30:20,840 --> 00:30:22,790
collection then yes we can go free up

789
00:30:22,790 --> 00:30:24,350
space as quickly as possible assuming

790
00:30:24,350 --> 00:30:25,550
there's not transactions that are you

791
00:30:25,550 --> 00:30:27,400
know sitting around the long time stamps

792
00:30:27,400 --> 00:30:30,350
but the issue is going to be will

793
00:30:30,350 --> 00:30:32,870
reclaim space more quickly but now we

794
00:30:32,870 --> 00:30:33,890
could be end up slowing down

795
00:30:33,890 --> 00:30:35,840
transactions because now the garbage

796
00:30:35,840 --> 00:30:36,980
collection threads if it's running in a

797
00:30:36,980 --> 00:30:40,340
background set up they start using CPU

798
00:30:40,340 --> 00:30:42,080
and that's gonna eat up cycles and make

799
00:30:42,080 --> 00:30:43,970
your queries and transactions run slower

800
00:30:43,970 --> 00:30:46,700
and obviously if we're - we're less

801
00:30:46,700 --> 00:30:47,930
aggressive and run this and - and

802
00:30:47,930 --> 00:30:52,130
frequently and now we're gonna have the

803
00:30:52,130 --> 00:30:53,570
size the database is gonna get larger

804
00:30:53,570 --> 00:30:55,130
because we're not reclaiming versions as

805
00:30:55,130 --> 00:30:57,740
quickly as we maybe should the Virgin

806
00:30:57,740 --> 00:30:59,240
chains could potentially get longer and

807
00:30:59,240 --> 00:31:00,590
that means that it takes longer for

808
00:31:00,590 --> 00:31:01,700
queries to go find the exact version

809
00:31:01,700 --> 00:31:03,950
that they want so if the delicate

810
00:31:03,950 --> 00:31:05,240
balance between the two of these I

811
00:31:05,240 --> 00:31:08,240
actually think the hyper approach is the

812
00:31:08,240 --> 00:31:10,520
better one then the background garbage

813
00:31:10,520 --> 00:31:12,260
collection so again so you run it

814
00:31:12,260 --> 00:31:13,780
periodically you run it continuously

815
00:31:13,780 --> 00:31:15,920
this is what hyper does this is what we

816
00:31:15,920 --> 00:31:19,700
do that's what no systems do so periodic

817
00:31:19,700 --> 00:31:21,700
eyes means that at some fixed interval

818
00:31:21,700 --> 00:31:25,100
or within when some threshold was met

819
00:31:25,100 --> 00:31:28,310
like if I have if I know I have 20% of

820
00:31:28,310 --> 00:31:30,980
my memories being used by on ivory

821
00:31:30,980 --> 00:31:32,810
claimable versions somehow I could

822
00:31:32,810 --> 00:31:34,160
compute this then I kick off the garbage

823
00:31:34,160 --> 00:31:36,080
clutter and go find things right sort of

824
00:31:36,080 --> 00:31:37,640
the JVM sort of does a similar thing

825
00:31:37,640 --> 00:31:39,110
look when you get you to your heap size

826
00:31:39,110 --> 00:31:40,940
when it gets by a certain percentage

827
00:31:40,940 --> 00:31:43,910
then it kicks off so this is just saying

828
00:31:43,910 --> 00:31:45,680
that right again I'd run it in the

829
00:31:45,680 --> 00:31:46,850
background thread and running it every

830
00:31:46,850 --> 00:31:48,680
so often and for some systems like in

831
00:31:48,680 --> 00:31:51,350
hackaton they can identify that if my

832
00:31:51,350 --> 00:31:54,410
load or my churn rate for my versions is

833
00:31:54,410 --> 00:31:57,350
really high then I can make this I can

834
00:31:57,350 --> 00:32:02,780
run this more frequently the the the

835
00:32:02,780 --> 00:32:04,370
hyper poach is that run is continuously

836
00:32:04,370 --> 00:32:06,470
where the the garbage collection

837
00:32:06,470 --> 00:32:09,830
procedures are just a part of the normal

838
00:32:09,830 --> 00:32:11,180
transaction processing or query

839
00:32:11,180 --> 00:32:16,820
execution steps right so in hyper they

840
00:32:16,820 --> 00:32:18,140
did it own commit so any time a

841
00:32:18,140 --> 00:32:20,150
transaction committed then they would

842
00:32:20,150 --> 00:32:21,590
have that thread go through and see well

843
00:32:21,590 --> 00:32:23,150
what can i reclaim what can i clean mop

844
00:32:23,150 --> 00:32:23,950
cleanup

845
00:32:23,950 --> 00:32:28,990
the the steam version in the in the

846
00:32:28,990 --> 00:32:31,330
newer version of hyper this is doing

847
00:32:31,330 --> 00:32:33,340
quick turn pretty oxygen so I call this

848
00:32:33,340 --> 00:32:34,390
the same thing as cooperative query

849
00:32:34,390 --> 00:32:36,280
execution part of cooperative cleaning

850
00:32:36,280 --> 00:32:37,360
the wait saying wait hackathon does

851
00:32:37,360 --> 00:32:39,640
where just add I'm running my queries if

852
00:32:39,640 --> 00:32:41,530
I see things that I need to clean up let

853
00:32:41,530 --> 00:32:42,820
me go ahead and clean them up

854
00:32:42,820 --> 00:32:45,340
but because hyper is doing news to

855
00:32:45,340 --> 00:32:46,840
oldest they don't have the dusty corner

856
00:32:46,840 --> 00:32:49,480
problem that hackathon has where you

857
00:32:49,480 --> 00:32:50,650
could have versions that are never

858
00:32:50,650 --> 00:32:52,330
visited and they never get reclaimed

859
00:32:52,330 --> 00:32:54,970
right if if you read it you'll see it

860
00:32:54,970 --> 00:32:58,960
and you can reclaim it so I think I

861
00:32:58,960 --> 00:33:02,320
would like to do this although the way

862
00:33:02,320 --> 00:33:04,300
we're sort of our system is sort of set

863
00:33:04,300 --> 00:33:06,370
up now our garbage collector is

864
00:33:06,370 --> 00:33:08,020
integrated with this other bits or

865
00:33:08,020 --> 00:33:11,140
background cleanup process that does a

866
00:33:11,140 --> 00:33:12,400
bunch of other memory management things

867
00:33:12,400 --> 00:33:14,020
so I don't think we can switch over to

868
00:33:14,020 --> 00:33:15,940
this I think we're stuck with this but

869
00:33:15,940 --> 00:33:17,260
again I like this better because it's

870
00:33:17,260 --> 00:33:19,390
like alright well if I actually lot of

871
00:33:19,390 --> 00:33:21,070
queries that do a lot of updates well

872
00:33:21,070 --> 00:33:22,630
it's sort of as they put it

873
00:33:22,630 --> 00:33:24,370
self-regulating because I'm creating a

874
00:33:24,370 --> 00:33:26,590
lot of versions as I run queries those

875
00:33:26,590 --> 00:33:27,940
queries will clean up the versions that

876
00:33:27,940 --> 00:33:31,180
that are claimed old and if queries run

877
00:33:31,180 --> 00:33:32,230
slower because I have a lot of versions

878
00:33:32,230 --> 00:33:34,000
to reclaim well that's actually gonna

879
00:33:34,000 --> 00:33:36,220
then end up slowing down the rate in

880
00:33:36,220 --> 00:33:39,280
which I create old versions so I like

881
00:33:39,280 --> 00:33:42,850
that model all right so now the question

882
00:33:42,850 --> 00:33:45,010
is how we're going to organize in

883
00:33:45,010 --> 00:33:46,960
internally the metadata for our garbage

884
00:33:46,960 --> 00:33:50,470
collector to determine whether we can go

885
00:33:50,470 --> 00:33:52,690
ahead and reclaim things right again and

886
00:33:52,690 --> 00:33:53,950
now again there's more trade-offs

887
00:33:53,950 --> 00:33:55,930
between whether we're gonna have sort of

888
00:33:55,930 --> 00:33:58,360
fine grain tracking information to say

889
00:33:58,360 --> 00:33:59,830
here's a single version that can be

890
00:33:59,830 --> 00:34:01,510
claimed within this time stamp or

891
00:34:01,510 --> 00:34:03,700
whether we can combine them together and

892
00:34:03,700 --> 00:34:05,320
just to have a time stamp across

893
00:34:05,320 --> 00:34:07,060
multiple tuples and that can amortize

894
00:34:07,060 --> 00:34:09,130
the storage costs of the tracking

895
00:34:09,130 --> 00:34:11,168
information for this in exchange for

896
00:34:11,168 --> 00:34:12,699
maybe not reclaiming things as fast as

897
00:34:12,699 --> 00:34:15,850
they possibly could be so this is just

898
00:34:15,850 --> 00:34:17,679
anything I just said now right so single

899
00:34:17,679 --> 00:34:20,380
version tracking would be for every

900
00:34:20,380 --> 00:34:22,449
single tuple I know what their version

901
00:34:22,449 --> 00:34:24,550
is and what their timestamps are and

902
00:34:24,550 --> 00:34:27,070
then when the garbage car kicks off I

903
00:34:27,070 --> 00:34:28,540
can make a decision at that point decide

904
00:34:28,540 --> 00:34:30,130
whether it's a it's okay - can we claim

905
00:34:30,130 --> 00:34:32,739
stuff so you get this sort of for free

906
00:34:32,739 --> 00:34:34,659
if you're doing the continuous or

907
00:34:34,659 --> 00:34:36,850
cooperative cleaning because as I scan

908
00:34:36,850 --> 00:34:37,869
along and my

909
00:34:37,869 --> 00:34:39,998
to try to find the version I want then I

910
00:34:39,998 --> 00:34:42,549
would end up cleaning things up as I

911
00:34:42,549 --> 00:34:44,859
find them and I'm already storing that

912
00:34:44,859 --> 00:34:46,389
metadata anyway in the headers of the

913
00:34:46,389 --> 00:34:48,279
tuples or the other records so it's not

914
00:34:48,279 --> 00:34:50,699
like I need to sort the stuff separately

915
00:34:50,699 --> 00:34:53,559
the group version is what I assured

916
00:34:53,559 --> 00:34:55,029
before in that one example with the

917
00:34:55,029 --> 00:34:57,099
vacuum thread and the idea is here as I

918
00:34:57,099 --> 00:34:59,890
say here's a bunch of tuples that were

919
00:34:59,890 --> 00:35:01,660
invalidated by a transaction at some

920
00:35:01,660 --> 00:35:03,519
timestamp and so anything that less than

921
00:35:03,519 --> 00:35:06,009
that timestamp any transaction has a

922
00:35:06,009 --> 00:35:07,180
timestamp less and this could still

923
00:35:07,180 --> 00:35:09,009
possibly see them otherwise they don't

924
00:35:09,009 --> 00:35:10,089
alright

925
00:35:10,089 --> 00:35:12,039
so again there's less overhead to track

926
00:35:12,039 --> 00:35:17,019
things but it may delay the time in

927
00:35:17,019 --> 00:35:18,400
which we can reclaim something and get

928
00:35:18,400 --> 00:35:21,099
memory back so there's a third approach

929
00:35:21,099 --> 00:35:23,470
that was in the Hana paper that you

930
00:35:23,470 --> 00:35:24,970
didn't you guys didn't read but I think

931
00:35:24,970 --> 00:35:27,609
the the hyper paper mentioned this where

932
00:35:27,609 --> 00:35:31,029
you can actually do reclaim all the

933
00:35:31,029 --> 00:35:34,779
versions from an entire table if you

934
00:35:34,779 --> 00:35:37,029
know that there's no transaction running

935
00:35:37,029 --> 00:35:38,380
right now and that could ever access it

936
00:35:38,380 --> 00:35:41,019
so how does this work right because

937
00:35:41,019 --> 00:35:44,230
remember I said here's one example like

938
00:35:44,230 --> 00:35:45,009
there was it could be another

939
00:35:45,009 --> 00:35:47,380
transaction at timestamp nine could it

940
00:35:47,380 --> 00:35:50,230
read a it may read B but we don't know

941
00:35:50,230 --> 00:35:52,029
because we don't know what queries that

942
00:35:52,029 --> 00:35:54,400
transaction is going to execute but in

943
00:35:54,400 --> 00:35:56,079
some cases if you execute your

944
00:35:56,079 --> 00:35:57,700
transactions as prepared statements or

945
00:35:57,700 --> 00:35:59,999
stored procedures then you know

946
00:35:59,999 --> 00:36:02,230
potentially what all possible queries it

947
00:36:02,230 --> 00:36:04,569
could ever execute like a prepared

948
00:36:04,569 --> 00:36:06,249
statement is like a predefined function

949
00:36:06,249 --> 00:36:08,019
that you can install in the database

950
00:36:08,019 --> 00:36:09,819
system say that runs some logic for

951
00:36:09,819 --> 00:36:11,259
transaction like and I'll have

952
00:36:11,259 --> 00:36:12,910
invocations of queries so you can see

953
00:36:12,910 --> 00:36:14,910
what all the queries are ahead of time

954
00:36:14,910 --> 00:36:18,039
not always but sometimes you can if

955
00:36:18,039 --> 00:36:23,170
everything is predetermines actions in

956
00:36:23,170 --> 00:36:25,180
my system and if I know what queries

957
00:36:25,180 --> 00:36:27,279
they could ever possibly execute then I

958
00:36:27,279 --> 00:36:28,480
know what tables they're tough though

959
00:36:28,480 --> 00:36:30,400
they will touch and I see that they are

960
00:36:30,400 --> 00:36:32,259
that they're they can never touch a

961
00:36:32,259 --> 00:36:34,299
particular table then I can go ahead and

962
00:36:34,299 --> 00:36:36,430
reclaim all the versions for that entire

963
00:36:36,430 --> 00:36:38,650
table without doing any you know fine

964
00:36:38,650 --> 00:36:40,779
grained tracking in case a Hana they're

965
00:36:40,779 --> 00:36:43,660
doing the time-travel storage so for a

966
00:36:43,660 --> 00:36:45,819
given table all the versions are sitting

967
00:36:45,819 --> 00:36:47,410
around and another you know another

968
00:36:47,410 --> 00:36:49,420
tablespace so I did blow away that

969
00:36:49,420 --> 00:36:52,029
entire time-travel storage space

970
00:36:52,029 --> 00:36:53,739
without having to do any you know any

971
00:36:53,739 --> 00:36:56,170
examination of their time stamps it's

972
00:36:56,170 --> 00:36:57,819
basically doing like a drop table and

973
00:36:57,819 --> 00:36:59,920
and creating it again which is super

974
00:36:59,920 --> 00:37:03,789
fast again this is this is this is a as

975
00:37:03,789 --> 00:37:05,499
I said a special case or a corner case

976
00:37:05,499 --> 00:37:07,599
right if your transact if your

977
00:37:07,599 --> 00:37:09,549
application is invoking a bunch of store

978
00:37:09,549 --> 00:37:11,229
procedures then then you can do this

979
00:37:11,229 --> 00:37:13,539
most systems do not cannot do this

980
00:37:13,539 --> 00:37:15,640
though right and I don't think if you're

981
00:37:15,640 --> 00:37:17,589
doing the Delta storage or the

982
00:37:17,589 --> 00:37:18,910
append-only storage where the versions

983
00:37:18,910 --> 00:37:21,069
are mixed together with regular tuples

984
00:37:21,069 --> 00:37:22,959
or as Delta Records I don't think this

985
00:37:22,959 --> 00:37:25,059
actually would work right this is sort

986
00:37:25,059 --> 00:37:26,469
of a special case for for Hana assays

987
00:37:26,469 --> 00:37:30,640
heaven alright the last thing we talk

988
00:37:30,640 --> 00:37:34,599
about is how to determine whether

989
00:37:34,599 --> 00:37:38,799
something is reclaimed right and ideally

990
00:37:38,799 --> 00:37:40,509
what we want here is that in order for

991
00:37:40,509 --> 00:37:43,479
our system to be scalable then we want

992
00:37:43,479 --> 00:37:44,559
to be able to examine what are our

993
00:37:44,559 --> 00:37:47,259
active transactions and what are the

994
00:37:47,259 --> 00:37:48,670
reclaim old versions we can deal with

995
00:37:48,670 --> 00:37:50,049
and we want to do this what I haven't

996
00:37:50,049 --> 00:37:52,329
acquired any latches so this what I've

997
00:37:52,329 --> 00:37:53,799
seen before in the hyper paper they

998
00:37:53,799 --> 00:37:55,749
maintain a latch free link list that I

999
00:37:55,749 --> 00:37:57,099
can keep sort of pretty efficiently and

1000
00:37:57,099 --> 00:37:58,719
I can use that to figure out what are my

1001
00:37:58,719 --> 00:38:02,859
current transactions so an important

1002
00:38:02,859 --> 00:38:05,289
concept to understand too is that unlike

1003
00:38:05,289 --> 00:38:07,779
in when we're actually running the

1004
00:38:07,779 --> 00:38:09,849
queries under snapshot isolation where

1005
00:38:09,849 --> 00:38:12,039
we can't have any false positives or

1006
00:38:12,039 --> 00:38:14,680
false negatives right of missing data we

1007
00:38:14,680 --> 00:38:16,660
should actually see and somehow we miss

1008
00:38:16,660 --> 00:38:19,239
it and for garbage collection we

1009
00:38:19,239 --> 00:38:20,739
actually can be a bit loosey goosey here

1010
00:38:20,739 --> 00:38:22,959
and it's okay if we end up missing

1011
00:38:22,959 --> 00:38:25,630
something right so if my garbage specter

1012
00:38:25,630 --> 00:38:27,670
runs and at that exact same moment

1013
00:38:27,670 --> 00:38:29,440
another thread commits a transaction

1014
00:38:29,440 --> 00:38:31,359
with a bunch of tuples that are

1015
00:38:31,359 --> 00:38:32,680
reclaiming bunch of physical versions

1016
00:38:32,680 --> 00:38:35,019
that are reclaimed well and if you know

1017
00:38:35,019 --> 00:38:37,209
if I end up missing at the carpet I

1018
00:38:37,209 --> 00:38:39,009
should ended up missing that during its

1019
00:38:39,009 --> 00:38:41,440
path of the you know that current

1020
00:38:41,440 --> 00:38:44,589
current invocation who cares because the

1021
00:38:44,589 --> 00:38:46,209
next time I run around then I'll then

1022
00:38:46,209 --> 00:38:49,930
I'll be able to see it so we can use we

1023
00:38:49,930 --> 00:38:52,269
don't need to you know we don't need to

1024
00:38:52,269 --> 00:38:53,890
have you know super tight protection

1025
00:38:53,890 --> 00:38:56,259
over the critical sections of where and

1026
00:38:56,259 --> 00:38:58,299
we decide how to reclaim things it's

1027
00:38:58,299 --> 00:39:00,759
okay for us to maybe know something you

1028
00:39:00,759 --> 00:39:01,959
know at least once and the second time

1029
00:39:01,959 --> 00:39:04,150
around we'll see it

1030
00:39:04,150 --> 00:39:05,920
so this is now is the important part of

1031
00:39:05,920 --> 00:39:07,650
the the the one of the main

1032
00:39:07,650 --> 00:39:09,490
contributions of the hyper paper

1033
00:39:09,490 --> 00:39:10,900
although they did not invent this

1034
00:39:10,900 --> 00:39:12,940
interval stuff it actually comes from

1035
00:39:12,940 --> 00:39:16,180
the from the Hana paper but it basically

1036
00:39:16,180 --> 00:39:17,440
saying how are you going to determine

1037
00:39:17,440 --> 00:39:19,180
whether something is a claimant or not

1038
00:39:19,180 --> 00:39:21,850
so for this one for the time stamp this

1039
00:39:21,850 --> 00:39:23,020
is what they call a traditional garbage

1040
00:39:23,020 --> 00:39:24,790
collection in their paper this is just

1041
00:39:24,790 --> 00:39:26,770
gonna I know what the minimum time stamp

1042
00:39:26,770 --> 00:39:29,050
is for all my active transactions and

1043
00:39:29,050 --> 00:39:31,300
therefore anything less than then that

1044
00:39:31,300 --> 00:39:33,400
time stamp is not visible to any of

1045
00:39:33,400 --> 00:39:34,900
those active transactions and therefore

1046
00:39:34,900 --> 00:39:38,050
I can go ahead and we claim that the

1047
00:39:38,050 --> 00:39:40,000
interval approach is that is will be a

1048
00:39:40,000 --> 00:39:43,900
bit more bit more crafty and we can then

1049
00:39:43,900 --> 00:39:48,210
now look at ranges of time stamps and

1050
00:39:48,210 --> 00:39:50,890
identify if there's vert partisan

1051
00:39:50,890 --> 00:39:52,840
version change that are not visible at

1052
00:39:52,840 --> 00:39:55,780
all and instead of actually waiting for

1053
00:39:55,780 --> 00:39:58,270
to you know to take the oldest one out

1054
00:39:58,270 --> 00:40:00,880
first and sort of prune it along in time

1055
00:40:00,880 --> 00:40:02,950
stamp order we can actually excise out

1056
00:40:02,950 --> 00:40:05,740
that range that's not visible reconnect

1057
00:40:05,740 --> 00:40:08,620
the Virgin chain and things are things

1058
00:40:08,620 --> 00:40:10,450
are perfectly fine because everybody can

1059
00:40:10,450 --> 00:40:11,590
see whatever you know what they're

1060
00:40:11,590 --> 00:40:13,630
supposed to see so the tricky thing is

1061
00:40:13,630 --> 00:40:14,920
going to be is how do we identify these

1062
00:40:14,920 --> 00:40:17,920
ranges and how do we do the solid ation

1063
00:40:17,920 --> 00:40:19,980
of our virgin chain to remove those

1064
00:40:19,980 --> 00:40:23,560
invisible ranges so let's say now we

1065
00:40:23,560 --> 00:40:25,390
have a simple example like this we have

1066
00:40:25,390 --> 00:40:28,260
transaction one he's gonna read a right

1067
00:40:28,260 --> 00:40:31,810
transaction to is going to update a high

1068
00:40:31,810 --> 00:40:35,290
and so now we have an older version or a

1069
00:40:35,290 --> 00:40:37,720
one that we eventually think we're gonna

1070
00:40:37,720 --> 00:40:39,220
remove is this guy who goes has and

1071
00:40:39,220 --> 00:40:41,860
commits which it does at twenty five so

1072
00:40:41,860 --> 00:40:43,510
now we have another transaction comes

1073
00:40:43,510 --> 00:40:47,080
along updates 30 and then commits it 35

1074
00:40:47,080 --> 00:40:49,870
it's not at this point here a two is

1075
00:40:49,870 --> 00:40:52,930
reclaim Abul because the only other

1076
00:40:52,930 --> 00:40:55,210
transaction running is is the first guy

1077
00:40:55,210 --> 00:40:58,000
here he's at timestamp 10 so he can

1078
00:40:58,000 --> 00:41:01,810
never see 25 or 35 he can't see this a3

1079
00:41:01,810 --> 00:41:04,030
either but under snaps isolation he's

1080
00:41:04,030 --> 00:41:06,160
not he's not allowed to so we had this

1081
00:41:06,160 --> 00:41:07,750
guy here that we need to go ahead and

1082
00:41:07,750 --> 00:41:10,840
remove so if we're doing the timestamp

1083
00:41:10,840 --> 00:41:13,030
comparison then our garbage collector

1084
00:41:13,030 --> 00:41:14,650
can't remove a two because our high

1085
00:41:14,650 --> 00:41:16,000
watermark are that the low-water mark

1086
00:41:16,000 --> 00:41:17,650
the lowest timestamp of inaccurate

1087
00:41:17,650 --> 00:41:21,009
and is 10 therefore 25 is greater than

1088
00:41:21,009 --> 00:41:24,009
10 so we can't remove this but if we're

1089
00:41:24,009 --> 00:41:25,960
doing the interval based approach then

1090
00:41:25,960 --> 00:41:27,670
we can't reclaim this because the

1091
00:41:27,670 --> 00:41:30,730
timestamp 10 does not intersect with the

1092
00:41:30,730 --> 00:41:33,369
lifetime range of 25 and 35 for this

1093
00:41:33,369 --> 00:41:36,099
version 10 can never see this thing so

1094
00:41:36,099 --> 00:41:39,999
we go ahead and remove this so for this

1095
00:41:39,999 --> 00:41:41,440
approach if you're doing the pen only

1096
00:41:41,440 --> 00:41:44,859
storage this is easy to do because all I

1097
00:41:44,859 --> 00:41:47,349
have to do now is just update if I'm

1098
00:41:47,349 --> 00:41:48,789
going oldest to newest I can just update

1099
00:41:48,789 --> 00:41:51,099
the pointer for a1 and now point it to a

1100
00:41:51,099 --> 00:41:54,009
3 and then a 2 now is essentially

1101
00:41:54,009 --> 00:41:55,150
missing and I can go ahead and reclaim

1102
00:41:55,150 --> 00:41:57,339
it and because everything I need to

1103
00:41:57,339 --> 00:41:59,980
reconstruct the tuple just say what you

1104
00:41:59,980 --> 00:42:01,180
know what is the version of this tuple

1105
00:42:01,180 --> 00:42:03,910
at and Pickler timestamp it's contained

1106
00:42:03,910 --> 00:42:06,130
in the tuple itself because again a pen

1107
00:42:06,130 --> 00:42:09,069
only has all the attributes this is now

1108
00:42:09,069 --> 00:42:11,170
harder to do though if you're doing

1109
00:42:11,170 --> 00:42:12,880
deltal storage because you may not have

1110
00:42:12,880 --> 00:42:15,249
all the attributes so let's look at

1111
00:42:15,249 --> 00:42:17,339
example here so say I have one tuple

1112
00:42:17,339 --> 00:42:21,009
right that's a timestamp 60 and then I

1113
00:42:21,009 --> 00:42:24,039
have a long version chain like this so I

1114
00:42:24,039 --> 00:42:26,289
have now my first transaction he's

1115
00:42:26,289 --> 00:42:28,539
running at timestamp 15 so again I need

1116
00:42:28,539 --> 00:42:31,140
to see a versions of tuples as existed

1117
00:42:31,140 --> 00:42:33,690
from committed transactions at time stam

1118
00:42:33,690 --> 00:42:36,730
time-stamped 15 or less so I can read a

1119
00:42:36,730 --> 00:42:40,539
10 down here my other guy here he's he's

1120
00:42:40,539 --> 00:42:44,680
going to read anything above a 55 and

1121
00:42:44,680 --> 00:42:47,289
less so that means that this basic chunk

1122
00:42:47,289 --> 00:42:50,349
of tuples here are potentially reclaimed

1123
00:42:50,349 --> 00:42:53,049
not 50 but all these other ones are here

1124
00:42:53,049 --> 00:42:54,880
our reclaim a little but but now the

1125
00:42:54,880 --> 00:42:57,430
problem is because we're doing Delta

1126
00:42:57,430 --> 00:42:59,470
storage some of these have touching

1127
00:42:59,470 --> 00:43:00,640
attribute - some of these are touching

1128
00:43:00,640 --> 00:43:02,140
attribute one so when we do our

1129
00:43:02,140 --> 00:43:04,690
consolidation we sort of need to take a

1130
00:43:04,690 --> 00:43:06,759
union and of these different Delta

1131
00:43:06,759 --> 00:43:09,039
records and only have the latest version

1132
00:43:09,039 --> 00:43:12,460
or latest modification to a particular

1133
00:43:12,460 --> 00:43:14,589
attribute in our final compacted or

1134
00:43:14,589 --> 00:43:17,109
consolidated Delta record right so in

1135
00:43:17,109 --> 00:43:19,660
this case here I update attribute to 3

1136
00:43:19,660 --> 00:43:23,380
times 77 88 99 so when I create now my

1137
00:43:23,380 --> 00:43:25,930
consolidated version the latest version

1138
00:43:25,930 --> 00:43:28,599
of attribute - is 99 and therefore I can

1139
00:43:28,599 --> 00:43:30,340
discard these other Delta

1140
00:43:30,340 --> 00:43:32,740
here but this guy down here modified

1141
00:43:32,740 --> 00:43:35,440
attribute one so I need to know that in

1142
00:43:35,440 --> 00:43:36,910
order to understand you know understand

1143
00:43:36,910 --> 00:43:38,620
order to recreate the version this tuple

1144
00:43:38,620 --> 00:43:41,500
at timestamp 50 so I had to record that

1145
00:43:41,500 --> 00:43:44,230
in my record as well and then the

1146
00:43:44,230 --> 00:43:46,150
timestamp I'm gonna sign for this

1147
00:43:46,150 --> 00:43:48,550
consolidated Delta record will be the

1148
00:43:48,550 --> 00:43:51,000
max timestamp of what I consolidate

1149
00:43:51,000 --> 00:43:55,450
alright so again now if I could you know

1150
00:43:55,450 --> 00:43:57,490
if I come along this guy wants to read

1151
00:43:57,490 --> 00:44:00,160
15 at times to 15 he can still get to a

1152
00:44:00,160 --> 00:44:02,440
10 this guy wants to read a timestamp 55

1153
00:44:02,440 --> 00:44:04,480
he can still find this one and it will

1154
00:44:04,480 --> 00:44:06,160
have all the information for all the

1155
00:44:06,160 --> 00:44:08,080
Delta Records that occurred after

1156
00:44:08,080 --> 00:44:11,530
timestamp 50 here so now to install it

1157
00:44:11,530 --> 00:44:14,020
right well I have the point into that I

1158
00:44:14,020 --> 00:44:15,670
just do a compare and swap on the

1159
00:44:15,670 --> 00:44:17,800
version vector to now update it here

1160
00:44:17,800 --> 00:44:19,720
again first writer wins we're treating

1161
00:44:19,720 --> 00:44:21,130
this as this you know it's like an

1162
00:44:21,130 --> 00:44:22,450
update but it's like an internal update

1163
00:44:22,450 --> 00:44:24,130
so if somebody else comes up this

1164
00:44:24,130 --> 00:44:25,270
version vector why we're doing some

1165
00:44:25,270 --> 00:44:28,150
consolidation then we fail and have to

1166
00:44:28,150 --> 00:44:30,100
restart but let's say again it succeeds

1167
00:44:30,100 --> 00:44:33,040
so now my my version vector points to

1168
00:44:33,040 --> 00:44:35,530
this consolidated one and then I can

1169
00:44:35,530 --> 00:44:37,570
blow away the the rest of the version

1170
00:44:37,570 --> 00:44:46,480
chain yes your question is do I require

1171
00:44:46,480 --> 00:44:47,530
that these rep these things are

1172
00:44:47,530 --> 00:44:50,200
committed again under Delta storage

1173
00:44:50,200 --> 00:44:55,000
first writer wins the it's either this

1174
00:44:55,000 --> 00:44:56,620
is always going to be the committed

1175
00:44:56,620 --> 00:44:58,810
version if the version vector is null or

1176
00:44:58,810 --> 00:45:00,550
the latest committed version is the

1177
00:45:00,550 --> 00:45:03,250
first one everything else is already

1178
00:45:03,250 --> 00:45:06,250
committed as well right so it's not like

1179
00:45:06,250 --> 00:45:07,480
this is like an in-flight transaction

1180
00:45:07,480 --> 00:45:09,330
because nobody no one can create another

1181
00:45:09,330 --> 00:45:11,620
no two transactions can create Delta

1182
00:45:11,620 --> 00:45:14,140
records on the same same logical tuple

1183
00:45:14,140 --> 00:45:16,300
because the first guy would be able to

1184
00:45:16,300 --> 00:45:23,670
succeed yes sorry

1185
00:45:32,349 --> 00:45:35,690
yeah question is how do I actually do

1186
00:45:35,690 --> 00:45:37,910
the union of do the consolidation of

1187
00:45:37,910 --> 00:45:40,489
these Delta records so you would go back

1188
00:45:40,489 --> 00:45:43,099
in time he would say I know I have X

1189
00:45:43,099 --> 00:45:45,229
number attributes and so I need to make

1190
00:45:45,229 --> 00:45:47,779
sure that when I do my pass as soon as I

1191
00:45:47,779 --> 00:45:50,539
see sooner that I see all all the

1192
00:45:50,539 --> 00:45:52,369
attributes then I know that there's

1193
00:45:52,369 --> 00:45:53,989
nothing else that I would care about

1194
00:45:53,989 --> 00:45:55,940
that comes after this and therefore that

1195
00:45:55,940 --> 00:45:58,279
I you stop the process it because you

1196
00:45:58,279 --> 00:46:00,259
have to be able say these you follow the

1197
00:46:00,259 --> 00:46:01,190
Virgin chain and say this is what I'm

1198
00:46:01,190 --> 00:46:03,289
gonna reclaim but you don't need to

1199
00:46:03,289 --> 00:46:04,849
you're not up being the Delta record

1200
00:46:04,849 --> 00:46:06,259
with the new Dell record with that

1201
00:46:06,259 --> 00:46:09,769
information so we did this as a class

1202
00:46:09,769 --> 00:46:13,309
project last year trying to member why

1203
00:46:13,309 --> 00:46:15,769
it was tricky I think it's something in

1204
00:46:15,769 --> 00:46:18,950
the ordering of reclaiming verbal link

1205
00:46:18,950 --> 00:46:22,119
data that makes this challenging because

1206
00:46:22,119 --> 00:46:24,529
you would have like this is showing the

1207
00:46:24,529 --> 00:46:26,509
string embedded in the Delta record but

1208
00:46:26,509 --> 00:46:28,130
if it's a large string then it's a this

1209
00:46:28,130 --> 00:46:29,450
is actually a pointer to the variable

1210
00:46:29,450 --> 00:46:31,369
length pool and I think we got into

1211
00:46:31,369 --> 00:46:33,259
trouble of trying to get the order of

1212
00:46:33,259 --> 00:46:35,569
that correct but this would be something

1213
00:46:35,569 --> 00:46:38,180
we could potentially explore again the

1214
00:46:38,180 --> 00:46:41,660
semester the it really you know if you

1215
00:46:41,660 --> 00:46:42,589
sort of do this project

1216
00:46:42,589 --> 00:46:43,700
it would really force you to think

1217
00:46:43,700 --> 00:46:44,930
through like this verging information

1218
00:46:44,930 --> 00:46:46,849
and what are all the corner cases but

1219
00:46:46,849 --> 00:46:47,930
this is obviously an over

1220
00:46:47,930 --> 00:46:50,170
oversimplification of the of the problem

1221
00:46:50,170 --> 00:46:54,219
so okay yes

1222
00:47:03,970 --> 00:47:07,340
your question is for doing garbage

1223
00:47:07,340 --> 00:47:09,109
question on Delta records do we have to

1224
00:47:09,109 --> 00:47:10,369
do this consolidation or cap action

1225
00:47:10,369 --> 00:47:15,609
first and then we can clean some no big

1226
00:47:19,540 --> 00:47:26,920
so how would you know action one - if

1227
00:47:26,920 --> 00:47:32,630
say I remove thread one right all I care

1228
00:47:32,630 --> 00:47:34,700
about like if I know that nobody else

1229
00:47:34,700 --> 00:47:35,930
can read anything that comes after this

1230
00:47:35,930 --> 00:47:37,910
then they're always gonna read the

1231
00:47:37,910 --> 00:47:39,980
version up here I'm only doing this

1232
00:47:39,980 --> 00:47:41,119
consolidation because I know that this

1233
00:47:41,119 --> 00:47:42,650
guy here could read this I need to know

1234
00:47:42,650 --> 00:47:44,359
what was the version that came after

1235
00:47:44,359 --> 00:47:48,470
that right if I don't event if I'm I

1236
00:47:48,470 --> 00:47:49,760
don't need to do this interval

1237
00:47:49,760 --> 00:47:52,970
consolidation it's a it's a nice thing

1238
00:47:52,970 --> 00:47:54,260
to have but you don't need it for

1239
00:47:54,260 --> 00:47:56,119
correctness right because without it

1240
00:47:56,119 --> 00:47:58,460
although I without it I have to wait for

1241
00:47:58,460 --> 00:48:01,400
this guy to commit or B go away before I

1242
00:48:01,400 --> 00:48:12,040
can then prune everything else yes yes

1243
00:48:12,040 --> 00:48:15,109
yes so his question is do I really need

1244
00:48:15,109 --> 00:48:21,920
to consolidate this couldn't I just yep

1245
00:48:21,920 --> 00:48:23,810
remove these guys keep this one and

1246
00:48:23,810 --> 00:48:25,640
would that be enough yeah that would

1247
00:48:25,640 --> 00:48:33,619
actually still work - it would need the

1248
00:48:33,619 --> 00:48:35,540
morning no because I think it would what

1249
00:48:35,540 --> 00:48:38,450
are you saying is right so we're back

1250
00:48:38,450 --> 00:48:40,910
here so instead of consolidating into

1251
00:48:40,910 --> 00:48:43,670
this new guy I keep this and I can

1252
00:48:43,670 --> 00:48:45,080
remove these guys because those are

1253
00:48:45,080 --> 00:48:47,240
overwritten by this and all I do is now

1254
00:48:47,240 --> 00:48:50,420
update this pointer now to this that

1255
00:48:50,420 --> 00:48:58,490
would work oh yeah so - yes when I when

1256
00:48:58,490 --> 00:49:00,350
I scan I want to get back to see what

1257
00:49:00,350 --> 00:49:04,450
the cry version is yes yeah

1258
00:49:06,820 --> 00:49:08,930
yeah I don't like the paper covers like

1259
00:49:08,930 --> 00:49:10,850
even obviously to devise different

1260
00:49:10,850 --> 00:49:12,740
synthetic benchmarks to exercise your

1261
00:49:12,740 --> 00:49:14,840
different update patterns I don't know

1262
00:49:14,840 --> 00:49:16,190
what real work was actually do you know

1263
00:49:16,190 --> 00:49:17,920
say went one way is better than another

1264
00:49:17,920 --> 00:49:20,590
when we did this last year I think we

1265
00:49:20,590 --> 00:49:23,840
created a new Delta record and then the

1266
00:49:23,840 --> 00:49:29,360
tricky thing was you create the new

1267
00:49:29,360 --> 00:49:31,820
Delta record yeah the tricky thing is

1268
00:49:31,820 --> 00:49:33,800
yeah no matter this the issue was going

1269
00:49:33,800 --> 00:49:36,560
to be this these things are sitting in

1270
00:49:36,560 --> 00:49:38,600
the the each of the tougher records are

1271
00:49:38,600 --> 00:49:39,860
sitting in the in the thread-local

1272
00:49:39,860 --> 00:49:41,960
memory for the transactions that ran

1273
00:49:41,960 --> 00:49:44,270
them but then now the problem is gonna

1274
00:49:44,270 --> 00:49:48,950
be and it would be normally only the

1275
00:49:48,950 --> 00:49:51,380
thread would reclaim that memory but now

1276
00:49:51,380 --> 00:49:53,510
you have this consolidation thread in

1277
00:49:53,510 --> 00:49:55,070
the background wants to be able reclaim

1278
00:49:55,070 --> 00:49:56,420
things and you have to like take latches

1279
00:49:56,420 --> 00:49:57,650
on protect the memory space and it

1280
00:49:57,650 --> 00:49:59,180
actually made up things go slower I

1281
00:49:59,180 --> 00:50:00,980
don't know the exact details of we have

1282
00:50:00,980 --> 00:50:08,200
notes to know for okay alright so the

1283
00:50:08,200 --> 00:50:10,310
the next thing what the sort of finish

1284
00:50:10,310 --> 00:50:14,210
up with this discussion is in all these

1285
00:50:14,210 --> 00:50:16,000
examples it's sort of obvious that yes

1286
00:50:16,000 --> 00:50:17,900
reclaiming memory is a good idea right

1287
00:50:17,900 --> 00:50:20,030
we want to get you if it's we don't need

1288
00:50:20,030 --> 00:50:21,830
the data we should go ahead and free up

1289
00:50:21,830 --> 00:50:23,869
the space but now the question is what

1290
00:50:23,869 --> 00:50:26,000
do we actually do with that memory we

1291
00:50:26,000 --> 00:50:29,630
just freed up right because say I have a

1292
00:50:29,630 --> 00:50:32,930
I inserted billion tuples and then I

1293
00:50:32,930 --> 00:50:35,690
delete a billion tuples what should

1294
00:50:35,690 --> 00:50:38,510
happen I should I give back the OS that

1295
00:50:38,510 --> 00:50:40,300
the the memory for that 1 billion tuples

1296
00:50:40,300 --> 00:50:42,440
or should I give back some of it or just

1297
00:50:42,440 --> 00:50:44,840
keep it all myself I think it's actually

1298
00:50:44,840 --> 00:50:46,430
want to be in in the middle right I

1299
00:50:46,430 --> 00:50:47,600
think you'd want to keep some of it but

1300
00:50:47,600 --> 00:50:48,619
you do want to give some back right

1301
00:50:48,619 --> 00:50:49,670
because I people would end up thinking

1302
00:50:49,670 --> 00:50:51,920
their system is broken if I sort of

1303
00:50:51,920 --> 00:50:53,330
billion things and then delete a billion

1304
00:50:53,330 --> 00:50:55,130
things and the memory you should doesn't

1305
00:50:55,130 --> 00:51:00,710
go down all right so for the very length

1306
00:51:00,710 --> 00:51:03,320
data data pool we can always just reuse

1307
00:51:03,320 --> 00:51:05,359
the the memory spaces right because

1308
00:51:05,359 --> 00:51:06,470
we're essentially doing a bin packing

1309
00:51:06,470 --> 00:51:08,180
problem to find you know for every

1310
00:51:08,180 --> 00:51:09,470
single move you actually need to store

1311
00:51:09,470 --> 00:51:11,030
in a Berlin data pool we just find a

1312
00:51:11,030 --> 00:51:13,010
free slot and put it in there for the

1313
00:51:13,010 --> 00:51:15,050
fixed link data start slots it's a bit

1314
00:51:15,050 --> 00:51:17,920
more tricky because

1315
00:51:19,200 --> 00:51:25,549
if we start reusing the slots for tuples

1316
00:51:25,549 --> 00:51:28,290
you know as we need them as we claim

1317
00:51:28,290 --> 00:51:30,450
versions then that could end up causing

1318
00:51:30,450 --> 00:51:33,839
us the sort of the the temporal aspect

1319
00:51:33,839 --> 00:51:35,549
of the temporal dimension all of our

1320
00:51:35,549 --> 00:51:40,020
data is now sort of randomized so what I

1321
00:51:40,020 --> 00:51:44,369
mean at that so like say I have a I have

1322
00:51:44,369 --> 00:51:45,869
an application where most of the time

1323
00:51:45,869 --> 00:51:48,000
people touch the latest data being like

1324
00:51:48,000 --> 00:51:50,430
reddit or hacker news mostly will only

1325
00:51:50,430 --> 00:51:52,980
comment on the latest posts nobody goes

1326
00:51:52,980 --> 00:51:54,660
back five months ago I don't think even

1327
00:51:54,660 --> 00:51:57,030
let you and tries to update know write a

1328
00:51:57,030 --> 00:51:58,230
comment on a post when five months ago

1329
00:51:58,230 --> 00:52:02,819
so that means that now if if I am if I

1330
00:52:02,819 --> 00:52:04,920
ignore the multi version and stuff if as

1331
00:52:04,920 --> 00:52:06,270
I create new tuples for all these

1332
00:52:06,270 --> 00:52:09,630
comments on these articles the they're

1333
00:52:09,630 --> 00:52:12,119
approximately going to be located close

1334
00:52:12,119 --> 00:52:13,559
to each other and had the same time

1335
00:52:13,559 --> 00:52:15,630
because say I'm inserting a new comment

1336
00:52:15,630 --> 00:52:17,609
sort of going from chronologically

1337
00:52:17,609 --> 00:52:19,500
they're all gonna be related together or

1338
00:52:19,500 --> 00:52:20,490
close together in the same amount of

1339
00:52:20,490 --> 00:52:21,920
time since when they were created right

1340
00:52:21,920 --> 00:52:24,240
it's not like I'm gonna go try to insert

1341
00:52:24,240 --> 00:52:25,680
a comment from an article five months

1342
00:52:25,680 --> 00:52:26,910
ago and now that's interspersed with

1343
00:52:26,910 --> 00:52:29,609
with articles from from today and so the

1344
00:52:29,609 --> 00:52:31,319
reason why that matters is because in

1345
00:52:31,319 --> 00:52:35,520
ogv workloads the probability that your

1346
00:52:35,520 --> 00:52:38,760
tuple is going to be updated is depends

1347
00:52:38,760 --> 00:52:39,720
on the sort of the last time there's

1348
00:52:39,720 --> 00:52:42,020
access or when it was inserted so if my

1349
00:52:42,020 --> 00:52:45,059
my first version was inserted today the

1350
00:52:45,059 --> 00:52:46,829
probability I'm gonna update it is

1351
00:52:46,829 --> 00:52:48,990
higher today than it will be five months

1352
00:52:48,990 --> 00:52:50,700
from now because most the times you only

1353
00:52:50,700 --> 00:52:55,020
only update the the latest things so if

1354
00:52:55,020 --> 00:52:57,119
now within my blocks of data if they're

1355
00:52:57,119 --> 00:52:58,920
all roughly around the same you know

1356
00:52:58,920 --> 00:53:01,079
create at the same time write the

1357
00:53:01,079 --> 00:53:02,160
versions are created at the same time

1358
00:53:02,160 --> 00:53:04,140
then I know they're gonna have the same

1359
00:53:04,140 --> 00:53:05,609
probability that they're going to be

1360
00:53:05,609 --> 00:53:07,020
updated and therefore it potentially

1361
00:53:07,020 --> 00:53:09,059
invalidated and so therefore if I have

1362
00:53:09,059 --> 00:53:10,770
data that's from five months ago all in

1363
00:53:10,770 --> 00:53:12,960
one block I can now compress it make it

1364
00:53:12,960 --> 00:53:15,869
read only and not worry about having to

1365
00:53:15,869 --> 00:53:19,049
go uncompress it to update something and

1366
00:53:19,049 --> 00:53:20,640
then rerun the compression scheme all

1367
00:53:20,640 --> 00:53:22,980
over again does that make sense

1368
00:53:22,980 --> 00:53:24,990
like if data is located together they're

1369
00:53:24,990 --> 00:53:26,309
all create at the same time therefore

1370
00:53:26,309 --> 00:53:28,020
it's all gonna be updated with the same

1371
00:53:28,020 --> 00:53:30,150
probability then I can use compression

1372
00:53:30,150 --> 00:53:32,069
now to come to reduce the size of that

1373
00:53:32,069 --> 00:53:33,090
block of data

1374
00:53:33,090 --> 00:53:34,590
and not worry about having a rerun

1375
00:53:34,590 --> 00:53:37,770
compression later on so you don't wanna

1376
00:53:37,770 --> 00:53:38,790
compress the newer things you want to

1377
00:53:38,790 --> 00:53:39,990
press the older things because the older

1378
00:53:39,990 --> 00:53:43,560
things are gonna be read-only so this is

1379
00:53:43,560 --> 00:53:45,330
sort of the two issues if I if I reuse

1380
00:53:45,330 --> 00:53:47,610
the slot anyway that I want as I create

1381
00:53:47,610 --> 00:53:50,430
new versions and and we claim old

1382
00:53:50,430 --> 00:53:53,430
versions then in my physical layout of

1383
00:53:53,430 --> 00:53:55,200
memory it's going to be randomized like

1384
00:53:55,200 --> 00:53:56,820
some stuff will be new some stuff will

1385
00:53:56,820 --> 00:53:59,220
be old and now if I go to compress it if

1386
00:53:59,220 --> 00:54:00,870
there's some intermix with old new if I

1387
00:54:00,870 --> 00:54:03,930
compress that block of data then the

1388
00:54:03,930 --> 00:54:05,160
there's something in there that could be

1389
00:54:05,160 --> 00:54:07,350
updated and then I have to you know do

1390
00:54:07,350 --> 00:54:09,000
compression all over again so we lose

1391
00:54:09,000 --> 00:54:12,000
that temporal locality we could just

1392
00:54:12,000 --> 00:54:14,250
leave leave it alone and basically have

1393
00:54:14,250 --> 00:54:16,590
these slots unused these holes in these

1394
00:54:16,590 --> 00:54:19,260
that in the slots and this is bad

1395
00:54:19,260 --> 00:54:21,660
because and you know ya know how much of

1396
00:54:21,660 --> 00:54:22,980
holes and space that we can't we can't

1397
00:54:22,980 --> 00:54:24,450
use but we're still allocated that

1398
00:54:24,450 --> 00:54:26,520
memory so at some later point we have to

1399
00:54:26,520 --> 00:54:30,270
go back and do compaction and and sort

1400
00:54:30,270 --> 00:54:31,740
of consolidate multiple blocks with a

1401
00:54:31,740 --> 00:54:33,360
bunch of holes and you know combine them

1402
00:54:33,360 --> 00:54:37,020
together so they get we get better we

1403
00:54:37,020 --> 00:54:38,730
get better utilization and less

1404
00:54:38,730 --> 00:54:42,480
fragmentation there's a third approach

1405
00:54:42,480 --> 00:54:45,720
that's sort of tied to this like when

1406
00:54:45,720 --> 00:54:47,340
you do truncate the command truncate

1407
00:54:47,340 --> 00:54:48,540
truncate basically delete without a

1408
00:54:48,540 --> 00:54:50,640
where clause but you can special case

1409
00:54:50,640 --> 00:54:53,190
special case it because instead of

1410
00:54:53,190 --> 00:54:55,770
having to scan through and delete tuples

1411
00:54:55,770 --> 00:54:57,750
and basically examine them with without

1412
00:54:57,750 --> 00:54:59,520
a where clause and set them to delete

1413
00:54:59,520 --> 00:55:02,280
the easy way to do truncation is just to

1414
00:55:02,280 --> 00:55:04,650
drop table and then recreate it blow

1415
00:55:04,650 --> 00:55:05,850
away all the indexes blow away the table

1416
00:55:05,850 --> 00:55:07,740
space and is recreated and that way you

1417
00:55:07,740 --> 00:55:09,480
don't worry about any of this locality

1418
00:55:09,480 --> 00:55:11,120
information or look look howdy

1419
00:55:11,120 --> 00:55:13,770
attributes it's just stuff from scratch

1420
00:55:13,770 --> 00:55:16,200
all over again but truncate truncate is

1421
00:55:16,200 --> 00:55:18,600
a special case so now to do the

1422
00:55:18,600 --> 00:55:21,090
compaction that I was talking about yeah

1423
00:55:21,090 --> 00:55:23,300
sorry

1424
00:55:28,620 --> 00:55:31,750
the question is for the 5-month example

1425
00:55:31,750 --> 00:55:33,760
why am i assuming that i would not that

1426
00:55:33,760 --> 00:55:34,960
would compact them all together and not

1427
00:55:34,960 --> 00:55:38,710
delete them all together you can protect

1428
00:55:38,710 --> 00:55:41,320
you would do both so like there's some

1429
00:55:41,320 --> 00:55:43,480
websites where they only expose like the

1430
00:55:43,480 --> 00:55:45,520
last 90 days of data to you and

1431
00:55:45,520 --> 00:55:48,010
essentially they're doing like a TTL or

1432
00:55:48,010 --> 00:55:50,290
deleting data as it gets older in that

1433
00:55:50,290 --> 00:55:52,930
case like if all the data is in a block

1434
00:55:52,930 --> 00:55:55,810
as it has was created within the same

1435
00:55:55,810 --> 00:55:58,180
timestamp at the same time range when I

1436
00:55:58,180 --> 00:55:59,800
do that pruning the whole block gets

1437
00:55:59,800 --> 00:56:02,350
blown away and then I can recycle it it

1438
00:56:02,350 --> 00:56:04,480
was all intermixed then I end up

1439
00:56:04,480 --> 00:56:05,740
deleting some tuples that are five

1440
00:56:05,740 --> 00:56:07,270
months old and some other tuples that

1441
00:56:07,270 --> 00:56:08,380
are three months old they have to stay

1442
00:56:08,380 --> 00:56:10,980
now but now I have a bunch of holes yeah

1443
00:56:10,980 --> 00:56:14,110
again for compression assuming we want

1444
00:56:14,110 --> 00:56:15,610
to keep all their data compression is we

1445
00:56:15,610 --> 00:56:17,710
want we want a block of data that is

1446
00:56:17,710 --> 00:56:20,380
never going to be updated again we could

1447
00:56:20,380 --> 00:56:21,880
still do it if we need to we have to

1448
00:56:21,880 --> 00:56:24,130
support that but it's unlikely to be

1449
00:56:24,130 --> 00:56:25,030
updated so therefore we can use

1450
00:56:25,030 --> 00:56:27,010
heavyweight compression to reduce its

1451
00:56:27,010 --> 00:56:30,100
size and then if anybody tries update it

1452
00:56:30,100 --> 00:56:31,090
well we'll take care of it but we want

1453
00:56:31,090 --> 00:56:32,950
to avoid that so it's all the same size

1454
00:56:32,950 --> 00:56:35,440
it won't be updated again it's all Craig

1455
00:56:35,440 --> 00:56:36,990
round the same time it won't be updated

1456
00:56:36,990 --> 00:56:40,090
again in the future all right so go

1457
00:56:40,090 --> 00:56:41,080
patch it again it's basically ideas

1458
00:56:41,080 --> 00:56:43,690
we're finding these empty blocks start

1459
00:56:43,690 --> 00:56:45,760
blocks that have holes in them all right

1460
00:56:45,760 --> 00:56:46,990
this one's half-full this one's half

1461
00:56:46,990 --> 00:56:48,460
full rather than having to have full

1462
00:56:48,460 --> 00:56:50,500
blocks I can bind them together into one

1463
00:56:50,500 --> 00:56:55,570
full full block so ideally again this is

1464
00:56:55,570 --> 00:56:57,490
what I've seen before if the if the

1465
00:56:57,490 --> 00:56:59,310
tuples are likely be accessed together

1466
00:56:59,310 --> 00:57:01,720
in the same window time we want to put

1467
00:57:01,720 --> 00:57:03,190
them in the same block because when we

1468
00:57:03,190 --> 00:57:06,190
compress them you know the likelihood

1469
00:57:06,190 --> 00:57:07,360
that one of them we updated and the

1470
00:57:07,360 --> 00:57:09,610
other ones won't be will be low right

1471
00:57:09,610 --> 00:57:11,440
there's another technique we can talk

1472
00:57:11,440 --> 00:57:13,270
about later on the semester is like if

1473
00:57:13,270 --> 00:57:15,040
we now also know that this data is very

1474
00:57:15,040 --> 00:57:17,050
unlikely not only is it not likely to be

1475
00:57:17,050 --> 00:57:19,080
updated it's also unlikely to be read

1476
00:57:19,080 --> 00:57:21,190
then we can start shoving it out the

1477
00:57:21,190 --> 00:57:23,980
disk right and start saving memory space

1478
00:57:23,980 --> 00:57:25,990
we still keep track of some information

1479
00:57:25,990 --> 00:57:27,430
in memory so if you try to read it we'll

1480
00:57:27,430 --> 00:57:31,090
go fetch it from disk but you know it's

1481
00:57:31,090 --> 00:57:32,920
still but it's the primary location is I

1482
00:57:32,920 --> 00:57:35,050
don't dis and the idea here is that at

1483
00:57:35,050 --> 00:57:36,130
the beginning the semester I said like

1484
00:57:36,130 --> 00:57:37,119
we want to be in memory

1485
00:57:37,119 --> 00:57:38,230
toom everything's in memory and we can

1486
00:57:38,230 --> 00:57:39,400
run fast but this is sort of bringing

1487
00:57:39,400 --> 00:57:41,289
back the disk in an intelligent way and

1488
00:57:41,289 --> 00:57:43,299
say well some data can be shoved out

1489
00:57:43,299 --> 00:57:45,099
most of the time we're gonna be in

1490
00:57:45,099 --> 00:57:47,230
memory but if we ever spilled a disk we

1491
00:57:47,230 --> 00:57:48,970
can handle that I think we covered that

1492
00:57:48,970 --> 00:57:52,150
on the the second or last lecture nettie

1493
00:57:52,150 --> 00:57:53,829
again it's like we're not bringing back

1494
00:57:53,829 --> 00:57:55,569
our buffer pool because that's slow it's

1495
00:57:55,569 --> 00:57:59,619
just sort of secondary storage all right

1496
00:57:59,619 --> 00:58:01,150
so the three ways we can figure out how

1497
00:58:01,150 --> 00:58:02,980
to do what's compact right we can just

1498
00:58:02,980 --> 00:58:04,930
go look at the time stamp since the last

1499
00:58:04,930 --> 00:58:07,539
the two was last updated we already had

1500
00:58:07,539 --> 00:58:08,769
that information because we're storing

1501
00:58:08,769 --> 00:58:09,940
the begin timestamp for every single

1502
00:58:09,940 --> 00:58:11,799
tuple right and we just look at that and

1503
00:58:11,799 --> 00:58:12,970
say well these things are all roughly

1504
00:58:12,970 --> 00:58:14,619
around the same time so we go ahead and

1505
00:58:14,619 --> 00:58:16,480
use that to figure out that we can go

1506
00:58:16,480 --> 00:58:18,069
ahead and remove things all right sir

1507
00:58:18,069 --> 00:58:20,950
yeah consolidating up action the other

1508
00:58:20,950 --> 00:58:22,119
approach is to look at the last time it

1509
00:58:22,119 --> 00:58:26,410
was accessed right because in if a tuple

1510
00:58:26,410 --> 00:58:29,769
was accessed now at some timestamp Mauri

1511
00:58:29,769 --> 00:58:31,059
the more recent it was access that

1512
00:58:31,059 --> 00:58:32,259
likelihood to be accessed again in the

1513
00:58:32,259 --> 00:58:33,819
near future is greater than if it was

1514
00:58:33,819 --> 00:58:34,869
access a long time ago

1515
00:58:34,869 --> 00:58:37,420
I sort of it has a decay effect for this

1516
00:58:37,420 --> 00:58:38,920
one if you're doing timestamp ordering

1517
00:58:38,920 --> 00:58:40,180
the basic time stamp warning protocol

1518
00:58:40,180 --> 00:58:41,799
with a retime sample you're recording

1519
00:58:41,799 --> 00:58:43,480
every time the thing was read then you

1520
00:58:43,480 --> 00:58:45,339
can use that otherwise you have to

1521
00:58:45,339 --> 00:58:46,839
maintain some additional metadata maybe

1522
00:58:46,839 --> 00:58:49,059
a block level because it would be too

1523
00:58:49,059 --> 00:58:51,039
expensive to maintain the access

1524
00:58:51,039 --> 00:58:52,779
timestamp on a per pupil basis because

1525
00:58:52,779 --> 00:58:54,759
now everything will read is it gonna

1526
00:58:54,759 --> 00:58:56,049
turn into a write because you have to

1527
00:58:56,049 --> 00:58:57,339
update this this timestamp

1528
00:58:57,339 --> 00:59:00,640
a third approach which as far as I know

1529
00:59:00,640 --> 00:59:02,410
nobody actually does this but a bunch of

1530
00:59:02,410 --> 00:59:05,200
people want to do this is if you can

1531
00:59:05,200 --> 00:59:07,869
infer some information about what the

1532
00:59:07,869 --> 00:59:10,599
data actually how data is related to

1533
00:59:10,599 --> 00:59:12,249
each other across tables or within the

1534
00:59:12,249 --> 00:59:14,680
same table then you can then maybe

1535
00:59:14,680 --> 00:59:16,210
combine or come back together things

1536
00:59:16,210 --> 00:59:19,410
that are going to be access to together

1537
00:59:19,410 --> 00:59:21,999
more frequently in the same block

1538
00:59:21,999 --> 00:59:23,890
because then you can apply the same

1539
00:59:23,890 --> 00:59:25,089
compaction or compression scheme you

1540
00:59:25,089 --> 00:59:27,099
want on that so foreign key would be an

1541
00:59:27,099 --> 00:59:28,660
obvious example of this if I you know if

1542
00:59:28,660 --> 00:59:31,900
I have two tables that have a foreign

1543
00:59:31,900 --> 00:59:33,819
key then the likelihood that I'm going

1544
00:59:33,819 --> 00:59:34,930
to access the parent table and then

1545
00:59:34,930 --> 00:59:36,249
follow the foreign key and get good at

1546
00:59:36,249 --> 00:59:38,230
the child table it's very high so maybe

1547
00:59:38,230 --> 00:59:40,119
I want to put those guys together close

1548
00:59:40,119 --> 00:59:41,410
together in memory so I can do

1549
00:59:41,410 --> 00:59:43,269
compaction compression together or

1550
00:59:43,269 --> 00:59:46,599
another another exam I heard once was it

1551
00:59:46,599 --> 00:59:49,690
was an order processing system where

1552
00:59:49,690 --> 00:59:50,980
they wanted to keep everything in memory

1553
00:59:50,980 --> 00:59:53,319
but then shoved sub cold orders out to

1554
00:59:53,319 --> 00:59:56,140
disk but if the order status of this of

1555
00:59:56,140 --> 00:59:58,990
this of his record this order was was

1556
00:59:58,990 --> 01:00:01,299
marked as open which could be open for

1557
01:00:01,299 --> 01:00:03,279
months at some later point they're gonna

1558
01:00:03,279 --> 01:00:04,750
come and access it again so if I can

1559
01:00:04,750 --> 01:00:07,089
learn that if the order says equals open

1560
01:00:07,089 --> 01:00:08,829
keep it in memory or keep these

1561
01:00:08,829 --> 01:00:10,509
locations anything that order status

1562
01:00:10,509 --> 01:00:12,309
close got shoved off to another location

1563
01:00:12,309 --> 01:00:14,140
then I can I can do this kind of

1564
01:00:14,140 --> 01:00:18,670
optimizations okay all right in the sake

1565
01:00:18,670 --> 01:00:19,869
of time I think we already talked about

1566
01:00:19,869 --> 01:00:23,079
truncate write basically trunk a zit

1567
01:00:23,079 --> 01:00:24,880
delete without aware clause delete

1568
01:00:24,880 --> 01:00:26,589
everything run your garbage collection

1569
01:00:26,589 --> 01:00:29,170
once you know everything is is not

1570
01:00:29,170 --> 01:00:31,779
visible and then recreate the table so

1571
01:00:31,779 --> 01:00:33,039
we'll talk about this in a week or two

1572
01:00:33,039 --> 01:00:36,250
about transaction catalogs so the

1573
01:00:36,250 --> 01:00:37,990
catalog an is storing the metadata about

1574
01:00:37,990 --> 01:00:40,480
what tables exist what what attributes

1575
01:00:40,480 --> 01:00:42,700
or columns that they have so if your

1576
01:00:42,700 --> 01:00:45,069
catalog is transactional meaning if I

1577
01:00:45,069 --> 01:00:49,359
call drop table then anybody that has a

1578
01:00:49,359 --> 01:00:50,950
timestamp before my drop table

1579
01:00:50,950 --> 01:00:53,019
transaction can still see the table and

1580
01:00:53,019 --> 01:00:54,910
then once they're all gone I can reclaim

1581
01:00:54,910 --> 01:00:56,109
the space so if this is all

1582
01:00:56,109 --> 01:00:58,569
transactional then doing this doing this

1583
01:00:58,569 --> 01:01:00,430
this truncation approach is super easy

1584
01:01:00,430 --> 01:01:02,230
same thing actually with compaction

1585
01:01:02,230 --> 01:01:04,480
right compaction is what compaction is

1586
01:01:04,480 --> 01:01:06,400
taking two blocks and combining them

1587
01:01:06,400 --> 01:01:07,569
together we're just moving the physical

1588
01:01:07,569 --> 01:01:09,069
location of those tuples in those blocks

1589
01:01:09,069 --> 01:01:11,410
into a new location so it's like it's

1590
01:01:11,410 --> 01:01:12,849
like a it's like a delete followed by an

1591
01:01:12,849 --> 01:01:14,230
insert so if I can do that

1592
01:01:14,230 --> 01:01:15,970
transactionally then I don't worry about

1593
01:01:15,970 --> 01:01:18,279
any false negative false positives from

1594
01:01:18,279 --> 01:01:19,599
transactions that are running the same

1595
01:01:19,599 --> 01:01:21,730
time of run and compaction so in our

1596
01:01:21,730 --> 01:01:24,490
system our our catalog is entirely

1597
01:01:24,490 --> 01:01:25,990
transactional and it makes all this

1598
01:01:25,990 --> 01:01:27,579
stuff easy we just we just haven't done

1599
01:01:27,579 --> 01:01:31,029
all of it yet all right so to finish up

1600
01:01:31,029 --> 01:01:33,490
again the this is just more of the

1601
01:01:33,490 --> 01:01:34,900
classic trade-off we see in computer

1602
01:01:34,900 --> 01:01:36,730
science and in databases of storage

1603
01:01:36,730 --> 01:01:38,380
versus in compute so you believe more

1604
01:01:38,380 --> 01:01:39,880
aggressive in doing garbage collection

1605
01:01:39,880 --> 01:01:42,160
and reclaim more memory space but that's

1606
01:01:42,160 --> 01:01:43,269
going to slow down our transactions

1607
01:01:43,269 --> 01:01:45,369
right or we can let our virgins are all

1608
01:01:45,369 --> 01:01:48,460
versions accumulate and that could you

1609
01:01:48,460 --> 01:01:50,440
know save our computational cycles but

1610
01:01:50,440 --> 01:01:51,460
we're spending more memory or spending

1611
01:01:51,460 --> 01:01:52,480
the more storage space to handle this

1612
01:01:52,480 --> 01:01:56,859
right and so in talking with people that

1613
01:01:56,859 --> 01:01:58,329
are running MVC systems especially in

1614
01:01:58,329 --> 01:02:01,329
memory systems everybody is willing to

1615
01:02:01,329 --> 01:02:03,100
pay a penalty for performance

1616
01:02:03,100 --> 01:02:04,630
in exchange for reducing the memory

1617
01:02:04,630 --> 01:02:10,600
footprint anyone thinking sy what's more

1618
01:02:10,600 --> 01:02:13,810
expensive Ram

1619
01:02:13,810 --> 01:02:15,850
Rams more expensive not only more has to

1620
01:02:15,850 --> 01:02:17,260
buy also more excited to maintain you

1621
01:02:17,260 --> 01:02:18,910
have to pay energy for this so if I can

1622
01:02:18,910 --> 01:02:21,130
run my database a little bit slower but

1623
01:02:21,130 --> 01:02:24,340
use a lot less memory then I can you

1624
01:02:24,340 --> 01:02:26,890
know that can be a bit cost savings so

1625
01:02:26,890 --> 01:02:28,870
that's why I like the the hyper approach

1626
01:02:28,870 --> 01:02:30,160
in the paper you guys read from steam

1627
01:02:30,160 --> 01:02:32,860
because they're running the the garbage

1628
01:02:32,860 --> 01:02:33,820
collection as they're running queries

1629
01:02:33,820 --> 01:02:36,160
the queries run slower but they're

1630
01:02:36,160 --> 01:02:37,990
reclaiming things as soon as possible

1631
01:02:37,990 --> 01:02:41,160
and reducing the memory footprint okay

1632
01:02:41,160 --> 01:02:46,150
any questions what you see all right

1633
01:02:46,150 --> 01:02:50,920
tips are profile okay so I assuming I

1634
01:02:50,920 --> 01:02:52,180
don't know at some point you might have

1635
01:02:52,180 --> 01:02:53,710
covered this kind of information I don't

1636
01:02:53,710 --> 01:02:56,980
think 213 covers this but this is there

1637
01:02:56,980 --> 01:02:58,510
be a reoccurring theme throughout the

1638
01:02:58,510 --> 01:02:59,560
semester like alright we want to

1639
01:02:59,560 --> 01:03:00,730
determine whether our system is running

1640
01:03:00,730 --> 01:03:04,240
slow and then if it's slow if so why so

1641
01:03:04,240 --> 01:03:05,320
let's look a really simple example here

1642
01:03:05,320 --> 01:03:07,480
I have two functions foo and bar in my

1643
01:03:07,480 --> 01:03:10,390
program alright so I want to I want to

1644
01:03:10,390 --> 01:03:12,340
speed it up I want to figure out how to

1645
01:03:12,340 --> 01:03:13,780
get why these guys are running slower

1646
01:03:13,780 --> 01:03:15,550
and what can I do to figure out you know

1647
01:03:15,550 --> 01:03:18,820
how to make them faster so a really

1648
01:03:18,820 --> 01:03:22,750
stupid way to do this would be our naive

1649
01:03:22,750 --> 01:03:24,160
way to do this would be run our program

1650
01:03:24,160 --> 01:03:27,240
in in a debugger gdb or whatever lld be

1651
01:03:27,240 --> 01:03:31,300
for Apple and every so often we just hit

1652
01:03:31,300 --> 01:03:34,360
pause on the program look at the stack

1653
01:03:34,360 --> 01:03:36,850
trace figure out what function it's in

1654
01:03:36,850 --> 01:03:39,640
and has record that and he's every so

1655
01:03:39,640 --> 01:03:40,870
often to keep hitting pause and

1656
01:03:40,870 --> 01:03:42,010
according to information and then over

1657
01:03:42,010 --> 01:03:45,550
time I would have information about what

1658
01:03:45,550 --> 01:03:48,060
what function was being called the most

1659
01:03:48,060 --> 01:03:51,480
time it's stupid but it would work right

1660
01:03:51,480 --> 01:03:55,060
so let's say that I did this I got 10

1661
01:03:55,060 --> 01:03:58,690
called call stack samples and then 6 out

1662
01:03:58,690 --> 01:04:00,370
of the 10 times I did that pause and

1663
01:04:00,370 --> 01:04:02,110
looked they were in the function foo

1664
01:04:02,110 --> 01:04:06,250
right so we would know that basement

1665
01:04:06,250 --> 01:04:07,660
based on our measurements that roughly

1666
01:04:07,660 --> 01:04:10,690
60% of our time of our program was spent

1667
01:04:10,690 --> 01:04:11,470
in this foo function

1668
01:04:11,470 --> 01:04:13,960
now obviously the accuracy of this of

1669
01:04:13,960 --> 01:04:15,940
this calculation would increase the more

1670
01:04:15,940 --> 01:04:16,869
time I hit pause like

1671
01:04:16,869 --> 01:04:18,430
if I get like a little motor hit Paul's

1672
01:04:18,430 --> 01:04:20,349
over and over again I can automate this

1673
01:04:20,349 --> 01:04:22,720
I could get more samples and they have a

1674
01:04:22,720 --> 01:04:25,299
more you know more accurate measurement

1675
01:04:25,299 --> 01:04:30,400
right so now say most the time we're

1676
01:04:30,400 --> 01:04:32,440
running foo and so this should be our

1677
01:04:32,440 --> 01:04:34,960
target of what we should optimize first

1678
01:04:34,960 --> 01:04:36,730
right we have two functions foo and bar

1679
01:04:36,730 --> 01:04:38,559
we should optimize foo first because

1680
01:04:38,559 --> 01:04:40,440
most their time is being spent and math

1681
01:04:40,440 --> 01:04:44,349
so let's say now we're able to make foo

1682
01:04:44,349 --> 01:04:47,200
run two times faster what would be the

1683
01:04:47,200 --> 01:04:50,140
expected overall improvement of our

1684
01:04:50,140 --> 01:04:54,609
system who here's a scene on dolls law

1685
01:04:54,609 --> 01:04:59,109
before yeah lesson half okay so I'm

1686
01:04:59,109 --> 01:05:01,660
those laws a way to calculate what the

1687
01:05:01,660 --> 01:05:03,670
expect improvement will be if we know

1688
01:05:03,670 --> 01:05:05,170
what percentage of our program is spent

1689
01:05:05,170 --> 01:05:06,999
in a particular function or different

1690
01:05:06,999 --> 01:05:09,400
part of the code so if we make this

1691
01:05:09,400 --> 01:05:11,289
thing go two percent faster or sorry 2x

1692
01:05:11,289 --> 01:05:13,749
faster and we know that six percent of

1693
01:05:13,749 --> 01:05:17,109
time is spent foo then we can cut this

1694
01:05:17,109 --> 01:05:18,309
time in half

1695
01:05:18,309 --> 01:05:19,960
but we're still spending 4 percent of

1696
01:05:19,960 --> 01:05:22,059
our time in this in this function bar so

1697
01:05:22,059 --> 01:05:24,039
um does law gives us this nice formula

1698
01:05:24,039 --> 01:05:26,079
that would tell us the overall expected

1699
01:05:26,079 --> 01:05:28,599
speed-up based on our distribution of

1700
01:05:28,599 --> 01:05:30,220
the functions that we're invoking and

1701
01:05:30,220 --> 01:05:32,529
the speed-up we expect to get right we

1702
01:05:32,529 --> 01:05:34,269
run we plug in child the math and we'd

1703
01:05:34,269 --> 01:05:35,829
say that we would get at one point four

1704
01:05:35,829 --> 01:05:37,720
times improvement so even though I made

1705
01:05:37,720 --> 01:05:39,039
that function which is called the

1706
01:05:39,039 --> 01:05:41,829
majority of time 2x faster the overall

1707
01:05:41,829 --> 01:05:44,549
system speed-up is only one point for X

1708
01:05:44,549 --> 01:05:47,619
so we can use on those law as a way to

1709
01:05:47,619 --> 01:05:49,539
figure out when we look at our look at

1710
01:05:49,539 --> 01:05:51,880
our database system what are we spending

1711
01:05:51,880 --> 01:05:53,859
our time and how much effort is it going

1712
01:05:53,859 --> 01:05:55,390
to be to make that particular function

1713
01:05:55,390 --> 01:05:57,730
go faster and we can then do a

1714
01:05:57,730 --> 01:05:59,380
back-of-the-envelope calculation decide

1715
01:05:59,380 --> 01:06:01,059
what should be the improvement we check

1716
01:06:01,059 --> 01:06:03,249
to see I mean sometimes you just want to

1717
01:06:03,249 --> 01:06:06,339
do this I when you're doing your as

1718
01:06:06,339 --> 01:06:07,720
you're doing you know performance

1719
01:06:07,720 --> 01:06:10,690
profiling and development because if my

1720
01:06:10,690 --> 01:06:12,069
function is not like all that often then

1721
01:06:12,069 --> 01:06:15,849
I probably don't want to improve it but

1722
01:06:15,849 --> 01:06:17,109
all right it's not how many times its

1723
01:06:17,109 --> 01:06:18,039
call it has how much time I'm spending

1724
01:06:18,039 --> 01:06:19,900
in it so I can use that to figure out

1725
01:06:19,900 --> 01:06:21,220
what about sort of high poles in the

1726
01:06:21,220 --> 01:06:22,450
tent what are the what are the parts of

1727
01:06:22,450 --> 01:06:24,009
the system that we're spending most of

1728
01:06:24,009 --> 01:06:25,150
our time in and those are the things we

1729
01:06:25,150 --> 01:06:27,039
should target to improve it but as we

1730
01:06:27,039 --> 01:06:29,380
assess how to improve it we can use this

1731
01:06:29,380 --> 01:06:30,580
form to decide well I think I

1732
01:06:30,580 --> 01:06:32,290
getting to be 2x faster what is the real

1733
01:06:32,290 --> 01:06:35,590
benefit I'm gonna get them that answer

1734
01:06:35,590 --> 01:06:38,440
it's an old adage in systems you want to

1735
01:06:38,440 --> 01:06:40,090
avoid premature optimizations so yes

1736
01:06:40,090 --> 01:06:41,260
there might be a fancy new lock-free

1737
01:06:41,260 --> 01:06:42,820
algorithm we could use for some part of

1738
01:06:42,820 --> 01:06:44,380
the system all right that could be

1739
01:06:44,380 --> 01:06:46,180
better than what we have now but at that

1740
01:06:46,180 --> 01:06:47,890
part of the code is not executed that

1741
01:06:47,890 --> 01:06:49,600
often then we're just wasting our time

1742
01:06:49,600 --> 01:06:50,950
there's other things we should worry

1743
01:06:50,950 --> 01:06:54,100
about all right so now we need to figure

1744
01:06:54,100 --> 01:06:55,030
out how can we actually get this

1745
01:06:55,030 --> 01:06:56,350
information so my little example of

1746
01:06:56,350 --> 01:06:57,550
hitting pause over know again on my

1747
01:06:57,550 --> 01:06:59,140
keyboard is stupid right but there's

1748
01:06:59,140 --> 01:07:00,670
actually real tools that'll do this for

1749
01:07:00,670 --> 01:07:03,130
us so the two main ones that we're going

1750
01:07:03,130 --> 01:07:05,020
to focus on is Val grant and call grind

1751
01:07:05,020 --> 01:07:08,500
and perf so Val brine is it is a

1752
01:07:08,500 --> 01:07:09,640
heavyweight instrumentation and

1753
01:07:09,640 --> 01:07:12,370
framework that is basically going to

1754
01:07:12,370 --> 01:07:17,050
inject inject things into the binary as

1755
01:07:17,050 --> 01:07:18,790
it's running that allows it to collect

1756
01:07:18,790 --> 01:07:21,370
information about what part of the

1757
01:07:21,370 --> 01:07:24,670
system that it's in and so this will

1758
01:07:24,670 --> 01:07:26,860
make your program run slower but you

1759
01:07:26,860 --> 01:07:30,910
know this will be I mean Andy Childress

1760
01:07:30,910 --> 01:07:32,790
and otherwise you go too slow but like

1761
01:07:32,790 --> 01:07:36,610
this will get you show you the yeah this

1762
01:07:36,610 --> 01:07:37,780
will tell you we've seen at the code

1763
01:07:37,780 --> 01:07:39,010
level where you're spending your time

1764
01:07:39,010 --> 01:07:41,230
this will sort of say things at like a

1765
01:07:41,230 --> 01:07:43,930
Harvard level so perf is a way to get

1766
01:07:43,930 --> 01:07:46,270
out the low-level performance counters

1767
01:07:46,270 --> 01:07:49,900
from that enterprise zone x86 and record

1768
01:07:49,900 --> 01:07:51,580
things like how many cycles I'm spending

1769
01:07:51,580 --> 01:07:53,500
on like individual lines of assembly

1770
01:07:53,500 --> 01:07:56,050
instruction or code so both of these can

1771
01:07:56,050 --> 01:07:57,880
be used for different things this one

1772
01:07:57,880 --> 01:07:59,500
will give you lower level information

1773
01:07:59,500 --> 01:08:02,080
like cache misses

1774
01:08:02,080 --> 01:08:04,600
cycle counts whereas this one tells you

1775
01:08:04,600 --> 01:08:08,080
like instruction counts for for this

1776
01:08:08,080 --> 01:08:09,040
tell you interruptions counts because it

1777
01:08:09,040 --> 01:08:10,090
doesn't know how long it actually spent

1778
01:08:10,090 --> 01:08:12,490
in the CPU whereas purple give you give

1779
01:08:12,490 --> 01:08:13,600
you that so you actually wanna use both

1780
01:08:13,600 --> 01:08:16,720
but I'll give a demo of perf it's again

1781
01:08:16,720 --> 01:08:19,330
Val grind is actually a toolkit a bunch

1782
01:08:19,330 --> 01:08:22,420
of other things we can use mem check is

1783
01:08:22,420 --> 01:08:26,050
a way to check for memory errors this

1784
01:08:26,050 --> 01:08:27,160
thing what this is what the original

1785
01:08:27,160 --> 01:08:28,720
version of valgrind was this is check

1786
01:08:28,720 --> 01:08:30,700
for things like if you if you have

1787
01:08:30,700 --> 01:08:32,140
memory leaks and things like that it'll

1788
01:08:32,140 --> 01:08:34,779
find those things we use address

1789
01:08:34,779 --> 01:08:37,990
sanitizers as part of clang or GCC from

1790
01:08:37,990 --> 01:08:39,609
Google and it's a more lightweight of

1791
01:08:39,609 --> 01:08:41,620
identifying these things call grind it

1792
01:08:41,620 --> 01:08:42,700
will show you where you're spending your

1793
01:08:42,700 --> 01:08:44,350
time in the source code and then

1794
01:08:44,350 --> 01:08:46,359
massif is a way to show you sort of

1795
01:08:46,359 --> 01:08:48,340
within the total heap space of the

1796
01:08:48,340 --> 01:08:50,380
address space of your process what parts

1797
01:08:50,380 --> 01:08:52,359
of the the you know of the program is

1798
01:08:52,359 --> 01:08:53,920
allocating the most amount of memory and

1799
01:08:53,920 --> 01:08:55,270
obviously for us the database portion

1800
01:08:55,270 --> 01:08:57,130
will always be larger the largest but

1801
01:08:57,130 --> 01:08:58,390
within that we can drill down and say

1802
01:08:58,390 --> 01:08:59,649
like how much time or you know how much

1803
01:08:59,649 --> 01:09:01,420
space were spending for the data

1804
01:09:01,420 --> 01:09:03,330
structures to keep track of things and

1805
01:09:03,330 --> 01:09:05,859
indexes and other stuff right when we

1806
01:09:05,859 --> 01:09:08,050
when we first build to be Debbie tree

1807
01:09:08,050 --> 01:09:10,390
it was allocated memory when he turned

1808
01:09:10,390 --> 01:09:11,590
the thing on and when he looked at

1809
01:09:11,590 --> 01:09:13,120
massive like even though you put zero

1810
01:09:13,120 --> 01:09:16,210
data in to the table the it would show

1811
01:09:16,210 --> 01:09:18,160
this huge block of memory being spent

1812
01:09:18,160 --> 01:09:19,300
for the be Debbie tree because it

1813
01:09:19,300 --> 01:09:21,310
allocated a mapping table for no reason

1814
01:09:21,310 --> 01:09:24,670
without actually using it yet all right

1815
01:09:24,670 --> 01:09:26,710
so let's see how to use call rent so for

1816
01:09:26,710 --> 01:09:29,560
call grind I I think you need to have

1817
01:09:29,560 --> 01:09:30,880
root privileges because your

1818
01:09:30,880 --> 01:09:33,850
instrumenting the binary and so you're

1819
01:09:33,850 --> 01:09:35,439
gonna use this on the command line for

1820
01:09:35,439 --> 01:09:37,990
this one I'm there's a instructions on

1821
01:09:37,990 --> 01:09:40,779
the wiki how to compile in release mode

1822
01:09:40,779 --> 01:09:43,359
without asserts but maintain the debug

1823
01:09:43,359 --> 01:09:46,240
symbols so that when you look at the the

1824
01:09:46,240 --> 01:09:48,370
trace in call grind or cake a shrine

1825
01:09:48,370 --> 01:09:50,529
it'll show you like here's the source

1826
01:09:50,529 --> 01:09:51,580
code or here you know here's the

1827
01:09:51,580 --> 01:09:52,870
function call here's the line number in

1828
01:09:52,870 --> 01:09:54,610
the source code that maintains

1829
01:09:54,610 --> 01:09:57,250
information so this compiling under this

1830
01:09:57,250 --> 01:09:59,770
mode will maintain all that simple

1831
01:09:59,770 --> 01:10:01,360
information without all the extra

1832
01:10:01,360 --> 01:10:02,890
asserts that'll slow the system down so

1833
01:10:02,890 --> 01:10:04,210
it'll be close as you can get to

1834
01:10:04,210 --> 01:10:05,200
actually running the written the real

1835
01:10:05,200 --> 01:10:07,570
system the other thing too is here this

1836
01:10:07,570 --> 01:10:11,580
is a I push this to the project one

1837
01:10:11,580 --> 01:10:14,230
branch last night but now you can pass

1838
01:10:14,230 --> 01:10:16,090
in through an environment variable how

1839
01:10:16,090 --> 01:10:18,310
many threads you want to run the

1840
01:10:18,310 --> 01:10:19,900
benchmark with so by default if you just

1841
01:10:19,900 --> 01:10:21,700
run slot iterator benchmark it'll give

1842
01:10:21,700 --> 01:10:23,740
you one thread you can set this to say

1843
01:10:23,740 --> 01:10:24,850
how many how many threads you want to

1844
01:10:24,850 --> 01:10:26,920
use remember for identifying what the

1845
01:10:26,920 --> 01:10:28,780
bottleneck is it won't show up if you

1846
01:10:28,780 --> 01:10:30,430
have one thread it'll show up when you

1847
01:10:30,430 --> 01:10:32,110
have more threads right it'll be really

1848
01:10:32,110 --> 01:10:33,640
obvious if you want to run with a higher

1849
01:10:33,640 --> 01:10:37,210
thread count and so so you run this for

1850
01:10:37,210 --> 01:10:40,030
a bit and then it'll spit out this call

1851
01:10:40,030 --> 01:10:42,220
grind file and then there's tools like

1852
01:10:42,220 --> 01:10:43,930
cake a shrine that'll give you a nice

1853
01:10:43,930 --> 01:10:46,060
visualization and break down a what

1854
01:10:46,060 --> 01:10:47,590
calling one so this is actually from the

1855
01:10:47,590 --> 01:10:49,000
benchmark that we gave students last

1856
01:10:49,000 --> 01:10:51,160
year but the the high-level idea is the

1857
01:10:51,160 --> 01:10:52,990
same so in here you can see the

1858
01:10:52,990 --> 01:10:55,390
community distribution time where it's

1859
01:10:55,390 --> 01:10:57,160
sort of at the top of the call stack

1860
01:10:57,160 --> 01:10:57,969
within

1861
01:10:57,969 --> 01:10:59,289
in the system you know what percentage

1862
01:10:59,289 --> 01:11:00,610
of the time you're spending in these

1863
01:11:00,610 --> 01:11:02,380
different function calls and then this

1864
01:11:02,380 --> 01:11:03,610
is a nice call graph view that you can

1865
01:11:03,610 --> 01:11:05,650
drill down and say well for this

1866
01:11:05,650 --> 01:11:07,690
function it invoked this function you

1867
01:11:07,690 --> 01:11:09,579
know a million times but I sent zero

1868
01:11:09,579 --> 01:11:10,449
point three four percent of my total

1869
01:11:10,449 --> 01:11:12,489
time in this but I spent nine percent

1870
01:11:12,489 --> 01:11:14,139
here but I go to nine million times so

1871
01:11:14,139 --> 01:11:16,059
you can drill down and see like what

1872
01:11:16,059 --> 01:11:17,800
function I'm actually spending the most

1873
01:11:17,800 --> 01:11:20,739
time on right but again this is showing

1874
01:11:20,739 --> 01:11:24,610
you this is like invocations and just in

1875
01:11:24,610 --> 01:11:26,829
wall clock time it's not gonna show you

1876
01:11:26,829 --> 01:11:29,170
the cycle count which is gonna be useful

1877
01:11:29,170 --> 01:11:32,800
as well all right so perfect and that's

1878
01:11:32,800 --> 01:11:35,199
collecting the low level performance

1879
01:11:35,199 --> 01:11:37,360
counters that form from Linux that the

1880
01:11:37,360 --> 01:11:40,030
exit eights provides you I think Mac

1881
01:11:40,030 --> 01:11:43,630
just to work I think it should I don't

1882
01:11:43,630 --> 01:11:44,949
know max I haven't try it but this just

1883
01:11:44,949 --> 01:11:47,979
don't work if it doesn't we'll figure

1884
01:11:47,979 --> 01:11:50,739
something out all right so basically

1885
01:11:50,739 --> 01:11:52,869
there's a bunch of different things you

1886
01:11:52,869 --> 01:11:55,929
vent you can collect from the from the

1887
01:11:55,929 --> 01:11:57,579
hardware about your process that's

1888
01:11:57,579 --> 01:12:00,519
running and then you can set how how

1889
01:12:00,519 --> 01:12:02,679
often you want to sample I say this is

1890
01:12:02,679 --> 01:12:03,999
gonna sample every two thousand

1891
01:12:03,999 --> 01:12:05,889
occurrences of the event and then as you

1892
01:12:05,889 --> 01:12:07,119
run it's gonna record this in this

1893
01:12:07,119 --> 01:12:08,820
perfect data file that gets generated

1894
01:12:08,820 --> 01:12:10,809
when you when you know after your

1895
01:12:10,809 --> 01:12:13,269
program runs so for this one this one

1896
01:12:13,269 --> 01:12:15,039
you definitely have to run under root

1897
01:12:15,039 --> 01:12:16,749
permissions because you're asking at low

1898
01:12:16,749 --> 01:12:18,130
level hardware get these Harvard

1899
01:12:18,130 --> 01:12:19,300
counters and there's something that the

1900
01:12:19,300 --> 01:12:21,280
OS nomen doesn't provide you because you

1901
01:12:21,280 --> 01:12:22,570
can do it for any any process that's

1902
01:12:22,570 --> 01:12:25,929
running right so basically what happens

1903
01:12:25,929 --> 01:12:27,280
is like there's the internal counters

1904
01:12:27,280 --> 01:12:28,960
and the hardware and then when they go

1905
01:12:28,960 --> 01:12:30,849
to a certain amount right based on the

1906
01:12:30,849 --> 01:12:34,389
the event counter then it records a

1907
01:12:34,389 --> 01:12:36,550
sample right and it contains all the

1908
01:12:36,550 --> 01:12:39,579
information about about the individual

1909
01:12:39,579 --> 01:12:41,050
lines of code and actually at the

1910
01:12:41,050 --> 01:12:42,909
Assembly level of what called what again

1911
01:12:42,909 --> 01:12:44,710
you want to compile this with release

1912
01:12:44,710 --> 01:12:46,389
mode with debug symbols so that when you

1913
01:12:46,389 --> 01:12:47,889
look at the per file put it'll show you

1914
01:12:47,889 --> 01:12:51,179
the actual lines of code yes

1915
01:12:55,489 --> 01:13:03,950
I eat it what will happen is if you run

1916
01:13:03,950 --> 01:13:05,360
it a little weak and do a demo if you

1917
01:13:05,360 --> 01:13:07,730
have time on a lower core count what the

1918
01:13:07,730 --> 01:13:09,440
bottleneck is may not appear because

1919
01:13:09,440 --> 01:13:11,270
everyone's not hitting it on the higher

1920
01:13:11,270 --> 01:13:12,770
core count it definitely shows up and

1921
01:13:12,770 --> 01:13:17,120
it'd be really obvious you can try it on

1922
01:13:17,120 --> 01:13:18,860
your laptop first coming up I'll show

1923
01:13:18,860 --> 01:13:20,270
you right now I should what it is it's

1924
01:13:20,270 --> 01:13:21,980
not none it's a lash right it's not not

1925
01:13:21,980 --> 01:13:28,850
a mystery right and what Indus INR yes

1926
01:13:28,850 --> 01:13:33,050
yes right so anyway so you run this if

1927
01:13:33,050 --> 01:13:36,200
you run perf I think I tried this this

1928
01:13:36,200 --> 01:13:37,610
morning if you run with a higher core

1929
01:13:37,610 --> 01:13:40,760
account a higher thread count it takes a

1930
01:13:40,760 --> 01:13:43,340
long time and then the benchmark won't

1931
01:13:43,340 --> 01:13:44,960
even finish and the file is like 10 gigs

1932
01:13:44,960 --> 01:13:47,210
so you I'll show you you can kill it off

1933
01:13:47,210 --> 01:13:49,969
early and then there's nice third-party

1934
01:13:49,969 --> 01:13:51,920
visualization tools I call it hot spot

1935
01:13:51,920 --> 01:13:53,000
it's for the Linux I don't know if it

1936
01:13:53,000 --> 01:13:54,590
works on a Mac that I'll give you like

1937
01:13:54,590 --> 01:13:55,730
flame graphs and show you things that

1938
01:13:55,730 --> 01:13:57,860
are more that are a bit easier to read

1939
01:13:57,860 --> 01:14:01,010
then like the perf tool but let me give

1940
01:14:01,010 --> 01:14:13,520
you a quick demo right so I say this is

1941
01:14:13,520 --> 01:14:15,800
again I compiled this with debug info

1942
01:14:15,800 --> 01:14:17,630
this is just H top at the bottom this is

1943
01:14:17,630 --> 01:14:18,860
the machine we have in the lab with 40

1944
01:14:18,860 --> 01:14:21,770
cores so I've already set the

1945
01:14:21,770 --> 01:14:23,150
environment variable actually I did not

1946
01:14:23,150 --> 01:14:28,900
do that I mean low back answer

1947
01:14:33,050 --> 01:14:36,270
so again I'm setting the environment

1948
01:14:36,270 --> 01:14:38,760
variable Terrier benchmark threads to 16

1949
01:14:38,760 --> 01:14:40,830
and that'll guarantee that that I'll

1950
01:14:40,830 --> 01:14:42,690
make it run with 16 threats so again

1951
01:14:42,690 --> 01:14:44,130
here I'm not gonna run the slop I'm

1952
01:14:44,130 --> 01:14:45,810
gonna run perf the salaat iterate

1953
01:14:45,810 --> 01:14:47,700
benchmark I'm gonna record cycle counts

1954
01:14:47,700 --> 01:14:49,650
and I don't collect samples every 2,000

1955
01:14:49,650 --> 01:14:51,240
and then just biz just the binary that

1956
01:14:51,240 --> 01:14:54,390
I'm gonna run right and then this is

1957
01:14:54,390 --> 01:14:56,960
just showing me at the bottom right that

1958
01:14:56,960 --> 01:15:00,660
shot that I'm using I'm using 16 cores

1959
01:15:00,660 --> 01:15:04,290
as expected right so again I'm maxing

1960
01:15:04,290 --> 01:15:07,590
out at 100% because there's a bottleneck

1961
01:15:07,590 --> 01:15:08,580
in their system where they're trying to

1962
01:15:08,580 --> 01:15:10,200
do something over and over again but

1963
01:15:10,200 --> 01:15:11,730
they're not actually getting making

1964
01:15:11,730 --> 01:15:12,840
forward progress they're not actually

1965
01:15:12,840 --> 01:15:14,340
getting worked on so even though it

1966
01:15:14,340 --> 01:15:16,080
looks like my utilization is fantastic

1967
01:15:16,080 --> 01:15:18,810
it's actually crap because it's I'm

1968
01:15:18,810 --> 01:15:21,480
stuck on this bottleneck so again this

1969
01:15:21,480 --> 01:15:23,910
could run forever run for a long time

1970
01:15:23,910 --> 01:15:26,910
and and take a while so you go control-c

1971
01:15:26,910 --> 01:15:28,350
and kill it it'll tell you how many

1972
01:15:28,350 --> 01:15:31,410
times that it it got woken up for some

1973
01:15:31,410 --> 01:15:34,710
data and then the perf trace was 32

1974
01:15:34,710 --> 01:15:36,390
Meg's again from only one a few seconds

1975
01:15:36,390 --> 01:15:42,060
it got to 32 Meg's so now I can run I

1976
01:15:42,060 --> 01:15:44,610
can run perf report actually here so in

1977
01:15:44,610 --> 01:15:47,820
in my directory it'll generate this perf

1978
01:15:47,820 --> 01:15:49,920
data file right so after you run perf

1979
01:15:49,920 --> 01:15:51,690
it'll spit that out so if I run perf

1980
01:15:51,690 --> 01:15:53,610
report again you have to be root for

1981
01:15:53,610 --> 01:15:56,660
this right it'll process the file and

1982
01:15:56,660 --> 01:16:01,740
then give you a give you a list of where

1983
01:16:01,740 --> 01:16:02,850
you're spending all your time for in

1984
01:16:02,850 --> 01:16:04,380
your program and because again I ran

1985
01:16:04,380 --> 01:16:05,580
with debug symbols on I can see

1986
01:16:05,580 --> 01:16:08,040
everything so lo and behold I look at

1987
01:16:08,040 --> 01:16:09,660
the very top for the slot iterative

1988
01:16:09,660 --> 01:16:13,590
benchmark I'm spending 48 49 percent of

1989
01:16:13,590 --> 01:16:15,480
my time in some function here and then

1990
01:16:15,480 --> 01:16:16,770
45 percent of my time they look function

1991
01:16:16,770 --> 01:16:19,200
here so the rest is just where it

1992
01:16:19,200 --> 01:16:21,120
actually did work so this is this is

1993
01:16:21,120 --> 01:16:22,470
obviously the bottleneck so what you can

1994
01:16:22,470 --> 01:16:24,540
do is you can Joe down purpose a nice

1995
01:16:24,540 --> 01:16:26,730
tool you can drill down into this you

1996
01:16:26,730 --> 01:16:29,220
say annotate the slot 8 or a plus plus

1997
01:16:29,220 --> 01:16:31,410
operator and then now I see source code

1998
01:16:31,410 --> 01:16:33,690
and then I can drill down see that I'm

1999
01:16:33,690 --> 01:16:36,630
spending 94% of my time for this

2000
01:16:36,630 --> 01:16:39,810
function in this test operator and

2001
01:16:39,810 --> 01:16:40,980
because what am i doing I'm trying to

2002
01:16:40,980 --> 01:16:42,300
try and acquire a spin latch so I'm

2003
01:16:42,300 --> 01:16:44,100
spinning on this latch trying to acquire

2004
01:16:44,100 --> 01:16:46,310
it and that's why I spent 94%

2005
01:16:46,310 --> 01:16:48,640
time on that right that's the bottleneck

2006
01:16:48,640 --> 01:16:52,760
and I can go back I think is escape and

2007
01:16:52,760 --> 01:16:57,290
see the other one annotate now spending

2008
01:16:57,290 --> 01:17:00,290
91% of my time on the same the same spin

2009
01:17:00,290 --> 01:17:02,780
match TVB is thread building blocks this

2010
01:17:02,780 --> 01:17:04,310
is the library we use some Intel to

2011
01:17:04,310 --> 01:17:06,290
provide us the spin match it's actually

2012
01:17:06,290 --> 01:17:08,690
a pretty good imitation but again it's

2013
01:17:08,690 --> 01:17:09,920
like anything like if you use it

2014
01:17:09,920 --> 01:17:11,150
incorrectly you're gonna have problems

2015
01:17:11,150 --> 01:17:12,410
so even though it's a great

2016
01:17:12,410 --> 01:17:14,870
implementation of a spin latch if you

2017
01:17:14,870 --> 01:17:16,850
have it a knack attention point it's

2018
01:17:16,850 --> 01:17:19,670
gonna be slow okay so I was sending out

2019
01:17:19,670 --> 01:17:21,410
a link there's this great video it's

2020
01:17:21,410 --> 01:17:25,220
like an hour long about how to use perf

2021
01:17:25,220 --> 01:17:27,920
bit further again this is the same thing

2022
01:17:27,920 --> 01:17:30,500
showed you there's a nice tools that'll

2023
01:17:30,500 --> 01:17:31,910
give you flame graphs like this but for

2024
01:17:31,910 --> 01:17:33,650
this one it's pretty obvious okay and

2025
01:17:33,650 --> 01:17:34,940
there's much of other events you can get

2026
01:17:34,940 --> 01:17:37,820
back bunch of links here alright so next

2027
01:17:37,820 --> 01:17:40,190
class will pick up on indexes we'll

2028
01:17:40,190 --> 01:17:41,390
spend a little time beginning talk about

2029
01:17:41,390 --> 01:17:42,470
tea trees because they're perpetuating

2030
01:17:42,470 --> 01:17:44,690
from a historical perspective well spend

2031
01:17:44,690 --> 01:17:46,160
most of our time talking about a lat

2032
01:17:46,160 --> 01:17:49,100
tree indexed ahead and the BW tree from

2033
01:17:49,100 --> 01:17:51,080
Microsoft and then we'll talk about how

2034
01:17:51,080 --> 01:17:53,060
to new version latching for B plus trees

2035
01:17:53,060 --> 01:17:56,300
okay any questions thank it in the side

2036
01:17:56,300 --> 01:17:59,620
park what is this

2037
01:17:59,780 --> 01:18:02,890
[Music]

2038
01:18:02,890 --> 01:18:05,020
here called the whole it cuz I'm og ice

2039
01:18:05,020 --> 01:18:07,750
you down with the test team hi you look

2040
01:18:07,750 --> 01:18:10,870
and it was go grab me a forty just to

2041
01:18:10,870 --> 01:18:12,970
get my buzz song cuz I needed just a

2042
01:18:12,970 --> 01:18:15,580
little more kick like a fish after just

2043
01:18:15,580 --> 01:18:18,040
one slip put it to my lips and rip the

2044
01:18:18,040 --> 01:18:21,940
top off April does a nice hot dog and my

2045
01:18:21,940 --> 01:18:24,520
heart will be to say I've diced you take

2046
01:18:24,520 --> 01:18:27,810
a sake to the prey

