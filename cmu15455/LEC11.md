# Lecture11: Joins Algorithms 连接算法
## 1. Joins 
The goal of a good database design is to minimize the amount of information repetition. This is why we compose tables based on normalization theory. Joins are therefore needed to reconstruct original tables.

一个良好的数据库设计的目标是尽量减少信息的冗余。这就是我们基于规范化理论编写表格的原因。因此，需要联接来重建原始表。

### Operator Output 输出运算符
For a tuple r ∈ R and a tuple s ∈ S that match on join attributes, the join operator concatenates r and s together into a new output tuple. 

对于在连接属性上匹配的元组r∈R和元组s∈S，连接运算符将r和s连接在一起生成一个新的输出元组。

In reality, contents of output tuples generated by a join operator varies. It depends on the DBMS’s procesing model, storage model, and the query itself:
* Data: Copy the values for the attributes in the outer and inner tables into tuples put into an intermediate result table just for that operator. The advantage of this approach is that future operators in the query plan never need to go back to the base tables to get more data. The disadvantage is that this requires more memory to materialize the entire tuple.
* Record Ids: The DBMS only copies the join keys along with the record ids of the matching tuples. This approach is ideal for column stores because the DBMS does not copy data that is not needed for the query. This is called late materialization.

实际上，由联接运算符生成的输出元组的内容各不相同。这取决于DBMS的进程模型、存储模型和查询本身：
* 数据：将外部和内部表中属性的值复制到元组中，这些元组仅针对该运算符放入中间结果表中。此方法的优点是，查询计划中的未来运算符永远不需要返回基表来获取更多数据。缺点是这需要更多的内存来物化整个元组。
* Record ID：DBMS仅复制连接键以及匹配元组的recordID。此方法非常适合列存储，因为DBMS不会复制查询不需要的数据。这称为晚物化。

### Cost Analysis 代价分析
The cost metric that we are going to use to analyze the different join algorithms will be the number of disk I/Os used to compute the join. This includes I/Os incurred by reading data from disk as well as writing intermediate data out to disk.

我们将连接操作所需要的磁盘I/O数作为不同连接算法的代价指标。这包括从磁盘读取数据以及将中间数据写出到磁盘而产生的I/O。

Variables used in this lecture:
• M pages in table R, m tuples total
• N pages in table S, n tuples total

本节中用到的变量
* R表总共有M页，m元组。
* S表总共有N页，n元组。


## 2. Nested Loop Join 循环嵌套连接
At a high-level, this type of join algorithm is comprised of two nested for loops that iterate over the tuples in both tables and compares each unique of them. If the tuples match the join predicate, then output them. The table in the outer for loop is called the outer table, while the table in the inner for loop is called the inner table.

在高层次上，这种类型的联接算法由两个嵌套的for循环组成，这两个循环逐个访问两个表中的元组并进行比较。如果元组与连接谓词匹配，则输出它们。外部for循环中的表称为外部表，而内部for循环中的表称为内部表。

The DBMS will always want to use the “smaller” table as the outer table. Smaller can be in terms of the number of tuples or number of pages. The DBMS will also want to buffer as much of the outer table in memory as possible. If possible, leverage an index to find matches in inner table.

DBMS将始终希望使用“较小”表作为外部表。较小的可以是元组数或页数。DBMS还希望在内存中缓冲尽可能多的外部表。如果可能，利用索引在内部表中查找匹配项。

### Simple Nested Loop Join 简单嵌套循环连接
For each tuple in the outer table, compare it with each tuple in the inner table. This is the worst case scenario where you assume that there is one disk I/O to read each tuple (i.e., there is no caching or access locality). 
Cost: M + (m × N)

对于外部表中的每一个元组，将它和内部表中的每一个元组进行比较。最差的情况是假设每读一次元组数据就需要一次磁盘I/O(例如，没有缓存或访问的位置)。

### Block Nested Loop Join 块嵌套循环连接
For each block in the outer table, fetch each block from the inner table and compare all the tuples in those two blocks. This algorithm performs fewer disk access because we scan the inner table for every outer table block instead of for every tuple.
Cost: M + (M × N)

对于外部中的每一个块，从内部表中取出一个块，并比较两个块中的所有元组。这个算法只需要更少的磁盘访问，因为我们通过块来扫描内表与外表，而不是扫描每个元组。

If the DBMS has B buffers available to compute the join, then it can use B-2 buffers to scan the outer table. It will use one buffer to hold a block from the inner table and one buffer to store the output of the join. 
Cost: M+ceil([M/(B-2)]) * N

如果DBMS具有B个可用于计算联接的缓冲区，那么它可以使用B-2缓冲区扫描外部表，用一个缓冲区来保存内部表中的块，并使用一个缓冲区来存储连接的输出。
代价：M+ceil([M/(B-2)]) * N

### Index Nested Loop Join 索引嵌套循环连接
The previous nested loop join algorithms perform poorly because the DBMS has to do a sequential scan to check for a match in the inner table. But if the database already has an index for one of the tables on the join key, then it can use that to speed up the comparison. The outer table will be the one without an index. The inner table will be the one with the index.
Assume the cost of each index probe is some constant value C per tuple.
Cost: M + (m × C)

前面提到的嵌套循环连接算法性能都不好，因为DBMS必须进行对内部表进行序列扫描来检查是否有匹配的元组，但是如果数据库中某个表已经在连接的key有索引了，那么就可以加速比较的过程。外部表为没有索引的表，内部表有索引。
假设每次通过索引寻找一个元组的代价为常数C
代价：M+( m × C )


## 3. Sort-Merge Join
The high-level is to sort the two tables on their join key. Then perform a sequential scan on the sorted tables to compute the join. This algorithm is useful if one or both tables are already sorted on join attribute(s). 

更好的解决方案是根据两个表的连接键对它们进行排序，然后对已排序的表执行顺序扫描以计算连接。如果一个或两个表已按连接属性排序，则此算法很有用。

The worst case scenario for this algorithm is if the join attribute for all the tuples in both tables contain the same value. This is very unlikely to happen in real databases.
* Phase #1 – Sort: First sort both input tables on the join attribute.
* Phase #2 – Merge: Scan the two sorted tables in parallel, and matching tuples.

这个算法最差的情况是两个表中所有元组的连接字段都是相同的值，但这在实际的数据库中很少出现。
* 步骤1-排序：首先将输入表的连接字段进行排序。
* 步骤2-归并：并行的扫描两个已经排序的表，并且进行元组匹配。

Assume that the DBMS has B buffers to use for the algorithm:
* Sort Cost for Table R: 2M × 1 + log_{B-1}^{ceil(M/B)}
* Sort Cost for Table S: 2N × 1 + log_{B-1}^{ceil(N/B)}
* Merge Cost: (M + N)
Total Cost: Sort + Merge

假设DBMS有B个buffer可以用于该算法：
* R表排序的代价：2M × 1 + log_{B-1}^{ceil(M/B)}
* S表排序的代价：2N × 1 + log_{B-1}^{ceil(N/B)}
* 归并代价：(M + N)
总代价：排序+归并

## 4. Hash Join 哈希连接
The high-level idea of the hash join algorithm is to use a hash table to split up the tuples into smaller chunks based on their join attribute(s). This reduces the number of comparisons that the DBMS needs to perform per tuple to compute the join. Hash join can only be used for equi-joins on the complete join key.

哈希联接算法的高级思想是使用哈希表根据其连接属性将元组拆分为较小的块。这减少了DBMS在计算连接时需要为每个元组执行的比较次数。哈希连接只能用于等值连连接。

If tuple r ∈ R and a tuple s ∈ S satisfy the join condition, then they have the same value for the join attributes. If that value is hashed to some value i, the R tuple has to be in bucket ri and the S tuple in bucket si . Thus, R tuples in bucket ri need only to be compared with S tuples in bucket si.

如果I元组r∈R并且s∈S满足连接的条件，那么他们的连接字段具有相同的值。如果这个值的哈希值为i，R表有元组在ri桶，S表有元组si个桶，那么ri中的R表元组只需要与si中的S表元组进行比较。

### Basic Hash Join 基础哈希连接
* Phase #1 – Build: Scan the outer relation and populate a hash table using the hash function h1 on the join attributes. The key in the hash table is the join attributes. The value depends on the implementation.
* Phase #2 – Probe: Scan the inner relation and use the hash function h1 on each tuple to jump to a location in the hash table and find a matching tuple. Since there may be collisions in the hash table, the DBMS will need to examine the original values of the join attribute(s) to determine whether tuples
are truly matching.

* 阶段1 - 创建：利用h1哈希函数对外部表中的连接字段进行哈希，哈希表中的key是表中的连接字段，value依赖与具体实现。
* 阶段2 - 查询：扫描内部表，并利用h1哈希函数对每个元组进行哈希，在哈希表中进行定位，并寻找匹配的元组。
由于哈希表可能出现哈希冲突，DBMS需要检查连接属性的原始值，以确定元组是否真正匹配。

If the DBMS knows the size of the outer table, the join can use a static hash table. If it does not know the size, then the join has to use a dynamic hash table or allow for overflow pages.

如果DBMS知道外部表的大小，则连接可以使用静态哈希表。如果它不知道大小，则联接必须使用动态哈希表或允许溢出。


### Grace Hash Join / Hybrid Hash Join Grace哈希连接/混合哈希连接
When the tables do not fit on main memory, you do not want the buffer pool manager constantly swapping tables in and out. The Grace Hash Join is an extension of the basic hash join that is also hashes the inner table into partitions that are written out to disk. The name “Grace” comes from GRACE database machine developed during the 1980s in Japan.

当表不适合放入主内存时，您不希望缓冲池管理器不断交换表。Grace哈希连接是基础哈希联接的扩展，该联接还将内部表散列到写出到磁盘的分区中。“Grace”这个名字来自1980年代在日本开发的GRACE数据库机器。

* Phase #1 – Build: Scan both the outer and inner tables and populate a hash table using the hash function h1 on the join attributes. The hash table’s buckets are written out to disk as needed. If a single bucket does not fit in memory, then use recursive partitioning with a second hash function h2
(where h1 = h2) to further divide the bucket. 
* Phase #2 – Probe: For each bucket level, retrieve the corresponding pages for both outer and inner tables. Then perform a nested loop join on the tuples in those two pages. The pages will fit in memory, so this join operation will be fast.
Partitioning Phase Cost: 2 × (M + N)
Probe Phase Cost: (M + N)
Total Cost: 3 × (M + N)


* 阶段1 – 创建：扫描外部表和内部表，并使用联接属性上的哈希函数h1填充哈希表。哈希表的存储桶将根据需要写出到磁盘。如果单个存储桶不适合内存，则将递归分区与第二个哈希函数h2一起使用（其中 h1 = h2） 以进一步划分存储桶。
* 阶段2 – 探测：对于每个存储桶级别，检索外部表和内部表的相应页面。然后对这两个页面中的元组执行嵌套循环联接。这些页面将适合内存，因此此联接操作将很快。

分桶步骤代价：2 × (M + N)
探测代价：(M + N)
总代价: 3 × (M + N)
