1
00:00:01,300 --> 00:00:05,129
[Music]

2
00:00:05,200 --> 00:00:05,930
[Applause]

3
00:00:05,930 --> 00:00:08,630
[Music]

4
00:00:08,630 --> 00:00:10,020
[Applause]

5
00:00:10,020 --> 00:00:11,480
[Music]

6
00:00:11,480 --> 00:00:13,889
today we thought that Constitution and

7
00:00:13,889 --> 00:00:16,379
as I said compilation and QWERTY

8
00:00:16,379 --> 00:00:18,600
compilation from glass class and vectors

9
00:00:18,600 --> 00:00:20,850
vectorization are sort of the two main

10
00:00:20,850 --> 00:00:22,890
methods we can apply in a modern

11
00:00:22,890 --> 00:00:25,170
database system to improve query

12
00:00:25,170 --> 00:00:27,359
performance so I'm gonna first start

13
00:00:27,359 --> 00:00:29,310
talk about what vector a vector ization

14
00:00:29,310 --> 00:00:31,230
is what however actually gonna use Sim D

15
00:00:31,230 --> 00:00:33,090
and then the paper you guys were signed

16
00:00:33,090 --> 00:00:36,210
to read was this sort of recipe book or

17
00:00:36,210 --> 00:00:38,790
guide from these the guys at Columbia on

18
00:00:38,790 --> 00:00:42,059
how to take sort of classic database

19
00:00:42,059 --> 00:00:43,620
algorithms to do various things we need

20
00:00:43,620 --> 00:00:45,629
in Saturday to system and implement them

21
00:00:45,629 --> 00:00:47,520
using the Cindy and I like it because

22
00:00:47,520 --> 00:00:49,440
again it covers like you know all the

23
00:00:49,440 --> 00:00:51,030
various things would actually need in a

24
00:00:51,030 --> 00:00:52,710
database system to run analytical

25
00:00:52,710 --> 00:00:54,899
queries the spoiler would be is that

26
00:00:54,899 --> 00:00:56,940
I'll just say upfront that none of it

27
00:00:56,940 --> 00:00:59,340
actually works with some exception

28
00:00:59,340 --> 00:01:00,510
because they're gonna make this big

29
00:01:00,510 --> 00:01:02,640
assumption about their operating

30
00:01:02,640 --> 00:01:03,840
environment which I'll cover when we get

31
00:01:03,840 --> 00:01:05,339
to that and then we'll finish up talking

32
00:01:05,339 --> 00:01:09,210
about project three topics okay all

33
00:01:09,210 --> 00:01:12,240
right so vectorization is the process or

34
00:01:12,240 --> 00:01:13,830
the the method we're going to apply in

35
00:01:13,830 --> 00:01:16,350
our database system to take an algorithm

36
00:01:16,350 --> 00:01:17,970
that was originally implemented assuming

37
00:01:17,970 --> 00:01:21,240
scale or operations and we're you're

38
00:01:21,240 --> 00:01:22,409
gonna take you know one piece of data

39
00:01:22,409 --> 00:01:25,860
and apply one change or modification or

40
00:01:25,860 --> 00:01:28,380
operation to it and the I and then we're

41
00:01:28,380 --> 00:01:30,869
gonna convert that to now being able to

42
00:01:30,869 --> 00:01:33,479
take a vector of data items whether

43
00:01:33,479 --> 00:01:35,729
they're tuple values tuple pointers

44
00:01:35,729 --> 00:01:39,119
it depends on the algorithm and then now

45
00:01:39,119 --> 00:01:41,850
we can invoke a simpie instruction that

46
00:01:41,850 --> 00:01:44,790
it's gonna allow us to apply the same

47
00:01:44,790 --> 00:01:46,860
modification apply the same operation on

48
00:01:46,860 --> 00:01:49,770
those vector of items within a single

49
00:01:49,770 --> 00:01:52,590
instruction right and so we'll see this

50
00:01:52,590 --> 00:01:55,649
though it's not always going to be there

51
00:01:55,649 --> 00:01:57,570
are there is some prep work where we

52
00:01:57,570 --> 00:01:59,009
have to put things into these special

53
00:01:59,009 --> 00:02:00,600
registers and then apply to vectorize

54
00:02:00,600 --> 00:02:01,920
instruction so it's not like we

55
00:02:01,920 --> 00:02:04,049
magically magically can make anything in

56
00:02:04,049 --> 00:02:06,479
our code become vectorize so again the

57
00:02:06,479 --> 00:02:07,530
paper you guys that we're reading was

58
00:02:07,530 --> 00:02:09,239
about how to take very specialized or

59
00:02:09,239 --> 00:02:10,889
take very specific algorithms or

60
00:02:10,889 --> 00:02:12,330
components of the dating system

61
00:02:12,330 --> 00:02:14,460
and and being able to run them in

62
00:02:14,460 --> 00:02:16,800
parallel so it's sort of obvious why

63
00:02:16,800 --> 00:02:19,470
we'd want to do this right because now

64
00:02:19,470 --> 00:02:21,810
we can do more work with your

65
00:02:21,810 --> 00:02:23,550
instructions but one of the big

66
00:02:23,550 --> 00:02:24,600
advantages we're also going to get from

67
00:02:24,600 --> 00:02:26,160
this is that this is gonna be

68
00:02:26,160 --> 00:02:28,440
independent of all the things we talked

69
00:02:28,440 --> 00:02:29,430
about before we when we talk about

70
00:02:29,430 --> 00:02:32,130
parallel query processing because that

71
00:02:32,130 --> 00:02:34,050
was all about how to take a query or

72
00:02:34,050 --> 00:02:35,310
whatever you wanted in our database

73
00:02:35,310 --> 00:02:37,380
system and divide the world cup across

74
00:02:37,380 --> 00:02:39,330
multiple threads now we're saying in

75
00:02:39,330 --> 00:02:40,560
this lecture here how do we take a

76
00:02:40,560 --> 00:02:43,200
single thread and make what it's doing

77
00:02:43,200 --> 00:02:46,470
actually being run in parallel right and

78
00:02:46,470 --> 00:02:47,970
again the speed up you can get

79
00:02:47,970 --> 00:02:49,470
potentially is massive because its

80
00:02:49,470 --> 00:02:52,020
multiplicative right so say I have a

81
00:02:52,020 --> 00:02:55,500
Algrim that I can run on 32 cores at 32

82
00:02:55,500 --> 00:02:58,530
threads so I get a 32x speed-up if I do

83
00:02:58,530 --> 00:03:00,330
a fight you know if I paralyze that but

84
00:03:00,330 --> 00:03:02,580
then now if I'm doing vectorization from

85
00:03:02,580 --> 00:03:03,750
what the work each thread is actually

86
00:03:03,750 --> 00:03:07,290
doing and say I have a four-lane Cindy

87
00:03:07,290 --> 00:03:10,530
register meaning for a piece of work I

88
00:03:10,530 --> 00:03:13,080
can run I can operate on four data items

89
00:03:13,080 --> 00:03:15,030
in parallel with one seen the

90
00:03:15,030 --> 00:03:17,880
instruction so now I'm gonna get also 4x

91
00:03:17,880 --> 00:03:20,880
speed up there so 32 times 4 is 128 so

92
00:03:20,880 --> 00:03:22,560
potentially I could go from a single

93
00:03:22,560 --> 00:03:24,300
threaded scalar implementation of an

94
00:03:24,300 --> 00:03:26,040
algorithm to something that I can run

95
00:03:26,040 --> 00:03:29,540
with 128 2128 X speed-up

96
00:03:29,540 --> 00:03:33,030
now the problems gonna be as as I said

97
00:03:33,030 --> 00:03:35,130
to him earlier before class started we

98
00:03:35,130 --> 00:03:37,320
are never ever gonna cheat thee that the

99
00:03:37,320 --> 00:03:38,880
maximum speed-up like this is our upper

100
00:03:38,880 --> 00:03:40,830
bound and we'll see what why when we go

101
00:03:40,830 --> 00:03:42,450
along again as we have a pair of things

102
00:03:42,450 --> 00:03:43,800
get in registers and out of registers

103
00:03:43,800 --> 00:03:45,660
why we're never actually going to either

104
00:03:45,660 --> 00:03:47,700
cheapest but like this is a good target

105
00:03:47,700 --> 00:03:49,019
this is something that we definitely

106
00:03:49,019 --> 00:03:51,300
want to achieve or try to treat to

107
00:03:51,300 --> 00:03:55,590
achieve so who here is taken in 16 for

108
00:03:55,590 --> 00:03:59,310
18 all right little a little over 1/2

109
00:03:59,310 --> 00:04:01,440
all right who here has never seen Cindy

110
00:04:01,440 --> 00:04:04,500
before ok that's fine all right

111
00:04:04,500 --> 00:04:07,890
so Cindy is a as the classes heap

112
00:04:07,890 --> 00:04:10,890
instructions that the processor is gonna

113
00:04:10,890 --> 00:04:13,110
provide for us that allows us to came to

114
00:04:13,110 --> 00:04:15,390
do these vectorized operations if we do

115
00:04:15,390 --> 00:04:18,029
trash this with sisty which is single

116
00:04:18,029 --> 00:04:19,620
structure and single data a data item

117
00:04:19,620 --> 00:04:21,680
Cindy is going to be single instruction

118
00:04:21,680 --> 00:04:25,710
multiple data items together and this is

119
00:04:25,710 --> 00:04:26,160
sort of

120
00:04:26,160 --> 00:04:28,740
this notion of Cindy versus sisty comes

121
00:04:28,740 --> 00:04:30,570
from flynn's taxonomy of parallel

122
00:04:30,570 --> 00:04:32,160
databases or started parallel systems

123
00:04:32,160 --> 00:04:36,030
from like the 1960s and so every

124
00:04:36,030 --> 00:04:38,220
instruction set for every CPU nowadays

125
00:04:38,220 --> 00:04:41,100
is gonna have and support for Cindy

126
00:04:41,100 --> 00:04:42,960
operations just the name of what they're

127
00:04:42,960 --> 00:04:44,850
gonna call the class of these extensions

128
00:04:44,850 --> 00:04:47,690
or instructions is gonna be different

129
00:04:47,690 --> 00:04:49,890
paper you guys read us all about Intel

130
00:04:49,890 --> 00:04:52,850
stuff and in their world it's SSE or ADX

131
00:04:52,850 --> 00:04:54,930
and paper you guys were deemed favored

132
00:04:54,930 --> 00:04:57,120
it's 2015 I think so they were dealing

133
00:04:57,120 --> 00:04:57,990
with avx2

134
00:04:57,990 --> 00:05:02,460
which is 250 256-bit registers the state

135
00:05:02,460 --> 00:05:06,450
of the art now is 200 and sorry 512 12

136
00:05:06,450 --> 00:05:09,570
bits power from IBM has this thing

137
00:05:09,570 --> 00:05:11,610
called altivec arm has their thing

138
00:05:11,610 --> 00:05:13,590
called neon and then a few years ago the

139
00:05:13,590 --> 00:05:15,510
action proposed something called SPE the

140
00:05:15,510 --> 00:05:16,830
scalable vector instructions

141
00:05:16,830 --> 00:05:18,120
so what's guy should be really cool

142
00:05:18,120 --> 00:05:19,980
about this and I don't know if anybody

143
00:05:19,980 --> 00:05:21,810
actually implements this yet is the way

144
00:05:21,810 --> 00:05:23,190
these they sort of set up the

145
00:05:23,190 --> 00:05:24,900
instructions is that they're not gonna

146
00:05:24,900 --> 00:05:28,320
be specific to any register size meaning

147
00:05:28,320 --> 00:05:30,780
they'll have a sort of a sort of generic

148
00:05:30,780 --> 00:05:33,180
class of vectorized instructions and

149
00:05:33,180 --> 00:05:34,500
then depending on how it's implemented

150
00:05:34,500 --> 00:05:37,050
in the actual CPU you you can then

151
00:05:37,050 --> 00:05:39,270
operate on like you know 1024 bits or

152
00:05:39,270 --> 00:05:42,240
512 bits at a time right when all this

153
00:05:42,240 --> 00:05:45,090
Intel stuff like avx2 or instructions to

154
00:05:45,090 --> 00:05:48,540
do 256 bit simply instructions then 512

155
00:05:48,540 --> 00:05:50,010
soar 5 in 12a and you can't just like

156
00:05:50,010 --> 00:05:52,890
you you can't just take these run it on

157
00:05:52,890 --> 00:05:54,240
a newer CPU and think you're gonna run

158
00:05:54,240 --> 00:05:55,500
on these ones you have to rewrite your

159
00:05:55,500 --> 00:05:57,510
your code to actually be aware that I'm

160
00:05:57,510 --> 00:05:59,310
running on a larger larger size

161
00:05:59,310 --> 00:06:02,130
registers so let's look at a really

162
00:06:02,130 --> 00:06:05,700
simple example of a simpie operation so

163
00:06:05,700 --> 00:06:08,550
say we have two vectors x and y and we

164
00:06:08,550 --> 00:06:10,560
just want to add together the elements

165
00:06:10,560 --> 00:06:12,870
of X with the elements of Y at each each

166
00:06:12,870 --> 00:06:14,940
all set so the way we would implement

167
00:06:14,940 --> 00:06:18,180
this you know in intro to CS class range

168
00:06:18,180 --> 00:06:19,830
or database class it's just we have a

169
00:06:19,830 --> 00:06:21,330
for loop where we know the size of the

170
00:06:21,330 --> 00:06:23,460
vector assuming the same size and then

171
00:06:23,460 --> 00:06:25,470
for every element X and the

172
00:06:25,470 --> 00:06:27,270
corresponding element of Y we add them

173
00:06:27,270 --> 00:06:30,000
together and we write them into to the

174
00:06:30,000 --> 00:06:32,280
output vector Z and so the way we would

175
00:06:32,280 --> 00:06:34,140
this would get implemented or executed

176
00:06:34,140 --> 00:06:36,210
with sisty instructions is just again

177
00:06:36,210 --> 00:06:38,310
taking the for loop ripping through and

178
00:06:38,310 --> 00:06:40,260
taking you know one element from x one

179
00:06:40,260 --> 00:06:42,840
from why invoking one instruction to do

180
00:06:42,840 --> 00:06:44,970
that do the addition and then writing it

181
00:06:44,970 --> 00:06:48,750
to a upper buffer now with Cindy what we

182
00:06:48,750 --> 00:06:51,570
can do is we're gonna take a vector of

183
00:06:51,570 --> 00:06:53,550
elements from these two arrays and then

184
00:06:53,550 --> 00:06:55,080
combine them together in a single

185
00:06:55,080 --> 00:06:57,420
register and then invoke one cindy

186
00:06:57,420 --> 00:06:59,130
instruction to add them together and

187
00:06:59,130 --> 00:07:00,900
print and produce our output buffer all

188
00:07:00,900 --> 00:07:02,130
right so we're gonna take four elements

189
00:07:02,130 --> 00:07:03,780
here so we would say this is a 4-lane

190
00:07:03,780 --> 00:07:06,120
register and assuming we have 32-bit

191
00:07:06,120 --> 00:07:08,310
integers we'll say this is a 128-bit

192
00:07:08,310 --> 00:07:11,580
Simbi register so once we populate this

193
00:07:11,580 --> 00:07:14,280
register we then invoke the simpie

194
00:07:14,280 --> 00:07:15,660
instruction on those two registers and

195
00:07:15,660 --> 00:07:18,090
then it's gonna write out some output

196
00:07:18,090 --> 00:07:20,070
result to another cindy register that's

197
00:07:20,070 --> 00:07:22,560
going to be the same size do the same

198
00:07:22,560 --> 00:07:24,330
thing for the next four elements evoke

199
00:07:24,330 --> 00:07:26,460
the sim D and now we produce our output

200
00:07:26,460 --> 00:07:34,230
yes this question is this question is

201
00:07:34,230 --> 00:07:37,980
loading into a cindy register just as

202
00:07:37,980 --> 00:07:40,320
fast is loading into a like a regular

203
00:07:40,320 --> 00:07:44,820
you know single data item right sure it

204
00:07:44,820 --> 00:07:47,490
depends on where the data is located

205
00:07:47,490 --> 00:07:48,600
like if you're doing that selectively

206
00:07:48,600 --> 00:07:50,700
store thing we talked about that Stefan

207
00:07:50,700 --> 00:07:53,220
can be slower is Miss pans multiple

208
00:07:53,220 --> 00:07:56,130
cache lines it's more work I think the

209
00:07:56,130 --> 00:07:59,220
way I think the way x86 works is you can

210
00:07:59,220 --> 00:08:02,070
only do one or two loads and stores per

211
00:08:02,070 --> 00:08:05,910
cycle so if this thing's really wide you

212
00:08:05,910 --> 00:08:08,670
may have to do multiple loads and like

213
00:08:08,670 --> 00:08:10,230
across multiple cycles whereas like

214
00:08:10,230 --> 00:08:13,860
writing one thing into the to a single

215
00:08:13,860 --> 00:08:16,050
data register is super fast and that's

216
00:08:16,050 --> 00:08:17,250
what I'm saying you're never going to

217
00:08:17,250 --> 00:08:20,190
achieve the theoretical maximum speed-up

218
00:08:20,190 --> 00:08:22,140
just because there's there's overhead of

219
00:08:22,140 --> 00:08:24,960
putting things in here right but

220
00:08:24,960 --> 00:08:26,190
certainly in the case of this you know

221
00:08:26,190 --> 00:08:28,200
it this would be a really good trade-off

222
00:08:28,200 --> 00:08:31,280
because we went from eight instructions

223
00:08:31,280 --> 00:08:34,500
to do it to do the addition to two two

224
00:08:34,500 --> 00:08:37,169
instructions that probably give me a win

225
00:08:37,169 --> 00:08:39,560
for us yes

226
00:08:47,680 --> 00:08:51,260
so this question is if we go to 512-bit

227
00:08:51,260 --> 00:08:53,930
registers in avx-512 that's going to hit

228
00:08:53,930 --> 00:08:56,050
our cache line limit does that mean now

229
00:08:56,050 --> 00:08:58,370
the loads into it are gonna be more

230
00:08:58,370 --> 00:09:00,290
expensive and they started the stores

231
00:09:00,290 --> 00:09:01,490
getting the data out with that and it'd

232
00:09:01,490 --> 00:09:03,110
be more expensive than this because I

233
00:09:03,110 --> 00:09:12,470
can't beat the spammable cache lines if

234
00:09:12,470 --> 00:09:13,550
you're not if you say if you're not

235
00:09:13,550 --> 00:09:15,830
cache a line yet like depends where this

236
00:09:15,830 --> 00:09:18,020
data is also like think of this is like

237
00:09:18,020 --> 00:09:21,110
this is hanging out in l1 so l1 is in

238
00:09:21,110 --> 00:09:24,470
Exodus 32 kilobytes so we could take all

239
00:09:24,470 --> 00:09:25,520
the data you want to store and keep that

240
00:09:25,520 --> 00:09:27,560
in l1 and then it's not like we're going

241
00:09:27,560 --> 00:09:29,029
out then then when you go get it all

242
00:09:29,029 --> 00:09:32,660
right all right so what can we do with

243
00:09:32,660 --> 00:09:34,790
Cindy well I showed some basic

244
00:09:34,790 --> 00:09:38,380
arithmetic operators and again under the

245
00:09:38,380 --> 00:09:42,709
at least for x86 for the sve I think

246
00:09:42,709 --> 00:09:45,290
they start the same issue like like the

247
00:09:45,290 --> 00:09:47,120
register side the size of the register

248
00:09:47,120 --> 00:09:48,740
will be will be fixed but like it

249
00:09:48,740 --> 00:09:52,550
doesn't necessarily mean that the the

250
00:09:52,550 --> 00:09:55,490
size of the Lane has to be fixed so my

251
00:09:55,490 --> 00:09:57,470
example here I had at 128 bits and

252
00:09:57,470 --> 00:09:59,360
therefore I had a simile instruction

253
00:09:59,360 --> 00:10:01,399
that could take 4 integers and add them

254
00:10:01,399 --> 00:10:03,790
together but if I had 16-bit integers

255
00:10:03,790 --> 00:10:06,260
there might be another instruction they

256
00:10:06,260 --> 00:10:08,089
provide to know how to take eight 16-bit

257
00:10:08,089 --> 00:10:10,730
integers and add them together right so

258
00:10:10,730 --> 00:10:12,230
typically the way you when you when you

259
00:10:12,230 --> 00:10:14,029
write Sindhi code you specify like I

260
00:10:14,029 --> 00:10:16,520
know what what with the data type sizes

261
00:10:16,520 --> 00:10:18,589
that I'm operating on we talked about

262
00:10:18,589 --> 00:10:20,720
how to move data in and out and then

263
00:10:20,720 --> 00:10:21,709
there's all these logical instructions

264
00:10:21,709 --> 00:10:23,930
to do comparisons on you know a bit

265
00:10:23,930 --> 00:10:27,290
manipulation we can do comparison

266
00:10:27,290 --> 00:10:29,029
instructions and that will need this to

267
00:10:29,029 --> 00:10:30,170
do predicates to say we know whether

268
00:10:30,170 --> 00:10:31,220
something equals something in our where

269
00:10:31,220 --> 00:10:34,070
clause shuffle instructions is the

270
00:10:34,070 --> 00:10:36,110
ability to take the output of or take

271
00:10:36,110 --> 00:10:37,910
one sim you register and write it into

272
00:10:37,910 --> 00:10:39,920
another simony register all right and

273
00:10:39,920 --> 00:10:41,630
this is give me a big win for us cuz now

274
00:10:41,630 --> 00:10:43,790
we don't have to take the output put it

275
00:10:43,790 --> 00:10:45,560
in l1 and then write it back out into

276
00:10:45,560 --> 00:10:47,089
another register we know directly from

277
00:10:47,089 --> 00:10:49,670
one register to the next and then the

278
00:10:49,670 --> 00:10:52,550
other random things like we'll see in a

279
00:10:52,550 --> 00:10:54,980
second like the the take the data that's

280
00:10:54,980 --> 00:10:56,510
sitting in l1 and then

281
00:10:56,510 --> 00:10:58,640
revert it into the form that the same

282
00:10:58,640 --> 00:11:01,790
deregister ones or if now we have

283
00:11:01,790 --> 00:11:03,020
something in our simply register maybe

284
00:11:03,020 --> 00:11:04,820
we want to write it out to memory but we

285
00:11:04,820 --> 00:11:06,620
don't want to pollute our CPU cache so

286
00:11:06,620 --> 00:11:08,270
these these these streaming instructions

287
00:11:08,270 --> 00:11:09,890
allow us to take the output directly

288
00:11:09,890 --> 00:11:11,990
from this Indy register and put it put

289
00:11:11,990 --> 00:11:13,280
it right into memory without going

290
00:11:13,280 --> 00:11:15,230
through the normal cash in hierarchy all

291
00:11:15,230 --> 00:11:18,800
right so the Bay I main idea what we're

292
00:11:18,800 --> 00:11:20,930
trying to achieve here is by having all

293
00:11:20,930 --> 00:11:24,500
these different instructions you know we

294
00:11:24,500 --> 00:11:28,340
can try to do it as pack as much useful

295
00:11:28,340 --> 00:11:30,140
data we want into our semi instructions

296
00:11:30,140 --> 00:11:32,480
and do as much processing as we can all

297
00:11:32,480 --> 00:11:34,310
in that data while that they're in our

298
00:11:34,310 --> 00:11:36,680
semi registers before we have to go

299
00:11:36,680 --> 00:11:39,230
shove it out into memory right and these

300
00:11:39,230 --> 00:11:41,470
like especially this these these

301
00:11:41,470 --> 00:11:43,400
conversion up or so that the shuffling

302
00:11:43,400 --> 00:11:45,470
operators this is gonna allow us to do

303
00:11:45,470 --> 00:11:46,730
this will change some operations

304
00:11:46,730 --> 00:11:48,470
together you never have to touch CPU

305
00:11:48,470 --> 00:11:50,570
cache and then we can produce the

306
00:11:50,570 --> 00:11:53,600
results that we want right because last

307
00:11:53,600 --> 00:11:54,980
one here is also super important to

308
00:11:54,980 --> 00:11:58,340
because especially for joins like if I

309
00:11:58,340 --> 00:12:01,640
know that I'm doing the join the tuple

310
00:12:01,640 --> 00:12:03,050
matches but there's a pipeline breaker

311
00:12:03,050 --> 00:12:05,270
above me and I can't I can't do anything

312
00:12:05,270 --> 00:12:07,850
with the output of the join I could then

313
00:12:07,850 --> 00:12:09,230
shove it out the memory because I know

314
00:12:09,230 --> 00:12:11,120
I'm not gonna need it again until I come

315
00:12:11,120 --> 00:12:13,550
back and go to the next pipeline so this

316
00:12:13,550 --> 00:12:16,070
these streaming functions allowed me

317
00:12:16,070 --> 00:12:17,270
your streaming instructions allow me to

318
00:12:17,270 --> 00:12:19,070
like use the data that's in the seamy

319
00:12:19,070 --> 00:12:21,500
red shirt and then you know put it out

320
00:12:21,500 --> 00:12:22,760
into memory before going back to it

321
00:12:22,760 --> 00:12:26,540
alright so we'll see after this after

322
00:12:26,540 --> 00:12:28,070
the spring break and after the the

323
00:12:28,070 --> 00:12:31,160
project proposals next class how we can

324
00:12:31,160 --> 00:12:34,040
use some of these techniques and in our

325
00:12:34,040 --> 00:12:40,340
joint operation as well yes the question

326
00:12:40,340 --> 00:12:41,690
is these these seeming structure

327
00:12:41,690 --> 00:12:43,130
streaming structures sound very nice are

328
00:12:43,130 --> 00:12:45,860
they available for non non semi

329
00:12:45,860 --> 00:12:49,820
operations yes I think so I yes I think

330
00:12:49,820 --> 00:12:52,580
if you streaming writes I think that's

331
00:12:52,580 --> 00:12:59,630
what they're called in in x86 yeah ok so

332
00:12:59,630 --> 00:13:01,340
again we're going to focus on x86

333
00:13:01,340 --> 00:13:02,780
because that's the dominant CPU

334
00:13:02,780 --> 00:13:04,370
architecture and this is just showing

335
00:13:04,370 --> 00:13:08,300
you a history of over time how the the

336
00:13:08,300 --> 00:13:10,279
Intel is expand this of course

337
00:13:10,279 --> 00:13:16,639
poor for for you know for Cindy the very

338
00:13:16,639 --> 00:13:18,829
beginning it was called MMX and this was

339
00:13:18,829 --> 00:13:20,810
like it's like super primitive but this

340
00:13:20,810 --> 00:13:22,790
is like I got a Pentium 3 days or

341
00:13:22,790 --> 00:13:24,680
pending two days until we have this big

342
00:13:24,680 --> 00:13:26,809
marketing pitch about hubby's I think

343
00:13:26,809 --> 00:13:28,430
MMX actually didn't stand for anything

344
00:13:28,430 --> 00:13:30,499
Intel's afraid of getting sued so like

345
00:13:30,499 --> 00:13:31,670
they just took three letters put it

346
00:13:31,670 --> 00:13:33,649
together I think now people think of

347
00:13:33,649 --> 00:13:35,300
these as like multimedia extensions but

348
00:13:35,300 --> 00:13:37,579
at the time I think there was a lawsuit

349
00:13:37,579 --> 00:13:40,879
where someone claimed that an intel

350
00:13:40,879 --> 00:13:42,709
stole their MMX name from some other

351
00:13:42,709 --> 00:13:44,089
company but then they found all this

352
00:13:44,089 --> 00:13:45,379
internal documentation that showed like

353
00:13:45,379 --> 00:13:47,629
oh it's three land random letters it

354
00:13:47,629 --> 00:13:48,620
means nothing all right

355
00:13:48,620 --> 00:13:50,449
today I lost that lawsuit but it very

356
00:13:50,449 --> 00:13:52,129
beginning was super permanent right it

357
00:13:52,129 --> 00:13:55,930
could only do some basic operations on

358
00:13:55,930 --> 00:13:58,879
32 or 16-bit integers and this early

359
00:13:58,879 --> 00:14:00,339
version as well it would it would be

360
00:14:00,339 --> 00:14:03,379
this the the CPU wouldn't be normally

361
00:14:03,379 --> 00:14:04,939
executing system instructions but then

362
00:14:04,939 --> 00:14:06,439
when you executed assembly instructions

363
00:14:06,439 --> 00:14:09,079
you had to pause the syste stuff do the

364
00:14:09,079 --> 00:14:11,180
sim D and then start back up the the

365
00:14:11,180 --> 00:14:14,420
sistine after that after MMX when SSE

366
00:14:14,420 --> 00:14:15,980
came out then you can actually do these

367
00:14:15,980 --> 00:14:17,449
in parallel that's what I was saying

368
00:14:17,449 --> 00:14:20,720
before about how with an atom or a tall

369
00:14:20,720 --> 00:14:23,839
order CPU architecture we can have

370
00:14:23,839 --> 00:14:25,160
different parts of the CPU doing

371
00:14:25,160 --> 00:14:26,930
different things at the same time right

372
00:14:26,930 --> 00:14:28,490
you could have executing some similar

373
00:14:28,490 --> 00:14:30,410
instructions on on the city registers

374
00:14:30,410 --> 00:14:32,750
what while we do you know stuff on

375
00:14:32,750 --> 00:14:35,600
regular CP registers what's the MMX you

376
00:14:35,600 --> 00:14:37,639
couldn't do that and in the modern era

377
00:14:37,639 --> 00:14:41,059
it started when AVX came out I don't

378
00:14:41,059 --> 00:14:43,579
think there's any I think this was just

379
00:14:43,579 --> 00:14:45,050
a naming change because they went from

380
00:14:45,050 --> 00:14:48,439
120 bits to 256 bits and then instead of

381
00:14:48,439 --> 00:14:50,689
calling this a vx5 which would make

382
00:14:50,689 --> 00:14:52,220
sense when they called a bx 2 or a VX

383
00:14:52,220 --> 00:14:54,319
whatever like they call it 512 and i've

384
00:14:54,319 --> 00:14:55,939
looked online and as far as I can tell

385
00:14:55,939 --> 00:14:58,639
they have no plans to put out 1024 bits

386
00:14:58,639 --> 00:15:00,620
so this is sort of the where we're at

387
00:15:00,620 --> 00:15:01,399
right right now

388
00:15:01,399 --> 00:15:02,990
and this link here will take you to this

389
00:15:02,990 --> 00:15:04,759
awesome video from the sky James randhir

390
00:15:04,759 --> 00:15:07,490
who was a like a Sindhi designer or

391
00:15:07,490 --> 00:15:09,259
evangelist at Intel and he basically

392
00:15:09,259 --> 00:15:10,999
shows all the awesome things you can do

393
00:15:10,999 --> 00:15:12,829
is Cindy not it's not a database person

394
00:15:12,829 --> 00:15:13,939
it's just like it's showing you how to

395
00:15:13,939 --> 00:15:15,620
actually flex the heart ring get the

396
00:15:15,620 --> 00:15:18,860
best you know get the best bang for the

397
00:15:18,860 --> 00:15:20,329
buck and I highly recommend this video

398
00:15:20,329 --> 00:15:22,309
like it's I think it's like an hour so

399
00:15:22,309 --> 00:15:23,350
long

400
00:15:23,350 --> 00:15:26,890
all right so uh so there's me trade-offs

401
00:15:26,890 --> 00:15:28,570
obviously using Cindy it seems like it's

402
00:15:28,570 --> 00:15:29,950
a magical thing or we're not always want

403
00:15:29,950 --> 00:15:32,560
to use and of course yes in some cases

404
00:15:32,560 --> 00:15:34,120
we will see will get a significant

405
00:15:34,120 --> 00:15:36,790
performance gains if we use them but the

406
00:15:36,790 --> 00:15:38,500
tricky thing is gonna be is actually

407
00:15:38,500 --> 00:15:40,300
implementing an algorithm to use

408
00:15:40,300 --> 00:15:42,850
vectorized instructions is is not gonna

409
00:15:42,850 --> 00:15:46,420
be trivial and as I said in some cases

410
00:15:46,420 --> 00:15:49,420
it's actually gonna because in the

411
00:15:49,420 --> 00:15:50,260
Columbia paper that make certain

412
00:15:50,260 --> 00:15:52,300
assumptions about the environment in a

413
00:15:52,300 --> 00:15:54,670
real database system their assumptions

414
00:15:54,670 --> 00:15:56,410
don't hold and actually Cindy will hurt

415
00:15:56,410 --> 00:15:58,480
you so what we'll cover what that is

416
00:15:58,480 --> 00:16:01,600
okay and again this is this is the issue

417
00:16:01,600 --> 00:16:02,860
we're gonna have of getting things in

418
00:16:02,860 --> 00:16:04,060
and out of the registers are the reason

419
00:16:04,060 --> 00:16:05,620
why we may not always get the speed-up

420
00:16:05,620 --> 00:16:11,470
we we want to achieve okay so now part

421
00:16:11,470 --> 00:16:12,820
of the reason why it's gonna be tricky

422
00:16:12,820 --> 00:16:16,600
is that there's no magic flag and the

423
00:16:16,600 --> 00:16:18,790
compiler that's gonna match take all our

424
00:16:18,790 --> 00:16:20,560
database in from you know database

425
00:16:20,560 --> 00:16:22,660
system all the source code and be able

426
00:16:22,660 --> 00:16:26,290
to paralyze everything right for for

427
00:16:26,290 --> 00:16:28,360
simple things maybe but for the more

428
00:16:28,360 --> 00:16:29,410
complex things we're doing with the

429
00:16:29,410 --> 00:16:31,120
process queries it's just not gonna

430
00:16:31,120 --> 00:16:33,760
happen so again if we want to have

431
00:16:33,760 --> 00:16:35,700
vectorization in our database system

432
00:16:35,700 --> 00:16:37,960
people pay you know people pay you money

433
00:16:37,960 --> 00:16:40,440
to go do this right because it's hard

434
00:16:40,440 --> 00:16:42,220
let's see how we can actually achieve

435
00:16:42,220 --> 00:16:45,490
this so the three ways are the automatic

436
00:16:45,490 --> 00:16:47,320
vectorization from the compiler and then

437
00:16:47,320 --> 00:16:49,030
we can then pass hints to the compiler

438
00:16:49,030 --> 00:16:50,890
and tell us what what we actually want

439
00:16:50,890 --> 00:16:53,320
and then there's also writing our source

440
00:16:53,320 --> 00:16:55,420
code with explicit vectorization using

441
00:16:55,420 --> 00:16:59,920
cpu intrinsics okay so the way to think

442
00:16:59,920 --> 00:17:02,200
about this is like the easiest one to

443
00:17:02,200 --> 00:17:03,550
use is the one at the top because that's

444
00:17:03,550 --> 00:17:04,959
just hoping the compiler figures it out

445
00:17:04,959 --> 00:17:06,849
the more in the bottom is the hardest to

446
00:17:06,849 --> 00:17:08,680
use but we'll have complete control of

447
00:17:08,680 --> 00:17:10,119
what's going into our registers what's

448
00:17:10,119 --> 00:17:11,800
command what instructions were executing

449
00:17:11,800 --> 00:17:15,220
so again easy to use that better better

450
00:17:15,220 --> 00:17:19,240
control but harder to write okay all

451
00:17:19,240 --> 00:17:22,150
right so automatic vectorization is just

452
00:17:22,150 --> 00:17:24,220
saying that where the compiler can

453
00:17:24,220 --> 00:17:27,280
identify when we have chunks of source

454
00:17:27,280 --> 00:17:29,920
code that inside of a loop where the

455
00:17:29,920 --> 00:17:32,740
kernel of the main operation inside that

456
00:17:32,740 --> 00:17:34,480
loop could then be converted into a

457
00:17:34,480 --> 00:17:37,410
vectorized instruction and so for free

458
00:17:37,410 --> 00:17:41,610
loop's this is gonna be easy to do but

459
00:17:41,610 --> 00:17:43,050
the problem is simple loops are not

460
00:17:43,050 --> 00:17:45,480
going to be very common in the the main

461
00:17:45,480 --> 00:17:46,650
thing we want to speed up which is query

462
00:17:46,650 --> 00:17:48,390
execution all right

463
00:17:48,390 --> 00:17:50,790
so in obviously this requires your

464
00:17:50,790 --> 00:17:51,990
Harvard to have the support experience

465
00:17:51,990 --> 00:17:53,580
in the instructions but pretty much

466
00:17:53,580 --> 00:17:56,550
every you know every modern intelligent

467
00:17:56,550 --> 00:17:58,380
net today whether you have 256 or 512

468
00:17:58,380 --> 00:18:00,540
it's actually I don't know the laptops

469
00:18:00,540 --> 00:18:04,380
have probably avx2 but any modern Xeon

470
00:18:04,380 --> 00:18:07,350
you know you buy today will have 512 all

471
00:18:07,350 --> 00:18:09,050
right so let's look an example here so

472
00:18:09,050 --> 00:18:11,850
here we have a for loop here and this is

473
00:18:11,850 --> 00:18:13,110
sort of like the the vector wise

474
00:18:13,110 --> 00:18:14,880
primitives we talked about before where

475
00:18:14,880 --> 00:18:16,980
they were going to have the predefined

476
00:18:16,980 --> 00:18:20,880
source code to do the the basic

477
00:18:20,880 --> 00:18:22,140
operations you would need to execute a

478
00:18:22,140 --> 00:18:23,760
query to process you know process data

479
00:18:23,760 --> 00:18:25,620
so what is this doing this is taking

480
00:18:25,620 --> 00:18:27,840
three pointers x y&z the same thing we

481
00:18:27,840 --> 00:18:29,340
showed in the very beginning and then

482
00:18:29,340 --> 00:18:30,750
we're just going to iterate over every

483
00:18:30,750 --> 00:18:32,940
element X and every element of Y and

484
00:18:32,940 --> 00:18:36,480
write them to an alpha but buffer Z so

485
00:18:36,480 --> 00:18:38,640
my question to you guys is is this

486
00:18:38,640 --> 00:18:40,650
something the compiler can automatically

487
00:18:40,650 --> 00:18:43,280
vectorize your shaking head yes why

488
00:18:43,280 --> 00:18:45,840
what's that he's saying bleep own

489
00:18:45,840 --> 00:18:49,530
rolling but that's not that's not but

490
00:18:49,530 --> 00:18:51,030
that's not that's not in using Sindhi

491
00:18:51,030 --> 00:18:55,080
instructions right so he said after you

492
00:18:55,080 --> 00:18:57,630
loop yeah say yeah you would recognize I

493
00:18:57,630 --> 00:18:58,950
have four lanes in the instruction or

494
00:18:58,950 --> 00:19:00,780
send me registers so I unroll it four

495
00:19:00,780 --> 00:19:04,500
times and then I and then you know then

496
00:19:04,500 --> 00:19:07,200
I can vectorize that who agrees or

497
00:19:07,200 --> 00:19:16,740
disagrees bingo that's it yes so it's

498
00:19:16,740 --> 00:19:18,450
not legal to automatically vectorize

499
00:19:18,450 --> 00:19:20,610
this because he's exactly right that you

500
00:19:20,610 --> 00:19:22,620
don't know what these are at compile

501
00:19:22,620 --> 00:19:25,080
time right and it may be the case that

502
00:19:25,080 --> 00:19:26,430
these are actually pointing to the same

503
00:19:26,430 --> 00:19:28,680
chunks of memory so now you have

504
00:19:28,680 --> 00:19:30,930
unpredictable side effects of when you

505
00:19:30,930 --> 00:19:32,240
actually start doing your computation

506
00:19:32,240 --> 00:19:39,120
yes he said he could do global analysis

507
00:19:39,120 --> 00:19:41,690
to prove that they're different

508
00:19:44,130 --> 00:19:45,570
that's not a static you can't do that a

509
00:19:45,570 --> 00:19:49,920
static statically at compile time you

510
00:19:49,920 --> 00:19:51,450
knew that word sure you can run it and

511
00:19:51,450 --> 00:19:54,300
go you can run your database system with

512
00:19:54,300 --> 00:19:59,660
this function check it right and like

513
00:19:59,660 --> 00:20:02,550
you may never see the case where these

514
00:20:02,550 --> 00:20:03,840
are actually pointing to the same thing

515
00:20:03,840 --> 00:20:06,060
but you don't know that because you

516
00:20:06,060 --> 00:20:07,410
don't know you have you know nobody

517
00:20:07,410 --> 00:20:08,970
you've seen all possible inputs to the

518
00:20:08,970 --> 00:20:09,710
database system

519
00:20:09,710 --> 00:20:23,070
yes you're basically claiming can you do

520
00:20:23,070 --> 00:20:25,800
optimistic vectorization where the

521
00:20:25,800 --> 00:20:27,480
compiler could insert some kind of magic

522
00:20:27,480 --> 00:20:28,430
here

523
00:20:28,430 --> 00:20:31,500
do the vectorized version or somehow do

524
00:20:31,500 --> 00:20:33,060
some an analysis on what these guys are

525
00:20:33,060 --> 00:20:35,280
and see whether this would have gotten

526
00:20:35,280 --> 00:20:37,500
stomped on inside the vectorized version

527
00:20:37,500 --> 00:20:40,410
and then if if if no go ahead and keep

528
00:20:40,410 --> 00:20:42,210
my result if yes go back into the scalar

529
00:20:42,210 --> 00:20:57,780
version I think tom is like well if you

530
00:20:57,780 --> 00:21:00,480
pass like what you're saying so I'm just

531
00:21:00,480 --> 00:21:02,130
showing this global variable but you'd

532
00:21:02,130 --> 00:21:04,740
have to pass that in right to this to

533
00:21:04,740 --> 00:21:06,900
this to this function so that you would

534
00:21:06,900 --> 00:21:09,060
then know and then you have to know that

535
00:21:09,060 --> 00:21:12,060
all right I'm gonna loop through from

536
00:21:12,060 --> 00:21:14,130
zero to two max for each of these things

537
00:21:14,130 --> 00:21:19,770
then check that yeah I that sounds like

538
00:21:19,770 --> 00:21:22,610
a lot of work yes

539
00:21:27,470 --> 00:21:30,919
if you do what sorry if he announce if

540
00:21:30,919 --> 00:21:33,379
you know all possible inputs Haley's

541
00:21:33,379 --> 00:21:38,000
analysis I let's let's talk with that

542
00:21:38,000 --> 00:21:39,740
efforts III don't actually what you're

543
00:21:39,740 --> 00:21:41,179
planning but I mean the really simple

544
00:21:41,179 --> 00:21:44,149
issue is like if my if Z is just the off

545
00:21:44,149 --> 00:21:46,850
the the memory location of X plus one

546
00:21:46,850 --> 00:21:51,110
what's gonna happen here now I take X x

547
00:21:51,110 --> 00:21:55,100
and y and I write that into Z but now

548
00:21:55,100 --> 00:21:58,039
when I come back I'm clobbering for the

549
00:21:58,039 --> 00:22:00,019
second loop now I'm clobbering the the

550
00:22:00,019 --> 00:22:02,659
second element of X and that's gonna

551
00:22:02,659 --> 00:22:04,100
produce completely incorrect results

552
00:22:04,100 --> 00:22:05,809
right we want to be able to vectorize

553
00:22:05,809 --> 00:22:07,639
this such that the output of the

554
00:22:07,639 --> 00:22:08,990
vectorized version has been exactly the

555
00:22:08,990 --> 00:22:12,159
same as the as the scalar version right

556
00:22:12,159 --> 00:22:14,750
so reason why this is difficult to do

557
00:22:14,750 --> 00:22:18,350
for a compiler the handle is it's just

558
00:22:18,350 --> 00:22:20,570
the nature of how we write c c++ right

559
00:22:20,570 --> 00:22:22,009
we're writing this code in a way

560
00:22:22,009 --> 00:22:23,600
describing this algorithm with this

561
00:22:23,600 --> 00:22:25,820
computation we want to do in in

562
00:22:25,820 --> 00:22:28,159
sequential terms and write over one

563
00:22:28,159 --> 00:22:30,230
element at a time take two numbers add

564
00:22:30,230 --> 00:22:32,110
together right into this to this buffer

565
00:22:32,110 --> 00:22:36,019
so that's again that's that's seeds are

566
00:22:36,019 --> 00:22:38,179
sort of not set up to provide the

567
00:22:38,179 --> 00:22:40,100
correct hints to the compiler to

568
00:22:40,100 --> 00:22:41,570
recognize that they could do this you

569
00:22:41,570 --> 00:22:42,620
have to do whatever he's proposed me to

570
00:22:42,620 --> 00:22:44,299
do or the next things that I'm

571
00:22:44,299 --> 00:22:46,639
describing the compiler wins okay

572
00:22:46,639 --> 00:22:49,700
again the main takeaway from this is GCC

573
00:22:49,700 --> 00:22:51,139
and clang are not gonna be able to

574
00:22:51,139 --> 00:22:55,399
vectorize that much ICC from from Intel

575
00:22:55,399 --> 00:22:57,409
their proprietary compiler is much more

576
00:22:57,409 --> 00:22:59,120
better at this but even then in many

577
00:22:59,120 --> 00:23:00,559
cases it's not gonna be it'll do because

578
00:23:00,559 --> 00:23:03,009
it's not gonna know what's going on here

579
00:23:03,009 --> 00:23:05,149
all right so what can we do against we

580
00:23:05,149 --> 00:23:07,299
can provide compiler hints to tell the

581
00:23:07,299 --> 00:23:11,149
compiler that we know that there's this

582
00:23:11,149 --> 00:23:13,610
piece of code that's safe for it to

583
00:23:13,610 --> 00:23:16,070
operate on in a vectorized manner right

584
00:23:16,070 --> 00:23:19,820
and so the two basic ways we can do this

585
00:23:19,820 --> 00:23:22,490
is either tell the compiler something up

586
00:23:22,490 --> 00:23:25,100
that we know about the memory locations

587
00:23:25,100 --> 00:23:26,330
that can we could be ever be passing

588
00:23:26,330 --> 00:23:29,149
into this function or we just tell the

589
00:23:29,149 --> 00:23:31,190
compiler hey you know to take you know

590
00:23:31,190 --> 00:23:33,500
unbuckle your seat belt take the safety

591
00:23:33,500 --> 00:23:35,509
off your gun like like just go buckwild

592
00:23:35,509 --> 00:23:36,619
and do whatever you want I don't care

593
00:23:36,619 --> 00:23:40,519
right so the first one is the restrict

594
00:23:40,519 --> 00:23:41,389
keyword and

595
00:23:41,389 --> 00:23:44,179
this is a flag we can add to in our C

596
00:23:44,179 --> 00:23:45,529
code or sleep a pulse code that

597
00:23:45,529 --> 00:23:48,019
basically says that we know that these

598
00:23:48,019 --> 00:23:49,519
are distinct memory locations and

599
00:23:49,519 --> 00:23:51,349
therefore it's safe for it to vectorize

600
00:23:51,349 --> 00:23:53,779
and anything that comes below this so

601
00:23:53,779 --> 00:23:55,879
this is in the C standard I don't know

602
00:23:55,879 --> 00:23:56,989
whether it's I don't think it's in the

603
00:23:56,989 --> 00:23:58,999
C++ standard but as far as you know as

604
00:23:58,999 --> 00:24:01,369
I've tested before it's like GCC and

605
00:24:01,369 --> 00:24:02,239
clang whoa

606
00:24:02,239 --> 00:24:05,839
we'll handle this right so again it's

607
00:24:05,839 --> 00:24:07,459
basically saying that we're allowing the

608
00:24:07,459 --> 00:24:08,479
programmer to declare that these

609
00:24:08,479 --> 00:24:11,269
pointers are will will never share the

610
00:24:11,269 --> 00:24:12,799
same data or you know the same memory

611
00:24:12,799 --> 00:24:15,200
locations and therefore anything that we

612
00:24:15,200 --> 00:24:17,479
do under here will not have weird side

613
00:24:17,479 --> 00:24:20,329
effects that was unexpected right but of

614
00:24:20,329 --> 00:24:21,440
course it's gonna be up to us as the

615
00:24:21,440 --> 00:24:22,549
programmer to make sure that we know

616
00:24:22,549 --> 00:24:24,079
what we're doing when we when we tell it

617
00:24:24,079 --> 00:24:27,829
hey don't check these things because you

618
00:24:27,829 --> 00:24:29,419
know after it's already compiled then we

619
00:24:29,419 --> 00:24:30,739
have no way to protect you know enforce

620
00:24:30,739 --> 00:24:33,769
that the other approach are these -

621
00:24:33,769 --> 00:24:35,719
these pragma hints and this is just

622
00:24:35,719 --> 00:24:37,909
basically saying that within this

623
00:24:37,909 --> 00:24:41,169
function you don't do any of those

624
00:24:41,169 --> 00:24:43,639
memory checks this is like sort of a

625
00:24:43,639 --> 00:24:48,049
more sort of brute force but a more

626
00:24:48,049 --> 00:24:51,049
coarse grain definition that it's okay

627
00:24:51,049 --> 00:24:52,549
to do vectorization here whereas in a

628
00:24:52,549 --> 00:24:53,929
restrictive or you know it's more

629
00:24:53,929 --> 00:24:55,729
fine-grain on individual elements right

630
00:24:55,729 --> 00:24:59,119
so this one is saying IV depth saying

631
00:24:59,119 --> 00:25:01,009
ignore vector vectorization dependencies

632
00:25:01,009 --> 00:25:03,349
there's other ones I think other

633
00:25:03,349 --> 00:25:05,059
languages like symbiote on Cindy off

634
00:25:05,059 --> 00:25:06,169
okay

635
00:25:06,169 --> 00:25:08,659
I don't know how I don't know how

636
00:25:08,659 --> 00:25:09,979
portable this one is I think this might

637
00:25:09,979 --> 00:25:11,839
be working for GCC I don't know what a

638
00:25:11,839 --> 00:25:13,519
clang or ICC do something different

639
00:25:13,519 --> 00:25:16,190
right or like we're using these other

640
00:25:16,190 --> 00:25:18,649
like libraries like OpenMP they have

641
00:25:18,649 --> 00:25:20,989
their own own Flags it's they're all

642
00:25:20,989 --> 00:25:22,039
they're all I test be doing the same

643
00:25:22,039 --> 00:25:24,409
thing all right okay

644
00:25:24,409 --> 00:25:26,179
so again the main takeaway from this is

645
00:25:26,179 --> 00:25:27,859
that we can we can tell the compiler we

646
00:25:27,859 --> 00:25:30,679
can what we can do what it can do but

647
00:25:30,679 --> 00:25:31,999
it's still all frosted the Davis

648
00:25:31,999 --> 00:25:34,359
developers - to protect ourselves

649
00:25:34,359 --> 00:25:36,979
the last one is through explicit

650
00:25:36,979 --> 00:25:38,619
vectorization we're going to write the

651
00:25:38,619 --> 00:25:40,879
exact same be instructions that we want

652
00:25:40,879 --> 00:25:42,859
to execute and again we have to know

653
00:25:42,859 --> 00:25:44,389
what the register size is we have to

654
00:25:44,389 --> 00:25:46,059
know what the datatype are operating on

655
00:25:46,059 --> 00:25:48,979
and then now there's there's no question

656
00:25:48,979 --> 00:25:50,569
about what to actually do because these

657
00:25:50,569 --> 00:25:51,919
intrinsics are essentially syntactic

658
00:25:51,919 --> 00:25:54,469
sugar that the compiler replaces with

659
00:25:54,469 --> 00:25:55,100
the exact

660
00:25:55,100 --> 00:25:57,770
instruction to do whatever is ever asked

661
00:25:57,770 --> 00:26:00,410
me to do the downside of intrinsic is

662
00:26:00,410 --> 00:26:03,290
that they're not portable meaning if my

663
00:26:03,290 --> 00:26:05,480
code if I compile I write all the x86

664
00:26:05,480 --> 00:26:06,980
intrinsics but I'm not running now I'm

665
00:26:06,980 --> 00:26:09,890
compiling my data system to arm they may

666
00:26:09,890 --> 00:26:11,630
not support that or if I'm compiling my

667
00:26:11,630 --> 00:26:15,200
code and it operates on the avx-512 and

668
00:26:15,200 --> 00:26:16,400
then I try to compile it on a machine

669
00:26:16,400 --> 00:26:18,260
that doesn't have those registers it's

670
00:26:18,260 --> 00:26:21,080
gonna fail or it might actually replace

671
00:26:21,080 --> 00:26:23,060
them with the scalar version of the

672
00:26:23,060 --> 00:26:26,300
operation if it's nice and I may not get

673
00:26:26,300 --> 00:26:28,490
into the vectorization that I'm

674
00:26:28,490 --> 00:26:32,630
expecting so here's the here's the SSE

675
00:26:32,630 --> 00:26:36,530
implementation of the actually this MMX

676
00:26:36,530 --> 00:26:39,560
the EPI this is a Symbian tation of the

677
00:26:39,560 --> 00:26:43,040
same same the same folder and then

678
00:26:43,040 --> 00:26:45,500
adding together two vectors and now you

679
00:26:45,500 --> 00:26:46,910
see what I have to do is there I have to

680
00:26:46,910 --> 00:26:51,170
take my sort of C C++ vectors of numbers

681
00:26:51,170 --> 00:26:54,650
and then convert them into the expected

682
00:26:54,650 --> 00:26:58,220
sim deregister vectors right and then

683
00:26:58,220 --> 00:27:00,650
this operation here is now doing the

684
00:27:00,650 --> 00:27:02,270
addition or loading things in you're

685
00:27:02,270 --> 00:27:04,880
just doing the addition on 32-bit

686
00:27:04,880 --> 00:27:07,220
integers and then loading it into this

687
00:27:07,220 --> 00:27:09,890
the simply vector here right

688
00:27:09,890 --> 00:27:12,110
it's ugly the the double underscore is

689
00:27:12,110 --> 00:27:15,380
is is what is how we do how these GCC

690
00:27:15,380 --> 00:27:17,240
defines intrinsics I think clang does

691
00:27:17,240 --> 00:27:20,570
the same thing and so you you can hide

692
00:27:20,570 --> 00:27:22,250
this with like a library that has a

693
00:27:22,250 --> 00:27:23,780
bunch of macro tricks to make you do

694
00:27:23,780 --> 00:27:25,040
this but there's no sort of one vibrate

695
00:27:25,040 --> 00:27:26,870
everyone uses you looking to get help

696
00:27:26,870 --> 00:27:28,040
you see a lot of times you see explicit

697
00:27:28,040 --> 00:27:32,300
instructions like this okay so for our

698
00:27:32,300 --> 00:27:35,120
purposes in our own system and in the

699
00:27:35,120 --> 00:27:36,560
company of you guys read they're gonna

700
00:27:36,560 --> 00:27:37,820
do this explicit vector vectorization

701
00:27:37,820 --> 00:27:38,810
because they won't have again

702
00:27:38,810 --> 00:27:40,490
fine-grained control exactly what the

703
00:27:40,490 --> 00:27:44,300
CPU is doing alright so now that we know

704
00:27:44,300 --> 00:27:47,480
how to write Cindy instructions what are

705
00:27:47,480 --> 00:27:49,190
the kind of Cindy operations we could to

706
00:27:49,190 --> 00:27:50,840
do so the first thing we need to talk

707
00:27:50,840 --> 00:27:52,340
about is like what direction are we

708
00:27:52,340 --> 00:27:54,260
applying our vectorization so the

709
00:27:54,260 --> 00:27:55,570
difference is horizontal versus vertical

710
00:27:55,570 --> 00:27:57,890
so with horizontal the idea is that

711
00:27:57,890 --> 00:28:01,100
we're gonna apply some operation on all

712
00:28:01,100 --> 00:28:03,230
the elements together that are within a

713
00:28:03,230 --> 00:28:06,140
single vector and then produce some some

714
00:28:06,140 --> 00:28:08,570
single output or scalar output

715
00:28:08,570 --> 00:28:11,840
so like say I want to take my register

716
00:28:11,840 --> 00:28:13,160
has the number zero one two three and

717
00:28:13,160 --> 00:28:15,500
then I can evoke a Sindhi horizontal

718
00:28:15,500 --> 00:28:17,360
instruction that just takes all the

719
00:28:17,360 --> 00:28:19,460
elements in my vector and then produce a

720
00:28:19,460 --> 00:28:20,960
single scalar output that's the sum of

721
00:28:20,960 --> 00:28:25,310
all of them so this one is only found in

722
00:28:25,310 --> 00:28:26,750
the new instructions that support as his

723
00:28:26,750 --> 00:28:31,390
SSE for and avx2 so that's roughly

724
00:28:31,390 --> 00:28:34,160
2015-2016 anything or anything newer

725
00:28:34,160 --> 00:28:36,170
than that should have it the next one is

726
00:28:36,170 --> 00:28:38,210
the vertical one and the idea here is

727
00:28:38,210 --> 00:28:41,120
that we're gonna take two vectors apply

728
00:28:41,120 --> 00:28:43,640
some steam the instruction on them and

729
00:28:43,640 --> 00:28:45,260
we're going to match up based on the

730
00:28:45,260 --> 00:28:47,270
offsets when the in each vector so this

731
00:28:47,270 --> 00:28:49,430
is offset 0 this is also 0 and then

732
00:28:49,430 --> 00:28:50,570
we'll add them together and then we'll

733
00:28:50,570 --> 00:28:52,340
write that out to offset 0 in our output

734
00:28:52,340 --> 00:28:55,990
vector so the Columbia paper is gonna

735
00:28:55,990 --> 00:29:00,100
kind of do everything based on this I

736
00:29:00,100 --> 00:29:02,840
forget why they said they didn't do this

737
00:29:02,840 --> 00:29:04,250
I think at the time I think they

738
00:29:04,250 --> 00:29:05,960
actually the CP they looked on we didn't

739
00:29:05,960 --> 00:29:08,380
have it all right

740
00:29:08,380 --> 00:29:10,580
this once again this this is the more

741
00:29:10,580 --> 00:29:14,240
common approach all right so now so

742
00:29:14,240 --> 00:29:16,520
going forward we're gonna assume that we

743
00:29:16,520 --> 00:29:18,080
have these intrinsics then we're gonna

744
00:29:18,080 --> 00:29:19,720
do these divert the vertical

745
00:29:19,720 --> 00:29:22,520
vectorization and now we want to do a

746
00:29:22,520 --> 00:29:24,740
bunch of different things and our in our

747
00:29:24,740 --> 00:29:29,600
in our database system to construct

748
00:29:29,600 --> 00:29:31,550
primitive operations that are vectorized

749
00:29:31,550 --> 00:29:33,500
and then we'll build up from those

750
00:29:33,500 --> 00:29:34,940
primitives and do the more complex

751
00:29:34,940 --> 00:29:36,890
things like the joins and the scans and

752
00:29:36,890 --> 00:29:39,880
the other stuff that you would want na i

753
00:29:39,880 --> 00:29:42,290
know you know what i have to do when you

754
00:29:42,290 --> 00:29:44,330
process queries so again I like this

755
00:29:44,330 --> 00:29:45,770
paper because it's just it's like

756
00:29:45,770 --> 00:29:47,240
everything like here's all these

757
00:29:47,240 --> 00:29:49,040
different techniques that we have

758
00:29:49,040 --> 00:29:51,080
actually the source code implementations

759
00:29:51,080 --> 00:29:52,520
I have you have you how you design all

760
00:29:52,520 --> 00:29:53,630
these algorithms and data structures to

761
00:29:53,630 --> 00:29:55,820
take advantage of vectorization all of

762
00:29:55,820 --> 00:29:58,340
them we're not gonna need but I want to

763
00:29:58,340 --> 00:29:59,570
cover like sort of the main the main

764
00:29:59,570 --> 00:30:05,030
primitives ok so again I've already just

765
00:30:05,030 --> 00:30:07,280
said this so this is all about how can

766
00:30:07,280 --> 00:30:09,500
we can do primitive operations that are

767
00:30:09,500 --> 00:30:10,940
vectorized then do more events

768
00:30:10,940 --> 00:30:12,140
algorithms and functionality in our

769
00:30:12,140 --> 00:30:15,470
database system the system they're gonna

770
00:30:15,470 --> 00:30:17,060
run on is actually not a full-fledged

771
00:30:17,060 --> 00:30:18,620
database system it's just like a little

772
00:30:18,620 --> 00:30:20,570
testbed prototype that does you know

773
00:30:20,570 --> 00:30:21,470
it's too

774
00:30:21,470 --> 00:30:23,510
hand-coded to do the one operation that

775
00:30:23,510 --> 00:30:25,100
they're trying to measure said means

776
00:30:25,100 --> 00:30:26,360
there's no sequel parser there's new

777
00:30:26,360 --> 00:30:29,330
transactions VOC query processing and it

778
00:30:29,330 --> 00:30:30,830
also means that they're not going to

779
00:30:30,830 --> 00:30:33,320
materialize the output in those cases

780
00:30:33,320 --> 00:30:36,080
which oftentimes is is a big overhead in

781
00:30:36,080 --> 00:30:39,590
in implementations the other big thing

782
00:30:39,590 --> 00:30:40,880
and this is the big assumption that I

783
00:30:40,880 --> 00:30:42,890
was saying before is that in their

784
00:30:42,890 --> 00:30:43,850
operating environment they're gonna

785
00:30:43,850 --> 00:30:45,650
assume that the database fits entirely

786
00:30:45,650 --> 00:30:48,280
in the CPU cache that is not realistic

787
00:30:48,280 --> 00:30:51,080
right because like l1 is like 32

788
00:30:51,080 --> 00:30:54,320
kilobytes l3 is like maybe 64 megabytes

789
00:30:54,320 --> 00:30:56,720
if you have a lot of money like there's

790
00:30:56,720 --> 00:30:57,860
no database that's gonna fit you know

791
00:30:57,860 --> 00:31:01,550
your CPU caches and what you'll see in

792
00:31:01,550 --> 00:31:02,870
the next paper you read after the spring

793
00:31:02,870 --> 00:31:05,630
break is that if everything now does not

794
00:31:05,630 --> 00:31:07,880
fit in the CPU cache this Cindy stuff

795
00:31:07,880 --> 00:31:09,340
actually doesn't doesn't matter at all

796
00:31:09,340 --> 00:31:13,760
right unless you start doing the the the

797
00:31:13,760 --> 00:31:15,620
relaxed operator fusion stuff that that

798
00:31:15,620 --> 00:31:17,210
will read about next like how to

799
00:31:17,210 --> 00:31:20,300
actually you know sort of stage your

800
00:31:20,300 --> 00:31:22,100
operations so that you can operate on

801
00:31:22,100 --> 00:31:24,740
vectors within your CPU caches and then

802
00:31:24,740 --> 00:31:26,930
you can prefetch the next piece of the

803
00:31:26,930 --> 00:31:28,010
next vector you're going to operate on

804
00:31:28,010 --> 00:31:30,200
to hide that latency of the memory stall

805
00:31:30,200 --> 00:31:32,270
and they're all they don't do any of

806
00:31:32,270 --> 00:31:33,440
that it's just like everything's might

807
00:31:33,440 --> 00:31:35,000
CPU cache let me rip through it very

808
00:31:35,000 --> 00:31:35,540
quickly

809
00:31:35,540 --> 00:31:39,020
okay the other big thing that they're

810
00:31:39,020 --> 00:31:40,940
gonna have in their design decision for

811
00:31:40,940 --> 00:31:42,590
their algorithms is that they want to

812
00:31:42,590 --> 00:31:45,200
maximize the Lane utilization so that

813
00:31:45,200 --> 00:31:46,940
for every single time you invoke an

814
00:31:46,940 --> 00:31:49,040
instruction you're always doing useful

815
00:31:49,040 --> 00:31:50,690
work for all the data items in your

816
00:31:50,690 --> 00:31:52,700
vectors all right this will make more

817
00:31:52,700 --> 00:31:54,530
sense when we talk about how they do the

818
00:31:54,530 --> 00:31:56,090
hash table probing but the idea is that

819
00:31:56,090 --> 00:31:58,640
I don't want to say I could put four

820
00:31:58,640 --> 00:32:00,860
elements into my vector but only two of

821
00:32:00,860 --> 00:32:02,270
them are I are one of them I actually

822
00:32:02,270 --> 00:32:03,500
need you have the rest were actually

823
00:32:03,500 --> 00:32:05,360
garbage I can throw away they want to

824
00:32:05,360 --> 00:32:07,880
pack in all you know all unique data or

825
00:32:07,880 --> 00:32:09,260
useful data and every single register

826
00:32:09,260 --> 00:32:10,730
for every single instruction so that

827
00:32:10,730 --> 00:32:15,140
they're maximizing the utilization all

828
00:32:15,140 --> 00:32:16,310
right so let's start with the

829
00:32:16,310 --> 00:32:18,290
fundamentals that they're gonna define

830
00:32:18,290 --> 00:32:20,060
select a low slept of stores and then

831
00:32:20,060 --> 00:32:21,710
the gather and scatter and then we'll

832
00:32:21,710 --> 00:32:23,660
see how we can then use these to do the

833
00:32:23,660 --> 00:32:25,400
scans and hash tables and and the

834
00:32:25,400 --> 00:32:30,410
histograms okay so with selective load

835
00:32:30,410 --> 00:32:33,500
the idea here is that we want to take

836
00:32:33,500 --> 00:32:35,210
some

837
00:32:35,210 --> 00:32:38,150
some some chunk of memory we have in our

838
00:32:38,150 --> 00:32:40,880
in our l1 cache and then we want to

839
00:32:40,880 --> 00:32:42,470
write them out to a register but we want

840
00:32:42,470 --> 00:32:44,810
to provide this mask to tell us what

841
00:32:44,810 --> 00:32:46,190
elements we actually want to store

842
00:32:46,190 --> 00:32:48,620
because without this we do have to take

843
00:32:48,620 --> 00:32:51,410
everything and write it out like all

844
00:32:51,410 --> 00:32:54,410
continuously which means that if we only

845
00:32:54,410 --> 00:32:55,670
want certain items

846
00:32:55,670 --> 00:32:58,540
we'd have to copy it then you know and

847
00:32:58,540 --> 00:33:02,150
in all in our CPU cache then align

848
00:33:02,150 --> 00:33:03,710
things the way we want and then right

849
00:33:03,710 --> 00:33:05,180
into our register so the idea is like we

850
00:33:05,180 --> 00:33:07,340
can take a chunk of memory that has some

851
00:33:07,340 --> 00:33:08,330
things we don't want and don't want

852
00:33:08,330 --> 00:33:10,340
provide this mask and this tells us how

853
00:33:10,340 --> 00:33:12,380
to populate the register all right so

854
00:33:12,380 --> 00:33:13,970
again the lane is like this the mask

855
00:33:13,970 --> 00:33:16,250
offset here corresponds to an offset and

856
00:33:16,250 --> 00:33:18,530
the vector so the first thing we do is

857
00:33:18,530 --> 00:33:20,750
look at the first element the mask the

858
00:33:20,750 --> 00:33:23,140
bit is set to zero so we're gonna skip

859
00:33:23,140 --> 00:33:25,190
what's what's in here right there's

860
00:33:25,190 --> 00:33:26,570
nothing else we want to write out into

861
00:33:26,570 --> 00:33:29,330
this Lane then we get into the one here

862
00:33:29,330 --> 00:33:31,160
and that's gonna tell us at the first

863
00:33:31,160 --> 00:33:34,460
offset that we've been writing into so

864
00:33:34,460 --> 00:33:35,720
sort of thinking like this every time we

865
00:33:35,720 --> 00:33:37,460
have a one there's some cursor here

866
00:33:37,460 --> 00:33:38,990
that's gonna copy out what's in the

867
00:33:38,990 --> 00:33:40,370
memory address of the memory location

868
00:33:40,370 --> 00:33:42,950
and then when we move to the next bit if

869
00:33:42,950 --> 00:33:44,300
there's another one we would move the

870
00:33:44,300 --> 00:33:46,400
cursor over by one so even though this

871
00:33:46,400 --> 00:33:48,950
is offset too or I'll offset one in our

872
00:33:48,950 --> 00:33:50,450
vector we're starting at offset zero

873
00:33:50,450 --> 00:33:52,160
from memory because we didn't knew we

874
00:33:52,160 --> 00:33:54,170
didn't write anything for all set zero

875
00:33:54,170 --> 00:33:56,090
so now this would get mapped into that

876
00:33:56,090 --> 00:33:58,220
and we write it up in here and then the

877
00:33:58,220 --> 00:33:59,390
same thing for the next one there's a

878
00:33:59,390 --> 00:34:01,520
zero so we skip that now we have a 1 and

879
00:34:01,520 --> 00:34:03,860
then the cursor moves over here for this

880
00:34:03,860 --> 00:34:06,470
V and we write it to offset 3 up and up

881
00:34:06,470 --> 00:34:11,570
in the vector right the Selective store

882
00:34:11,570 --> 00:34:13,909
is the opposite of this as where we have

883
00:34:13,909 --> 00:34:16,130
our vector and we want to take its

884
00:34:16,130 --> 00:34:18,020
contents of its elements and write it

885
00:34:18,020 --> 00:34:21,139
out to 2 to memory so again the lanes

886
00:34:21,139 --> 00:34:23,480
match up just as before so we can start

887
00:34:23,480 --> 00:34:25,340
here with a zero and this is saying we

888
00:34:25,340 --> 00:34:27,139
don't want to copy anything then we get

889
00:34:27,139 --> 00:34:29,000
here to the 1 and then it's gonna take

890
00:34:29,000 --> 00:34:30,620
the same offset in the mass for the

891
00:34:30,620 --> 00:34:32,090
offset and the vector then we're gonna

892
00:34:32,090 --> 00:34:33,530
write it to the first location in memory

893
00:34:33,530 --> 00:34:36,830
and then same thing for this skip from 0

894
00:34:36,830 --> 00:34:41,449
the 1 then read it up there right so is

895
00:34:41,449 --> 00:34:44,230
another this is another spoiler of this

896
00:34:44,230 --> 00:34:47,909
of this paper is that

897
00:34:47,909 --> 00:34:50,760
there are no Cindy instructions no Zeon

898
00:34:50,760 --> 00:34:52,649
does not currently support doing this

899
00:34:52,649 --> 00:34:55,349
like like with a single instruction it

900
00:34:55,349 --> 00:34:57,240
has to be emulated doing other semi

901
00:34:57,240 --> 00:34:59,460
operations and every year I always

902
00:34:59,460 --> 00:35:01,589
google to see whether check out Google

903
00:35:01,589 --> 00:35:02,670
to see whether select the stores like

904
00:35:02,670 --> 00:35:06,839
this load has been implemented in in in

905
00:35:06,839 --> 00:35:09,359
x86 and the only thing ever shows up or

906
00:35:09,359 --> 00:35:11,099
free things either the Columbia paper

907
00:35:11,099 --> 00:35:13,559
that describes that the technique my

908
00:35:13,559 --> 00:35:16,140
slides from this class or people in

909
00:35:16,140 --> 00:35:18,829
Korea or Wisconsin stole my slides and

910
00:35:18,829 --> 00:35:21,420
talked about the same thing I will see

911
00:35:21,420 --> 00:35:23,369
what they look like in a second um so

912
00:35:23,369 --> 00:35:27,119
again and this means that you also know

913
00:35:27,119 --> 00:35:28,380
you can't do this atomically this to be

914
00:35:28,380 --> 00:35:30,420
multiple instructions to make this work

915
00:35:30,420 --> 00:35:32,760
and the idea of what they're doing is

916
00:35:32,760 --> 00:35:34,230
the reason why you'd actually want this

917
00:35:34,230 --> 00:35:37,130
again is that I don't want to have to

918
00:35:37,130 --> 00:35:39,839
you know take the chunk of memory and in

919
00:35:39,839 --> 00:35:43,140
and copy things over over never again to

920
00:35:43,140 --> 00:35:44,789
line at the way I want before I load it

921
00:35:44,789 --> 00:35:46,880
and write and load it and take it out

922
00:35:46,880 --> 00:35:49,109
ideally if I could do this in the single

923
00:35:49,109 --> 00:35:50,430
struction that'd be great but it doesn't

924
00:35:50,430 --> 00:35:53,160
exist all right the next is gonna be

925
00:35:53,160 --> 00:35:56,760
this the the scatter and gather right so

926
00:35:56,760 --> 00:35:59,069
with gather the idea is that again we

927
00:35:59,069 --> 00:36:00,510
have our index vector that lines up with

928
00:36:00,510 --> 00:36:04,260
our value vector and we want to take we

929
00:36:04,260 --> 00:36:05,700
want to take elements that are in memory

930
00:36:05,700 --> 00:36:08,520
and then write them out in two different

931
00:36:08,520 --> 00:36:11,609
locations in in our vector right so

932
00:36:11,609 --> 00:36:13,230
think of these as all set from zero to

933
00:36:13,230 --> 00:36:15,599
five so when I look at this thing here

934
00:36:15,599 --> 00:36:18,049
the index vector says at all set to

935
00:36:18,049 --> 00:36:20,730
right which is here right it into the

936
00:36:20,730 --> 00:36:23,819
first lane of my register then I get

937
00:36:23,819 --> 00:36:26,640
here offset one take take you know take

938
00:36:26,640 --> 00:36:29,069
offset one in memory write it out the to

939
00:36:29,069 --> 00:36:31,650
the the the second lane or the first

940
00:36:31,650 --> 00:36:33,119
lane anyone I'll say you're looking at

941
00:36:33,119 --> 00:36:34,829
do this and so far for all the other

942
00:36:34,829 --> 00:36:38,579
ones and again like I don't think

943
00:36:38,579 --> 00:36:41,039
actually I think Xeon now supports both

944
00:36:41,039 --> 00:36:42,779
of these the the selectively gather and

945
00:36:42,779 --> 00:36:44,069
the selectively gather there's a

946
00:36:44,069 --> 00:36:45,690
selectively gather and scatter so you

947
00:36:45,690 --> 00:36:47,640
can do this it'll be a single

948
00:36:47,640 --> 00:36:49,770
instruction but it won't be done in a

949
00:36:49,770 --> 00:36:52,289
single cycle because again l1 can only

950
00:36:52,289 --> 00:36:55,319
do a one or two loads and stores per

951
00:36:55,319 --> 00:36:57,359
cycle so if I have a bunch of stuff that

952
00:36:57,359 --> 00:36:59,549
if I'm populating a large register it

953
00:36:59,549 --> 00:37:01,800
may took a bunch of cycles

954
00:37:01,800 --> 00:37:06,530
laid it up using this technique yes I

955
00:37:12,260 --> 00:37:14,580
know I I don't think Emily does I think

956
00:37:14,580 --> 00:37:17,080
it actually supports this yeah

957
00:37:17,080 --> 00:37:20,270
[Music]

958
00:37:21,330 --> 00:37:23,400
could you use can you use selective

959
00:37:23,400 --> 00:37:25,080
gathering to emulate the selective

960
00:37:25,080 --> 00:37:27,390
loading store from last yeah yes I I

961
00:37:27,390 --> 00:37:28,680
don't think that ketose like the paper

962
00:37:28,680 --> 00:37:30,780
describes it but it's there's again the

963
00:37:30,780 --> 00:37:31,920
main takeaway so it's not one

964
00:37:31,920 --> 00:37:35,730
instruction like this is okay scatter

965
00:37:35,730 --> 00:37:38,220
again is the opposite we're going to

966
00:37:38,220 --> 00:37:41,820
take elements in an a register and then

967
00:37:41,820 --> 00:37:42,960
write them out to different locations

968
00:37:42,960 --> 00:37:44,730
here so for the first element here at

969
00:37:44,730 --> 00:37:46,500
index vector to that I'm writing into

970
00:37:46,500 --> 00:37:48,960
memory location too and I do the same

971
00:37:48,960 --> 00:37:52,650
thing for everything else okay so I've

972
00:37:52,650 --> 00:37:54,930
already said this law before the the

973
00:37:54,930 --> 00:37:56,340
gather scatters are not really executed

974
00:37:56,340 --> 00:37:59,370
parallel because we can only load so

975
00:37:59,370 --> 00:38:02,880
many things in a single cycle the

976
00:38:02,880 --> 00:38:04,920
gathers are only supported in the the

977
00:38:04,920 --> 00:38:09,090
newer words since 2014 was when avx2

978
00:38:09,090 --> 00:38:11,220
came out in the house well prior to that

979
00:38:11,220 --> 00:38:13,650
it wasn't supportive and then again

980
00:38:13,650 --> 00:38:16,140
these are you have to implement these or

981
00:38:16,140 --> 00:38:19,080
emulate them using multiple multiple CPU

982
00:38:19,080 --> 00:38:22,140
instructions okay all right so that's

983
00:38:22,140 --> 00:38:23,670
good to forget stuff all right so we had

984
00:38:23,670 --> 00:38:25,230
these printers now and let's talk about

985
00:38:25,230 --> 00:38:27,840
how we do scans hash tables and your

986
00:38:27,840 --> 00:38:29,940
partitioning for histograms the paper

987
00:38:29,940 --> 00:38:31,890
also talks about how to you join sorting

988
00:38:31,890 --> 00:38:34,050
and bloom filters I don't think of it I

989
00:38:34,050 --> 00:38:35,360
don't whether they talk about how to do

990
00:38:35,360 --> 00:38:37,260
cindy hash functions but we'll cover

991
00:38:37,260 --> 00:38:40,020
that later too as well but we will cover

992
00:38:40,020 --> 00:38:41,580
these after the spring break we'll talk

993
00:38:41,580 --> 00:38:44,400
about how to do this in the part of the

994
00:38:44,400 --> 00:38:46,770
radix partitioning hash join or the

995
00:38:46,770 --> 00:38:49,560
photonic sorting techniques let me talk

996
00:38:49,560 --> 00:38:50,880
about sort merge join so we'll cover

997
00:38:50,880 --> 00:38:52,410
these in more detail after after spring

998
00:38:52,410 --> 00:38:53,760
break and I think we'll also talk about

999
00:38:53,760 --> 00:38:55,320
this but this one's pretty easy to

1000
00:38:55,320 --> 00:38:57,510
figure out as well okay so again

1001
00:38:57,510 --> 00:38:59,640
nothing's gonna work because they're

1002
00:38:59,640 --> 00:39:01,500
gonna soon well because assume

1003
00:39:01,500 --> 00:39:02,520
everything is to fit in CPU cache

1004
00:39:02,520 --> 00:39:04,200
they're also gonna make this other big

1005
00:39:04,200 --> 00:39:05,610
assumption I should mention this earlier

1006
00:39:05,610 --> 00:39:08,310
is that they're gonna operate there to

1007
00:39:08,310 --> 00:39:10,950
assume all their keys or 32 bits and all

1008
00:39:10,950 --> 00:39:13,110
their pointers to tuples are 32 bits

1009
00:39:13,110 --> 00:39:15,599
because again they're operating on 201

1010
00:39:15,599 --> 00:39:19,259
six bit registers and so for a key and

1011
00:39:19,259 --> 00:39:23,789
value pair that has to be 64 bits in a

1012
00:39:23,789 --> 00:39:25,559
real data in memory database system the

1013
00:39:25,559 --> 00:39:27,059
values are sorry the batteries are gonna

1014
00:39:27,059 --> 00:39:28,140
be the to post laws of the tuple

1015
00:39:28,140 --> 00:39:30,380
pointers those are gonna be 64 bits and

1016
00:39:30,380 --> 00:39:33,390
then keys are often not just gonna be

1017
00:39:33,390 --> 00:39:35,430
you know 32 or 64 bits

1018
00:39:35,430 --> 00:39:36,690
sometimes you can have a composite keys

1019
00:39:36,690 --> 00:39:39,660
and if you have those then then many of

1020
00:39:39,660 --> 00:39:41,549
these techniques don't work because now

1021
00:39:41,549 --> 00:39:43,019
you can't align things nicely in two

1022
00:39:43,019 --> 00:39:46,829
lanes in the semi register right all

1023
00:39:46,829 --> 00:39:49,529
right so let's how did you vector I

1024
00:39:49,529 --> 00:39:51,539
selected scans so we solved these two

1025
00:39:51,539 --> 00:39:53,309
examples before when we talked about

1026
00:39:53,309 --> 00:39:56,069
query processing this is how we can do a

1027
00:39:56,069 --> 00:39:58,109
branching version and a branchless

1028
00:39:58,109 --> 00:40:00,180
version of doing the scan right for the

1029
00:40:00,180 --> 00:40:01,859
branching version you have an if clause

1030
00:40:01,859 --> 00:40:03,900
will you check the predicate first and

1031
00:40:03,900 --> 00:40:05,819
then if it matches then you then you

1032
00:40:05,819 --> 00:40:07,229
copy the tuple and in the output buffer

1033
00:40:07,229 --> 00:40:09,239
and then the branch left version you

1034
00:40:09,239 --> 00:40:12,150
always copy it and then you then check

1035
00:40:12,150 --> 00:40:15,019
this you check it by using this you know

1036
00:40:15,019 --> 00:40:17,339
bitwise everything you know comparison

1037
00:40:17,339 --> 00:40:18,630
operations so it's not really a branch

1038
00:40:18,630 --> 00:40:21,469
and then based based on the output of

1039
00:40:21,469 --> 00:40:24,119
this comparison that tells you whether

1040
00:40:24,119 --> 00:40:25,859
you you increment the offset of the

1041
00:40:25,859 --> 00:40:28,529
output vector by 1 or 0 which then

1042
00:40:28,529 --> 00:40:29,670
determines whether if you come back

1043
00:40:29,670 --> 00:40:31,109
around you overwrite the last one you

1044
00:40:31,109 --> 00:40:33,029
you you cop it into because you don't

1045
00:40:33,029 --> 00:40:36,509
want it there all right and we solve

1046
00:40:36,509 --> 00:40:38,700
this this graph from the vector buys

1047
00:40:38,700 --> 00:40:41,640
people where the the branchless version

1048
00:40:41,640 --> 00:40:43,140
of the algorithm always has almost a

1049
00:40:43,140 --> 00:40:44,519
fixed cost because you're doing the same

1050
00:40:44,519 --> 00:40:45,569
amount of work no matter what the

1051
00:40:45,569 --> 00:40:48,599
selectivity is of the predicate and in

1052
00:40:48,599 --> 00:40:50,519
in the the branching case when you have

1053
00:40:50,519 --> 00:40:53,039
low selectivity or very high selectivity

1054
00:40:53,039 --> 00:40:56,489
then it'll do better than the branchless

1055
00:40:56,489 --> 00:40:58,559
one but in this middle part here you

1056
00:40:58,559 --> 00:41:00,989
know the the branch misprediction

1057
00:41:00,989 --> 00:41:02,819
penalty we're paying in our cpu becomes

1058
00:41:02,819 --> 00:41:05,180
higher and higher and therefore you know

1059
00:41:05,180 --> 00:41:07,349
there's cash dolls or the pipeline

1060
00:41:07,349 --> 00:41:11,269
flushes of having to you know undo our

1061
00:41:11,269 --> 00:41:14,039
mispredicted branch starts you know

1062
00:41:14,039 --> 00:41:17,880
comes a big bottleneck alright so in a

1063
00:41:17,880 --> 00:41:20,759
vectorized selection scan operation we

1064
00:41:20,759 --> 00:41:23,099
can't do the branching version because

1065
00:41:23,099 --> 00:41:25,440
there is no notion or no concept of if

1066
00:41:25,440 --> 00:41:28,570
clauses in our in our sending

1067
00:41:28,570 --> 00:41:30,490
structions so they're going to do a

1068
00:41:30,490 --> 00:41:33,220
vectorized branchless version so this is

1069
00:41:33,220 --> 00:41:35,170
a gross approximation of what the

1070
00:41:35,170 --> 00:41:37,600
algorithm is but now we're gonna scan

1071
00:41:37,600 --> 00:41:40,180
through our table and whereas before I

1072
00:41:40,180 --> 00:41:41,890
would get one back one tuple at a time

1073
00:41:41,890 --> 00:41:43,900
now I'm gonna get back a vector tuples

1074
00:41:43,900 --> 00:41:46,270
not saying what that with the register

1075
00:41:46,270 --> 00:41:47,920
size is whether it's four four elements

1076
00:41:47,920 --> 00:41:49,630
or sixteen elements or eight whatever it

1077
00:41:49,630 --> 00:41:51,760
doesn't matter we get a vector and then

1078
00:41:51,760 --> 00:41:53,680
we're gonna load the key we want to do a

1079
00:41:53,680 --> 00:41:55,630
comparison on again assuming we only

1080
00:41:55,630 --> 00:41:57,580
need to look at one key well load this

1081
00:41:57,580 --> 00:42:01,570
into a key vector and in Tsim deem and

1082
00:42:01,570 --> 00:42:03,640
you know this is just again syntactic

1083
00:42:03,640 --> 00:42:05,320
sugar this is not actually really really

1084
00:42:05,320 --> 00:42:06,580
how you to write this code there's no

1085
00:42:06,580 --> 00:42:10,330
cindy-lou function then we do our the

1086
00:42:10,330 --> 00:42:11,380
same comparison we did and the

1087
00:42:11,380 --> 00:42:13,270
branchless scan where we're doing the

1088
00:42:13,270 --> 00:42:14,770
bit manipulation to see whether we match

1089
00:42:14,770 --> 00:42:16,660
or not but then we're writing our mask

1090
00:42:16,660 --> 00:42:21,640
out of to our to our register here then

1091
00:42:21,640 --> 00:42:23,650
this is saying if the tuple at the

1092
00:42:23,650 --> 00:42:26,530
offset in our and our vector we got from

1093
00:42:26,530 --> 00:42:28,270
the table if that satisfies our

1094
00:42:28,270 --> 00:42:30,250
predicate and we set the one if it

1095
00:42:30,250 --> 00:42:31,540
doesn't satisfy a predicate it's set to

1096
00:42:31,540 --> 00:42:34,420
zero then now we take that mask and now

1097
00:42:34,420 --> 00:42:36,790
do the Select of a store to the copy the

1098
00:42:36,790 --> 00:42:39,310
tuples we want that match our match to

1099
00:42:39,310 --> 00:42:41,080
our predicate enter in our mask to our

1100
00:42:41,080 --> 00:42:43,770
output buffer and then we just take the

1101
00:42:43,770 --> 00:42:47,220
we take the cardinality of the number of

1102
00:42:47,220 --> 00:42:51,010
ones we have in our mask vector and that

1103
00:42:51,010 --> 00:42:52,690
tells us what our offset should be and

1104
00:42:52,690 --> 00:42:54,340
again there's more loop out there's more

1105
00:42:54,340 --> 00:42:55,660
work if you do outside the for look to

1106
00:42:55,660 --> 00:42:56,740
make sure that we don't keep around

1107
00:42:56,740 --> 00:42:57,970
things that didn't match in the last

1108
00:42:57,970 --> 00:43:00,280
iteration but I'm ignoring that for now

1109
00:43:00,280 --> 00:43:04,090
so again this would be a Sindhi load

1110
00:43:04,090 --> 00:43:06,310
this would be a Sindhi comparison

1111
00:43:06,310 --> 00:43:08,020
there's to be two instructions because

1112
00:43:08,020 --> 00:43:09,970
you have to the vector is greater than

1113
00:43:09,970 --> 00:43:11,260
equal to and the vector is less than

1114
00:43:11,260 --> 00:43:12,910
equal to but again that's just hanging

1115
00:43:12,910 --> 00:43:14,740
out in our Sidney registers that's not a

1116
00:43:14,740 --> 00:43:17,140
big deal and then this is a sim D store

1117
00:43:17,140 --> 00:43:20,080
to now take the the selective store mask

1118
00:43:20,080 --> 00:43:22,720
from Deb reproduce from this take our

1119
00:43:22,720 --> 00:43:23,920
two bolts I'm ready to our output buffer

1120
00:43:23,920 --> 00:43:28,080
and this will be sitting in memory yes

1121
00:43:28,260 --> 00:43:31,330
all set in the output buffer right so

1122
00:43:31,330 --> 00:43:34,390
here this sells again this is telling

1123
00:43:34,390 --> 00:43:36,400
but this we had this output buffer here

1124
00:43:36,400 --> 00:43:39,220
and we keep track of I in eyes where the

1125
00:43:39,220 --> 00:43:41,140
the starting location of where we should

1126
00:43:41,140 --> 00:43:42,520
write tuples that match

1127
00:43:42,520 --> 00:43:44,500
right it's actually easier to understand

1128
00:43:44,500 --> 00:43:47,160
if you go back to the the scalar version

1129
00:43:47,160 --> 00:43:51,400
right there we go

1130
00:43:51,400 --> 00:43:54,670
right so I equals zero I always copied

1131
00:43:54,670 --> 00:43:58,330
into the current offset I if the tuple

1132
00:43:58,330 --> 00:44:00,970
matches then this M flag will be set to

1133
00:44:00,970 --> 00:44:03,430
1 so therefore I want to keep whatever I

1134
00:44:03,430 --> 00:44:06,670
copied in here so I add add M to I which

1135
00:44:06,670 --> 00:44:08,140
is plus 1 so that when I come back

1136
00:44:08,140 --> 00:44:10,720
around now I'm writing at the next

1137
00:44:10,720 --> 00:44:12,520
offset and I'm not clobbering with the

1138
00:44:12,520 --> 00:44:14,410
last thing I copied in if this doesn't

1139
00:44:14,410 --> 00:44:17,650
match then 0 then I overwrite the next

1140
00:44:17,650 --> 00:44:18,670
time to come around because I didn't

1141
00:44:18,670 --> 00:44:20,800
wanna keep the last thing I wrote so in

1142
00:44:20,800 --> 00:44:23,350
the vectorized case this operation here

1143
00:44:23,350 --> 00:44:24,970
you want to count the number of ones you

1144
00:44:24,970 --> 00:44:26,830
have that's gonna tell us how to move

1145
00:44:26,830 --> 00:44:28,450
the offset forward and you can actually

1146
00:44:28,450 --> 00:44:30,400
do this there's a it's called the rank

1147
00:44:30,400 --> 00:44:32,619
instruction you can do this in the CPU

1148
00:44:32,619 --> 00:44:33,700
actually very efficiently if you take a

1149
00:44:33,700 --> 00:44:35,860
vector of things and say get count the

1150
00:44:35,860 --> 00:44:37,660
number ones in it that's a sort of

1151
00:44:37,660 --> 00:44:40,290
example of horizontal vectorization

1152
00:44:40,290 --> 00:44:42,280
alright so let's look let's look at a

1153
00:44:42,280 --> 00:44:43,270
real example of this

1154
00:44:43,270 --> 00:44:45,910
ok let's say now we replace our query

1155
00:44:45,910 --> 00:44:48,369
put in real values we want to find all

1156
00:44:48,369 --> 00:44:49,869
the matching tuples where the key is

1157
00:44:49,869 --> 00:44:51,970
greater than equal to 0 and the key is

1158
00:44:51,970 --> 00:44:54,460
less than the letter U so let's say now

1159
00:44:54,460 --> 00:44:57,880
our table looks like this right we have

1160
00:44:57,880 --> 00:45:01,510
the key Jo y su X and so the in order to

1161
00:45:01,510 --> 00:45:02,859
use comparison we're gonna first copy

1162
00:45:02,859 --> 00:45:05,260
this into our key vector right and

1163
00:45:05,260 --> 00:45:08,530
that's this this this step here then now

1164
00:45:08,530 --> 00:45:10,330
we do our sim to compare right and

1165
00:45:10,330 --> 00:45:11,470
that's this part here and we're gonna

1166
00:45:11,470 --> 00:45:14,140
bad our met but get out our mask and

1167
00:45:14,140 --> 00:45:15,760
this is gonna tell us which of these

1168
00:45:15,760 --> 00:45:18,910
keys actually matched and then now we

1169
00:45:18,910 --> 00:45:21,910
have this pre computed all set map right

1170
00:45:21,910 --> 00:45:23,109
this is just something we can predefined

1171
00:45:23,109 --> 00:45:24,850
and our source code at a time and this

1172
00:45:24,850 --> 00:45:27,790
is just saying the offset at at you know

1173
00:45:27,790 --> 00:45:30,430
the implicit offset here corresponds to

1174
00:45:30,430 --> 00:45:33,850
the offset 0 in memory right and up to

1175
00:45:33,850 --> 00:45:36,220
you know 1 2 3 4 5 so then now we use

1176
00:45:36,220 --> 00:45:38,500
this to do our sim D selective store and

1177
00:45:38,500 --> 00:45:41,109
that skin is what this is saying here if

1178
00:45:41,109 --> 00:45:44,650
I have a 1 here and I would know that

1179
00:45:44,650 --> 00:45:46,570
the offset I'm matching here should go

1180
00:45:46,570 --> 00:45:48,520
into the first location here so now

1181
00:45:48,520 --> 00:45:50,890
these are just offsets here so I'm

1182
00:45:50,890 --> 00:45:52,869
matching that like alright the tuple

1183
00:45:52,869 --> 00:45:55,990
that the vaquita match my cindy compare

1184
00:45:55,990 --> 00:45:59,140
at this offset can be found you know I'm

1185
00:45:59,140 --> 00:46:01,599
writing what that offset is so now and

1186
00:46:01,599 --> 00:46:03,760
then I gotta go back now and say whoa I

1187
00:46:03,760 --> 00:46:06,220
have offsets 134 if I need to

1188
00:46:06,220 --> 00:46:08,560
materialize the keys up above in my

1189
00:46:08,560 --> 00:46:10,570
micro plan tree I'll go back in here and

1190
00:46:10,570 --> 00:46:12,700
jump to that offset to copy out the

1191
00:46:12,700 --> 00:46:16,470
actual key right is this clear

1192
00:46:16,470 --> 00:46:19,570
so in my opinion this this is like the

1193
00:46:19,570 --> 00:46:21,339
most useful thing you'll probably get

1194
00:46:21,339 --> 00:46:22,900
out of this lecture in terms of like

1195
00:46:22,900 --> 00:46:25,210
here's something actually you can do in

1196
00:46:25,210 --> 00:46:26,470
in do something could we actually do

1197
00:46:26,470 --> 00:46:29,440
this now in our own system and the magic

1198
00:46:29,440 --> 00:46:31,270
is this offset a pre-computer off that

1199
00:46:31,270 --> 00:46:35,349
thing so again as I said if you go

1200
00:46:35,349 --> 00:46:37,930
Google selectively store you'll find the

1201
00:46:37,930 --> 00:46:39,190
Columbia paper of my slides and the

1202
00:46:39,190 --> 00:46:40,599
people I've copied my slides and the

1203
00:46:40,599 --> 00:46:41,920
reason why I know that copying my slides

1204
00:46:41,920 --> 00:46:43,930
is they don't know what this is they

1205
00:46:43,930 --> 00:46:47,109
always include this ju y su x joy was my

1206
00:46:47,109 --> 00:46:49,480
first PG student right that's why his

1207
00:46:49,480 --> 00:46:51,010
names in here so you go look at a bunch

1208
00:46:51,010 --> 00:46:53,050
of other slides and sure enough like joy

1209
00:46:53,050 --> 00:46:54,460
sucks right

1210
00:46:54,460 --> 00:46:56,640
joy suck a geek they copy the entire

1211
00:46:56,640 --> 00:46:59,680
yeah all right all right I don't care

1212
00:46:59,680 --> 00:47:02,950
it's fine all right so let's see what

1213
00:47:02,950 --> 00:47:04,630
you performers benefit you can actually

1214
00:47:04,630 --> 00:47:06,430
get from this so for this one they're

1215
00:47:06,430 --> 00:47:08,140
gonna do four lanes to me registers and

1216
00:47:08,140 --> 00:47:10,030
they're gonna actually compare against

1217
00:47:10,030 --> 00:47:13,030
two CPU architectures so this one here

1218
00:47:13,030 --> 00:47:14,980
the xeon phi who here has ever heard of

1219
00:47:14,980 --> 00:47:17,589
the xeon phi well your dad worked at

1220
00:47:17,589 --> 00:47:20,800
Intel buddy very few people write Xeon

1221
00:47:20,800 --> 00:47:22,810
Phi with a coprocessor that Intel used

1222
00:47:22,810 --> 00:47:25,599
to sell that sort of look comes in a

1223
00:47:25,599 --> 00:47:27,220
bunch of different form factors the

1224
00:47:27,220 --> 00:47:28,480
easiest way to think about it was like

1225
00:47:28,480 --> 00:47:31,540
it was like their version of a GPU that

1226
00:47:31,540 --> 00:47:33,040
was meant for highly parallel

1227
00:47:33,040 --> 00:47:35,140
computation so it wasn't like you

1228
00:47:35,140 --> 00:47:36,640
wouldn't get a you know you know

1229
00:47:36,640 --> 00:47:39,400
thousands of cores as you would from you

1230
00:47:39,400 --> 00:47:41,080
know from from from Nvidia and their

1231
00:47:41,080 --> 00:47:45,520
GPUs you get maybe like 60 or 70 cores

1232
00:47:45,520 --> 00:47:47,230
but these cores were actually more

1233
00:47:47,230 --> 00:47:50,020
complex than a GPU core they're

1234
00:47:50,020 --> 00:47:52,119
basically like the Intel Pentium 4

1235
00:47:52,119 --> 00:47:53,619
architecture or like the atom

1236
00:47:53,619 --> 00:47:55,060
architecture later on so like the low

1237
00:47:55,060 --> 00:47:57,910
powered very simple but you'll get more

1238
00:47:57,910 --> 00:47:59,530
than you know more of course and then

1239
00:47:59,530 --> 00:48:01,599
you get on loozy on so you could have a

1240
00:48:01,599 --> 00:48:03,609
sit down so you'd have it by one you

1241
00:48:03,609 --> 00:48:05,530
could have a sit down on the the PCI

1242
00:48:05,530 --> 00:48:07,630
Express bus like look at GPU but they

1243
00:48:07,630 --> 00:48:09,349
had did have ones that could sit up

1244
00:48:09,349 --> 00:48:11,239
on the motherboard and a socket like

1245
00:48:11,239 --> 00:48:12,289
this one here you could actually have

1246
00:48:12,289 --> 00:48:14,299
run the operating system based on you

1247
00:48:14,299 --> 00:48:15,710
know own the Zeon 5 didn't need like a

1248
00:48:15,710 --> 00:48:17,839
busy on to drive everything and this one

1249
00:48:17,839 --> 00:48:19,249
here just has this little Omni path

1250
00:48:19,249 --> 00:48:21,440
connector so that you can do like remote

1251
00:48:21,440 --> 00:48:24,319
remote memory access to a to another

1252
00:48:24,319 --> 00:48:27,140
another machine right Intel killed this

1253
00:48:27,140 --> 00:48:31,930
off I think last year or two years ago

1254
00:48:32,710 --> 00:48:34,729
they were roughly around than a five

1255
00:48:34,729 --> 00:48:36,859
thousand dollars or so high it was an

1256
00:48:36,859 --> 00:48:40,970
interesting experiment but for machine

1257
00:48:40,970 --> 00:48:42,680
learning the the GPUs already better

1258
00:48:42,680 --> 00:48:45,380
alright so the main thing though I want

1259
00:48:45,380 --> 00:48:46,549
to point out though is the Xeon Phi

1260
00:48:46,549 --> 00:48:48,109
they're going to run here is going to be

1261
00:48:48,109 --> 00:48:50,450
a it's an older version of the xeon phi

1262
00:48:50,450 --> 00:48:52,759
so it's going to be do in order

1263
00:48:52,759 --> 00:48:54,349
execution so you can't do the

1264
00:48:54,349 --> 00:48:56,089
out-of-order stuff that the xeon can and

1265
00:48:56,089 --> 00:48:58,160
it can't do spec it of execution right

1266
00:48:58,160 --> 00:48:59,839
so it's gonna take your your your

1267
00:48:59,839 --> 00:49:01,579
pipeline and execute instructions one

1268
00:49:01,579 --> 00:49:02,150
after another

1269
00:49:02,150 --> 00:49:07,099
all right and and it can't do the just a

1270
00:49:07,099 --> 00:49:09,019
to me yeah it doesn't do it doesn't do

1271
00:49:09,019 --> 00:49:11,210
branch prediction and you spec of

1272
00:49:11,210 --> 00:49:13,249
execution so if you have a jump and if

1273
00:49:13,249 --> 00:49:15,890
the flush your des pipeline then you

1274
00:49:15,890 --> 00:49:18,229
know that that gets expensive so we're

1275
00:49:18,229 --> 00:49:19,249
gonna have four variants of the

1276
00:49:19,249 --> 00:49:21,410
selection scan so gonna do the scalar

1277
00:49:21,410 --> 00:49:23,329
version with sixty instructions the

1278
00:49:23,329 --> 00:49:25,160
branching versus the branchless and then

1279
00:49:25,160 --> 00:49:26,210
they'll have that vectorized version

1280
00:49:26,210 --> 00:49:27,469
which is always going to be branchless

1281
00:49:27,469 --> 00:49:28,819
but they'll do one with an early

1282
00:49:28,819 --> 00:49:30,559
mutilation and late materialization this

1283
00:49:30,559 --> 00:49:32,960
just means do i need to copy the the

1284
00:49:32,960 --> 00:49:35,390
tuple effort i Matt to the offsets do I

1285
00:49:35,390 --> 00:49:36,859
need to copy materialize it into a

1286
00:49:36,859 --> 00:49:39,739
buffer to pass it up to the next the

1287
00:49:39,739 --> 00:49:41,059
next operator in the query plan but

1288
00:49:41,059 --> 00:49:42,349
again it's not a full-fledged database

1289
00:49:42,349 --> 00:49:44,509
system so there is no other nothing else

1290
00:49:44,509 --> 00:49:48,019
after they do the scan right alright so

1291
00:49:48,019 --> 00:49:49,930
the first thing here you see is that

1292
00:49:49,930 --> 00:49:52,849
this the Xeon Phi is going to outperform

1293
00:49:52,849 --> 00:49:57,920
the the Xeon for the the branch in case

1294
00:49:57,920 --> 00:49:59,599
and the branch list case because this is

1295
00:49:59,599 --> 00:50:01,729
the the scan up is actually it's a

1296
00:50:01,729 --> 00:50:03,200
pretty simple instructions we're doing

1297
00:50:03,200 --> 00:50:05,269
in our for loop and this thing just has

1298
00:50:05,269 --> 00:50:07,339
way more cores but I always think this

1299
00:50:07,339 --> 00:50:10,369
is a typo right like it's this thing has

1300
00:50:10,369 --> 00:50:12,440
61 course I don't know why I said that

1301
00:50:12,440 --> 00:50:14,599
weird number it's not 60 or 62 or 64

1302
00:50:14,599 --> 00:50:17,749
right it's 61 whatever right and then

1303
00:50:17,749 --> 00:50:19,849
this Z on here I think has it's four

1304
00:50:19,849 --> 00:50:21,650
cores with hyper-threading so this has

1305
00:50:21,650 --> 00:50:23,069
way more cores the

1306
00:50:23,069 --> 00:50:24,690
for this is pretty straightforward so it

1307
00:50:24,690 --> 00:50:26,180
can rip through thinking more quickly

1308
00:50:26,180 --> 00:50:29,039
but this now shows you a portent

1309
00:50:29,039 --> 00:50:30,359
difference between with the benefit get

1310
00:50:30,359 --> 00:50:32,699
from branchless versus branching when

1311
00:50:32,699 --> 00:50:34,440
you can do in order versus out order

1312
00:50:34,440 --> 00:50:40,130
execution so again the the Xeon CPU has

1313
00:50:40,130 --> 00:50:43,890
the outer board execution it has the the

1314
00:50:43,890 --> 00:50:45,359
spec of execution and the branch

1315
00:50:45,359 --> 00:50:48,989
prediction so in that case the the the

1316
00:50:48,989 --> 00:50:51,479
the branch list one is is it's gonna do

1317
00:50:51,479 --> 00:50:53,999
much better right for this as you scale

1318
00:50:53,999 --> 00:50:56,699
up the selectivity all right sorry as

1319
00:50:56,699 --> 00:50:59,430
the second biggest lower I don't know

1320
00:50:59,430 --> 00:51:00,959
why this doesn't arc like the other one

1321
00:51:00,959 --> 00:51:03,089
oh yeah because in this case here you

1322
00:51:03,089 --> 00:51:05,279
you run out of CPU cache alright so

1323
00:51:05,279 --> 00:51:07,440
think of this is like zero one two five

1324
00:51:07,440 --> 00:51:09,660
ten this is like that first part of the

1325
00:51:09,660 --> 00:51:11,699
graph I showed from vector wise and then

1326
00:51:11,699 --> 00:51:13,769
when you go beyond 20 or 50 that's when

1327
00:51:13,769 --> 00:51:16,049
it crosses so that's why that's why you

1328
00:51:16,049 --> 00:51:18,900
know they converge there in the case

1329
00:51:18,900 --> 00:51:20,579
again the Xeon Phi they don't have that

1330
00:51:20,579 --> 00:51:23,729
branch misprediction respected execution

1331
00:51:23,729 --> 00:51:26,039
so like copying everything every single

1332
00:51:26,039 --> 00:51:28,619
time sucks in their world because it's a

1333
00:51:28,619 --> 00:51:29,729
lot of ways to work when your

1334
00:51:29,729 --> 00:51:32,609
selectivity is really low alright so

1335
00:51:32,609 --> 00:51:33,959
here again when you have the selectivity

1336
00:51:33,959 --> 00:51:36,269
at 100% the memory bandwidth on both of

1337
00:51:36,269 --> 00:51:38,099
these is what you're paying the penalty

1338
00:51:38,099 --> 00:51:40,339
for trying to get the data in and off of

1339
00:51:40,339 --> 00:51:43,619
your CPU caches so it doesn't make a

1340
00:51:43,619 --> 00:51:45,959
difference in either algorithm for the

1341
00:51:45,959 --> 00:51:48,690
vectorize one what you see is that the

1342
00:51:48,690 --> 00:51:50,729
in the case of the with late

1343
00:51:50,729 --> 00:51:52,890
materialization for both of these it's

1344
00:51:52,890 --> 00:51:54,779
gonna perform the best it's no surprise

1345
00:51:54,779 --> 00:51:56,640
because I I'm not copying tuples that

1346
00:51:56,640 --> 00:51:59,729
match like I'm just doing less work but

1347
00:51:59,729 --> 00:52:00,900
you have a more pronounced difference

1348
00:52:00,900 --> 00:52:02,369
between the early materialization and

1349
00:52:02,369 --> 00:52:04,709
the late winter and versus late

1350
00:52:04,709 --> 00:52:06,359
materialization on the two architectures

1351
00:52:06,359 --> 00:52:08,930
again for this one because in this world

1352
00:52:08,930 --> 00:52:12,779
the because the CPU is it's quite simple

1353
00:52:12,779 --> 00:52:15,630
the copy instructions become expensive

1354
00:52:15,630 --> 00:52:19,920
and like you know you're just doing a

1355
00:52:19,920 --> 00:52:21,390
lot the cost of doing wasted work

1356
00:52:21,390 --> 00:52:23,219
becomes more expensive and then

1357
00:52:23,219 --> 00:52:24,930
everything converges down to the same

1358
00:52:24,930 --> 00:52:27,869
performance when you start maxing out

1359
00:52:27,869 --> 00:52:30,930
the memory bandwidth right so here's a

1360
00:52:30,930 --> 00:52:32,519
good example also to of like as I was

1361
00:52:32,519 --> 00:52:33,719
saying like doesn't matter whether

1362
00:52:33,719 --> 00:52:35,729
you're fanciest indie or not like if the

1363
00:52:35,729 --> 00:52:36,750
query in the data

1364
00:52:36,750 --> 00:52:38,910
are not amenable to doing vectra's

1365
00:52:38,910 --> 00:52:43,400
operations it doesn't help you alright

1366
00:52:43,400 --> 00:52:45,900
this is also another good example of

1367
00:52:45,900 --> 00:52:47,400
what I was saying the beginning about

1368
00:52:47,400 --> 00:52:48,930
how you never achieved that the

1369
00:52:48,930 --> 00:52:50,400
theoretical and performance improvement

1370
00:52:50,400 --> 00:52:52,080
you could possibly get with vectorized

1371
00:52:52,080 --> 00:52:56,640
instructions so in this case here the on

1372
00:52:56,640 --> 00:53:02,240
the Z on this is doing on roughy 2.5 2.6

1373
00:53:02,240 --> 00:53:05,430
billion tuples per second but the semi

1374
00:53:05,430 --> 00:53:08,420
version is doing you know rounding up 6

1375
00:53:08,420 --> 00:53:10,830
so it's getting less than a 3x

1376
00:53:10,830 --> 00:53:15,650
improvement but we said we had a 4x

1377
00:53:15,650 --> 00:53:18,510
Sidney registers so this should really

1378
00:53:18,510 --> 00:53:20,640
be if we're actually achieving that full

1379
00:53:20,640 --> 00:53:23,250
full paralyzation we should have been 4x

1380
00:53:23,250 --> 00:53:25,080
faster and we're not because again it's

1381
00:53:25,080 --> 00:53:27,570
that cost of moving things in and out of

1382
00:53:27,570 --> 00:53:29,960
the registers that we pay a penalty for

1383
00:53:29,960 --> 00:53:32,280
just because we vectorized maybe one

1384
00:53:32,280 --> 00:53:33,780
piece of it doesn't and the rest of it's

1385
00:53:33,780 --> 00:53:36,540
not vectorized that that's going to be a

1386
00:53:36,540 --> 00:53:41,490
bottleneck for us ok all right so let's

1387
00:53:41,490 --> 00:53:43,140
look at some other things we do hash

1388
00:53:43,140 --> 00:53:44,220
tables is another one I think it's

1389
00:53:44,220 --> 00:53:45,330
really interesting that they talk about

1390
00:53:45,330 --> 00:53:47,070
this and they come up some interesting

1391
00:53:47,070 --> 00:53:50,300
techniques again this one we definitely

1392
00:53:50,300 --> 00:53:51,960
evaluated and it definitely does not

1393
00:53:51,960 --> 00:53:53,970
work once you're at a CPU cache alright

1394
00:53:53,970 --> 00:53:57,330
so say we want to do do a probe in our

1395
00:53:57,330 --> 00:53:58,260
hash table and we're doing linear

1396
00:53:58,260 --> 00:54:00,810
probing so we have and the scale version

1397
00:54:00,810 --> 00:54:03,000
we have a single input key well do well

1398
00:54:03,000 --> 00:54:06,060
hash it produce some offset for a slot

1399
00:54:06,060 --> 00:54:08,280
number in our hash table well go jump to

1400
00:54:08,280 --> 00:54:09,870
that all set can take whatever keys

1401
00:54:09,870 --> 00:54:11,550
inside of it compare it with our keys

1402
00:54:11,550 --> 00:54:14,580
see we match if we find a match we're

1403
00:54:14,580 --> 00:54:16,170
done if not then we just keep scanning

1404
00:54:16,170 --> 00:54:18,000
down until we keep till we find a slot

1405
00:54:18,000 --> 00:54:19,950
that's either empty meaning mean we know

1406
00:54:19,950 --> 00:54:21,330
our keys not in there or we find the one

1407
00:54:21,330 --> 00:54:25,770
that we're looking for right so the only

1408
00:54:25,770 --> 00:54:27,210
thing you can really vectorize in this

1409
00:54:27,210 --> 00:54:28,710
particular example you can vectorize

1410
00:54:28,710 --> 00:54:32,070
this right there are the the hyper guys

1411
00:54:32,070 --> 00:54:33,360
have a vectorized hash function which

1412
00:54:33,360 --> 00:54:35,340
I'll talk about when we talk about joins

1413
00:54:35,340 --> 00:54:38,040
but like that's not the expensive part

1414
00:54:38,040 --> 00:54:39,540
the expensive part is is doing this

1415
00:54:39,540 --> 00:54:41,640
comparison and jumping through memory in

1416
00:54:41,640 --> 00:54:44,310
the hash table so let's see how we can

1417
00:54:44,310 --> 00:54:46,800
vectorize this using vertical or start

1418
00:54:46,800 --> 00:54:48,630
horizontal vectorization so what we're

1419
00:54:48,630 --> 00:54:50,130
going to do now in our hash table

1420
00:54:50,130 --> 00:54:52,380
we're gonna expand out the number

1421
00:54:52,380 --> 00:54:56,309
Ellen's restoring purse law so within

1422
00:54:56,309 --> 00:54:58,710
each slot we'll have four keys and then

1423
00:54:58,710 --> 00:55:00,920
they'll have we'll have four values

1424
00:55:00,920 --> 00:55:03,509
so now we'll meet when we take a single

1425
00:55:03,509 --> 00:55:06,450
key we hash it we get our hash index we

1426
00:55:06,450 --> 00:55:08,039
jump to that location we're gonna get

1427
00:55:08,039 --> 00:55:11,490
back four keys then we can do our sim D

1428
00:55:11,490 --> 00:55:14,160
compare get get back our match mask and

1429
00:55:14,160 --> 00:55:15,420
then we check to see if any one of them

1430
00:55:15,420 --> 00:55:18,869
is one then we know we know we have a

1431
00:55:18,869 --> 00:55:20,190
match we know how to find the offset of

1432
00:55:20,190 --> 00:55:22,589
our matching key if there are all 0 then

1433
00:55:22,589 --> 00:55:23,880
we know that there's nothing in this

1434
00:55:23,880 --> 00:55:25,920
slot that we have and we just jump down

1435
00:55:25,920 --> 00:55:27,210
to the next location and then do the

1436
00:55:27,210 --> 00:55:30,900
same vectorized comparison all right so

1437
00:55:30,900 --> 00:55:33,059
for this one

1438
00:55:33,059 --> 00:55:35,460
this one to me this seems like actually

1439
00:55:35,460 --> 00:55:37,349
a really good idea turns out not to be

1440
00:55:37,349 --> 00:55:41,339
not to work because they're just there's

1441
00:55:41,339 --> 00:55:44,940
so much extra overhead of the cost of

1442
00:55:44,940 --> 00:55:46,200
going getting these things and scanning

1443
00:55:46,200 --> 00:55:49,559
and ripping through them you know

1444
00:55:49,559 --> 00:55:51,180
copying this into the Sidney Bechet errs

1445
00:55:51,180 --> 00:55:53,130
like that that's the penalty you're

1446
00:55:53,130 --> 00:56:08,640
paying yes so we seem is did we try

1447
00:56:08,640 --> 00:56:11,250
software prefetching on this where I'm

1448
00:56:11,250 --> 00:56:15,630
here and then I'm gonna assume that I'm

1449
00:56:15,630 --> 00:56:17,039
not gonna match and therefore I'm gonna

1450
00:56:17,039 --> 00:56:20,069
prefetch the next thing but what if I

1451
00:56:20,069 --> 00:56:21,630
match then I did prefetch some crap and

1452
00:56:21,630 --> 00:56:23,549
I flew to my CPU cache and then it

1453
00:56:23,549 --> 00:56:25,710
doesn't work like this is the cache

1454
00:56:25,710 --> 00:56:26,970
servers are so random that it's like

1455
00:56:26,970 --> 00:56:28,589
it's hard to say what you actually

1456
00:56:28,589 --> 00:56:31,380
should do it doesn't in our experience

1457
00:56:31,380 --> 00:56:34,980
it doesn't work confession doesn't help

1458
00:56:34,980 --> 00:56:38,910
yeah yeah all right so let's see how to

1459
00:56:38,910 --> 00:56:41,220
do this with vertical vectorization so

1460
00:56:41,220 --> 00:56:43,470
before we were taking one key and then

1461
00:56:43,470 --> 00:56:45,089
looking for that key in you know you

1462
00:56:45,089 --> 00:56:46,740
know in the needle the single needle in

1463
00:56:46,740 --> 00:56:48,599
our haystack now with vertical

1464
00:56:48,599 --> 00:56:50,059
vectorization we're going to take

1465
00:56:50,059 --> 00:56:52,769
multiple keys at the same time and do

1466
00:56:52,769 --> 00:56:56,309
our search in parallel for them so we'll

1467
00:56:56,309 --> 00:56:57,299
take four keys here

1468
00:56:57,299 --> 00:57:00,269
we'll run four hash functions and so

1469
00:57:00,269 --> 00:57:01,859
this you have to do scaler and there's

1470
00:57:01,859 --> 00:57:03,759
no Cindy instruction that do

1471
00:57:03,759 --> 00:57:06,189
a four lane hash can we can vectorize

1472
00:57:06,189 --> 00:57:09,729
the hash function itself the operations

1473
00:57:09,729 --> 00:57:10,929
women have something like there's no

1474
00:57:10,929 --> 00:57:12,809
like humor hash or

1475
00:57:12,809 --> 00:57:16,589
xxx hash that can be run entirely in Sim

1476
00:57:16,589 --> 00:57:19,659
d4 multiple elements so we're gonna run

1477
00:57:19,659 --> 00:57:21,880
this as a four lips rip through this we

1478
00:57:21,880 --> 00:57:23,949
can unroll the loop if we wanted to and

1479
00:57:23,949 --> 00:57:25,989
we'll get four locations in our hash

1480
00:57:25,989 --> 00:57:28,299
function or hash table we'd I'll jump to

1481
00:57:28,299 --> 00:57:31,209
those locations and then do it the Cindy

1482
00:57:31,209 --> 00:57:33,099
gather to put them into a single vector

1483
00:57:33,099 --> 00:57:35,469
and then now we can do our Cindy compare

1484
00:57:35,469 --> 00:57:37,509
and check to see whether we have a match

1485
00:57:37,509 --> 00:57:40,569
and that's gonna produce an offset sorry

1486
00:57:40,569 --> 00:57:43,509
produces a bit mass that is me one if

1487
00:57:43,509 --> 00:57:45,519
their keys match or zero if our keys

1488
00:57:45,519 --> 00:57:48,249
don't match but now what's the problem

1489
00:57:48,249 --> 00:57:50,459
here

1490
00:57:52,259 --> 00:57:54,969
well so in my last case when I'm looking

1491
00:57:54,969 --> 00:57:57,339
at one key at a time it took if that one

1492
00:57:57,339 --> 00:57:59,319
key matches I'm done that key doesn't

1493
00:57:59,319 --> 00:58:01,029
match then I jumped down to the next one

1494
00:58:01,029 --> 00:58:03,729
but now I have two of them match to them

1495
00:58:03,729 --> 00:58:12,669
doesn't don't match yes yeah so he said

1496
00:58:12,669 --> 00:58:15,279
like and this this is this this notion

1497
00:58:15,279 --> 00:58:19,059
of them they always wanted to have full

1498
00:58:19,059 --> 00:58:21,669
utilization of all the lanes so these

1499
00:58:21,669 --> 00:58:23,859
guys match so I don't need to go look

1500
00:58:23,859 --> 00:58:26,079
anymore else in the and the hash of a

1501
00:58:26,079 --> 00:58:28,449
seat to find a match for them these guys

1502
00:58:28,449 --> 00:58:30,669
don't match so I have to go look for

1503
00:58:30,669 --> 00:58:33,749
them so one thing I could do is just

1504
00:58:33,749 --> 00:58:36,519
keep these guys or keep you know keep

1505
00:58:36,519 --> 00:58:38,469
these keys in my register everybody

1506
00:58:38,469 --> 00:58:40,899
jumps down to one offset in and they're

1507
00:58:40,899 --> 00:58:42,069
in a corresponding location in the hash

1508
00:58:42,069 --> 00:58:43,989
table bring those new keys in and do

1509
00:58:43,989 --> 00:58:45,519
comparison and no matter what the first

1510
00:58:45,519 --> 00:58:47,499
key and the last key produce as the

1511
00:58:47,499 --> 00:58:49,059
comparison I ignored that because I know

1512
00:58:49,059 --> 00:58:51,819
that I already found them but now that's

1513
00:58:51,819 --> 00:58:53,859
in that I'm getting 50% utilization

1514
00:58:53,859 --> 00:58:56,289
because I'm doing useless computation on

1515
00:58:56,289 --> 00:58:57,249
those keys because I already knew I

1516
00:58:57,249 --> 00:58:59,619
found a match so I'm just I'm doing

1517
00:58:59,619 --> 00:59:04,899
unnecessary work again so the other

1518
00:59:04,899 --> 00:59:07,089
other thing could be say 3 out of 4

1519
00:59:07,089 --> 00:59:09,009
match and so I keep scanning yeah I loop

1520
00:59:09,009 --> 00:59:10,449
through the entire thing to find that

1521
00:59:10,449 --> 00:59:12,609
that the key the last key doesn't never

1522
00:59:12,609 --> 00:59:14,739
matches and now I just wasted all this

1523
00:59:14,739 --> 00:59:16,869
work so what they're gonna do is they're

1524
00:59:16,869 --> 00:59:17,620
gonna maintain

1525
00:59:17,620 --> 00:59:19,450
internal bookkeeping to keep track of

1526
00:59:19,450 --> 00:59:21,940
all right well these guys matched and

1527
00:59:21,940 --> 00:59:24,100
therefore now I need to go get two new

1528
00:59:24,100 --> 00:59:26,050
keys to replace them they're gonna go

1529
00:59:26,050 --> 00:59:27,970
back over here replace the input key

1530
00:59:27,970 --> 00:59:30,160
vector with the next two elements that

1531
00:59:30,160 --> 00:59:33,100
are in our column near on our hash

1532
00:59:33,100 --> 00:59:35,950
function and for the this the second and

1533
00:59:35,950 --> 00:59:38,350
third key I the hash function is really

1534
00:59:38,350 --> 00:59:40,300
just saying take the last location add

1535
00:59:40,300 --> 00:59:41,590
one to it cuz I'm moving down to the

1536
00:59:41,590 --> 00:59:43,570
next location in the slot array but I

1537
00:59:43,570 --> 00:59:46,090
get a new starting location for the the

1538
00:59:46,090 --> 00:59:48,490
first in the last key and then do this

1539
00:59:48,490 --> 00:59:49,780
all over again jump to those locations

1540
00:59:49,780 --> 00:59:51,940
fill up my vectors and then do my Cindy

1541
00:59:51,940 --> 00:59:58,510
compare oh right yes just can you go can

1542
00:59:58,510 --> 01:00:02,340
you do multiplicative hashing with Cindy

1543
01:00:03,870 --> 01:00:08,580
across multiple keys at the same time I

1544
01:00:08,850 --> 01:00:14,200
don't know the answer uh we have to

1545
01:00:14,200 --> 01:00:17,740
check like yeah I don't know because I

1546
01:00:17,740 --> 01:00:19,030
think you know there's a trade-off of

1547
01:00:19,030 --> 01:00:24,280
like collisions versus speed I I think

1548
01:00:24,280 --> 01:00:25,210
the collision rate might be kind of high

1549
01:00:25,210 --> 01:00:32,890
on that we could try alright um so this

1550
01:00:32,890 --> 01:00:34,600
is also not gonna work too when you we

1551
01:00:34,600 --> 01:00:36,070
know you don't fit your seat the caches

1552
01:00:36,070 --> 01:00:37,330
because getting all this bookkeeping

1553
01:00:37,330 --> 01:00:38,650
overhead to go back to get your keys and

1554
01:00:38,650 --> 01:00:40,290
fill them in it's gonna be expensive

1555
01:00:40,290 --> 01:00:43,450
there's another issue with this this

1556
01:00:43,450 --> 01:00:45,400
implementation that is a bit more

1557
01:00:45,400 --> 01:00:47,680
nuanced on the engineering side and if

1558
01:00:47,680 --> 01:00:49,030
anybody caught that when they read the

1559
01:00:49,030 --> 01:00:51,580
paper like what's one problem you'd have

1560
01:00:51,580 --> 01:00:52,780
at this if you're like the person

1561
01:00:52,780 --> 01:00:54,790
building a database system and when you

1562
01:00:54,790 --> 01:00:59,680
use this algorithm yes

1563
01:00:59,680 --> 01:01:03,120
the cookery show now is ignore all that

1564
01:01:03,120 --> 01:01:08,280
the issue is gonna be that the the

1565
01:01:08,280 --> 01:01:10,750
probic algorithm is not gonna be stable

1566
01:01:10,750 --> 01:01:13,570
meaning for the same data set and the

1567
01:01:13,570 --> 01:01:16,510
same query we we could get different

1568
01:01:16,510 --> 01:01:19,300
ordered results every single time you

1569
01:01:19,300 --> 01:01:22,270
run that query now okay well

1570
01:01:22,270 --> 01:01:24,190
relational model is unordered right so

1571
01:01:24,190 --> 01:01:26,170
so this is we're not supposed to really

1572
01:01:26,170 --> 01:01:28,900
care about the order but like if I'm

1573
01:01:28,900 --> 01:01:30,370
trying to actually debug stuff and try

1574
01:01:30,370 --> 01:01:32,080
to understand it well somehow the the

1575
01:01:32,080 --> 01:01:34,090
data I'm writing to one register gets

1576
01:01:34,090 --> 01:01:35,710
you know one location gets clobber but

1577
01:01:35,710 --> 01:01:37,060
another one doesn't like if every single

1578
01:01:37,060 --> 01:01:38,530
time I'm getting completely different

1579
01:01:38,530 --> 01:01:40,360
random results depending on what order

1580
01:01:40,360 --> 01:01:42,450
had these things matching my hash table

1581
01:01:42,450 --> 01:01:45,690
then it could be hard to debug things I

1582
01:01:45,690 --> 01:01:52,780
I somewhat agree with that i i i don't

1583
01:01:52,780 --> 01:01:54,130
know how much that that is actually in

1584
01:01:54,130 --> 01:01:55,300
issue but this is something they said in

1585
01:01:55,300 --> 01:01:57,220
the paper that of all the algorithms

1586
01:01:57,220 --> 01:01:58,420
this is the only one that they had this

1587
01:01:58,420 --> 01:02:00,040
particular issue like the selective scan

1588
01:02:00,040 --> 01:02:01,420
stuff we talked about doesn't have this

1589
01:02:01,420 --> 01:02:05,410
problem yeah all right let's look at

1590
01:02:05,410 --> 01:02:07,570
some performance results so again we're

1591
01:02:07,570 --> 01:02:09,430
gonna roll on the Phi and the Xeon so

1592
01:02:09,430 --> 01:02:10,900
they're gonna have the scalar hash probe

1593
01:02:10,900 --> 01:02:12,880
and then the vector ax is vertical and

1594
01:02:12,880 --> 01:02:16,450
horizontal the along the x axis they're

1595
01:02:16,450 --> 01:02:18,430
going to crease the hash table size so

1596
01:02:18,430 --> 01:02:20,350
with the scalar version the performance

1597
01:02:20,350 --> 01:02:22,210
looks like this and notice that the y

1598
01:02:22,210 --> 01:02:23,890
axis scales are different because the

1599
01:02:23,890 --> 01:02:25,450
the xeon phi has more cores than the

1600
01:02:25,450 --> 01:02:26,760
other one

1601
01:02:26,760 --> 01:02:31,720
the when okay and we're gonna see that

1602
01:02:31,720 --> 01:02:33,400
again the difference though is that the

1603
01:02:33,400 --> 01:02:34,750
vertical vectorization will be much

1604
01:02:34,750 --> 01:02:37,480
better for the for the xeon phi because

1605
01:02:37,480 --> 01:02:41,440
it doesn't have the it doesn't have the

1606
01:02:41,440 --> 01:02:45,490
the branch misprediction error like it's

1607
01:02:45,490 --> 01:02:47,290
always gonna sort of programmatically go

1608
01:02:47,290 --> 01:02:50,740
through and do the you know the checks

1609
01:02:50,740 --> 01:02:53,200
in the right the same order whereas in

1610
01:02:53,200 --> 01:02:56,530
the horizontal case your you know you

1611
01:02:56,530 --> 01:02:58,060
may have to check you know in direction

1612
01:02:58,060 --> 01:03:01,780
or different non-determinism in how you

1613
01:03:01,780 --> 01:03:05,170
evaluate the keys in the case of the and

1614
01:03:05,170 --> 01:03:07,630
the xeon I forget why there's is the

1615
01:03:07,630 --> 01:03:09,640
crossing point here where the vertical

1616
01:03:09,640 --> 01:03:12,250
sub got back to got better than the the

1617
01:03:12,250 --> 01:03:13,329
horizontal

1618
01:03:13,329 --> 01:03:15,309
to point out here is that same before

1619
01:03:15,309 --> 01:03:16,930
once everything is not in your CPU cache

1620
01:03:16,930 --> 01:03:21,209
all this doesn't matter right so the the

1621
01:03:21,209 --> 01:03:23,890
Xeon Phi has a smaller cache than the

1622
01:03:23,890 --> 01:03:26,349
than the regular Xeon so you hit this

1623
01:03:26,349 --> 01:03:28,690
this sort of convergence point much more

1624
01:03:28,690 --> 01:03:32,380
much much sooner so again this is what I

1625
01:03:32,380 --> 01:03:33,969
was saying I I doubts over P fetching

1626
01:03:33,969 --> 01:03:35,979
would happen in this case and Xeon Phi

1627
01:03:35,979 --> 01:03:37,569
least the older version stuff they

1628
01:03:37,569 --> 01:03:38,799
definitely not have prefix up or

1629
01:03:38,799 --> 01:03:40,479
prefetching that's only in sort of

1630
01:03:40,479 --> 01:03:41,140
modern Zeon's

1631
01:03:41,140 --> 01:03:45,670
modern last ten years yeah alright the

1632
01:03:45,670 --> 01:03:48,400
last thing I'm gonna talk about is have

1633
01:03:48,400 --> 01:03:49,630
you partitioning with histograms and

1634
01:03:49,630 --> 01:03:51,339
basically the idea here is we can use

1635
01:03:51,339 --> 01:03:55,089
scatter and gather to do our histogram

1636
01:03:55,089 --> 01:03:57,729
computation in parallel so they say this

1637
01:03:57,729 --> 01:04:00,219
is our input key vector we're gonna use

1638
01:04:00,219 --> 01:04:02,799
a sim the latest instruction think of

1639
01:04:02,799 --> 01:04:03,819
this or like in the same thing as a

1640
01:04:03,819 --> 01:04:06,039
radix tree where I just go grab one

1641
01:04:06,039 --> 01:04:08,469
digit or one byte of each key and I'm

1642
01:04:08,469 --> 01:04:09,609
using that essentially as the hash

1643
01:04:09,609 --> 01:04:10,809
function to tell me what my offset

1644
01:04:10,809 --> 01:04:12,729
should be in like it's a it's a cheap

1645
01:04:12,729 --> 01:04:14,950
poor-man's hash function and then now

1646
01:04:14,950 --> 01:04:16,569
what I'm gonna do is I take these

1647
01:04:16,569 --> 01:04:18,729
locations and then I'm gonna map them to

1648
01:04:18,729 --> 01:04:20,859
some histogram and I'll just do a

1649
01:04:20,859 --> 01:04:23,440
Symbian where I take whatever value was

1650
01:04:23,440 --> 01:04:25,630
in the vector I'm writing into and I and

1651
01:04:25,630 --> 01:04:28,359
I add one to it alright for everything

1652
01:04:28,359 --> 01:04:30,640
ever it for every matching element

1653
01:04:30,640 --> 01:04:32,650
within that location in the vector I'm

1654
01:04:32,650 --> 01:04:34,630
writing to the problems gonna be though

1655
01:04:34,630 --> 01:04:37,029
is that I have two keys mapping to the

1656
01:04:37,029 --> 01:04:39,880
same location and again with Cindy it's

1657
01:04:39,880 --> 01:04:42,849
going to be atomic so the the

1658
01:04:42,849 --> 01:04:45,249
instruction is add one to this location

1659
01:04:45,249 --> 01:04:47,170
based on the previous value is I can't I

1660
01:04:47,170 --> 01:04:48,039
can't

1661
01:04:48,039 --> 01:04:49,959
it's not there's no foil to say add one

1662
01:04:49,959 --> 01:04:51,940
first time and add one again it's like

1663
01:04:51,940 --> 01:04:54,130
add one based on the old value is so

1664
01:04:54,130 --> 01:04:55,779
we're losing one of these one of these

1665
01:04:55,779 --> 01:04:57,390
updates so our counts are gonna be wrong

1666
01:04:57,390 --> 01:04:59,799
so the way they can handle that is you

1667
01:04:59,799 --> 01:05:02,559
do a Cindy scatter now to have each of

1668
01:05:02,559 --> 01:05:04,559
these guys writing two different vectors

1669
01:05:04,559 --> 01:05:06,819
right so this is the first vector for

1670
01:05:06,819 --> 01:05:08,109
the first keep for the first element

1671
01:05:08,109 --> 01:05:09,819
this is the next vector for the next

1672
01:05:09,819 --> 01:05:11,440
element and now they're doing the same

1673
01:05:11,440 --> 01:05:12,640
thing we had before with the writing

1674
01:05:12,640 --> 01:05:14,499
into the offset of the vector but then

1675
01:05:14,499 --> 01:05:15,640
now they're not clobbering each other

1676
01:05:15,640 --> 01:05:18,489
because they're only one you know one

1677
01:05:18,489 --> 01:05:20,759
lane can write into one vector at a time

1678
01:05:20,759 --> 01:05:23,319
so now the only thing I if I need to do

1679
01:05:23,319 --> 01:05:26,830
is what the final histogram it is

1680
01:05:26,830 --> 01:05:30,520
I just do a Simba had to do the

1681
01:05:30,520 --> 01:05:33,220
computation across across this way

1682
01:05:33,220 --> 01:05:36,570
horizontally to produce the final result

1683
01:05:36,570 --> 01:05:38,470
all right so I think I think this is

1684
01:05:38,470 --> 01:05:42,250
kind of cool okay all right there's a

1685
01:05:42,250 --> 01:05:44,170
finish up quickly vectorization is super

1686
01:05:44,170 --> 01:05:46,540
important for OLAP queries we've already

1687
01:05:46,540 --> 01:05:47,830
covered this nothing works when your CPU

1688
01:05:47,830 --> 01:05:49,990
cache and then all the inner query

1689
01:05:49,990 --> 01:05:51,370
panels and stuff that we talked about so

1690
01:05:51,370 --> 01:05:52,810
far plus the stuff we'll talk about when

1691
01:05:52,810 --> 01:05:54,850
we start to turn my joins vectorization

1692
01:05:54,850 --> 01:05:57,010
is just another tool we can add to speed

1693
01:05:57,010 --> 01:05:59,890
things up so in an ideal case an ideal

1694
01:05:59,890 --> 01:06:02,410
system you can do query compilation with

1695
01:06:02,410 --> 01:06:04,540
vectorization that also supports

1696
01:06:04,540 --> 01:06:07,570
parallel queries and in our system we're

1697
01:06:07,570 --> 01:06:09,970
almost there hyper actually could not do

1698
01:06:09,970 --> 01:06:11,290
vectorization they can only do

1699
01:06:11,290 --> 01:06:13,780
compilation and parallel queries right

1700
01:06:13,780 --> 01:06:17,320
dr. wise can only do I sort of pre

1701
01:06:17,320 --> 01:06:19,900
compiled yeah some cases it helps

1702
01:06:19,900 --> 01:06:22,330
sometimes it doesn't help but they could

1703
01:06:22,330 --> 01:06:28,240
they could do better ization yes that's

1704
01:06:28,240 --> 01:06:30,730
for rights the rights they have only on

1705
01:06:30,730 --> 01:06:33,010
a single thread but for OLAP queries or

1706
01:06:33,010 --> 01:06:34,150
read-only queries they can run those in

1707
01:06:34,150 --> 01:06:35,950
parallel that's the mortal stuff we

1708
01:06:35,950 --> 01:06:38,550
talked about wouldn't for the schedulers

1709
01:06:38,550 --> 01:06:42,010
okay any question that vectorization all

1710
01:06:42,010 --> 01:06:44,650
right let's finish up with Patrick 3 ok

1711
01:06:44,650 --> 01:06:48,040
so the project 3 the pot the goal is for

1712
01:06:48,040 --> 01:06:50,130
you in your group to implement some

1713
01:06:50,130 --> 01:06:52,960
substantial or large piece of software

1714
01:06:52,960 --> 01:06:55,480
component or feature in the data system

1715
01:06:55,480 --> 01:06:56,560
we've been working on for the first two

1716
01:06:56,560 --> 01:06:58,960
projects and the idea is that these

1717
01:06:58,960 --> 01:07:00,430
products should incorporate the various

1718
01:07:00,430 --> 01:07:01,930
topics and techniques and methods and

1719
01:07:01,930 --> 01:07:03,880
optimizations that we've talked about so

1720
01:07:03,880 --> 01:07:06,760
far in the course as well as whatever

1721
01:07:06,760 --> 01:07:09,010
you interested in your own sort of line

1722
01:07:09,010 --> 01:07:11,590
of work or research or your hobby if you

1723
01:07:11,590 --> 01:07:13,240
want to bring that in as well then I'm

1724
01:07:13,240 --> 01:07:15,280
totally fine with that all right because

1725
01:07:15,280 --> 01:07:16,360
I certainly I don't know everything that

1726
01:07:16,360 --> 01:07:18,340
you know and think outside databases I'm

1727
01:07:18,340 --> 01:07:19,780
very limited knowledge so if you come

1728
01:07:19,780 --> 01:07:21,490
along with something that I don't know

1729
01:07:21,490 --> 01:07:22,420
about it would be kind of cool to play

1730
01:07:22,420 --> 01:07:24,970
with I'm totally down with that the

1731
01:07:24,970 --> 01:07:26,260
important thing though is that whatever

1732
01:07:26,260 --> 01:07:27,430
you pick for your project has to be

1733
01:07:27,430 --> 01:07:29,800
unique from every other group so I can't

1734
01:07:29,800 --> 01:07:31,690
have two people two groups also

1735
01:07:31,690 --> 01:07:33,430
implementing constraints because the

1736
01:07:33,430 --> 01:07:35,710
goal is we want to have your software be

1737
01:07:35,710 --> 01:07:37,390
able to be merge back into the full

1738
01:07:37,390 --> 01:07:39,850
system so that you know that you know

1739
01:07:39,850 --> 01:07:40,750
you go off and

1740
01:07:40,750 --> 01:07:42,070
in real-world ago in the and the job

1741
01:07:42,070 --> 01:07:43,060
where I couldn't be able to say look you

1742
01:07:43,060 --> 01:07:44,800
know here's this piece of our database

1743
01:07:44,800 --> 01:07:48,730
system that that I helped implement so

1744
01:07:48,730 --> 01:07:50,500
what do you have to do well there's me

1745
01:07:50,500 --> 01:07:51,190
proposal

1746
01:07:51,190 --> 01:07:53,230
that'll be due after the spring break

1747
01:07:53,230 --> 01:07:54,970
then later on before the end semester

1748
01:07:54,970 --> 01:07:56,980
via satis update with design documents

1749
01:07:56,980 --> 01:07:58,480
will also do code reviews with each

1750
01:07:58,480 --> 01:08:00,640
other alright so you talk about this in

1751
01:08:00,640 --> 01:08:01,900
a second but you mean you have to look

1752
01:08:01,900 --> 01:08:02,890
over other people's code and see whether

1753
01:08:02,890 --> 01:08:04,030
they're doing stupid things and a look

1754
01:08:04,030 --> 01:08:04,990
at your code to see whether your do

1755
01:08:04,990 --> 01:08:06,100
you're doing stupid things

1756
01:08:06,100 --> 01:08:07,960
and there'll be a final presentation and

1757
01:08:07,960 --> 01:08:09,580
then the code drop which is submitting a

1758
01:08:09,580 --> 01:08:11,950
PR on us on github it has a cleanly

1759
01:08:11,950 --> 01:08:14,140
merge into our master branch so let's go

1760
01:08:14,140 --> 01:08:16,210
through each of these so for the first

1761
01:08:16,210 --> 01:08:18,339
Monday after Spring Break everyone every

1762
01:08:18,339 --> 01:08:19,630
group will come up here and they'll

1763
01:08:19,630 --> 01:08:21,339
spend five minutes to talk about what

1764
01:08:21,339 --> 01:08:24,009
you're what you're proposing to build so

1765
01:08:24,009 --> 01:08:25,720
this is not just like at a high level

1766
01:08:25,720 --> 01:08:27,580
here's what I want to do you actually

1767
01:08:27,580 --> 01:08:29,020
should spend time looking at the source

1768
01:08:29,020 --> 01:08:31,299
code and try to come up with a good

1769
01:08:31,299 --> 01:08:33,100
approximation of what will actually take

1770
01:08:33,100 --> 01:08:35,229
for you to implement that particular

1771
01:08:35,229 --> 01:08:37,060
feature or component so you should know

1772
01:08:37,060 --> 01:08:38,490
what files you need to modify or add

1773
01:08:38,490 --> 01:08:40,810
Hydra acts you're gonna test whether

1774
01:08:40,810 --> 01:08:41,979
your implementation is working correctly

1775
01:08:41,979 --> 01:08:44,020
and then this is why I have you guys

1776
01:08:44,020 --> 01:08:45,759
list and every single paper you read

1777
01:08:45,759 --> 01:08:47,589
what workloads they used to evaluate

1778
01:08:47,589 --> 01:08:49,870
their their their research you should

1779
01:08:49,870 --> 01:08:51,460
know about what workload you want to use

1780
01:08:51,460 --> 01:08:53,890
for your project so right now we can

1781
01:08:53,890 --> 01:08:56,200
support some basic ot workloads TATP

1782
01:08:56,200 --> 01:08:59,380
small bank and why says be and we can

1783
01:08:59,380 --> 01:09:02,859
support some queries in TP CH but it is

1784
01:09:02,859 --> 01:09:05,080
something else you want to evaluate let

1785
01:09:05,080 --> 01:09:07,839
me know we can figure something out then

1786
01:09:07,839 --> 01:09:09,850
we'll have a checkpoint in April where

1787
01:09:09,850 --> 01:09:11,020
again you come back up spend five

1788
01:09:11,020 --> 01:09:12,220
minutes and tell everyone what you've

1789
01:09:12,220 --> 01:09:13,330
done what you've worked on what the

1790
01:09:13,330 --> 01:09:15,790
current status is of your project if

1791
01:09:15,790 --> 01:09:19,299
there's any change in your plans because

1792
01:09:19,299 --> 01:09:20,439
there's something in the system that

1793
01:09:20,439 --> 01:09:22,149
like was broken or not implemented or

1794
01:09:22,149 --> 01:09:23,410
you found something else that was super

1795
01:09:23,410 --> 01:09:24,819
interesting then you talk about what

1796
01:09:24,819 --> 01:09:27,790
those differences are and this is always

1797
01:09:27,790 --> 01:09:29,560
fun to you people who discuss like what

1798
01:09:29,560 --> 01:09:30,910
are some some prizes they found when

1799
01:09:30,910 --> 01:09:32,109
they would start looking into the bowels

1800
01:09:32,109 --> 01:09:33,520
of the system like oh I thought it was

1801
01:09:33,520 --> 01:09:35,229
gonna work this way but it did this way

1802
01:09:35,229 --> 01:09:36,399
I would the be derek she has a memory

1803
01:09:36,399 --> 01:09:38,080
leak right well that's not a surprise at

1804
01:09:38,080 --> 01:09:40,240
this point but like like things like

1805
01:09:40,240 --> 01:09:42,850
that right and it was also super useful

1806
01:09:42,850 --> 01:09:45,520
but this is and you'll see this this

1807
01:09:45,520 --> 01:09:46,839
definite is happening previous semesters

1808
01:09:46,839 --> 01:09:49,210
is that sometimes one group will need

1809
01:09:49,210 --> 01:09:53,890
you know sort of one feature like like

1810
01:09:53,890 --> 01:09:56,800
we need a settings manager or a locked

1811
01:09:56,800 --> 01:09:58,830
away to lock tables in a certain way and

1812
01:09:58,830 --> 01:10:01,030
another group might need the same thing

1813
01:10:01,030 --> 01:10:02,860
so then rather than you know the two

1814
01:10:02,860 --> 01:10:04,090
groups both implementing the same

1815
01:10:04,090 --> 01:10:06,640
redundant piece of software you guys

1816
01:10:06,640 --> 01:10:07,870
could potentially work together or maybe

1817
01:10:07,870 --> 01:10:09,100
one group finished or the other group

1818
01:10:09,100 --> 01:10:10,090
and the other group could take their

1819
01:10:10,090 --> 01:10:12,040
take their code so this is meant to be

1820
01:10:12,040 --> 01:10:13,330
like a collaborative process it's not

1821
01:10:13,330 --> 01:10:14,620
like project one or project you or

1822
01:10:14,620 --> 01:10:15,580
you're in competition with each other

1823
01:10:15,580 --> 01:10:18,100
it's meant to say I we should all be

1824
01:10:18,100 --> 01:10:19,240
working together and trying to make the

1825
01:10:19,240 --> 01:10:21,640
thing better the design document I'll

1826
01:10:21,640 --> 01:10:22,840
provide you guys with the template and

1827
01:10:22,840 --> 01:10:24,310
it's just written in markdown it's

1828
01:10:24,310 --> 01:10:26,650
basically it's a description of what the

1829
01:10:26,650 --> 01:10:28,420
what your feature is or what your

1830
01:10:28,420 --> 01:10:30,040
component actually is why you designed

1831
01:10:30,040 --> 01:10:31,540
it a certain way you know what are the

1832
01:10:31,540 --> 01:10:32,710
different trade-offs that you have to

1833
01:10:32,710 --> 01:10:34,120
consider for this implementation and

1834
01:10:34,120 --> 01:10:37,180
then future work for if anybody wants to

1835
01:10:37,180 --> 01:10:38,980
come along and continue with with your

1836
01:10:38,980 --> 01:10:40,990
project you know what could it actually

1837
01:10:40,990 --> 01:10:42,700
do if you had more time what would you

1838
01:10:42,700 --> 01:10:44,740
actually do and for those of you that

1839
01:10:44,740 --> 01:10:46,930
are considering doing like a capstone

1840
01:10:46,930 --> 01:10:48,250
and a pen study in the fall semester

1841
01:10:48,250 --> 01:10:50,170
this is also a useful point for you to

1842
01:10:50,170 --> 01:10:52,030
write down what your state of mind was

1843
01:10:52,030 --> 01:10:53,200
at the end of the semester because you'd

1844
01:10:53,200 --> 01:10:55,360
go off in the summer and come back in

1845
01:10:55,360 --> 01:10:56,320
the fall and you're like what the hell

1846
01:10:56,320 --> 01:10:57,550
was actually thinking back in the April

1847
01:10:57,550 --> 01:10:59,580
May and this is a good you know a good

1848
01:10:59,580 --> 01:11:03,070
reminder for yourself for the code

1849
01:11:03,070 --> 01:11:05,110
review again you'll be two rounds of

1850
01:11:05,110 --> 01:11:06,850
code reviews again I'll pair up

1851
01:11:06,850 --> 01:11:08,680
different groups so to look at each

1852
01:11:08,680 --> 01:11:10,840
other's code and we'll just use the the

1853
01:11:10,840 --> 01:11:12,580
pull request review process through

1854
01:11:12,580 --> 01:11:14,860
through github and I'll spend time in

1855
01:11:14,860 --> 01:11:15,940
class to talk about what does it mean to

1856
01:11:15,940 --> 01:11:17,530
actually do a code view you know it's

1857
01:11:17,530 --> 01:11:19,180
not like things like you know you you

1858
01:11:19,180 --> 01:11:20,710
misspelled this word like it's actually

1859
01:11:20,710 --> 01:11:22,600
spending time to look at the code and

1860
01:11:22,600 --> 01:11:23,830
try to figure out you know are they

1861
01:11:23,830 --> 01:11:25,300
making reasonable assumptions or in

1862
01:11:25,300 --> 01:11:28,240
their implementation and what I'll say

1863
01:11:28,240 --> 01:11:30,460
also too is this is meant to be

1864
01:11:30,460 --> 01:11:32,800
everyone's mentor can contribute so I

1865
01:11:32,800 --> 01:11:34,420
don't want for the like the first

1866
01:11:34,420 --> 01:11:35,800
recurred review one person does it and

1867
01:11:35,800 --> 01:11:36,850
the second code review the next person

1868
01:11:36,850 --> 01:11:38,470
does it everyone should be contributing

1869
01:11:38,470 --> 01:11:40,750
equally and how we divide up the source

1870
01:11:40,750 --> 01:11:42,430
code for what you want to look at right

1871
01:11:42,430 --> 01:11:45,340
that'll vary based on the project like

1872
01:11:45,340 --> 01:11:46,960
certainly sometimes this if you're doing

1873
01:11:46,960 --> 01:11:50,170
a I'm gonna file basis sometimes clearly

1874
01:11:50,170 --> 01:11:52,660
some from files on War they more

1875
01:11:52,660 --> 01:11:54,190
modified than other files and that may

1876
01:11:54,190 --> 01:11:55,870
not be a good way to divide things up

1877
01:11:55,870 --> 01:11:58,300
but well we will discuss ways to handle

1878
01:11:58,300 --> 01:12:00,760
this final presentations will be

1879
01:12:00,760 --> 01:12:02,680
whenever we're scheduled for the final

1880
01:12:02,680 --> 01:12:05,740
exam I think some Monday at like 8:30 or

1881
01:12:05,740 --> 01:12:07,329
5:30 p.m. we're not

1882
01:12:07,329 --> 01:12:08,829
we're not at the night where we're not

1883
01:12:08,829 --> 01:12:10,089
in the morning with the night so we'll

1884
01:12:10,089 --> 01:12:11,530
get Pete so we'll get food but they

1885
01:12:11,530 --> 01:12:12,639
think you just show up spend 10 minutes

1886
01:12:12,639 --> 01:12:14,169
to say here's what we've actually done

1887
01:12:14,169 --> 01:12:15,820
and in previous years a few I'm given

1888
01:12:15,820 --> 01:12:17,589
demos if you can do a demo for the

1889
01:12:17,589 --> 01:12:19,300
status update that's awesome - like to

1890
01:12:19,300 --> 01:12:20,530
show it like hey this thing actually

1891
01:12:20,530 --> 01:12:22,479
does do what we say it does and now we

1892
01:12:22,479 --> 01:12:23,889
actually support sequel in our system so

1893
01:12:23,889 --> 01:12:25,510
doing demos should be much easier for

1894
01:12:25,510 --> 01:12:30,999
people not project you project 3 so the

1895
01:12:30,999 --> 01:12:33,070
way it's gonna work though is it's not

1896
01:12:33,070 --> 01:12:34,149
like other classes where you can write

1897
01:12:34,149 --> 01:12:36,639
some code that's sitting in your private

1898
01:12:36,639 --> 01:12:39,760
github repo or your laptop and then no

1899
01:12:39,760 --> 01:12:42,489
one ever sees that nobody ever cares you

1900
01:12:42,489 --> 01:12:43,959
have to make sure your code actually can

1901
01:12:43,959 --> 01:12:45,939
merge into the master branch right to

1902
01:12:45,939 --> 01:12:47,859
get a final grade the reason why we do

1903
01:12:47,859 --> 01:12:50,019
this is just because one you know it

1904
01:12:50,019 --> 01:12:51,760
gives you visibility about what you're

1905
01:12:51,760 --> 01:12:53,559
doing because if you want to go get a

1906
01:12:53,559 --> 01:12:54,789
job at a database company and this one

1907
01:12:54,789 --> 01:12:55,059
honestly

1908
01:12:55,059 --> 01:12:56,530
email me say hey do you know the student

1909
01:12:56,530 --> 01:12:57,999
what do they do and I can point to your

1910
01:12:57,999 --> 01:12:59,229
project and here's the actual source

1911
01:12:59,229 --> 01:13:02,109
code so we wanted some cases we want to

1912
01:13:02,109 --> 01:13:03,699
merge some code sometimes we don't but

1913
01:13:03,699 --> 01:13:05,379
at least there's a PR that can cleanly

1914
01:13:05,379 --> 01:13:07,539
merge passes all the tests and then we

1915
01:13:07,539 --> 01:13:08,889
can point to is like the final body of

1916
01:13:08,889 --> 01:13:11,530
work okay we're not a company we're not

1917
01:13:11,530 --> 01:13:13,359
you know we're not trying to sell this

1918
01:13:13,359 --> 01:13:15,070
software but we're still trying to do

1919
01:13:15,070 --> 01:13:17,019
high quality software engineering to the

1920
01:13:17,019 --> 01:13:19,359
extent that we can in academia and I

1921
01:13:19,359 --> 01:13:22,929
think this is you know actually I had a

1922
01:13:22,929 --> 01:13:25,689
student come back he's doing an

1923
01:13:25,689 --> 01:13:26,979
internship at a dangerous company now

1924
01:13:26,979 --> 01:13:30,909
and was surprised at how messy the

1925
01:13:30,909 --> 01:13:32,260
commercial source code they were looking

1926
01:13:32,260 --> 01:13:35,109
at versus versus our source code and so

1927
01:13:35,109 --> 01:13:36,849
I like to think that like you know going

1928
01:13:36,849 --> 01:13:38,260
through this process you get at least

1929
01:13:38,260 --> 01:13:39,909
you know appreciate what is it what does

1930
01:13:39,909 --> 01:13:41,800
it take to actually write you know clean

1931
01:13:41,800 --> 01:13:43,239
and reasonable source code so it has

1932
01:13:43,239 --> 01:13:44,530
emergent it's a mess branch and they

1933
01:13:44,530 --> 01:13:45,999
have that you know we do all the clang

1934
01:13:45,999 --> 01:13:47,739
tidy clang format and the doxygen checks

1935
01:13:47,739 --> 01:13:49,989
as well now the tricky thing is gonna be

1936
01:13:49,989 --> 01:13:51,219
of course if there's conflicts between

1937
01:13:51,219 --> 01:13:52,599
different groups so they modify the same

1938
01:13:52,599 --> 01:13:55,839
file how we determine if we're going to

1939
01:13:55,839 --> 01:13:57,309
merge things who gets to merge first

1940
01:13:57,309 --> 01:13:59,679
this one want to do at random or we're

1941
01:13:59,679 --> 01:14:01,599
taking our case-by-case basis our

1942
01:14:01,599 --> 01:14:03,339
success rate has been about 50% so 50%

1943
01:14:03,339 --> 01:14:04,989
of the student projects in previous

1944
01:14:04,989 --> 01:14:06,719
years have merged into the master branch

1945
01:14:06,719 --> 01:14:11,199
okay well in terms of resources again

1946
01:14:11,199 --> 01:14:14,019
we'll get you more credits for Amazon if

1947
01:14:14,019 --> 01:14:16,659
you submit a PR to our main repo battle

1948
01:14:16,659 --> 01:14:18,339
fire off builds and Travis and Jenkins

1949
01:14:18,339 --> 01:14:19,809
we're probably gonna drop Travis because

1950
01:14:19,809 --> 01:14:20,719
we're running the

1951
01:14:20,719 --> 01:14:23,060
taking too long but the Jenkins one will

1952
01:14:23,060 --> 01:14:26,540
cover like you know OSX and Ubuntu um if

1953
01:14:26,540 --> 01:14:27,860
you think you need special hardware

1954
01:14:27,860 --> 01:14:29,600
which I think this year there shouldn't

1955
01:14:29,600 --> 01:14:32,000
be anything let me know and we can see

1956
01:14:32,000 --> 01:14:34,940
what we can do okay all right and yeah

1957
01:14:34,940 --> 01:14:36,440
you've already guys know this story it's

1958
01:14:36,440 --> 01:14:37,850
a work in progress bunch of things

1959
01:14:37,850 --> 01:14:39,410
aren't gonna work some things are made

1960
01:14:39,410 --> 01:14:41,180
me broken but we'll fix it as we go

1961
01:14:41,180 --> 01:14:43,070
along all right let's see what potential

1962
01:14:43,070 --> 01:14:46,400
topics so let's go there's a bunch of

1963
01:14:46,400 --> 01:14:47,840
these let's go but want one me one so

1964
01:14:47,840 --> 01:14:49,610
the first one is for a query the query

1965
01:14:49,610 --> 01:14:51,739
optimizer so we have a full Cascades

1966
01:14:51,739 --> 01:14:54,020
query optimizer you'll learn with the

1967
01:14:54,020 --> 01:14:55,580
Cascades actually means and a few more

1968
01:14:55,580 --> 01:14:57,830
lectures so this project would actually

1969
01:14:57,830 --> 01:14:58,850
working on the internals of the

1970
01:14:58,850 --> 01:15:02,390
optimizer to add support for more

1971
01:15:02,390 --> 01:15:04,100
complex queries more complex

1972
01:15:04,100 --> 01:15:06,170
transformations things like outer joins

1973
01:15:06,170 --> 01:15:08,630
which I think we this might be fixed but

1974
01:15:08,630 --> 01:15:10,160
nested queries we need to potentially

1975
01:15:10,160 --> 01:15:12,530
improve our cost model actually be defi

1976
01:15:12,530 --> 01:15:13,699
we know we need to improve our cost

1977
01:15:13,699 --> 01:15:15,890
model for how we can determine whether

1978
01:15:15,890 --> 01:15:18,350
one plan is better than another but I

1979
01:15:18,350 --> 01:15:19,730
would say like I can go more details

1980
01:15:19,730 --> 01:15:21,140
later on about what kind of things you

1981
01:15:21,140 --> 01:15:24,080
could do with this but if you do work on

1982
01:15:24,080 --> 01:15:26,390
the query optimizer then you have to the

1983
01:15:26,390 --> 01:15:28,160
very first thing you have to do is also

1984
01:15:28,160 --> 01:15:30,880
send me your CV because a resume because

1985
01:15:30,880 --> 01:15:33,469
this is the one thing all the database

1986
01:15:33,469 --> 01:15:35,180
companies want to hire you saw if you

1987
01:15:35,180 --> 01:15:36,590
were an intro class last year or last

1988
01:15:36,590 --> 01:15:38,810
semester the guy from Oracle came and

1989
01:15:38,810 --> 01:15:39,920
he's like yeah we don't JavaScript

1990
01:15:39,920 --> 01:15:41,150
programmers we went from one query

1991
01:15:41,150 --> 01:15:43,040
optimizer people alright and I also get

1992
01:15:43,040 --> 01:15:44,660
emails like this like this is from a

1993
01:15:44,660 --> 01:15:46,550
pretty famous database person at a day

1994
01:15:46,550 --> 01:15:48,890
startup and he's like emailing a bunch

1995
01:15:48,890 --> 01:15:50,120
of people and I was on the list although

1996
01:15:50,120 --> 01:15:51,260
I'm not a senior database person

1997
01:15:51,260 --> 01:15:52,699
whatever but he's like hey does anybody

1998
01:15:52,699 --> 01:15:54,199
know there's like any loose query

1999
01:15:54,199 --> 01:15:56,390
optimizer people we could hire and

2000
01:15:56,390 --> 01:15:57,350
because they're super hard because like

2001
01:15:57,350 --> 01:15:58,610
query optimization was a big thing in

2002
01:15:58,610 --> 01:16:00,710
the 80s and 90s and it's like these old

2003
01:16:00,710 --> 01:16:02,270
white dudes that are you know that like

2004
01:16:02,270 --> 01:16:04,940
you know not very likely to leave leave

2005
01:16:04,940 --> 01:16:08,060
companies and go join startups so people

2006
01:16:08,060 --> 01:16:09,890
cannot hire these these places fast

2007
01:16:09,890 --> 01:16:11,690
enough and like all the nocebo database

2008
01:16:11,690 --> 01:16:12,620
companies that were like oh we don't

2009
01:16:12,620 --> 01:16:13,790
need a query optimizer we're just gonna

2010
01:16:13,790 --> 01:16:15,830
do you know get them sets and JSON like

2011
01:16:15,830 --> 01:16:17,930
they then soon realized oh we do need a

2012
01:16:17,930 --> 01:16:18,890
query optimization

2013
01:16:18,890 --> 01:16:20,469
query optimizer and so people are

2014
01:16:20,469 --> 01:16:23,150
struggling to find them so again this

2015
01:16:23,150 --> 01:16:25,160
guy was a bit more vulgar with his

2016
01:16:25,160 --> 01:16:26,960
request but same thing he wanted to hire

2017
01:16:26,960 --> 01:16:30,670
people to do to find query optimizer

2018
01:16:30,670 --> 01:16:32,540
query ah people can work at the quarry

2019
01:16:32,540 --> 01:16:34,400
optimizer related this for the cost

2020
01:16:34,400 --> 01:16:35,900
we don't have any good way to maintain

2021
01:16:35,900 --> 01:16:39,680
statistics information about what the

2022
01:16:39,680 --> 01:16:41,150
data looks like so then we can feed that

2023
01:16:41,150 --> 01:16:42,560
into our cost model to make estimations

2024
01:16:42,560 --> 01:16:45,050
of the quality of a query so we would

2025
01:16:45,050 --> 01:16:47,420
need a way to collect statistics about

2026
01:16:47,420 --> 01:16:49,550
that we didn't feed into the system we

2027
01:16:49,550 --> 01:16:51,110
could also do sampling which is another

2028
01:16:51,110 --> 01:16:53,060
technique that Microsoft uses where you

2029
01:16:53,060 --> 01:16:54,890
just make a small little mini table and

2030
01:16:54,890 --> 01:16:56,570
copy something data in and then do your

2031
01:16:56,570 --> 01:16:59,330
estimations based on that if that's this

2032
01:16:59,330 --> 01:17:01,850
then also been used for a new cost model

2033
01:17:01,850 --> 01:17:02,630
that we can hook it to the quarry

2034
01:17:02,630 --> 01:17:04,810
optimizer that would be amazing as well

2035
01:17:04,810 --> 01:17:06,860
if you're more interested in sort of

2036
01:17:06,860 --> 01:17:09,740
like like how do you actually queries we

2037
01:17:09,740 --> 01:17:11,330
want to support common table expressions

2038
01:17:11,330 --> 01:17:14,360
so right now again we support TPC HT PCH

2039
01:17:14,360 --> 01:17:16,430
is from the 90s it doesn't have CT es is

2040
01:17:16,430 --> 01:17:19,940
pretty straightforward CPC des is a more

2041
01:17:19,940 --> 01:17:25,370
complex to sit the DSN sort decision

2042
01:17:25,370 --> 01:17:27,530
support say more complex OLAP workload

2043
01:17:27,530 --> 01:17:29,390
analytical work on the NT PCH and this

2044
01:17:29,390 --> 01:17:30,830
has a bunch of CT ease but we don't

2045
01:17:30,830 --> 01:17:32,480
support any of that so this would be

2046
01:17:32,480 --> 01:17:34,340
modifying our parser extending the

2047
01:17:34,340 --> 01:17:35,690
parser to support the width and union

2048
01:17:35,690 --> 01:17:39,110
clauses modify the optimizer to reason

2049
01:17:39,110 --> 01:17:43,730
about you know the the wif clause and

2050
01:17:43,730 --> 01:17:45,590
potentially rewriting that to joins in

2051
01:17:45,590 --> 01:17:48,290
some cases and then I don't know whether

2052
01:17:48,290 --> 01:17:49,490
it's true or not but you may have to

2053
01:17:49,490 --> 01:17:51,650
also modify the execution engine to

2054
01:17:51,650 --> 01:17:53,090
actually support CTS depending on how

2055
01:17:53,090 --> 01:17:54,260
what the queries actually looked like

2056
01:17:54,260 --> 01:17:56,960
and I will fully admit I don't know full

2057
01:17:56,960 --> 01:17:59,420
I don't know all the ways you can unroll

2058
01:17:59,420 --> 01:18:03,080
or D correlate or rewrite CT es there's

2059
01:18:03,080 --> 01:18:05,390
a there's a actually a really good

2060
01:18:05,390 --> 01:18:08,360
textbook from not the hyper guide in

2061
01:18:08,360 --> 01:18:10,610
Germany but his other German adviser so

2062
01:18:10,610 --> 01:18:11,900
another German wrote a book about query

2063
01:18:11,900 --> 01:18:13,520
optimizers then we have access to that

2064
01:18:13,520 --> 01:18:14,600
describe all the various techniques for

2065
01:18:14,600 --> 01:18:16,010
this so this is something we could do as

2066
01:18:16,010 --> 01:18:19,010
well we also use a port for add/drop

2067
01:18:19,010 --> 01:18:21,710
indexes so right now we can call create

2068
01:18:21,710 --> 01:18:23,390
index when you create the table and then

2069
01:18:23,390 --> 01:18:24,890
as you insert tuples into a table we

2070
01:18:24,890 --> 01:18:26,750
will populate it but if the table

2071
01:18:26,750 --> 01:18:28,130
already exists with a bunch of data in

2072
01:18:28,130 --> 01:18:30,020
it and you call create an index it can't

2073
01:18:30,020 --> 01:18:32,060
go back and populate it easiest way to

2074
01:18:32,060 --> 01:18:34,190
do that as you pause the execution of

2075
01:18:34,190 --> 01:18:36,710
all transactions do they then populate

2076
01:18:36,710 --> 01:18:38,330
it and then turn transactions back on

2077
01:18:38,330 --> 01:18:40,310
but obviously that that's bad because

2078
01:18:40,310 --> 01:18:42,230
you're blocking everything so being able

2079
01:18:42,230 --> 01:18:46,850
to do to build the index while you still

2080
01:18:46,850 --> 01:18:47,989
up cake up the up

2081
01:18:47,989 --> 01:18:51,019
the tables is super interesting a bunch

2082
01:18:51,019 --> 01:18:52,789
of systems are just adding like PostGIS

2083
01:18:52,789 --> 01:18:54,639
just add this in the last couple years

2084
01:18:54,639 --> 01:18:58,010
so this would be really awesome to do be

2085
01:18:58,010 --> 01:18:59,449
awesome to do this also with parallel

2086
01:18:59,449 --> 01:19:00,679
threads think of this as doing the

2087
01:19:00,679 --> 01:19:02,659
sequential scan with multiple threads

2088
01:19:02,659 --> 01:19:05,320
and they're all inserting into the index

2089
01:19:05,320 --> 01:19:07,429
related this would be multiple T

2090
01:19:07,429 --> 01:19:10,999
threaded queries the current the current

2091
01:19:10,999 --> 01:19:12,260
version we have that you guys working on

2092
01:19:12,260 --> 01:19:15,860
and the system only supports single

2093
01:19:15,860 --> 01:19:18,530
threaded queries but there is my PhD

2094
01:19:18,530 --> 01:19:19,699
student per shot has a branch that

2095
01:19:19,699 --> 01:19:22,039
supports parallel queries but hey he

2096
01:19:22,039 --> 01:19:23,570
only has the only heads over the

2097
01:19:23,570 --> 01:19:25,340
execution engine side of things if the

2098
01:19:25,340 --> 01:19:27,260
idea would be porting over his parallel

2099
01:19:27,260 --> 01:19:29,449
query implementation but then been

2100
01:19:29,449 --> 01:19:31,070
modifying the rest of the infrastructure

2101
01:19:31,070 --> 01:19:32,989
of the system to recognize oh I can run

2102
01:19:32,989 --> 01:19:34,820
queries in parallel make sure that you

2103
01:19:34,820 --> 01:19:36,769
know plan your plans come out the right

2104
01:19:36,769 --> 01:19:38,809
way so they can be paralyzed we could

2105
01:19:38,809 --> 01:19:40,369
also start adding support for like the

2106
01:19:40,369 --> 01:19:41,300
pneuma where of data placement

2107
01:19:41,300 --> 01:19:43,909
techniques that the hyper guys are doing

2108
01:19:43,909 --> 01:19:46,929
with morsels once we get to the basic

2109
01:19:46,929 --> 01:19:49,639
the basic that in parallel engine

2110
01:19:49,639 --> 01:19:52,699
working prepared statements are also

2111
01:19:52,699 --> 01:19:55,039
super important we currently don't

2112
01:19:55,039 --> 01:19:56,749
support this so again prepared statement

2113
01:19:56,749 --> 01:19:58,400
is a pair of statement it says I'm gonna

2114
01:19:58,400 --> 01:20:00,380
cue this query over never again here's

2115
01:20:00,380 --> 01:20:02,360
some placeholders for some parameters so

2116
01:20:02,360 --> 01:20:03,949
you need to like cache that and then you

2117
01:20:03,949 --> 01:20:06,139
can invoke it and and and and we use the

2118
01:20:06,139 --> 01:20:07,639
plan over and over again so there's a

2119
01:20:07,639 --> 01:20:09,139
bunch of different design decisions you

2120
01:20:09,139 --> 01:20:12,380
have to consider to when you want to do

2121
01:20:12,380 --> 01:20:13,999
prepared statements like when you

2122
01:20:13,999 --> 01:20:15,079
actually run it through the optimizer

2123
01:20:15,079 --> 01:20:16,429
when you actually decide to replan

2124
01:20:16,429 --> 01:20:18,349
things all the various data systems do

2125
01:20:18,349 --> 01:20:20,210
different things and this would be sort

2126
01:20:20,210 --> 01:20:21,679
of an evaluation of the different

2127
01:20:21,679 --> 01:20:23,360
techniques so you'd have to modify the

2128
01:20:23,360 --> 01:20:26,780
the wire protocol to handle this and

2129
01:20:26,780 --> 01:20:28,670
then make sure and we actually would be

2130
01:20:28,670 --> 01:20:31,070
super awesome to is if instead of having

2131
01:20:31,070 --> 01:20:32,869
a prepared statement cache and then a

2132
01:20:32,869 --> 01:20:34,670
compiled query cache if we can unify

2133
01:20:34,670 --> 01:20:35,989
them all together that would be a big

2134
01:20:35,989 --> 01:20:37,849
win so my PhD student matt is actually

2135
01:20:37,849 --> 01:20:38,989
looking into this now so if we

2136
01:20:38,989 --> 01:20:41,599
interested in pursuing this you know let

2137
01:20:41,599 --> 01:20:43,699
me know we can start talking next week

2138
01:20:43,699 --> 01:20:46,579
or this week we compare these support

2139
01:20:46,579 --> 01:20:47,780
the write out log which I think we can

2140
01:20:47,780 --> 01:20:51,050
replay the log upon restart this is not

2141
01:20:51,050 --> 01:20:52,219
true I think we can reuse to all the

2142
01:20:52,219 --> 01:20:54,139
catalogs but as I said you want to also

2143
01:20:54,139 --> 01:20:55,369
be able to take checkpoints we don't the

2144
01:20:55,369 --> 01:20:57,320
replay the entire log so this would be

2145
01:20:57,320 --> 01:21:01,730
added support to do checkpoints so the

2146
01:21:01,730 --> 01:21:03,350
I think the simplest way to do this

2147
01:21:03,350 --> 01:21:04,340
would be the snapshot isolation

2148
01:21:04,340 --> 01:21:07,160
possession checkpoint and you just pick

2149
01:21:07,160 --> 01:21:08,270
you back up with this Winchell scan

2150
01:21:08,270 --> 01:21:09,440
implementation that's available in the

2151
01:21:09,440 --> 01:21:11,480
day system now and again this nagra's

2152
01:21:11,480 --> 01:21:13,850
here to see an example where if you can

2153
01:21:13,850 --> 01:21:15,380
work in tandem with another team if

2154
01:21:15,380 --> 01:21:16,820
another team is doing parallel queries

2155
01:21:16,820 --> 01:21:18,620
and they support a parallel scruncho

2156
01:21:18,620 --> 01:21:21,050
scans you could then support that in

2157
01:21:21,050 --> 01:21:23,270
your checkpoint algorithm and now do

2158
01:21:23,270 --> 01:21:25,700
special scans and parallel to write the

2159
01:21:25,700 --> 01:21:27,890
checkpoint out and then we want to be

2160
01:21:27,890 --> 01:21:29,780
able to load the checkpoint in after we

2161
01:21:29,780 --> 01:21:31,460
start then replay the log all right so

2162
01:21:31,460 --> 01:21:32,750
it sounds I take a checkpoint I'm done

2163
01:21:32,750 --> 01:21:34,489
integrating the full sentiment this is

2164
01:21:34,489 --> 01:21:37,150
tricky we want to support constraints

2165
01:21:37,150 --> 01:21:41,300
like the Czech uniqueness foreign keys

2166
01:21:41,300 --> 01:21:44,270
and so this is this is modifying the

2167
01:21:44,270 --> 01:21:48,380
catalogue modifying the the modifying

2168
01:21:48,380 --> 01:21:49,580
like that the front of the system David

2169
01:21:49,580 --> 01:21:51,320
hand this information modifying the

2170
01:21:51,320 --> 01:21:53,090
stores are the excuse change to enforce

2171
01:21:53,090 --> 01:21:55,760
these constraints so if I have a check

2172
01:21:55,760 --> 01:21:57,530
clause that says like where value is not

2173
01:21:57,530 --> 01:21:59,840
you know not negative I have to know

2174
01:21:59,840 --> 01:22:00,980
that when I'm inserting something I

2175
01:22:00,980 --> 01:22:02,300
complied that predicate and see whether

2176
01:22:02,300 --> 01:22:04,150
that was true or not

2177
01:22:04,150 --> 01:22:07,460
same thing with foreign keys to

2178
01:22:07,460 --> 01:22:09,080
additional things you could do is do

2179
01:22:09,080 --> 01:22:10,930
online constraint changes with alter

2180
01:22:10,930 --> 01:22:12,860
mean if I add a constraint that says

2181
01:22:12,860 --> 01:22:14,630
this key can't be null I've to scan

2182
01:22:14,630 --> 01:22:15,770
through and make sure nothing is null

2183
01:22:15,770 --> 01:22:17,180
because therefore I would you know if I

2184
01:22:17,180 --> 01:22:17,989
try to plug your sharing that would

2185
01:22:17,989 --> 01:22:19,160
already be violated at the beginning

2186
01:22:19,160 --> 01:22:21,950
that's bad another cool thing to

2187
01:22:21,950 --> 01:22:24,020
actually be able to do is extend the

2188
01:22:24,020 --> 01:22:26,570
query optimizer to be aware of some of

2189
01:22:26,570 --> 01:22:28,610
these constraints like I know that

2190
01:22:28,610 --> 01:22:29,989
something can't be negative so therefore

2191
01:22:29,989 --> 01:22:31,610
I may want to change how I do my join or

2192
01:22:31,610 --> 01:22:34,400
do a scan alright that's the high end

2193
01:22:34,400 --> 01:22:35,960
systems that can do this that would

2194
01:22:35,960 --> 01:22:38,540
actually be super cool sequences are the

2195
01:22:38,540 --> 01:22:40,400
auto increment keys so this would be

2196
01:22:40,400 --> 01:22:41,960
added support that we can store

2197
01:22:41,960 --> 01:22:44,870
sequences in the catalog and supply

2198
01:22:44,870 --> 01:22:46,700
support the next valve function or the

2199
01:22:46,700 --> 01:22:48,500
serial type so that we can do easily do

2200
01:22:48,500 --> 01:22:51,080
auto increment keys this one is a bit

2201
01:22:51,080 --> 01:22:53,840
more tricky because when you caching in

2202
01:22:53,840 --> 01:22:55,970
the catalog so that everybody everybody

2203
01:22:55,970 --> 01:22:57,230
everybody calling next valve doesn't

2204
01:22:57,230 --> 01:22:58,820
always update the catalog you could have

2205
01:22:58,820 --> 01:22:59,840
something sitting around in memory that

2206
01:22:59,840 --> 01:23:01,940
you hand out in batches

2207
01:23:01,940 --> 01:23:03,560
the tricky thing though is you have to

2208
01:23:03,560 --> 01:23:05,360
then alright out in the right ahead log

2209
01:23:05,360 --> 01:23:07,820
how that that value got incremented so

2210
01:23:07,820 --> 01:23:09,290
if I crash come back the counter doesn't

2211
01:23:09,290 --> 01:23:11,450
start at zero again I don't I don't have

2212
01:23:11,450 --> 01:23:14,390
duplicate values different types are be

2213
01:23:14,390 --> 01:23:15,649
interesting to do as well

2214
01:23:15,649 --> 01:23:17,329
so we talked about how the numeric type

2215
01:23:17,329 --> 01:23:18,889
from the Germans they claim is faster

2216
01:23:18,889 --> 01:23:21,619
than the floating-point numbers and then

2217
01:23:21,619 --> 01:23:22,760
they claim that there's this book called

2218
01:23:22,760 --> 01:23:25,039
hackers delight which is Google you can

2219
01:23:25,039 --> 01:23:29,510
find that describes the the sort of the

2220
01:23:29,510 --> 01:23:32,389
underlying method for doing low little

2221
01:23:32,389 --> 01:23:34,369
bit operations on fixed point decimals

2222
01:23:34,369 --> 01:23:36,050
it doesn't describe exactly how to do in

2223
01:23:36,050 --> 01:23:37,340
the concept of a database like there's

2224
01:23:37,340 --> 01:23:39,169
much other stuff we have to do but the

2225
01:23:39,169 --> 01:23:41,929
bit manipulation techniques can be found

2226
01:23:41,929 --> 01:23:42,439
in this book

2227
01:23:42,439 --> 01:23:44,149
so I'm actually super interested this as

2228
01:23:44,149 --> 01:23:45,860
well I don't know how to do it but we

2229
01:23:45,860 --> 01:23:48,169
could sit down and learn it together if

2230
01:23:48,169 --> 01:23:49,909
you're injured in types I want to do

2231
01:23:49,909 --> 01:23:51,829
something more easy enum type would be

2232
01:23:51,829 --> 01:23:53,570
another one you could do and this is

2233
01:23:53,570 --> 01:23:55,489
just like enum you have in C++ or Java

2234
01:23:55,489 --> 01:23:58,639
same thing in the idea what you have to

2235
01:23:58,639 --> 01:24:00,289
do is that you would support the at the

2236
01:24:00,289 --> 01:24:01,879
cattle will keep track all the enums as

2237
01:24:01,879 --> 01:24:03,829
the array modifying the binder to be

2238
01:24:03,829 --> 01:24:05,300
able to enforce those enum constraints

2239
01:24:05,300 --> 01:24:06,590
so someone gives us a value that doesn't

2240
01:24:06,590 --> 01:24:08,570
exist you know we throw an error and

2241
01:24:08,570 --> 01:24:10,189
then we have to be able to support this

2242
01:24:10,189 --> 01:24:13,159
in the execution engine to know that I'm

2243
01:24:13,159 --> 01:24:14,689
operating on an enum and then

2244
01:24:14,689 --> 01:24:15,949
materialize the correct value of when it

2245
01:24:15,949 --> 01:24:17,449
produces the result to to the

2246
01:24:17,449 --> 01:24:21,079
application I'm gonna do this quickly

2247
01:24:21,079 --> 01:24:22,789
but you know all the slides are online I

2248
01:24:22,789 --> 01:24:23,989
don't have to talk about about this

2249
01:24:23,989 --> 01:24:26,929
afterwards so we haven't any talk about

2250
01:24:26,929 --> 01:24:28,070
views but I think of them as like a

2251
01:24:28,070 --> 01:24:29,929
virtual table like an define a view on a

2252
01:24:29,929 --> 01:24:32,059
select query and I give it a name and it

2253
01:24:32,059 --> 01:24:33,709
looks like a table then now I can run a

2254
01:24:33,709 --> 01:24:36,469
query on that view and treat it as if it

2255
01:24:36,469 --> 01:24:38,629
was a table and typically the way it is

2256
01:24:38,629 --> 01:24:40,789
the data some handles this is that it'll

2257
01:24:40,789 --> 01:24:44,749
rewrite your query into the the to be

2258
01:24:44,749 --> 01:24:47,059
doing a look-up on on the actual

2259
01:24:47,059 --> 01:24:51,110
underlying you know view query so we'd

2260
01:24:51,110 --> 01:24:52,489
have to support the extend the catalog

2261
01:24:52,489 --> 01:24:54,349
to put these things we have to modify

2262
01:24:54,349 --> 01:24:56,510
the binder to transform the view into

2263
01:24:56,510 --> 01:24:58,879
the original query and as far as you

2264
01:24:58,879 --> 01:24:59,989
know I don't think we're have to modify

2265
01:24:59,989 --> 01:25:01,369
this you stream engine you can rewrite

2266
01:25:01,369 --> 01:25:02,869
the views as a nested query and I think

2267
01:25:02,869 --> 01:25:05,179
just work and then the optimizer can

2268
01:25:05,179 --> 01:25:07,039
just you know D correlate or optimize as

2269
01:25:07,039 --> 01:25:08,169
necessary

2270
01:25:08,169 --> 01:25:10,669
alright last two concurrent schema

2271
01:25:10,669 --> 01:25:13,489
changes would be if I add a drop a

2272
01:25:13,489 --> 01:25:15,439
column can I do that without having to

2273
01:25:15,439 --> 01:25:17,059
lock everything this is actually super

2274
01:25:17,059 --> 01:25:18,709
tricky this is the the second year we've

2275
01:25:18,709 --> 01:25:20,239
tried this we have we think now we have

2276
01:25:20,239 --> 01:25:21,949
the infrastructure to be able to do this

2277
01:25:21,949 --> 01:25:24,530
in a very interesting way because now we

2278
01:25:24,530 --> 01:25:26,629
can do like this lazy method where you

2279
01:25:26,629 --> 01:25:29,150
say at a column we tell you we added

2280
01:25:29,150 --> 01:25:30,949
but we don't actually go through it and

2281
01:25:30,949 --> 01:25:34,370
and you know shuffled at around to add

2282
01:25:34,370 --> 01:25:36,590
that that memory location it's only when

2283
01:25:36,590 --> 01:25:38,060
you insert new things or you try to read

2284
01:25:38,060 --> 01:25:39,590
back old stuff then we can materialize

2285
01:25:39,590 --> 01:25:40,600
it on the fly

2286
01:25:40,600 --> 01:25:44,150
the last one is data compression so we

2287
01:25:44,150 --> 01:25:46,820
support Apache arrow and we have support

2288
01:25:46,820 --> 01:25:48,050
for the their dictionary compression

2289
01:25:48,050 --> 01:25:49,730
scheme which is very straightforward but

2290
01:25:49,730 --> 01:25:52,520
it's not turned on meaning we can't take

2291
01:25:52,520 --> 01:25:53,929
hot data and convert it into a

2292
01:25:53,929 --> 01:25:56,600
compressed cold data block we used to

2293
01:25:56,600 --> 01:25:57,860
have that infrastructure but we don't

2294
01:25:57,860 --> 01:26:00,080
anymore so this would be adding support

2295
01:26:00,080 --> 01:26:03,110
for convert doing this conversion the

2296
01:26:03,110 --> 01:26:04,040
reason why we don't have it cuz we

2297
01:26:04,040 --> 01:26:05,570
because you have to also update indexes

2298
01:26:05,570 --> 01:26:06,650
because you're moving tuples from one

2299
01:26:06,650 --> 01:26:07,429
location to another

2300
01:26:07,429 --> 01:26:09,110
but then the tricky thing is going to be

2301
01:26:09,110 --> 01:26:11,480
is now modified the execution engine in

2302
01:26:11,480 --> 01:26:13,400
some way to be able to process the

2303
01:26:13,400 --> 01:26:15,710
compressed data directly because right

2304
01:26:15,710 --> 01:26:18,230
now we can't do that we would have to

2305
01:26:18,230 --> 01:26:20,239
have the data table decompress it before

2306
01:26:20,239 --> 01:26:21,860
we can do scans on it which defeats the

2307
01:26:21,860 --> 01:26:23,600
whole purpose to compression all right

2308
01:26:23,600 --> 01:26:24,440
so how do I get started

2309
01:26:24,440 --> 01:26:26,000
form a team which is already sorted done

2310
01:26:26,000 --> 01:26:29,060
with project two you should meet your

2311
01:26:29,060 --> 01:26:30,460
team discuss your potential topics

2312
01:26:30,460 --> 01:26:32,390
potentially look over the source code or

2313
01:26:32,390 --> 01:26:34,640
contact me to sort of point you at what

2314
01:26:34,640 --> 01:26:35,600
parts of the source code you want to

2315
01:26:35,600 --> 01:26:37,940
look at I'm around all next week or send

2316
01:26:37,940 --> 01:26:39,860
me an email and have a discuss you know

2317
01:26:39,860 --> 01:26:41,120
what are some potential stoppers you can

2318
01:26:41,120 --> 01:26:43,460
look up okay all right sorry for going

2319
01:26:43,460 --> 01:26:46,219
over time next class I'll post this on

2320
01:26:46,219 --> 01:26:47,870
Piazza with more details but you have

2321
01:26:47,870 --> 01:26:49,790
your prose or presentations five minutes

2322
01:26:49,790 --> 01:26:50,989
and it's a hard limit okay

2323
01:26:50,989 --> 01:26:52,880
all right guys awesome thank you see you

2324
01:26:52,880 --> 01:26:55,400
cranked it in the side park what is this

2325
01:26:55,400 --> 01:26:57,540
some fools say you're here

2326
01:26:57,540 --> 01:26:58,810
[Music]

2327
01:26:58,810 --> 01:27:01,360
 ain't dead here called the hawk

2328
01:27:01,360 --> 01:27:04,150
it cuz I mochi ice cube down with the

2329
01:27:04,150 --> 01:27:04,840
testy

2330
01:27:04,840 --> 01:27:08,110
hi you look and it was go grab me a 40

2331
01:27:08,110 --> 01:27:10,450
just to get my buzz song cuz I need it

2332
01:27:10,450 --> 01:27:13,120
just a little more kick like a fish to

2333
01:27:13,120 --> 01:27:18,480
just one simple just drop them say nice

2334
01:27:18,480 --> 01:27:21,610
and my hood wants me to say I'm nice

2335
01:27:21,610 --> 01:27:25,590
cute take a say I celebrate

