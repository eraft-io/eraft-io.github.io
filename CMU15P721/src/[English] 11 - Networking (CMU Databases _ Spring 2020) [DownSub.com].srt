1
00:00:01,300 --> 00:00:05,129
[Music]

2
00:00:05,200 --> 00:00:05,930
[Applause]

3
00:00:05,930 --> 00:00:08,630
[Music]

4
00:00:08,630 --> 00:00:10,020
[Applause]

5
00:00:10,020 --> 00:00:11,540
[Music]

6
00:00:11,540 --> 00:00:15,599
we're starting all right today we're

7
00:00:15,599 --> 00:00:17,609
starting with networking protocols so

8
00:00:17,609 --> 00:00:20,250
we're at the point in the semester where

9
00:00:20,250 --> 00:00:21,720
I now want to do like a high-level

10
00:00:21,720 --> 00:00:25,230
overview of what we've talked about and

11
00:00:25,230 --> 00:00:27,090
what we plan on talking about it's kind

12
00:00:27,090 --> 00:00:28,080
of difficult to show this at the very

13
00:00:28,080 --> 00:00:30,869
beginning because the topics we talked

14
00:00:30,869 --> 00:00:32,399
about we're a bit scattered let's

15
00:00:32,399 --> 00:00:35,130
Kearney tall with indexes it's it's some

16
00:00:35,130 --> 00:00:37,739
storage stuff but this is sort of

17
00:00:37,739 --> 00:00:40,980
conceptual illustration of what the

18
00:00:40,980 --> 00:00:42,930
system that were sort of envisioning in

19
00:00:42,930 --> 00:00:43,920
our mind that we're talking about

20
00:00:43,920 --> 00:00:45,149
discussing the various topics that how

21
00:00:45,149 --> 00:00:47,610
to build what it looks like so this is

22
00:00:47,610 --> 00:00:50,070
our application they send a sequel query

23
00:00:50,070 --> 00:00:51,989
this is gonna land in our networking

24
00:00:51,989 --> 00:00:53,100
layer and this what we're going to talk

25
00:00:53,100 --> 00:00:55,620
about today then we hit the query

26
00:00:55,620 --> 00:00:57,780
optimizer or the planner so the reports

27
00:00:57,780 --> 00:00:59,699
the sequel bind to the catalog objects

28
00:00:59,699 --> 00:01:01,710
do any rewriting we want to do and then

29
00:01:01,710 --> 00:01:03,030
run it through our query optimizer to

30
00:01:03,030 --> 00:01:05,459
generate a physical plan then we're

31
00:01:05,459 --> 00:01:06,840
gonna pass now this through a compiler

32
00:01:06,840 --> 00:01:08,340
which won't make sense now but we'll

33
00:01:08,340 --> 00:01:09,900
talk about this in a few weeks basically

34
00:01:09,900 --> 00:01:11,369
we're gonna take of that physical plan

35
00:01:11,369 --> 00:01:13,710
and convert it into machine code instead

36
00:01:13,710 --> 00:01:15,810
of actually interpreting it then we have

37
00:01:15,810 --> 00:01:16,860
our execution engine where actually

38
00:01:16,860 --> 00:01:18,780
we'll execute the query in threads and

39
00:01:18,780 --> 00:01:20,070
then we have a storage meander down

40
00:01:20,070 --> 00:01:22,830
below so this one we've already talked

41
00:01:22,830 --> 00:01:24,570
about a bunch of stuff already this one

42
00:01:24,570 --> 00:01:25,409
we already talked a bunch of stuff

43
00:01:25,409 --> 00:01:26,939
already so these are the sort of the

44
00:01:26,939 --> 00:01:28,110
parts we've already covered we've

45
00:01:28,110 --> 00:01:29,070
covered how to do convergent role

46
00:01:29,070 --> 00:01:31,530
indexes Gorge models and logging

47
00:01:31,530 --> 00:01:34,170
checkpoints so now again today we're

48
00:01:34,170 --> 00:01:36,329
going back to the top and then going

49
00:01:36,329 --> 00:01:37,950
forward we'll sort of jump around and

50
00:01:37,950 --> 00:01:40,670
start here and then work our way back up

51
00:01:40,670 --> 00:01:42,960
this part though like for opera

52
00:01:42,960 --> 00:01:44,729
execution we'll cover this all basically

53
00:01:44,729 --> 00:01:46,049
throughout the rest of the semester like

54
00:01:46,049 --> 00:01:47,579
we'll talk about how to do parallel or

55
00:01:47,579 --> 00:01:50,540
vectorize hash joins vectorize sorting

56
00:01:50,540 --> 00:01:54,299
and the nvcc stuff sort of covers all of

57
00:01:54,299 --> 00:01:56,100
this like at least up to the planner

58
00:01:56,100 --> 00:01:57,780
like in the back of your mind to think

59
00:01:57,780 --> 00:01:59,130
about oh I'm working on multi Verte on

60
00:01:59,130 --> 00:02:00,990
multi version database what are the

61
00:02:00,990 --> 00:02:02,880
implications of that as I design my

62
00:02:02,880 --> 00:02:05,549
system alright so this is sort of out

63
00:02:05,549 --> 00:02:07,590
for the rest of the semester and then at

64
00:02:07,590 --> 00:02:09,030
the very end the last two lectures would

65
00:02:09,030 --> 00:02:10,860
be like the potpourri things we have a

66
00:02:10,860 --> 00:02:12,720
new hardware or doing applying machine

67
00:02:12,720 --> 00:02:13,300
learning method

68
00:02:13,300 --> 00:02:18,100
to the stack okay so as I said today

69
00:02:18,100 --> 00:02:19,150
we're gonna talk about the networking

70
00:02:19,150 --> 00:02:21,970
protocol and this is either the data

71
00:02:21,970 --> 00:02:23,650
coming into the database from the client

72
00:02:23,650 --> 00:02:26,410
or how we send data out to our replicas

73
00:02:26,410 --> 00:02:28,900
for high availability but the paper how

74
00:02:28,900 --> 00:02:30,880
do you guys read was all about ingesting

75
00:02:30,880 --> 00:02:32,980
Gator and taking queries in and getting

76
00:02:32,980 --> 00:02:35,950
data out so let's talk about basically

77
00:02:35,950 --> 00:02:37,330
how you would write in your application

78
00:02:37,330 --> 00:02:40,330
the different methods for accessing the

79
00:02:40,330 --> 00:02:41,950
database and running queries then we'll

80
00:02:41,950 --> 00:02:44,080
talk about what the actual never wider

81
00:02:44,080 --> 00:02:45,340
protocol looks like that you're sending

82
00:02:45,340 --> 00:02:46,870
back responses over the network

83
00:02:46,870 --> 00:02:48,580
then we'll briefly talk about the

84
00:02:48,580 --> 00:02:49,900
different replication protocols that are

85
00:02:49,900 --> 00:02:51,220
out there what are the sort of setup you

86
00:02:51,220 --> 00:02:53,140
can have and then we'll finish up with

87
00:02:53,140 --> 00:02:56,470
sort of a two different techniques to

88
00:02:56,470 --> 00:02:58,120
bypass the operating system as much as

89
00:02:58,120 --> 00:03:00,460
possible called kernel bypass methods so

90
00:03:00,460 --> 00:03:02,410
for all these consumer going over the TC

91
00:03:02,410 --> 00:03:05,020
IP stack and for simplicity we're just

92
00:03:05,020 --> 00:03:06,580
assume we're going through the OS this

93
00:03:06,580 --> 00:03:09,130
is a way to work around that and then

94
00:03:09,130 --> 00:03:10,270
we'll finish off briefly talking about

95
00:03:10,270 --> 00:03:14,440
what's expected for a project - okay all

96
00:03:14,440 --> 00:03:14,680
right

97
00:03:14,680 --> 00:03:19,600
so up until now all the demos that I've

98
00:03:19,600 --> 00:03:22,450
given in class about you know using

99
00:03:22,450 --> 00:03:25,060
Postgres or interruption class we showed

100
00:03:25,060 --> 00:03:27,160
my sequel we showed Oracle all of those

101
00:03:27,160 --> 00:03:29,920
were opening up the terminal over SSH

102
00:03:29,920 --> 00:03:31,840
me typing in some queries hitting Enter

103
00:03:31,840 --> 00:03:34,840
and then getting back a text response so

104
00:03:34,840 --> 00:03:37,150
in a real application that's not how it

105
00:03:37,150 --> 00:03:39,730
actually works because what I'm getting

106
00:03:39,730 --> 00:03:41,920
back is showing the terminal is is like

107
00:03:41,920 --> 00:03:46,870
is text it's it's characters and so if I

108
00:03:46,870 --> 00:03:48,489
was writing an application where I would

109
00:03:48,489 --> 00:03:50,590
go through the terminal like that I

110
00:03:50,590 --> 00:03:52,209
basically have to now parse the text

111
00:03:52,209 --> 00:03:54,220
field extract out what the values I'm

112
00:03:54,220 --> 00:03:55,360
looking for and convert them to the

113
00:03:55,360 --> 00:03:56,890
right type of my avocation and that

114
00:03:56,890 --> 00:03:59,410
would be super slow and nobody would

115
00:03:59,410 --> 00:04:02,800
actually ever do that right so what

116
00:04:02,800 --> 00:04:04,480
we're really gonna do in a real program

117
00:04:04,480 --> 00:04:08,260
is that we're gonna have a an API that a

118
00:04:08,260 --> 00:04:09,880
programming interface that we can then

119
00:04:09,880 --> 00:04:11,620
write queries against on our database

120
00:04:11,620 --> 00:04:14,380
and then what we're exposed to in our

121
00:04:14,380 --> 00:04:17,829
application is is binary values for the

122
00:04:17,829 --> 00:04:19,630
most part if it's you for getting back

123
00:04:19,630 --> 00:04:23,110
JSON then not always but like in real

124
00:04:23,110 --> 00:04:25,000
applications or if you really cut out

125
00:04:25,000 --> 00:04:26,080
performance then you want to get binary

126
00:04:26,080 --> 00:04:27,080
dated back to application

127
00:04:27,080 --> 00:04:28,460
then you don't have to do any of that

128
00:04:28,460 --> 00:04:30,379
conversion yourself in your application

129
00:04:30,379 --> 00:04:31,849
like oh I know I'm looking at an integer

130
00:04:31,849 --> 00:04:33,259
but I have a string representation of

131
00:04:33,259 --> 00:04:36,500
that integer let me now convert it to to

132
00:04:36,500 --> 00:04:36,889
an end

133
00:04:36,889 --> 00:04:39,560
so all these the API is the way to get

134
00:04:39,560 --> 00:04:41,629
best performances to go through certain

135
00:04:41,629 --> 00:04:44,990
standard programming interfaces so well

136
00:04:44,990 --> 00:04:46,939
first talk about direct access these are

137
00:04:46,939 --> 00:04:50,180
going to be a papaya type api's or

138
00:04:50,180 --> 00:04:51,830
libraries that each database vendor

139
00:04:51,830 --> 00:04:53,810
could provide and then we'll talk about

140
00:04:53,810 --> 00:04:56,810
ways to actually now have a more generic

141
00:04:56,810 --> 00:04:59,659
or generalized access methods or api's

142
00:04:59,659 --> 00:05:02,599
that potentially would not have the

143
00:05:02,599 --> 00:05:04,190
requires to rewrite our application to

144
00:05:04,190 --> 00:05:06,050
use if we switch woman one day to this

145
00:05:06,050 --> 00:05:07,430
vendor to another we may have to change

146
00:05:07,430 --> 00:05:10,159
the sequel query dialect but if we

147
00:05:10,159 --> 00:05:11,330
program against these things then this

148
00:05:11,330 --> 00:05:18,169
will be standardized okay where was I

149
00:05:18,169 --> 00:05:21,680
started right again the idea of these

150
00:05:21,680 --> 00:05:23,900
guys is that if I read my application

151
00:05:23,900 --> 00:05:27,590
using either ODBC or JDBC then if I'm

152
00:05:27,590 --> 00:05:29,449
using my sequel today that I side to

153
00:05:29,449 --> 00:05:31,310
give IBM money and I'll switch to my

154
00:05:31,310 --> 00:05:33,560
application over at db2 I don't have to

155
00:05:33,560 --> 00:05:35,419
rewrite any my application code because

156
00:05:35,419 --> 00:05:38,539
these things are the API for that you

157
00:05:38,539 --> 00:05:41,389
would use for my sequel and and and db2

158
00:05:41,389 --> 00:05:43,129
would be standardized on these things I

159
00:05:43,129 --> 00:05:45,620
can sequel my head change but like the

160
00:05:45,620 --> 00:05:50,979
actual code itself won't change so the

161
00:05:50,979 --> 00:05:52,969
actually just go back real quickly this

162
00:05:52,969 --> 00:05:53,900
one we're not gonna talk about too much

163
00:05:53,900 --> 00:05:54,770
there's nothing for there to say about

164
00:05:54,770 --> 00:05:58,490
this other than like okay like everybody

165
00:05:58,490 --> 00:06:00,560
has their own thing and ideally should

166
00:06:00,560 --> 00:06:02,900
not programming us these api's right you

167
00:06:02,900 --> 00:06:04,759
should always have either like a some

168
00:06:04,759 --> 00:06:06,319
kind of one of these things in front of

169
00:06:06,319 --> 00:06:07,789
it so that so that you make your thing

170
00:06:07,789 --> 00:06:09,349
more portable and some applications like

171
00:06:09,349 --> 00:06:10,550
if you know you're gonna be running on a

172
00:06:10,550 --> 00:06:12,259
phone you're only gonna be you know

173
00:06:12,259 --> 00:06:15,500
executing a sequel light you could

174
00:06:15,500 --> 00:06:16,759
program it that way but even then like

175
00:06:16,759 --> 00:06:19,039
Apple or Android or provide you with a

176
00:06:19,039 --> 00:06:21,289
database wrapper or API that hides the

177
00:06:21,289 --> 00:06:23,080
fact that you actually using sequel Lite

178
00:06:23,080 --> 00:06:26,330
all right so the first sort of

179
00:06:26,330 --> 00:06:27,949
standardized API for dat sesemann was

180
00:06:27,949 --> 00:06:31,099
called ODBC and this wasn't actually

181
00:06:31,099 --> 00:06:33,319
it's it's not the first exit II that was

182
00:06:33,319 --> 00:06:35,209
implemented like Sybase actually tried

183
00:06:35,209 --> 00:06:37,880
this back in the late 1980s where they

184
00:06:37,880 --> 00:06:39,219
got together with some other database

185
00:06:39,219 --> 00:06:40,909
vendors and some

186
00:06:40,909 --> 00:06:43,099
application programming frameworks and

187
00:06:43,099 --> 00:06:45,619
they took this Sybase api stripped out

188
00:06:45,619 --> 00:06:47,959
all the side basis if ik logic in it and

189
00:06:47,959 --> 00:06:49,729
tried to propose this as a standard API

190
00:06:49,729 --> 00:06:52,189
called DB library that ever can use for

191
00:06:52,189 --> 00:06:53,679
whatever reason that never took off

192
00:06:53,679 --> 00:06:56,240
Microsoft then hooked up with this other

193
00:06:56,240 --> 00:06:57,800
company called Simo technologies and

194
00:06:57,800 --> 00:07:00,379
then they proposed in the early 1990s

195
00:07:00,379 --> 00:07:02,869
this thing called ODBC and pretty much

196
00:07:02,869 --> 00:07:03,349
today

197
00:07:03,349 --> 00:07:06,020
every major database vendor actually

198
00:07:06,020 --> 00:07:07,639
whether your relation or non-relational

199
00:07:07,639 --> 00:07:09,770
is chances out there they're gonna have

200
00:07:09,770 --> 00:07:11,899
a toady BC library like MongoDB has won

201
00:07:11,899 --> 00:07:13,189
even though Hmong enemy doesn't support

202
00:07:13,189 --> 00:07:16,099
sequel it's just you give them longer to

203
00:07:16,099 --> 00:07:18,409
be you know queries and you write mommy

204
00:07:18,409 --> 00:07:20,389
to be queries in their syntax but it

205
00:07:20,389 --> 00:07:25,789
still supports their API so the way it

206
00:07:25,789 --> 00:07:27,529
basically works is OTP they're gonna

207
00:07:27,529 --> 00:07:28,819
follow what's called a device driver

208
00:07:28,819 --> 00:07:32,569
model and the idea is that in the on the

209
00:07:32,569 --> 00:07:35,809
client side the ODBC driver is this is

210
00:07:35,809 --> 00:07:37,789
something that the vendor provides and

211
00:07:37,789 --> 00:07:39,589
underneath the covers they'll have all

212
00:07:39,589 --> 00:07:41,719
the logic that you need to communicate

213
00:07:41,719 --> 00:07:43,219
with the database server over the

214
00:07:43,219 --> 00:07:45,019
proprietary protocol look if I sent a

215
00:07:45,019 --> 00:07:46,699
query request here this request is going

216
00:07:46,699 --> 00:07:49,129
to be specific to my database system and

217
00:07:49,129 --> 00:07:51,469
then when I get back to result it's up

218
00:07:51,469 --> 00:07:53,899
to this driver now to then convert it

219
00:07:53,899 --> 00:07:56,089
into the format that the ODBC API

220
00:07:56,089 --> 00:08:00,199
specifies alright so the parlance we're

221
00:08:00,199 --> 00:08:01,579
going to use with this class is that I'm

222
00:08:01,579 --> 00:08:03,949
going to refer to this part here this is

223
00:08:03,949 --> 00:08:05,300
the part that we care about this is the

224
00:08:05,300 --> 00:08:07,819
wire protocol and again every database

225
00:08:07,819 --> 00:08:08,749
system is going to do something

226
00:08:08,749 --> 00:08:09,969
different

227
00:08:09,969 --> 00:08:12,259
unless you're following what you know

228
00:08:12,259 --> 00:08:13,490
copying with my Segel and Postgres tier

229
00:08:13,490 --> 00:08:15,349
which is very common but this is not

230
00:08:15,349 --> 00:08:16,999
gonna have anything like this doesn't

231
00:08:16,999 --> 00:08:18,319
know anything about ODBC it just knows

232
00:08:18,319 --> 00:08:18,529
that

233
00:08:18,529 --> 00:08:20,269
here are some Seco queries and here's a

234
00:08:20,269 --> 00:08:23,990
result now the ODBC API does have

235
00:08:23,990 --> 00:08:26,179
additional things or it has certain

236
00:08:26,179 --> 00:08:28,459
features that not every database system

237
00:08:28,459 --> 00:08:30,079
is going to be a little support but you

238
00:08:30,079 --> 00:08:31,849
can essentially emulate that through on

239
00:08:31,849 --> 00:08:34,068
the client side in the driver so for

240
00:08:34,068 --> 00:08:35,539
example if your database system doesn't

241
00:08:35,539 --> 00:08:38,328
support cursors so cursor is like if I

242
00:08:38,328 --> 00:08:39,679
run a sequel query instead of getting

243
00:08:39,679 --> 00:08:41,299
back all the results on once I can get a

244
00:08:41,299 --> 00:08:43,159
handle a cursor handle to that result

245
00:08:43,159 --> 00:08:45,290
like an iterator and I'm called get next

246
00:08:45,290 --> 00:08:47,120
get next get next and that'll send a

247
00:08:47,120 --> 00:08:48,529
message over the network to get back the

248
00:08:48,529 --> 00:08:50,149
next query you would do this it's like

249
00:08:50,149 --> 00:08:51,980
if your if your result is huge and you

250
00:08:51,980 --> 00:08:52,939
don't want to ship everything all at

251
00:08:52,939 --> 00:08:53,930
once

252
00:08:53,930 --> 00:08:56,270
so not every database systems supports

253
00:08:56,270 --> 00:08:59,390
cursors so you can fake that through DC

254
00:08:59,390 --> 00:09:01,220
library so you can still call through to

255
00:09:01,220 --> 00:09:02,450
be seen your application and hey give me

256
00:09:02,450 --> 00:09:04,460
a cursor underneath the covers they'll

257
00:09:04,460 --> 00:09:06,020
send the sequel query to get back all

258
00:09:06,020 --> 00:09:08,300
the results but then expose to you like

259
00:09:08,300 --> 00:09:10,370
the iterator API to walk through the

260
00:09:10,370 --> 00:09:12,649
cursor that's sort of nice that you

261
00:09:12,649 --> 00:09:14,290
could you can hide all that complexity

262
00:09:14,290 --> 00:09:16,640
if you don't support everything you need

263
00:09:16,640 --> 00:09:20,260
for ODBC in the driver itself all right

264
00:09:20,260 --> 00:09:23,209
so the other important thing to

265
00:09:23,209 --> 00:09:26,120
understand too is that the the ODBC

266
00:09:26,120 --> 00:09:29,240
standard specifies what the you know a

267
00:09:29,240 --> 00:09:32,600
fixed specifies what the data types are

268
00:09:32,600 --> 00:09:34,790
that you're gonna get when you say like

269
00:09:34,790 --> 00:09:35,930
give me an integer from this you know

270
00:09:35,930 --> 00:09:38,120
from this from this result set and so

271
00:09:38,120 --> 00:09:39,830
it's up for the driver to make sure that

272
00:09:39,830 --> 00:09:42,470
whatever the the ODBC driver API

273
00:09:42,470 --> 00:09:44,810
specifies as a data type that it has to

274
00:09:44,810 --> 00:09:46,760
give that to you in your application so

275
00:09:46,760 --> 00:09:48,290
that way you don't have an unexpected

276
00:09:48,290 --> 00:09:50,060
result and it makes it more portable so

277
00:09:50,060 --> 00:09:52,490
for example if we store every integer as

278
00:09:52,490 --> 00:09:54,920
64 bits for whatever reason and then the

279
00:09:54,920 --> 00:09:57,020
ODBC API says give me a 32-bit integer

280
00:09:57,020 --> 00:09:59,450
when I get back to 64 energy from the

281
00:09:59,450 --> 00:10:01,730
server again that to convert that to 32

282
00:10:01,730 --> 00:10:03,740
bits because that's what the API

283
00:10:03,740 --> 00:10:04,610
specifies

284
00:10:04,610 --> 00:10:07,630
so again that's all trying to hide the

285
00:10:07,630 --> 00:10:10,610
the specifics or the nuances of every

286
00:10:10,610 --> 00:10:12,920
single database system right bite

287
00:10:12,920 --> 00:10:17,050
through this this client or driver model

288
00:10:17,470 --> 00:10:20,510
all right so the other more common one

289
00:10:20,510 --> 00:10:23,240
too is JDBC and the way to think about

290
00:10:23,240 --> 00:10:25,279
this is like ODBC it's not specific to

291
00:10:25,279 --> 00:10:27,200
Windows anymore but it sort of came out

292
00:10:27,200 --> 00:10:28,820
of the environment and so that's sort of

293
00:10:28,820 --> 00:10:31,580
designed for C or C++ applications JDBC

294
00:10:31,580 --> 00:10:33,709
is designed for Java based applications

295
00:10:33,709 --> 00:10:35,000
for applications that are designed to

296
00:10:35,000 --> 00:10:38,720
run on the JVM so this was developed by

297
00:10:38,720 --> 00:10:42,740
sun in 1997 when a few years after they

298
00:10:42,740 --> 00:10:45,620
released the the Java Runtime in the

299
00:10:45,620 --> 00:10:47,600
java language and again the idea was

300
00:10:47,600 --> 00:10:49,010
that they recognized that they wanted

301
00:10:49,010 --> 00:10:51,079
java applications to run in the

302
00:10:51,079 --> 00:10:53,329
enterprise those things enterprise

303
00:10:53,329 --> 00:10:54,980
applications need to talk to relational

304
00:10:54,980 --> 00:10:57,310
databases or sequel databases so you

305
00:10:57,310 --> 00:10:59,570
JDBC was their attempt to standardize an

306
00:10:59,570 --> 00:11:02,450
API for this and again like I said like

307
00:11:02,450 --> 00:11:04,880
you think it'll be C is for C and JDBC

308
00:11:04,880 --> 00:11:08,000
is obviously for Java and so we

309
00:11:08,000 --> 00:11:09,920
to be slightly different though in in

310
00:11:09,920 --> 00:11:13,280
JDBC is that because they're running the

311
00:11:13,280 --> 00:11:17,660
Java Runtime they're not always going to

312
00:11:17,660 --> 00:11:21,770
have a driver written in Java it's more

313
00:11:21,770 --> 00:11:23,720
common now but back in the day not so

314
00:11:23,720 --> 00:11:26,360
much right for for ODBC yes if you

315
00:11:26,360 --> 00:11:27,380
released your driver

316
00:11:27,380 --> 00:11:29,390
if you driver it spot it's going to be

317
00:11:29,390 --> 00:11:31,490
in C right and that would be universal

318
00:11:31,490 --> 00:11:33,640
not so sort of as a way to bridge people

319
00:11:33,640 --> 00:11:37,520
to be able to use JDBC before there were

320
00:11:37,520 --> 00:11:39,770
enough drivers written in Java then they

321
00:11:39,770 --> 00:11:41,060
have a bunch of different levels or

322
00:11:41,060 --> 00:11:43,340
connectivity methods you can use to

323
00:11:43,340 --> 00:11:45,410
communicate with the database system so

324
00:11:45,410 --> 00:11:47,180
the first one is exactly as I was saying

325
00:11:47,180 --> 00:11:49,880
so instead of having the the JDBC driver

326
00:11:49,880 --> 00:11:51,290
communicate directly with the database

327
00:11:51,290 --> 00:11:53,890
system you have a little bridge

328
00:11:53,890 --> 00:11:55,910
middleware sitting in front of it that

329
00:11:55,910 --> 00:11:58,490
converts JDBC commands into ODBC

330
00:11:58,490 --> 00:12:01,040
commands and then ODBC then communicates

331
00:12:01,040 --> 00:12:02,390
to the database system over its

332
00:12:02,390 --> 00:12:04,640
proprietary wire protocol so this is

333
00:12:04,640 --> 00:12:06,500
actually not supported anymore as of

334
00:12:06,500 --> 00:12:09,500
like I think JDK 1.8 but and this is

335
00:12:09,500 --> 00:12:10,640
actually was a pain in the ass to set up

336
00:12:10,640 --> 00:12:12,020
I had to do this four times ten when we

337
00:12:12,020 --> 00:12:14,720
do some testing here it's a nightmare

338
00:12:14,720 --> 00:12:16,730
it was really finicky but like again

339
00:12:16,730 --> 00:12:19,970
this was a stopgap solution in case GBC

340
00:12:19,970 --> 00:12:21,650
didn't have exactly what you wanted for

341
00:12:21,650 --> 00:12:24,380
your particular database system the next

342
00:12:24,380 --> 00:12:27,140
approach is to have the JDBC calls just

343
00:12:27,140 --> 00:12:31,730
invoke the proprietary native API of the

344
00:12:31,730 --> 00:12:34,040
database system right again so sequel

345
00:12:34,040 --> 00:12:34,970
Lite would be the best way to think

346
00:12:34,970 --> 00:12:35,960
about this because Seco lights in a

347
00:12:35,960 --> 00:12:37,430
better database system so it's gonna be

348
00:12:37,430 --> 00:12:40,010
running inside your same process as your

349
00:12:40,010 --> 00:12:43,430
application so you could have the JDBC

350
00:12:43,430 --> 00:12:46,700
driver invoke through J and I to the C

351
00:12:46,700 --> 00:12:48,680
commands to execute queries or open up

352
00:12:48,680 --> 00:12:51,710
cursors or tables on the database system

353
00:12:51,710 --> 00:12:53,930
but I don't think this would work if

354
00:12:53,930 --> 00:12:55,339
you're going over the network this is

355
00:12:55,339 --> 00:12:57,920
only for the bit embedded embedded

356
00:12:57,920 --> 00:13:00,190
databases running on in the same process

357
00:13:00,190 --> 00:13:03,860
the next approach is to have a the JDBC

358
00:13:03,860 --> 00:13:05,600
driver communicate with some other

359
00:13:05,600 --> 00:13:08,420
middleware system that then knows how to

360
00:13:08,420 --> 00:13:11,030
then speak the wire protocol of the of

361
00:13:11,030 --> 00:13:12,680
the database system so it's sort of like

362
00:13:12,680 --> 00:13:14,300
the first one but the idea here is that

363
00:13:14,300 --> 00:13:17,959
the the commands coming out of the of

364
00:13:17,959 --> 00:13:21,800
JDBC are shouldn't generic

365
00:13:21,800 --> 00:13:24,199
for JDBC but then when they land on

366
00:13:24,199 --> 00:13:25,339
those middleware that the dated

367
00:13:25,339 --> 00:13:27,259
assistant would have to provide it then

368
00:13:27,259 --> 00:13:28,369
know how to convert and convert that

369
00:13:28,369 --> 00:13:30,439
into the wire protocol that you expected

370
00:13:30,439 --> 00:13:32,899
right whereas this thing is is sort of

371
00:13:32,899 --> 00:13:37,610
the JDBC is invoking ODBC commands the

372
00:13:37,610 --> 00:13:39,290
last one which I my opinion is the best

373
00:13:39,290 --> 00:13:43,040
one is where the database so that the

374
00:13:43,040 --> 00:13:45,559
the JDBC implementation itself can

375
00:13:45,559 --> 00:13:48,170
invoke or send the packets that you need

376
00:13:48,170 --> 00:13:49,369
for the wire protocol or the database

377
00:13:49,369 --> 00:13:52,660
system so this is not wasn't that common

378
00:13:52,660 --> 00:13:55,069
so much in the early days but it's more

379
00:13:55,069 --> 00:13:57,739
common now like you can download a

380
00:13:57,739 --> 00:14:00,529
Postgres implementation or Postgres JDBC

381
00:14:00,529 --> 00:14:02,720
driver purely written in Java and you

382
00:14:02,720 --> 00:14:04,879
don't need to worry about any of the the

383
00:14:04,879 --> 00:14:06,920
C stuff and this will run the fastest

384
00:14:06,920 --> 00:14:08,660
cuz again you just go natively in Java

385
00:14:08,660 --> 00:14:10,220
over the network to get the packets and

386
00:14:10,220 --> 00:14:14,679
get everything back right so this one

387
00:14:14,679 --> 00:14:18,439
this one I think not actually this one

388
00:14:18,439 --> 00:14:22,519
you sort of see in in other languages

389
00:14:22,519 --> 00:14:25,489
like if you want to have like if you

390
00:14:25,489 --> 00:14:27,499
have some obscure programming like rust

391
00:14:27,499 --> 00:14:30,740
or go aren't secure or obscure but like

392
00:14:30,740 --> 00:14:32,420
in the early days there weren't a lot of

393
00:14:32,420 --> 00:14:35,629
drivers written for for different

394
00:14:35,629 --> 00:14:37,639
databases and go and rust and whatever

395
00:14:37,639 --> 00:14:39,439
language you want to use so you a

396
00:14:39,439 --> 00:14:41,540
stopgap solution would be this thing

397
00:14:41,540 --> 00:14:43,279
would wrap around like ODBC you would

398
00:14:43,279 --> 00:14:46,699
have a go wrapper around the ODBC driver

399
00:14:46,699 --> 00:14:48,949
which is written in C and but that means

400
00:14:48,949 --> 00:14:51,290
again you have to then go out of the

401
00:14:51,290 --> 00:14:53,929
could go runtime into the C program to

402
00:14:53,929 --> 00:14:55,670
send these commands whereas if you have

403
00:14:55,670 --> 00:14:58,129
a native go implementation yeah that's

404
00:14:58,129 --> 00:14:59,600
me way faster because it's less copying

405
00:14:59,600 --> 00:15:01,129
a packets or less copy my buffers so

406
00:15:01,129 --> 00:15:03,290
this this was always gonna be better way

407
00:15:03,290 --> 00:15:07,819
to do this so as I said all of the

408
00:15:07,819 --> 00:15:08,949
database systems are going to implement

409
00:15:08,949 --> 00:15:11,720
their own proprietary wire protocol and

410
00:15:11,720 --> 00:15:14,240
these are as far as I know I don't know

411
00:15:14,240 --> 00:15:15,199
of any other system that doesn't do this

412
00:15:15,199 --> 00:15:18,019
everything is going to go over tcp/ip I

413
00:15:18,019 --> 00:15:19,730
don't know of any database system that

414
00:15:19,730 --> 00:15:22,999
goes over UDP and we tough to do if you

415
00:15:22,999 --> 00:15:24,139
want to support transactions because you

416
00:15:24,139 --> 00:15:25,009
don't know whether your packers are

417
00:15:25,009 --> 00:15:26,480
actually gonna show up and you need to

418
00:15:26,480 --> 00:15:28,759
send back aknowledge mints so for that

419
00:15:28,759 --> 00:15:30,769
reason everyone's going over tcp/ip now

420
00:15:30,769 --> 00:15:33,069
above that they could have additional

421
00:15:33,069 --> 00:15:35,070
confirmation messages in back

422
00:15:35,070 --> 00:15:36,389
but you know to say look did you get

423
00:15:36,389 --> 00:15:38,040
this packet yes I got this packet like

424
00:15:38,040 --> 00:15:39,660
at the application level but of course

425
00:15:39,660 --> 00:15:41,339
TCP is gonna do that for you on the

426
00:15:41,339 --> 00:15:44,519
covers as well so the typically way the

427
00:15:44,519 --> 00:15:46,290
way the clients gonna interact with our

428
00:15:46,290 --> 00:15:48,180
database server is that they're going to

429
00:15:48,180 --> 00:15:49,740
connect to the database system they'll

430
00:15:49,740 --> 00:15:51,509
go through some kind of authentication

431
00:15:51,509 --> 00:15:53,459
process like username passwords Kerberos

432
00:15:53,459 --> 00:15:56,519
can use things like that if most systems

433
00:15:56,519 --> 00:15:58,589
also now support SSL by default so you

434
00:15:58,589 --> 00:16:00,300
go through that process to encrypt the

435
00:16:00,300 --> 00:16:03,660
the the channel then you send over a

436
00:16:03,660 --> 00:16:05,730
query the database has executed that

437
00:16:05,730 --> 00:16:08,639
query sterilizes the results it sends

438
00:16:08,639 --> 00:16:09,959
that back over the wire protocol to the

439
00:16:09,959 --> 00:16:11,190
client and the client can then hand that

440
00:16:11,190 --> 00:16:15,779
off to to the application code so what

441
00:16:15,779 --> 00:16:17,040
we're gonna focus on today and the paper

442
00:16:17,040 --> 00:16:18,720
you had you guys read was focusing on

443
00:16:18,720 --> 00:16:20,430
this problem here how do you actually

444
00:16:20,430 --> 00:16:22,170
sterilize the data and get out of it

445
00:16:22,170 --> 00:16:23,399
because this is actually where the

446
00:16:23,399 --> 00:16:25,680
opportunity for optimization is actually

447
00:16:25,680 --> 00:16:27,420
available or there are things that we

448
00:16:27,420 --> 00:16:29,610
can improve right there's not much we

449
00:16:29,610 --> 00:16:31,920
can do for this there's not much there's

450
00:16:31,920 --> 00:16:33,810
not really much optimization we can do

451
00:16:33,810 --> 00:16:35,910
for this because most sequel queries are

452
00:16:35,910 --> 00:16:37,560
gonna be short rather there's strings we

453
00:16:37,560 --> 00:16:39,779
send over you can then maybe say I run

454
00:16:39,779 --> 00:16:41,339
these as prepared statements or stored

455
00:16:41,339 --> 00:16:42,750
procedures but that's just really

456
00:16:42,750 --> 00:16:44,670
reducing the size of the message most

457
00:16:44,670 --> 00:16:46,860
queries aren't that big there's some

458
00:16:46,860 --> 00:16:49,350
applications I've seen or heard from

459
00:16:49,350 --> 00:16:51,779
people in the wild where like the sequel

460
00:16:51,779 --> 00:16:54,540
query could be like 10 megabytes you see

461
00:16:54,540 --> 00:16:57,660
this like big big corporations where

462
00:16:57,660 --> 00:16:58,860
they have like this eaten internal

463
00:16:58,860 --> 00:17:01,170
dashboards to do like reporting and you

464
00:17:01,170 --> 00:17:02,970
click a bunch of options to like you

465
00:17:02,970 --> 00:17:04,679
know just get all the people from a zip

466
00:17:04,679 --> 00:17:06,480
code or some you know some geographical

467
00:17:06,480 --> 00:17:09,390
region and then you you sort of you

468
00:17:09,390 --> 00:17:10,679
click all the options you want for the

469
00:17:10,679 --> 00:17:12,720
query you click go and then that

470
00:17:12,720 --> 00:17:14,220
converts whatever you clicked on the

471
00:17:14,220 --> 00:17:15,659
dashboard into a sequel query and

472
00:17:15,659 --> 00:17:17,189
sometimes you can have these really long

473
00:17:17,189 --> 00:17:20,309
in clauses like where zip code in and

474
00:17:20,309 --> 00:17:21,569
then you know list of every single zip

475
00:17:21,569 --> 00:17:23,490
code and in that case the sequel where

476
00:17:23,490 --> 00:17:25,740
it can get really big but the only

477
00:17:25,740 --> 00:17:27,119
optimization you really can do for that

478
00:17:27,119 --> 00:17:29,760
it's just you compress it with like

479
00:17:29,760 --> 00:17:31,320
snappy or gzip whatever you want to use

480
00:17:31,320 --> 00:17:32,940
all right so there's not really any

481
00:17:32,940 --> 00:17:34,650
techniques we can do in a database

482
00:17:34,650 --> 00:17:37,650
system to make this go faster so we're

483
00:17:37,650 --> 00:17:41,850
gonna be focus on this one here right so

484
00:17:41,850 --> 00:17:45,150
I say all major Davis systems implement

485
00:17:45,150 --> 00:17:48,670
their own proprietary waterfall protocol

486
00:17:48,670 --> 00:18:02,620
that's not entirely true question good

487
00:18:02,620 --> 00:18:05,730
question so the question is are there

488
00:18:05,730 --> 00:18:07,780
are there any database systems where the

489
00:18:07,780 --> 00:18:09,160
client can actually be somewhat

490
00:18:09,160 --> 00:18:13,150
intelligent and maybe I mean do

491
00:18:13,150 --> 00:18:15,100
compression maybe do some query

492
00:18:15,100 --> 00:18:17,250
rewriting before it sends it to you I

493
00:18:17,250 --> 00:18:19,210
was also gonna think you know she made

494
00:18:19,210 --> 00:18:23,160
me do client-side query caching as well

495
00:18:24,390 --> 00:18:28,200
not really for a couple reasons

496
00:18:28,200 --> 00:18:30,670
the so the example you gave is like can

497
00:18:30,670 --> 00:18:32,770
I do query rewriting I don't know if

498
00:18:32,770 --> 00:18:34,390
anybody does that in the client driver

499
00:18:34,390 --> 00:18:37,450
because like convert you know one equals

500
00:18:37,450 --> 00:18:39,850
want you know two equals one plus one

501
00:18:39,850 --> 00:18:41,760
can I convert that just to be true

502
00:18:41,760 --> 00:18:44,020
because you basically would need to

503
00:18:44,020 --> 00:18:45,700
implement that logic to parse the sequel

504
00:18:45,700 --> 00:18:47,740
statement understand the semantics of

505
00:18:47,740 --> 00:18:49,390
what the where clause is actually doing

506
00:18:49,390 --> 00:18:52,720
on the client side then now you also

507
00:18:52,720 --> 00:18:54,280
need to if you're supporting a bunch of

508
00:18:54,280 --> 00:18:56,260
different programming languages and

509
00:18:56,260 --> 00:18:58,030
you're using having a native drivers for

510
00:18:58,030 --> 00:18:59,230
those things now you got to rewrite all

511
00:18:59,230 --> 00:19:01,510
that in every single language for that

512
00:19:01,510 --> 00:19:03,040
reason nobody I don't think anybody does

513
00:19:03,040 --> 00:19:06,370
that I there is there was a system

514
00:19:06,370 --> 00:19:09,040
called foundation DB which is a

515
00:19:09,040 --> 00:19:10,660
distributed key-value store that Apple

516
00:19:10,660 --> 00:19:12,970
bought it is now open-source snowflake

517
00:19:12,970 --> 00:19:15,250
uses it internal for the metadata but

518
00:19:15,250 --> 00:19:17,220
they only use it as a key value store

519
00:19:17,220 --> 00:19:19,570
when put for pound eight before Apple

520
00:19:19,570 --> 00:19:21,370
bought foundation BB BB what they would

521
00:19:21,370 --> 00:19:23,680
do is they added a sequel glare and all

522
00:19:23,680 --> 00:19:25,390
that would do was in the client they

523
00:19:25,390 --> 00:19:27,160
would convert your sequel statement into

524
00:19:27,160 --> 00:19:29,980
individual get get queries get command

525
00:19:29,980 --> 00:19:32,170
to is send for the key value store so

526
00:19:32,170 --> 00:19:33,700
that's one that's the only tip I can

527
00:19:33,700 --> 00:19:35,200
think of offhand they do this kind of

528
00:19:35,200 --> 00:19:37,990
stuff other things like caching query

529
00:19:37,990 --> 00:19:41,350
results well if you don't know what's in

530
00:19:41,350 --> 00:19:42,490
the database server on the client side

531
00:19:42,490 --> 00:19:44,200
how do you know that like you have the

532
00:19:44,200 --> 00:19:46,450
latest version so you so for this routes

533
00:19:46,450 --> 00:19:47,770
and everyone always goes always go to

534
00:19:47,770 --> 00:19:52,780
the network there I have thought about

535
00:19:52,780 --> 00:19:53,290
this

536
00:19:53,290 --> 00:19:55,450
we haven't pursued it yet but like I

537
00:19:55,450 --> 00:19:57,370
there was some research done up in

538
00:19:57,370 --> 00:20:02,740
Waterloo where like you could provide

539
00:20:02,740 --> 00:20:04,810
hints about like hey I'm sending you

540
00:20:04,810 --> 00:20:06,730
this query but oh by the way I'm gonna

541
00:20:06,730 --> 00:20:08,080
actually these other queries pretty soon

542
00:20:08,080 --> 00:20:10,810
as well but I don't think any that makes

543
00:20:10,810 --> 00:20:12,490
it any commercialism the client drivers

544
00:20:12,490 --> 00:20:14,050
are usually pretty brain-dead there's

545
00:20:14,050 --> 00:20:15,430
like give me this query here's a result

546
00:20:15,430 --> 00:20:26,580
yes what would be an existing protocol

547
00:20:27,210 --> 00:20:29,860
then what's a like a me to use an

548
00:20:29,860 --> 00:20:31,450
existing protocol what do you mean like

549
00:20:31,450 --> 00:20:49,750
like I want like tcp/ip so I think we're

550
00:20:49,750 --> 00:20:52,270
you saying are you when you say existing

551
00:20:52,270 --> 00:20:54,460
protocols do you mean it like at the

552
00:20:54,460 --> 00:20:57,370
lower level in the stack like at tcp/ip

553
00:20:57,370 --> 00:20:59,290
level or do you mean like at the

554
00:20:59,290 --> 00:21:03,670
application level right so - what with

555
00:21:03,670 --> 00:21:11,530
an existing protocol that's tcpip but

556
00:21:11,530 --> 00:21:13,210
that's that's a layer below we're above

557
00:21:13,210 --> 00:21:17,320
and we're in the data server so 221 of

558
00:21:17,320 --> 00:21:20,410
those existing protocols so some eight

559
00:21:20,410 --> 00:21:23,160
my question is what's an existing one

560
00:21:23,160 --> 00:21:25,210
it's a leading question because it's the

561
00:21:25,210 --> 00:21:31,300
next slide okay so right so as I was

562
00:21:31,300 --> 00:21:33,400
saying like all the major database

563
00:21:33,400 --> 00:21:35,440
vendors like Postgres the my sequel the

564
00:21:35,440 --> 00:21:37,690
other big three Oracle db2 sequel server

565
00:21:37,690 --> 00:21:39,670
pretty much everyone implements their

566
00:21:39,670 --> 00:21:42,940
own wire protocol from scratch but where

567
00:21:42,940 --> 00:21:46,270
I thought you were gonna go is that most

568
00:21:46,270 --> 00:21:48,250
of the newer systems however don't do

569
00:21:48,250 --> 00:21:49,540
this and they need to be implemented in

570
00:21:49,540 --> 00:21:52,030
an existing one in particular Postgres

571
00:21:52,030 --> 00:21:55,240
on my sequel right and the benefit of

572
00:21:55,240 --> 00:21:57,130
doing this is that and we do the same

573
00:21:57,130 --> 00:21:58,630
thing in our system of building here is

574
00:21:58,630 --> 00:22:00,520
that now I don't have to worry about

575
00:22:00,520 --> 00:22:01,900
supporting a bunch of different

576
00:22:01,900 --> 00:22:03,340
programming languages for my drivers

577
00:22:03,340 --> 00:22:05,600
right for JDBC and ODBC

578
00:22:05,600 --> 00:22:07,880
I guess if I speak the post s wire

579
00:22:07,880 --> 00:22:10,160
protocol then anybody that comes along

580
00:22:10,160 --> 00:22:12,799
with a you know the the Postgres driver

581
00:22:12,799 --> 00:22:15,289
in rust they can just use that first

582
00:22:15,289 --> 00:22:16,309
ghost driver and communicate in my

583
00:22:16,309 --> 00:22:18,830
database system now these aren't going

584
00:22:18,830 --> 00:22:20,360
to be the best protocols and we can talk

585
00:22:20,360 --> 00:22:21,590
offline to the troubles we've been

586
00:22:21,590 --> 00:22:24,710
having with the Postgres one but if you

587
00:22:24,710 --> 00:22:26,090
think about it if your database startup

588
00:22:26,090 --> 00:22:27,440
or your like your your research project

589
00:22:27,440 --> 00:22:30,350
like AWS do you want to be spending your

590
00:22:30,350 --> 00:22:33,679
time on writing client drivers for every

591
00:22:33,679 --> 00:22:34,580
single programming language in order

592
00:22:34,580 --> 00:22:36,679
people to user your database or can use

593
00:22:36,679 --> 00:22:37,760
piggyback of what's already been done

594
00:22:37,760 --> 00:22:39,710
and a large ecosystem and happy will

595
00:22:39,710 --> 00:22:41,419
just you know use what's already there

596
00:22:41,419 --> 00:22:43,909
so that's why this is actually very very

597
00:22:43,909 --> 00:22:46,460
common so but I will say though

598
00:22:46,460 --> 00:22:47,690
sometimes you'll see in the

599
00:22:47,690 --> 00:22:50,210
documentation that oh we are Postgres

600
00:22:50,210 --> 00:22:52,309
compatible you see in this application

601
00:22:52,309 --> 00:22:53,870
of these different database systems or

602
00:22:53,870 --> 00:22:55,130
Postgres compatible or my sequel

603
00:22:55,130 --> 00:22:57,530
compatible but just because they speak

604
00:22:57,530 --> 00:22:58,730
the wire protocol it doesn't mean

605
00:22:58,730 --> 00:23:00,799
actually truly compatible but they're

606
00:23:00,799 --> 00:23:02,360
not always gonna be an exact drop-in

607
00:23:02,360 --> 00:23:04,159
replacement because there's a bunch of

608
00:23:04,159 --> 00:23:07,460
other stuff that are specific to that

609
00:23:07,460 --> 00:23:09,590
you know Postgres of my sequel that you

610
00:23:09,590 --> 00:23:11,179
may not actually be emulating in your

611
00:23:11,179 --> 00:23:13,480
server or in your new system and

612
00:23:13,480 --> 00:23:15,590
therefore it's not going to work you

613
00:23:15,590 --> 00:23:18,350
know your application code using GBC

614
00:23:18,350 --> 00:23:20,600
ODBC may start sending sequel queries in

615
00:23:20,600 --> 00:23:22,010
a dialect that your server doesn't

616
00:23:22,010 --> 00:23:24,039
support and it's not gonna work

617
00:23:24,039 --> 00:23:26,330
right so this will get you that sort of

618
00:23:26,330 --> 00:23:28,760
it by following their protocol you'll

619
00:23:28,760 --> 00:23:30,200
get the transport to go from the client

620
00:23:30,200 --> 00:23:31,730
to the server correct but then this

621
00:23:31,730 --> 00:23:34,039
query shows up and now what do you do

622
00:23:34,039 --> 00:23:35,720
right it's not going exactly the same

623
00:23:35,720 --> 00:23:37,820
other times - they'll be queries that

624
00:23:37,820 --> 00:23:39,409
like if you don't support the same

625
00:23:39,409 --> 00:23:40,970
catalog structure as post customize

626
00:23:40,970 --> 00:23:43,309
sequel a lot of these like visualization

627
00:23:43,309 --> 00:23:44,450
tools the first thing you do when they

628
00:23:44,450 --> 00:23:46,159
turn them on is that go look in the

629
00:23:46,159 --> 00:23:47,480
catalog sit and figure out what tables

630
00:23:47,480 --> 00:23:48,890
you have what Commons you have but you

631
00:23:48,890 --> 00:23:51,530
don't speak that if you're not formatted

632
00:23:51,530 --> 00:23:54,049
the same way that post goes my sequel

633
00:23:54,049 --> 00:23:56,120
are then that's going to break then

634
00:23:56,120 --> 00:23:57,710
there's other things too were like the

635
00:23:57,710 --> 00:24:00,049
tools may go at the the database server

636
00:24:00,049 --> 00:24:03,289
in sort of a physical level like looking

637
00:24:03,289 --> 00:24:04,820
at files on disk look there's a lot of

638
00:24:04,820 --> 00:24:06,919
extensions and tools or Postgres that

639
00:24:06,919 --> 00:24:09,320
can manipulate the actual files of the

640
00:24:09,320 --> 00:24:10,580
database without actually having to go

641
00:24:10,580 --> 00:24:12,890
through the the database system itself

642
00:24:12,890 --> 00:24:14,000
no no that's going to work because

643
00:24:14,000 --> 00:24:15,200
underneath the coverage your system is

644
00:24:15,200 --> 00:24:16,680
going to be completely different

645
00:24:16,680 --> 00:24:22,740
yes the drivers especially this just

646
00:24:22,740 --> 00:24:26,430
like write a string of sequel into some

647
00:24:26,430 --> 00:24:28,200
function that magically like writes that

648
00:24:28,200 --> 00:24:30,570
over a network into like I saw it and

649
00:24:30,570 --> 00:24:31,980
then like get some result back in some

650
00:24:31,980 --> 00:24:34,710
form in so this question is what are

651
00:24:34,710 --> 00:24:36,030
these drivers actually look like is it

652
00:24:36,030 --> 00:24:37,500
at the bare bones are they just like

653
00:24:37,500 --> 00:24:39,750
here's a sequel string you say go run

654
00:24:39,750 --> 00:24:41,430
this for me and then that goes it gets

655
00:24:41,430 --> 00:24:43,230
converted into the the packets to send

656
00:24:43,230 --> 00:24:44,940
to the Davis system you get a result and

657
00:24:44,940 --> 00:24:46,740
you get back data on some binary form in

658
00:24:46,740 --> 00:24:48,990
the most simplest form yes but he start

659
00:24:48,990 --> 00:24:51,420
doing like prepared statements or

660
00:24:51,420 --> 00:24:54,420
cursors like you can specify like here's

661
00:24:54,420 --> 00:24:55,920
the query template I want to use and

662
00:24:55,920 --> 00:24:57,840
then the first values in second that is

663
00:24:57,840 --> 00:25:00,000
a double like there's the API is

664
00:25:00,000 --> 00:25:04,110
actually kind of big and all that won't

665
00:25:04,110 --> 00:25:06,180
be you know passing everything just

666
00:25:06,180 --> 00:25:07,590
through a sequel string there are ways

667
00:25:07,590 --> 00:25:09,630
to construct queries programmatically

668
00:25:09,630 --> 00:25:11,220
through the API that isn't just hey

669
00:25:11,220 --> 00:25:13,280
here's the sequel string and then the

670
00:25:13,280 --> 00:25:16,170
again the API specifies says you know

671
00:25:16,170 --> 00:25:17,250
when you get back a result and you call

672
00:25:17,250 --> 00:25:21,900
next row the you know when you say you

673
00:25:21,900 --> 00:25:23,670
know for this current row give me the

674
00:25:23,670 --> 00:25:25,860
the third tuple or give me the third

675
00:25:25,860 --> 00:25:28,500
field as an integer it needs to know

676
00:25:28,500 --> 00:25:29,790
that I'm gonna get back a third you

677
00:25:29,790 --> 00:25:31,410
Pittenger not some other thing that your

678
00:25:31,410 --> 00:25:33,060
your your davis administering internally

679
00:25:33,060 --> 00:25:35,550
so like sequel light stores everything

680
00:25:35,550 --> 00:25:37,050
that's varchars to meet the covers and

681
00:25:37,050 --> 00:25:38,790
it's only when it gets exposed outside

682
00:25:38,790 --> 00:25:39,780
the database system then it gets

683
00:25:39,780 --> 00:25:41,940
converted to the correct binary form so

684
00:25:41,940 --> 00:25:46,500
the driver have to handle that yes front

685
00:25:46,500 --> 00:25:57,630
row yes sequel or sequel server sure all

686
00:25:57,630 --> 00:25:58,290
right so that's that's the

687
00:25:58,290 --> 00:26:00,950
implementation yes

688
00:26:03,830 --> 00:26:05,330
what does the different client-side

689
00:26:05,330 --> 00:26:19,640
caching and server-side caching question

690
00:26:19,640 --> 00:26:21,700
is is I made a comment about the

691
00:26:21,700 --> 00:26:23,720
client-side caching versus server-side

692
00:26:23,720 --> 00:26:26,269
caching server side query result caching

693
00:26:26,269 --> 00:26:30,470
would be I I sent a sequel query it does

694
00:26:30,470 --> 00:26:33,110
some some complex calculation I send

695
00:26:33,110 --> 00:26:34,760
back the result to the client but then I

696
00:26:34,760 --> 00:26:36,500
also remember that I actually that VAT

697
00:26:36,500 --> 00:26:37,730
sequel query with the result

698
00:26:37,730 --> 00:26:39,289
so now someone comes along execute the

699
00:26:39,289 --> 00:26:40,639
same sequel query I don't have to

700
00:26:40,639 --> 00:26:41,870
recompute it I just get back the same

701
00:26:41,870 --> 00:26:44,929
result so an alternative could be that

702
00:26:44,929 --> 00:26:47,029
the client could do this so the client

703
00:26:47,029 --> 00:26:49,760
says I exited the same sequel query you

704
00:26:49,760 --> 00:26:51,620
know a few seconds ago here's a result

705
00:26:51,620 --> 00:26:54,380
just reuse that the pom is if you if you

706
00:26:54,380 --> 00:26:56,750
care about having the data be fresh and

707
00:26:56,750 --> 00:26:59,029
up-to-date on the client-side I don't

708
00:26:59,029 --> 00:27:00,230
know if somebody else came in and

709
00:27:00,230 --> 00:27:02,299
modified the tables and therefore

710
00:27:02,299 --> 00:27:05,510
invalidated my cache result so you'd

711
00:27:05,510 --> 00:27:07,070
have to think about how do you actually

712
00:27:07,070 --> 00:27:08,750
implement this you could then say like

713
00:27:08,750 --> 00:27:11,389
the client could go to the database

714
00:27:11,389 --> 00:27:14,419
server say hey has the state of this of

715
00:27:14,419 --> 00:27:16,490
this has this cache result been

716
00:27:16,490 --> 00:27:17,750
invalidated yes or no

717
00:27:17,750 --> 00:27:20,210
then if yes then you react security if

718
00:27:20,210 --> 00:27:21,769
no then you just reuse what you've done

719
00:27:21,769 --> 00:27:23,299
I don't think anybody actually does that

720
00:27:23,299 --> 00:27:25,370
though because it's sort of 1x turn it

721
00:27:25,370 --> 00:27:32,330
round trip oh it's a huge quarter can

722
00:27:32,330 --> 00:27:33,860
make a difference absolutely if my query

723
00:27:33,860 --> 00:27:35,710
takes an albacore run and I can cache it

724
00:27:35,710 --> 00:27:38,600
fantastic right so we're not gonna talk

725
00:27:38,600 --> 00:27:41,330
about it this semester it's also another

726
00:27:41,330 --> 00:27:44,480
area that I fully understand myself you

727
00:27:44,480 --> 00:27:46,460
can kind of get this on the database

728
00:27:46,460 --> 00:27:49,159
service side so queries alt caching

729
00:27:49,159 --> 00:27:50,600
isn't always good because it's like core

730
00:27:50,600 --> 00:27:52,700
spring it's like you have their cache

731
00:27:52,700 --> 00:27:54,710
result for the entire sequel query so

732
00:27:54,710 --> 00:27:58,100
like if I say you know if the giant

733
00:27:58,100 --> 00:27:59,809
select query has has a predicate or say

734
00:27:59,809 --> 00:28:02,360
where name equals Andy my cache that

735
00:28:02,360 --> 00:28:04,159
then your query shows up with your name

736
00:28:04,159 --> 00:28:06,559
I can't reuse any things that I computed

737
00:28:06,559 --> 00:28:07,789
even though maybe one piece has change

738
00:28:07,789 --> 00:28:10,639
so a very common thing to do is what's

739
00:28:10,639 --> 00:28:12,440
called materialized views where you can

740
00:28:12,440 --> 00:28:13,940
actually materialize pieces of that

741
00:28:13,940 --> 00:28:17,270
query and so like maybe you Prima

742
00:28:17,270 --> 00:28:19,070
sterilize some expensive join and then

743
00:28:19,070 --> 00:28:20,360
the predicate this comes in and is how

744
00:28:20,360 --> 00:28:21,770
to do a filter on that materialized

745
00:28:21,770 --> 00:28:23,510
query and the high-end servers like

746
00:28:23,510 --> 00:28:25,550
sequel server in particular can know how

747
00:28:25,550 --> 00:28:27,500
to like reuse materialized views across

748
00:28:27,500 --> 00:28:30,650
different queries right but again for

749
00:28:30,650 --> 00:28:32,570
your table you would need an explicit

750
00:28:32,570 --> 00:28:35,210
cache invalidation message and I don't

751
00:28:35,210 --> 00:28:39,100
think anybody actually does that right

752
00:28:39,430 --> 00:29:06,620
alright so yeah so a question is why

753
00:29:06,620 --> 00:29:08,930
would I ever want to have a cursor where

754
00:29:08,930 --> 00:29:11,420
I return one tuple at a time versus like

755
00:29:11,420 --> 00:29:13,010
descending everything all the ones so I

756
00:29:13,010 --> 00:29:15,620
think cursors I think I don't know the

757
00:29:15,620 --> 00:29:16,940
exact details like I think they vary per

758
00:29:16,940 --> 00:29:18,410
system they don't mean it's not just one

759
00:29:18,410 --> 00:29:21,380
quick it'll be one be one packet one

760
00:29:21,380 --> 00:29:23,120
message to get one result they sent a

761
00:29:23,120 --> 00:29:25,700
batch with the question is do I send you

762
00:29:25,700 --> 00:29:27,410
know five million results I sent all 1

763
00:29:27,410 --> 00:29:31,600
million or do I send 10,000 at a time

764
00:29:33,880 --> 00:29:36,470
correct same is if your davis ism

765
00:29:36,470 --> 00:29:39,260
doesn't support support cursors you have

766
00:29:39,260 --> 00:29:41,840
to send one my results yes and then

767
00:29:41,840 --> 00:29:47,170
think about like think about like think

768
00:29:47,170 --> 00:29:49,550
about what a database server would look

769
00:29:49,550 --> 00:29:50,810
like versus what an application server

770
00:29:50,810 --> 00:29:52,700
would look like a database server is

771
00:29:52,700 --> 00:29:54,190
usually going to be running on high-end

772
00:29:54,190 --> 00:29:57,560
software now distributed database the

773
00:29:57,560 --> 00:29:59,630
world is different but like fingers like

774
00:29:59,630 --> 00:30:01,580
you know a big heavy expensive machine

775
00:30:01,580 --> 00:30:03,560
it's kind of a lot of memory fastest the

776
00:30:03,560 --> 00:30:04,790
application servers can be these you

777
00:30:04,790 --> 00:30:08,240
know off-brand ec2 instances they're not

778
00:30:08,240 --> 00:30:09,740
gonna have as much memory so maybe I

779
00:30:09,740 --> 00:30:11,360
don't want to blast it with all 1

780
00:30:11,360 --> 00:30:13,580
million tuples that's sort of a thinking

781
00:30:13,580 --> 00:30:19,400
of it right I don't know I I don't know

782
00:30:19,400 --> 00:30:20,630
what difference it I actually don't know

783
00:30:20,630 --> 00:30:22,100
what difference how different it is to

784
00:30:22,100 --> 00:30:24,200
do two different things right cuz also

785
00:30:24,200 --> 00:30:27,230
to like you could imagine the the way

786
00:30:27,230 --> 00:30:28,370
you implement cursors could be different

787
00:30:28,370 --> 00:30:30,620
too cuz like it could be I execute the

788
00:30:30,620 --> 00:30:30,980
query

789
00:30:30,980 --> 00:30:32,899
I now buffer the result and you call get

790
00:30:32,899 --> 00:30:34,190
next on the cursor I'm miss feeding

791
00:30:34,190 --> 00:30:37,070
through that or I could have it be set

792
00:30:37,070 --> 00:30:39,799
up where I have a pipeline breaker where

793
00:30:39,799 --> 00:30:41,779
I say here's the final result of a query

794
00:30:41,779 --> 00:30:45,320
and called get next get next inside the

795
00:30:45,320 --> 00:30:46,970
execution engine get a bunch of tuples

796
00:30:46,970 --> 00:30:48,080
but one time you've reached my cursor

797
00:30:48,080 --> 00:30:50,299
limit then I hand that back to the

798
00:30:50,299 --> 00:30:51,470
client because maybe they're not gonna

799
00:30:51,470 --> 00:30:53,269
come back and ask for more if they do

800
00:30:53,269 --> 00:30:54,980
come ask for more then I'll just now s

801
00:30:54,980 --> 00:30:56,630
cute the rest of the query could stage

802
00:30:56,630 --> 00:30:57,529
it that way

803
00:30:57,529 --> 00:31:00,019
I think everyone buffers it and then

804
00:31:00,019 --> 00:31:01,429
gives you a handle to the cursor of the

805
00:31:01,429 --> 00:31:03,860
buffer but you could implement it the

806
00:31:03,860 --> 00:31:05,419
other way I think that's how it was

807
00:31:05,419 --> 00:31:06,830
originally envisioned back but this like

808
00:31:06,830 --> 00:31:09,860
the 1980s in the pipeline not the

809
00:31:09,860 --> 00:31:11,450
pipeline model but like the the volcano

810
00:31:11,450 --> 00:31:14,210
model wait is the pipeline it's about

811
00:31:14,210 --> 00:31:16,480
you volcano iterator pipeline model yes

812
00:31:16,480 --> 00:31:22,700
same thing okay so this is just a table

813
00:31:22,700 --> 00:31:25,580
showing what you know what other systems

814
00:31:25,580 --> 00:31:27,559
are actually using the Mexico's wire

815
00:31:27,559 --> 00:31:29,570
protocol I thought they're actually more

816
00:31:29,570 --> 00:31:31,970
system using hive but the only one I

817
00:31:31,970 --> 00:31:33,080
could find that speaks the high wire

818
00:31:33,080 --> 00:31:36,710
protocol is spark so my sequel is very

819
00:31:36,710 --> 00:31:38,269
common a bunch of these though are

820
00:31:38,269 --> 00:31:41,330
hacked up versions of my sequel like mem

821
00:31:41,330 --> 00:31:43,039
sequel in the very beginning actually

822
00:31:43,039 --> 00:31:46,070
wasn't a it was not a full-fledged

823
00:31:46,070 --> 00:31:47,690
database system it was a storage engine

824
00:31:47,690 --> 00:31:50,120
like in ODB or rocks DB that sat

825
00:31:50,120 --> 00:31:51,860
underneath my sequel so they got to my

826
00:31:51,860 --> 00:31:53,630
sequel you know compatibility and wire

827
00:31:53,630 --> 00:31:55,549
protocol for free eventually with all

828
00:31:55,549 --> 00:31:56,419
that out and they wrote everything

829
00:31:56,419 --> 00:31:58,340
themselves because they otherwise you'd

830
00:31:58,340 --> 00:31:59,990
violate the GPL and their proprietary

831
00:31:59,990 --> 00:32:02,120
but so they basically speak the my

832
00:32:02,120 --> 00:32:03,470
sequel protocol now so they are my

833
00:32:03,470 --> 00:32:07,429
secret peddled cluster is based on my

834
00:32:07,429 --> 00:32:09,889
sequel but it had sort of a layer above

835
00:32:09,889 --> 00:32:11,600
that that was distributed so there's a

836
00:32:11,600 --> 00:32:13,190
there's a framework called my sequel

837
00:32:13,190 --> 00:32:15,919
proxy that gives you like a gives you

838
00:32:15,919 --> 00:32:16,820
like a middleware front-end

839
00:32:16,820 --> 00:32:18,380
implementation of the my sequel wire

840
00:32:18,380 --> 00:32:20,240
protocol and a bunch of these other ones

841
00:32:20,240 --> 00:32:21,919
are sort of again speaking the wire

842
00:32:21,919 --> 00:32:24,049
protocol Amazon Aurora is slightly

843
00:32:24,049 --> 00:32:24,649
different

844
00:32:24,649 --> 00:32:26,720
I'll talk about in a second here's a

845
00:32:26,720 --> 00:32:27,980
bunch of these ones that are basement

846
00:32:27,980 --> 00:32:30,289
Postgres so a couple of these are

847
00:32:30,289 --> 00:32:33,110
written from scratch like hyper copy HDD

848
00:32:33,110 --> 00:32:35,929
our old system Umbra these are systems

849
00:32:35,929 --> 00:32:37,940
where like we look the specification of

850
00:32:37,940 --> 00:32:39,830
the purpose wire protocol and read

851
00:32:39,830 --> 00:32:42,440
implemented it just in our system things

852
00:32:42,440 --> 00:32:44,380
like redshift greenplum Vertica

853
00:32:44,380 --> 00:32:45,670
and I think maybe you could bite these

854
00:32:45,670 --> 00:32:48,160
are they the original code they started

855
00:32:48,160 --> 00:32:50,200
with Postgres and they ripped out the

856
00:32:50,200 --> 00:32:51,940
parts they didn't want and then rewrote

857
00:32:51,940 --> 00:32:54,010
it for to do whatever they wanted to do

858
00:32:54,010 --> 00:32:56,050
so they kept that front end piece of

859
00:32:56,050 --> 00:32:58,450
code the networking layer for for

860
00:32:58,450 --> 00:33:02,020
Postgres so the reason why Aurora is

861
00:33:02,020 --> 00:33:06,580
different is because because Amazon

862
00:33:06,580 --> 00:33:08,350
controls the whole stack of like if

863
00:33:08,350 --> 00:33:10,330
you're running in in in in their cloud

864
00:33:10,330 --> 00:33:12,280
center they collude to control the

865
00:33:12,280 --> 00:33:13,570
networking layer excuse you layer and

866
00:33:13,570 --> 00:33:15,400
the storage layer so what they do is

867
00:33:15,400 --> 00:33:16,570
actually super interesting at least from

868
00:33:16,570 --> 00:33:17,560
my sequel I don't know if they do this

869
00:33:17,560 --> 00:33:19,660
for Postgres they actually take out some

870
00:33:19,660 --> 00:33:21,400
of the networking logic for the wire

871
00:33:21,400 --> 00:33:24,160
protocol for my sequel and shove it up

872
00:33:24,160 --> 00:33:26,200
into the Amazon like load balancing

873
00:33:26,200 --> 00:33:28,240
networking layer right so now when you

874
00:33:28,240 --> 00:33:30,730
hit like when your application speaks to

875
00:33:30,730 --> 00:33:33,910
your database instance and running an

876
00:33:33,910 --> 00:33:35,770
Aurora you may not actually be hitting

877
00:33:35,770 --> 00:33:37,720
up the actual Aurora system itself

878
00:33:37,720 --> 00:33:39,790
you're running up and there's networking

879
00:33:39,790 --> 00:33:42,100
there's never a cool there's never pink

880
00:33:42,100 --> 00:33:43,570
layer up above that doesn't load

881
00:33:43,570 --> 00:33:44,560
balancing for you which is really

882
00:33:44,560 --> 00:33:47,050
fascinating and what they can do is they

883
00:33:47,050 --> 00:33:51,520
can switch over sort of transparently

884
00:33:51,520 --> 00:33:53,770
from one instance to another like if say

885
00:33:53,770 --> 00:33:55,630
I'm running on a small machine I'm gonna

886
00:33:55,630 --> 00:33:57,550
upgrade Amazon to a my Aurora instance

887
00:33:57,550 --> 00:33:59,620
or a bigger machine in the networking

888
00:33:59,620 --> 00:34:01,150
layer because it's now decoupled from

889
00:34:01,150 --> 00:34:04,480
the actual database server they can copy

890
00:34:04,480 --> 00:34:07,270
over your session variables from from

891
00:34:07,270 --> 00:34:09,250
you know form all your clients from one

892
00:34:09,250 --> 00:34:10,780
server to the other then it's had the

893
00:34:10,780 --> 00:34:13,239
networking layer switch over to the the

894
00:34:13,239 --> 00:34:14,500
new instance and it looks like you

895
00:34:14,500 --> 00:34:16,810
magically just got more more more you

896
00:34:16,810 --> 00:34:19,060
know more RAM more CPUs without actually

897
00:34:19,060 --> 00:34:20,500
you know closing any of your connections

898
00:34:20,500 --> 00:34:21,790
so that's crazy

899
00:34:21,790 --> 00:34:23,520
I think only Amazon can do that because

900
00:34:23,520 --> 00:34:27,909
it's Amazon right so we take this

901
00:34:27,909 --> 00:34:29,469
offline implementing this has been a

902
00:34:29,469 --> 00:34:31,629
huge pain taxes been awful you talk to

903
00:34:31,629 --> 00:34:34,300
Matt about it this is our third attempt

904
00:34:34,300 --> 00:34:35,710
trying to read them the post goes wire

905
00:34:35,710 --> 00:34:38,370
protocol and it's it's really ugly

906
00:34:38,370 --> 00:34:40,120
because they have two different modes

907
00:34:40,120 --> 00:34:44,020
which is a mess okay all right so let's

908
00:34:44,020 --> 00:34:45,159
talk about the paper you guys read today

909
00:34:45,159 --> 00:34:50,500
for this class so as I said the where we

910
00:34:50,500 --> 00:34:52,210
can have opportunity to get better

911
00:34:52,210 --> 00:34:54,550
performance in it and improve the wire

912
00:34:54,550 --> 00:34:56,860
protocol is when we serialize the data

913
00:34:56,860 --> 00:34:57,880
back to the

914
00:34:57,880 --> 00:34:59,530
client right we can ignore the cursor

915
00:34:59,530 --> 00:35:01,300
stuffed assume that they ran a query and

916
00:35:01,300 --> 00:35:02,560
they want to they want a bunch of

917
00:35:02,560 --> 00:35:04,720
results and the papery how do you guys

918
00:35:04,720 --> 00:35:07,420
read came from the same authors that are

919
00:35:07,420 --> 00:35:09,910
building dub DB or bridge of people are

920
00:35:09,910 --> 00:35:12,070
also working on Monet DB at a CWI and

921
00:35:12,070 --> 00:35:14,410
what they were focused on was doing

922
00:35:14,410 --> 00:35:16,780
these large data exports so not so much

923
00:35:16,780 --> 00:35:18,280
running complex queries and getting back

924
00:35:18,280 --> 00:35:18,460
up

925
00:35:18,460 --> 00:35:21,040
you know aggregated results but I have

926
00:35:21,040 --> 00:35:23,470
my Python or data science application

927
00:35:23,470 --> 00:35:25,180
running some results and I have all my

928
00:35:25,180 --> 00:35:27,130
database my data in my sequel database

929
00:35:27,130 --> 00:35:29,140
how quickly can I get that data out and

930
00:35:29,140 --> 00:35:32,310
put it into my machine learning pipeline

931
00:35:32,310 --> 00:35:34,780
so a lot of things were talked about

932
00:35:34,780 --> 00:35:37,270
today look like all the stores stuff we

933
00:35:37,270 --> 00:35:39,160
talked about before right how to do

934
00:35:39,160 --> 00:35:40,840
compression how to do the row versus

935
00:35:40,840 --> 00:35:42,730
calm stuff because that's essentially

936
00:35:42,730 --> 00:35:44,920
what it is right we have some giant

937
00:35:44,920 --> 00:35:47,320
chunk and data what's the optimal way

938
00:35:47,320 --> 00:35:50,500
that we should organize it to send it

939
00:35:50,500 --> 00:35:53,140
over the wire and it's basically the

940
00:35:53,140 --> 00:35:55,090
same thing we want to store a bunch of

941
00:35:55,090 --> 00:35:57,250
data on disk or in memory what's the

942
00:35:57,250 --> 00:36:01,720
optimal way to do that right so the

943
00:36:01,720 --> 00:36:02,860
other thing I'll say to you also is that

944
00:36:02,860 --> 00:36:05,490
everything we're to talk about here

945
00:36:05,490 --> 00:36:08,500
whatever however we organize the data on

946
00:36:08,500 --> 00:36:11,260
the server side and then send it over to

947
00:36:11,260 --> 00:36:13,300
the client the client has to be able to

948
00:36:13,300 --> 00:36:15,670
interpret that and reverse it so that's

949
00:36:15,670 --> 00:36:18,640
gonna somewhat limit what we can

950
00:36:18,640 --> 00:36:19,990
actually do because we don't want to

951
00:36:19,990 --> 00:36:21,670
burden the client with actually doing a

952
00:36:21,670 --> 00:36:24,970
ton of work now again they're focusing

953
00:36:24,970 --> 00:36:27,750
on doing these bulk exports of the data

954
00:36:27,750 --> 00:36:30,370
but a lot of times the same client

955
00:36:30,370 --> 00:36:32,050
driver you would use in other systems

956
00:36:32,050 --> 00:36:33,610
like the same client driver you would

957
00:36:33,610 --> 00:36:36,040
use for your Android application would

958
00:36:36,040 --> 00:36:37,450
be the same client driver you would use

959
00:36:37,450 --> 00:36:39,850
for whatever your applications are

960
00:36:39,850 --> 00:36:42,550
running on a you know giant xeon box so

961
00:36:42,550 --> 00:36:44,470
now no one's downloading a terabyte of

962
00:36:44,470 --> 00:36:45,940
data to their cell phone that's stupid

963
00:36:45,940 --> 00:36:48,010
right but like it just means that we

964
00:36:48,010 --> 00:36:49,390
need a little support whatever the

965
00:36:49,390 --> 00:36:51,250
optimizations we have apply here for the

966
00:36:51,250 --> 00:36:52,630
data we have to ever be able to reverse

967
00:36:52,630 --> 00:36:54,310
them and to interpret them so that that

968
00:36:54,310 --> 00:36:58,140
means that we can't be too heavy weight

969
00:36:58,140 --> 00:37:00,100
and because we don't want have to

970
00:37:00,100 --> 00:37:01,900
duplicate that that that logic in a

971
00:37:01,900 --> 00:37:05,440
bunch of locations right like again if i

972
00:37:05,440 --> 00:37:07,300
want to support all the different

973
00:37:07,300 --> 00:37:08,710
programming languages and i have native

974
00:37:08,710 --> 00:37:09,850
drivers for each of these program

975
00:37:09,850 --> 00:37:11,740
languages whatever i need to do to

976
00:37:11,740 --> 00:37:13,570
decompress data in one language I got to

977
00:37:13,570 --> 00:37:15,970
do for another one right so sort of like

978
00:37:15,970 --> 00:37:17,800
the lowest common denominator which

979
00:37:17,800 --> 00:37:19,119
which is somewhat limiting but it is

980
00:37:19,119 --> 00:37:22,960
what it is all right so the first thing

981
00:37:22,960 --> 00:37:24,310
is going to be talked about is the row

982
00:37:24,310 --> 00:37:28,089
versus column so the odbc jdbc are

983
00:37:28,089 --> 00:37:32,260
inherently row oriented api's we we're

984
00:37:32,260 --> 00:37:33,609
gonna the servers are always gonna

985
00:37:33,609 --> 00:37:36,820
package up the tuples and results one

986
00:37:36,820 --> 00:37:38,500
tuple at a time and sort of package that

987
00:37:38,500 --> 00:37:40,000
as a single message that sends it gets

988
00:37:40,000 --> 00:37:40,660
sent over the network

989
00:37:40,660 --> 00:37:41,890
now with these stream a bunch of

990
00:37:41,890 --> 00:37:43,900
messages all at once but the way these

991
00:37:43,900 --> 00:37:45,640
these the servers are mostly written is

992
00:37:45,640 --> 00:37:47,290
that it assumes that I'm gonna iterate

993
00:37:47,290 --> 00:37:49,359
on the server side over one tuple at a

994
00:37:49,359 --> 00:37:51,130
time I'll construct a message that says

995
00:37:51,130 --> 00:37:53,020
here's what's actually in this tuple and

996
00:37:53,020 --> 00:37:54,970
I put as many of those messages up I

997
00:37:54,970 --> 00:37:56,920
guess I can to my packet ship that over

998
00:37:56,920 --> 00:37:58,240
and then the client has to reverse that

999
00:37:58,240 --> 00:38:01,750
so back in the 1990s when they first

1000
00:38:01,750 --> 00:38:04,240
started building to be seen JDBC this

1001
00:38:04,240 --> 00:38:07,420
made sense because it was you you were

1002
00:38:07,420 --> 00:38:09,190
either running all three applications

1003
00:38:09,190 --> 00:38:12,040
where the result sets are small like go

1004
00:38:12,040 --> 00:38:13,720
get Andes account record go get all the

1005
00:38:13,720 --> 00:38:15,400
orders that Annie bought from Amazon

1006
00:38:15,400 --> 00:38:18,099
that that's not a lot of data and it's

1007
00:38:18,099 --> 00:38:20,619
not not a lot of tuples if you're doing

1008
00:38:20,619 --> 00:38:24,250
analytics oftentimes would just be you

1009
00:38:24,250 --> 00:38:27,640
know computing the the the sales totals

1010
00:38:27,640 --> 00:38:29,050
of you know on a quarterly basis and

1011
00:38:29,050 --> 00:38:30,790
then you do something aggregations on

1012
00:38:30,790 --> 00:38:32,859
that so like the query the query is a

1013
00:38:32,859 --> 00:38:34,000
bit more complex and a little to be

1014
00:38:34,000 --> 00:38:34,869
decided but the amount of the end you're

1015
00:38:34,869 --> 00:38:37,180
getting back is not it's not a lot but

1016
00:38:37,180 --> 00:38:39,010
again as I said the duck TB guys are

1017
00:38:39,010 --> 00:38:41,230
focused on exposing the database

1018
00:38:41,230 --> 00:38:43,570
contents to these modern machine

1019
00:38:43,570 --> 00:38:47,619
learning software and in this world we

1020
00:38:47,619 --> 00:38:50,740
want things as as columns or matrices so

1021
00:38:50,740 --> 00:38:53,080
this row oriented approach is is as

1022
00:38:53,080 --> 00:38:56,440
limiting so what they propose to do is

1023
00:38:56,440 --> 00:38:59,470
that instead of sending over in a row or

1024
00:38:59,470 --> 00:39:01,119
engine format we could actually send it

1025
00:39:01,119 --> 00:39:04,420
over as vectors and in particular the

1026
00:39:04,420 --> 00:39:05,770
way they're gonna do this is they're

1027
00:39:05,770 --> 00:39:07,119
gonna organize a bunch of tuples

1028
00:39:07,119 --> 00:39:10,359
together and within a block and then it

1029
00:39:10,359 --> 00:39:11,859
within that block they'll be organized

1030
00:39:11,859 --> 00:39:13,900
as columns so it's not like I'm gonna

1031
00:39:13,900 --> 00:39:17,260
stream over one column at a time in a

1032
00:39:17,260 --> 00:39:18,609
bunch of messages and then when I'm done

1033
00:39:18,609 --> 00:39:19,780
with that column switch over to the next

1034
00:39:19,780 --> 00:39:21,790
next column and do that they're gonna

1035
00:39:21,790 --> 00:39:23,740
say here's a bunch of tuples convert it

1036
00:39:23,740 --> 00:39:25,029
as a as a

1037
00:39:25,029 --> 00:39:26,469
I'm store within that block and then

1038
00:39:26,469 --> 00:39:28,630
ship that block over and then for the

1039
00:39:28,630 --> 00:39:30,279
next batch of tuples on the server side

1040
00:39:30,279 --> 00:39:32,829
you do the same thing so we didn't talk

1041
00:39:32,829 --> 00:39:34,919
about this exactly when we we talk about

1042
00:39:34,919 --> 00:39:37,959
stores layouts but this is called the

1043
00:39:37,959 --> 00:39:38,709
packs model

1044
00:39:38,709 --> 00:39:42,459
I was actually invented not here at CMU

1045
00:39:42,459 --> 00:39:45,219
but by a professor who used to be here

1046
00:39:45,219 --> 00:39:48,009
at CMU and now she's at EPFL and this is

1047
00:39:48,009 --> 00:39:49,029
actually what we do in our day to be

1048
00:39:49,029 --> 00:39:51,549
system now we organize our data as one

1049
00:39:51,549 --> 00:39:53,109
megabyte blocks and then within that

1050
00:39:53,109 --> 00:39:55,059
block we have all the attributes or

1051
00:39:55,059 --> 00:39:56,949
fields for a single tuple but each of

1052
00:39:56,949 --> 00:39:58,449
those fields will be organized as a

1053
00:39:58,449 --> 00:40:00,699
column store because we follow what we

1054
00:40:00,699 --> 00:40:02,409
follow the arrow does and this is used

1055
00:40:02,409 --> 00:40:11,099
in park' agent or yes the question is is

1056
00:40:11,099 --> 00:40:15,159
is sorry is is this approach to

1057
00:40:15,159 --> 00:40:18,489
effective or ODBC so again he doesn't

1058
00:40:18,489 --> 00:40:21,519
know about any of us he doesn't know

1059
00:40:21,519 --> 00:40:23,130
that I got a batch of two blows back and

1060
00:40:23,130 --> 00:40:26,739
their own as as columns it just because

1061
00:40:26,739 --> 00:40:28,630
they now the programming interface is

1062
00:40:28,630 --> 00:40:30,609
that is definitely row oriented right I

1063
00:40:30,609 --> 00:40:33,130
get a cursor a call get next and then I

1064
00:40:33,130 --> 00:40:34,749
do whatever need to do on that on that

1065
00:40:34,749 --> 00:40:37,119
single column or that single tuple I

1066
00:40:37,119 --> 00:40:39,279
can't tell it would we see gave me the

1067
00:40:39,279 --> 00:40:42,819
vector of a to give me the vector of

1068
00:40:42,819 --> 00:40:44,979
column vector of values for a single

1069
00:40:44,979 --> 00:40:49,089
column across all tuples so I think what

1070
00:40:49,089 --> 00:40:50,799
the proposing here is that you could

1071
00:40:50,799 --> 00:40:53,079
you'd have to rewrite or have your own

1072
00:40:53,079 --> 00:40:56,369
API at the application server level

1073
00:40:56,369 --> 00:41:00,069
application side API to support getting

1074
00:41:00,069 --> 00:41:02,919
these vectors I actually don't know

1075
00:41:02,919 --> 00:41:05,049
whether I don't know whether it would be

1076
00:41:05,049 --> 00:41:07,929
C as a way to say give me my results

1077
00:41:07,929 --> 00:41:10,679
that and just dump it out all at once I

1078
00:41:10,679 --> 00:41:12,999
all the code I've written using G a B C

1079
00:41:12,999 --> 00:41:14,679
or D C has always been like you know a

1080
00:41:14,679 --> 00:41:20,289
while can't get next okay so the benefit

1081
00:41:20,289 --> 00:41:21,459
we're gonna get from this is that if we

1082
00:41:21,459 --> 00:41:23,769
have everything as as a column store

1083
00:41:23,769 --> 00:41:25,630
then we apply all the techniques that we

1084
00:41:25,630 --> 00:41:26,919
talked about last week of compressing

1085
00:41:26,919 --> 00:41:28,269
our data because we know all the values

1086
00:41:28,269 --> 00:41:29,409
are going to be within the same domain

1087
00:41:29,409 --> 00:41:31,239
and we're gonna get a better compression

1088
00:41:31,239 --> 00:41:34,179
ratio so it's the same thing that we

1089
00:41:34,179 --> 00:41:36,130
talked about before right we can do the

1090
00:41:36,130 --> 00:41:37,599
naive compression approach where we just

1091
00:41:37,599 --> 00:41:38,440
take take

1092
00:41:38,440 --> 00:41:40,089
our bites that we have in our block that

1093
00:41:40,089 --> 00:41:42,040
we're sending over and we just run gzip

1094
00:41:42,040 --> 00:41:44,109
on it or snappy send that over to the

1095
00:41:44,109 --> 00:41:45,819
why the wire and the climb didn't just

1096
00:41:45,819 --> 00:41:48,849
just calls the same you know using the

1097
00:41:48,849 --> 00:41:51,280
same correction algorithm to decompress

1098
00:41:51,280 --> 00:41:53,950
it the other approach to do the column

1099
00:41:53,950 --> 00:41:56,770
not specific encoding like our le or the

1100
00:41:56,770 --> 00:41:58,839
dictionary encoding or the Delta

1101
00:41:58,839 --> 00:42:02,440
encoding as far as I know no system

1102
00:42:02,440 --> 00:42:05,200
actually does this this does show up in

1103
00:42:05,200 --> 00:42:07,150
in some systems like my secret weapon

1104
00:42:07,150 --> 00:42:09,220
use gzip of all things took a press data

1105
00:42:09,220 --> 00:42:12,550
so as they talked about in the paper

1106
00:42:12,550 --> 00:42:13,690
this is obviously you're gonna get a

1107
00:42:13,690 --> 00:42:17,470
better compression ratio if you have the

1108
00:42:17,470 --> 00:42:20,950
more data you have and what's also nice

1109
00:42:20,950 --> 00:42:24,040
about too for larger blocks this is

1110
00:42:24,040 --> 00:42:25,690
actually gonna work even better

1111
00:42:25,690 --> 00:42:28,810
and they say that this is the better way

1112
00:42:28,810 --> 00:42:32,260
to do this because the the approach is

1113
00:42:32,260 --> 00:42:34,089
agnostic to what the actual data is so

1114
00:42:34,089 --> 00:42:35,680
there's no logic on the client server

1115
00:42:35,680 --> 00:42:37,750
side to say oh I'm looking at this

1116
00:42:37,750 --> 00:42:39,040
column and it's dealt on coding so I

1117
00:42:39,040 --> 00:42:41,230
need to now basically replay the Delta

1118
00:42:41,230 --> 00:42:44,020
to give me back the original values if

1119
00:42:44,020 --> 00:42:45,339
I'm just using snappy I just take my

1120
00:42:45,339 --> 00:42:47,290
byte stream or byte array and just run

1121
00:42:47,290 --> 00:42:48,670
it through that and I get everything out

1122
00:42:48,670 --> 00:42:51,130
but I want the other thing they tell us

1123
00:42:51,130 --> 00:42:52,540
to talk about in the paper is that if

1124
00:42:52,540 --> 00:42:54,880
the network is slow then a more

1125
00:42:54,880 --> 00:42:57,790
heavyweight algorithm like gzip will be

1126
00:42:57,790 --> 00:42:59,530
preferable over something like snappy

1127
00:42:59,530 --> 00:43:02,380
because you're paying you know you're

1128
00:43:02,380 --> 00:43:04,270
paying a higher CPU overhead cost to get

1129
00:43:04,270 --> 00:43:06,369
to get a better compression ratio and

1130
00:43:06,369 --> 00:43:08,140
that's usually going to be a good

1131
00:43:08,140 --> 00:43:10,630
trade-off again this what is it sound

1132
00:43:10,630 --> 00:43:12,609
like it sounds like a disc right it's

1133
00:43:12,609 --> 00:43:14,950
which it is it's essentially a slow

1134
00:43:14,950 --> 00:43:16,240
piece of hardware that we need to get

1135
00:43:16,240 --> 00:43:18,579
data through like a straw from one side

1136
00:43:18,579 --> 00:43:21,339
to the other so again if we know it's

1137
00:43:21,339 --> 00:43:23,260
gonna be slow we're gonna have low

1138
00:43:23,260 --> 00:43:25,089
bandwidth then we want to do as much

1139
00:43:25,089 --> 00:43:27,400
work we can on the on the on the the

1140
00:43:27,400 --> 00:43:31,740
ingestion and reading of the data to

1141
00:43:31,740 --> 00:43:35,020
minimize that overhead so for this

1142
00:43:35,020 --> 00:43:36,250
reason they claimed that this is better

1143
00:43:36,250 --> 00:43:38,020
and like I said nobody I don't know of

1144
00:43:38,020 --> 00:43:41,890
any system that does this now we get in

1145
00:43:41,890 --> 00:43:43,060
the question of how we're actually going

1146
00:43:43,060 --> 00:43:44,410
to represent the data or how are you

1147
00:43:44,410 --> 00:43:47,890
going to serialize it so the first

1148
00:43:47,890 --> 00:43:50,069
approach is to do binary encoding where

1149
00:43:50,069 --> 00:43:52,369
again it's just like as we talked about

1150
00:43:52,369 --> 00:43:54,259
when we took like alignment and and

1151
00:43:54,259 --> 00:43:56,990
layout we would represent the data in

1152
00:43:56,990 --> 00:43:59,990
its binary form and that's typically

1153
00:43:59,990 --> 00:44:01,849
native to whatever like C or super ball

1154
00:44:01,849 --> 00:44:03,259
so what the hard it gives us if we're

1155
00:44:03,259 --> 00:44:05,299
following the the I Triple E 754

1156
00:44:05,299 --> 00:44:08,269
standard so what will happen is the

1157
00:44:08,269 --> 00:44:09,619
client-side I'll be responsible for

1158
00:44:09,619 --> 00:44:11,269
handing any ns because the server

1159
00:44:11,269 --> 00:44:12,829
doesn't know what you actually want so

1160
00:44:12,829 --> 00:44:15,049
the server will send it out in you know

1161
00:44:15,049 --> 00:44:16,640
in one in DNS and the client says oh

1162
00:44:16,640 --> 00:44:19,339
well I was told I you know the servers

1163
00:44:19,339 --> 00:44:20,809
running x86 and therefore he gave me

1164
00:44:20,809 --> 00:44:22,519
little endian but at mine running on my

1165
00:44:22,519 --> 00:44:24,230
cell phone I need big-endian to the

1166
00:44:24,230 --> 00:44:26,420
clients responsible for reversing that

1167
00:44:26,420 --> 00:44:27,769
but that's not too expensive

1168
00:44:27,769 --> 00:44:28,999
other than this happen having to copy

1169
00:44:28,999 --> 00:44:32,119
data the other thing that's be important

1170
00:44:32,119 --> 00:44:34,670
too is that if we can have whatever the

1171
00:44:34,670 --> 00:44:37,069
format is that the data system uses to

1172
00:44:37,069 --> 00:44:39,650
store data right in the actual columns

1173
00:44:39,650 --> 00:44:42,259
itself where the rows themselves if our

1174
00:44:42,259 --> 00:44:44,690
wire protocol can match this what we're

1175
00:44:44,690 --> 00:44:46,249
actually storing then it's gonna be

1176
00:44:46,249 --> 00:44:49,009
super cheap or have low overhead for us

1177
00:44:49,009 --> 00:44:50,960
to go take data out from a result of a

1178
00:44:50,960 --> 00:44:53,150
query and then put that into a packet so

1179
00:44:53,150 --> 00:44:55,700
send that over the wire so what I mean

1180
00:44:55,700 --> 00:44:58,579
that if using my our old system as an

1181
00:44:58,579 --> 00:45:01,999
example and our old system we built our

1182
00:45:01,999 --> 00:45:03,380
execution engine and Storage Manager

1183
00:45:03,380 --> 00:45:04,940
separately and then we sort of grafted

1184
00:45:04,940 --> 00:45:06,829
it onto Postgres and then when we

1185
00:45:06,829 --> 00:45:09,109
actually want to go put the the results

1186
00:45:09,109 --> 00:45:11,779
of queries into a packet and send it

1187
00:45:11,779 --> 00:45:13,819
over the process wire protocol how it

1188
00:45:13,819 --> 00:45:15,349
represented strings was different than

1189
00:45:15,349 --> 00:45:17,569
how we represented strings so we would

1190
00:45:17,569 --> 00:45:19,400
then have to convert it right and

1191
00:45:19,400 --> 00:45:21,410
basically it means copying the data you

1192
00:45:21,410 --> 00:45:23,180
know into our original format and copied

1193
00:45:23,180 --> 00:45:25,099
it into into and converted to post

1194
00:45:25,099 --> 00:45:26,960
business format so that extra copying

1195
00:45:26,960 --> 00:45:28,369
starts to add up because if you're doing

1196
00:45:28,369 --> 00:45:29,690
this for every single query and every

1197
00:45:29,690 --> 00:45:31,130
single tuple and every and every single

1198
00:45:31,130 --> 00:45:32,989
result then that you're spending all

1199
00:45:32,989 --> 00:45:34,160
your time to do in copying and

1200
00:45:34,160 --> 00:45:35,420
serializing deserializing

1201
00:45:35,420 --> 00:45:38,809
sucks right I mean with peloton we had

1202
00:45:38,809 --> 00:45:40,489
another mistake like we had like three

1203
00:45:40,489 --> 00:45:42,440
copies of updated just to get over the

1204
00:45:42,440 --> 00:45:44,809
wire protocol two of them you needed one

1205
00:45:44,809 --> 00:45:47,119
of them was was was was superfluous but

1206
00:45:47,119 --> 00:45:49,190
it probably reason why we killed that

1207
00:45:49,190 --> 00:45:52,839
system the other thing you can do too is

1208
00:45:52,839 --> 00:45:56,299
instead of implementing your own you

1209
00:45:56,299 --> 00:45:58,519
know binary format for sending over the

1210
00:45:58,519 --> 00:46:00,589
messages that you represent in getting

1211
00:46:00,589 --> 00:46:02,359
messages you actually can rely on these

1212
00:46:02,359 --> 00:46:04,099
serial serialization open source

1213
00:46:04,099 --> 00:46:05,480
stabilization formats that are out there

1214
00:46:05,480 --> 00:46:07,430
two most famous ones are Google's

1215
00:46:07,430 --> 00:46:09,170
protocol buffers or Facebook thrift

1216
00:46:09,170 --> 00:46:12,109
right think about this as you define in

1217
00:46:12,109 --> 00:46:16,760
a DSL what a packet looks like what the

1218
00:46:16,760 --> 00:46:19,099
types are and so forth and then they

1219
00:46:19,099 --> 00:46:22,250
have a way to then to compile and

1220
00:46:22,250 --> 00:46:24,619
generate you code that you can then use

1221
00:46:24,619 --> 00:46:26,240
to build struck sand fill out these

1222
00:46:26,240 --> 00:46:28,550
these buffers and then they'll sterilize

1223
00:46:28,550 --> 00:46:29,900
it for you so that you can send over the

1224
00:46:29,900 --> 00:46:32,960
network I don't know of any system that

1225
00:46:32,960 --> 00:46:35,530
actually does uses protocol buffers or

1226
00:46:35,530 --> 00:46:37,400
flatbuffers is the new version of

1227
00:46:37,400 --> 00:46:38,540
protocol buffers I think it's zero

1228
00:46:38,540 --> 00:46:42,020
copying so it's faster heíd uses thrift

1229
00:46:42,020 --> 00:46:43,520
thrift brings you a bunch of other stuff

1230
00:46:43,520 --> 00:46:45,849
like RPC you know and like other

1231
00:46:45,849 --> 00:46:48,170
networking communication protocol stuff

1232
00:46:48,170 --> 00:46:50,480
which is more than maybe you actually

1233
00:46:50,480 --> 00:46:52,490
want but faith hive is the only one that

1234
00:46:52,490 --> 00:46:56,180
know that uses this so I would not

1235
00:46:56,180 --> 00:46:59,390
recommend these things because these are

1236
00:46:59,390 --> 00:47:02,750
actually gonna be a bit verbose right

1237
00:47:02,750 --> 00:47:05,630
like they would have to record all this

1238
00:47:05,630 --> 00:47:07,130
extra metadata to tell you what the type

1239
00:47:07,130 --> 00:47:08,960
actually of the data actually storing in

1240
00:47:08,960 --> 00:47:12,290
our networking protocol if we if we if

1241
00:47:12,290 --> 00:47:13,490
we do it ourselves

1242
00:47:13,490 --> 00:47:15,710
maybe just in the header of the packets

1243
00:47:15,710 --> 00:47:17,030
we send over to say hey we're about to

1244
00:47:17,030 --> 00:47:17,869
send you a bunch of tuples that have

1245
00:47:17,869 --> 00:47:19,490
these types here they are rather than

1246
00:47:19,490 --> 00:47:20,750
these things I think they have to they

1247
00:47:20,750 --> 00:47:22,220
make multiple copies of that metadata

1248
00:47:22,220 --> 00:47:24,980
right for every single message so for

1249
00:47:24,980 --> 00:47:27,079
this reason I I don't recommend that

1250
00:47:27,079 --> 00:47:28,790
this you want to you want to roll your

1251
00:47:28,790 --> 00:47:33,020
own all right the image so in addition

1252
00:47:33,020 --> 00:47:34,700
your the metadata about what my types

1253
00:47:34,700 --> 00:47:36,410
are we got to keep track of like how do

1254
00:47:36,410 --> 00:47:40,430
we actually represent nulls the sizes

1255
00:47:40,430 --> 00:47:42,980
are our data right all that gets gets

1256
00:47:42,980 --> 00:47:44,420
expensive and some systems do it better

1257
00:47:44,420 --> 00:47:48,319
than others the alternate is that the

1258
00:47:48,319 --> 00:47:51,109
server just sends over all your data as

1259
00:47:51,109 --> 00:47:55,730
plain text right and so the advantage of

1260
00:47:55,730 --> 00:47:56,839
this is that you don't have to worry

1261
00:47:56,839 --> 00:47:58,670
about in these Indian Asst it's up to

1262
00:47:58,670 --> 00:48:00,290
now the clients responsibility to figure

1263
00:48:00,290 --> 00:48:01,579
out how to actually interpret what what

1264
00:48:01,579 --> 00:48:02,770
it is it you're actually looking at

1265
00:48:02,770 --> 00:48:06,680
right so yeah think of it this way so

1266
00:48:06,680 --> 00:48:09,890
say I have my server side I my my query

1267
00:48:09,890 --> 00:48:11,930
result has one was as one two boy has

1268
00:48:11,930 --> 00:48:13,369
one attribute the number of one two

1269
00:48:13,369 --> 00:48:15,319
three four five six so there's a 32-bit

1270
00:48:15,319 --> 00:48:17,599
integer I can represent in four bytes so

1271
00:48:17,599 --> 00:48:19,340
if I send this over in binary form

1272
00:48:19,340 --> 00:48:20,990
just say hey I have a four byte integer

1273
00:48:20,990 --> 00:48:23,390
on alternative could be I could convert

1274
00:48:23,390 --> 00:48:25,010
one two three four five six into the

1275
00:48:25,010 --> 00:48:26,990
string of characters one two three four

1276
00:48:26,990 --> 00:48:29,960
five six and send that over now in that

1277
00:48:29,960 --> 00:48:32,330
case assuming I'm asking in coded I need

1278
00:48:32,330 --> 00:48:34,100
one byte for every single character I

1279
00:48:34,100 --> 00:48:36,530
have six numbers so I need six bytes for

1280
00:48:36,530 --> 00:48:38,900
those but then depending on how I'm

1281
00:48:38,900 --> 00:48:42,140
representing either the length or say

1282
00:48:42,140 --> 00:48:43,190
help you know how long the thing

1283
00:48:43,190 --> 00:48:45,260
actually is I would need an extra byte

1284
00:48:45,260 --> 00:48:47,060
potentially to say here's a null

1285
00:48:47,060 --> 00:48:48,440
terminator or here's the length of the

1286
00:48:48,440 --> 00:48:51,350
string and then now on the client side

1287
00:48:51,350 --> 00:48:53,690
is called a 2 I if you're using C to

1288
00:48:53,690 --> 00:48:56,210
convert this string into the correct

1289
00:48:56,210 --> 00:48:58,640
form that we can then hand off to ODBC

1290
00:48:58,640 --> 00:49:02,570
or JDBC so this seems kind of crazy why

1291
00:49:02,570 --> 00:49:04,600
would actually one ever want to do this

1292
00:49:04,600 --> 00:49:07,150
you see it as in systems that support

1293
00:49:07,150 --> 00:49:09,890
essentially JSON types or JSON result

1294
00:49:09,890 --> 00:49:14,360
sets as like the output of a query Monay

1295
00:49:14,360 --> 00:49:15,470
DB we're seeing a second actually

1296
00:49:15,470 --> 00:49:18,860
supports this as well I forget why I

1297
00:49:18,860 --> 00:49:20,210
think it's just for historical reasons

1298
00:49:20,210 --> 00:49:22,970
they did this but as we'll see in the

1299
00:49:22,970 --> 00:49:24,770
results you know storing in the binary

1300
00:49:24,770 --> 00:49:26,150
format is the better way to do this

1301
00:49:26,150 --> 00:49:31,940
always okay all right all right the last

1302
00:49:31,940 --> 00:49:32,720
time you got talked about is how we

1303
00:49:32,720 --> 00:49:34,040
actually handle strings and I sort of

1304
00:49:34,040 --> 00:49:37,310
mentioned this just now so the three

1305
00:49:37,310 --> 00:49:38,600
approaches again the same thing but

1306
00:49:38,600 --> 00:49:39,650
actually we want to do in our database

1307
00:49:39,650 --> 00:49:42,380
system do we just do the standard C way

1308
00:49:42,380 --> 00:49:44,240
and have a null byte at the end of the

1309
00:49:44,240 --> 00:49:45,620
string to denote the end of the string

1310
00:49:45,620 --> 00:49:47,060
so now if I'm parsing the packet that

1311
00:49:47,060 --> 00:49:48,200
I'm getting over the network

1312
00:49:48,200 --> 00:49:50,660
as soon as I see this is no Terminator

1313
00:49:50,660 --> 00:49:52,430
character I know that that this is the

1314
00:49:52,430 --> 00:49:56,570
end of the string and then the manage of

1315
00:49:56,570 --> 00:49:58,580
this is I use all my clients I can use

1316
00:49:58,580 --> 00:50:00,590
all the sturby standard C API

1317
00:50:00,590 --> 00:50:02,390
strings string functions because they

1318
00:50:02,390 --> 00:50:03,530
know how to operate on strings with

1319
00:50:03,530 --> 00:50:06,380
multimeters the other approach is in how

1320
00:50:06,380 --> 00:50:06,980
we do this

1321
00:50:06,980 --> 00:50:08,450
natively in our database system where we

1322
00:50:08,450 --> 00:50:09,890
just add the length of the string to the

1323
00:50:09,890 --> 00:50:11,120
beginning of the pipes of the string so

1324
00:50:11,120 --> 00:50:12,860
we know the client knows how far needs

1325
00:50:12,860 --> 00:50:13,880
to jump ahead to find everything you

1326
00:50:13,880 --> 00:50:16,640
need the last one would be like a char

1327
00:50:16,640 --> 00:50:18,830
field instead of a varchar' where you

1328
00:50:18,830 --> 00:50:24,620
just use you have a fixed size the bytes

1329
00:50:24,620 --> 00:50:27,260
that you use just represent every every

1330
00:50:27,260 --> 00:50:29,870
string for every tuple well for every

1331
00:50:29,870 --> 00:50:32,870
attribute of a tuple you have a fixed

1332
00:50:32,870 --> 00:50:33,380
size

1333
00:50:33,380 --> 00:50:35,450
and then you just Pat out whatever the

1334
00:50:35,450 --> 00:50:37,220
value is for each individual to pool to

1335
00:50:37,220 --> 00:50:40,160
fill out the rest of the the rest of

1336
00:50:40,160 --> 00:50:41,720
that size the rest of that that that

1337
00:50:41,720 --> 00:50:44,480
allocated space so this seems kind of

1338
00:50:44,480 --> 00:50:47,150
also wasteful as well but like if most

1339
00:50:47,150 --> 00:50:50,360
of my strings are say you know assessed

1340
00:50:50,360 --> 00:50:52,490
by my chart field to be 16 16 characters

1341
00:50:52,490 --> 00:50:54,350
and most my strings are eight characters

1342
00:50:54,350 --> 00:50:56,480
or nine characters I'm a bunch of zeros

1343
00:50:56,480 --> 00:50:58,940
and if I'm using gzip or snappy that's a

1344
00:50:58,940 --> 00:50:59,930
good opportunity for get good

1345
00:50:59,930 --> 00:51:01,190
compression because you can see repeated

1346
00:51:01,190 --> 00:51:02,510
byte sequences over and over again I

1347
00:51:02,510 --> 00:51:04,700
think though in the in the paper they

1348
00:51:04,700 --> 00:51:06,140
discussed that this only really makes

1349
00:51:06,140 --> 00:51:07,490
sense think it's the best performance if

1350
00:51:07,490 --> 00:51:09,230
like all your streams are like one

1351
00:51:09,230 --> 00:51:12,710
character right and then the paper also

1352
00:51:12,710 --> 00:51:15,200
talks about how sometimes this is faster

1353
00:51:15,200 --> 00:51:17,870
or sometimes this is faster right it

1354
00:51:17,870 --> 00:51:19,730
just depends on what your strengths look

1355
00:51:19,730 --> 00:51:22,880
like and as far as they know no system

1356
00:51:22,880 --> 00:51:24,020
is actually gonna implement both you

1357
00:51:24,020 --> 00:51:25,460
just pick one and stick with it

1358
00:51:25,460 --> 00:51:27,290
because it'd be too much engineering

1359
00:51:27,290 --> 00:51:29,450
overhead both on the server side and the

1360
00:51:29,450 --> 00:51:31,880
client side to have missed support both

1361
00:51:31,880 --> 00:51:35,410
of these right the other thing to point

1362
00:51:35,410 --> 00:51:37,820
point out too as well is that the

1363
00:51:37,820 --> 00:51:39,410
performance are gonna get depending on

1364
00:51:39,410 --> 00:51:41,180
how you represent strings is not going

1365
00:51:41,180 --> 00:51:43,730
to be it's not in a you know independent

1366
00:51:43,730 --> 00:51:45,470
of just what the approach you're using

1367
00:51:45,470 --> 00:51:47,450
if I'm doing compression then sometimes

1368
00:51:47,450 --> 00:51:48,590
this would be really good and the other

1369
00:51:48,590 --> 00:51:51,080
ones could be bad so again there's a

1370
00:51:51,080 --> 00:51:52,730
multiplicative effect of based on how

1371
00:51:52,730 --> 00:51:55,040
we're designing all and what compression

1372
00:51:55,040 --> 00:51:56,030
scheme we're going to use and what the

1373
00:51:56,030 --> 00:51:57,620
put the we're doing Road services

1374
00:51:57,620 --> 00:52:00,580
counselor all these things combined will

1375
00:52:00,580 --> 00:52:02,990
you know affect what the performance is

1376
00:52:02,990 --> 00:52:06,500
gonna be all right so let's just show

1377
00:52:06,500 --> 00:52:10,250
two quick quick graphs so they did two

1378
00:52:10,250 --> 00:52:11,450
experiments on the paper the first one

1379
00:52:11,450 --> 00:52:13,640
is we're gonna go measure the time it

1380
00:52:13,640 --> 00:52:15,650
takes to send one tuple and time it

1381
00:52:15,650 --> 00:52:17,870
takes to send a million tuples and so

1382
00:52:17,870 --> 00:52:19,760
they're gonna compare against my sequel

1383
00:52:19,760 --> 00:52:23,030
both width without gzip and enabled own

1384
00:52:23,030 --> 00:52:25,670
a DVD Oracle MongoDB db2 and hive so

1385
00:52:25,670 --> 00:52:27,740
again although MongoDB doesn't support

1386
00:52:27,740 --> 00:52:28,790
sequel

1387
00:52:28,790 --> 00:52:31,970
they still support an OTP ODBC driver so

1388
00:52:31,970 --> 00:52:35,540
this works so what you see is going

1389
00:52:35,540 --> 00:52:39,260
across is that hive is actually can do

1390
00:52:39,260 --> 00:52:41,630
the worst here followed by db2 but then

1391
00:52:41,630 --> 00:52:43,640
these other ones here are roughly all

1392
00:52:43,640 --> 00:52:45,070
about the same

1393
00:52:45,070 --> 00:52:46,730
what's in the

1394
00:52:46,730 --> 00:52:48,530
though is that Moni to be is the only

1395
00:52:48,530 --> 00:52:49,850
one of these ones doing text encoding

1396
00:52:49,850 --> 00:52:51,710
where everything else is doing binary

1397
00:52:51,710 --> 00:52:53,930
encoding and it still outperforms the

1398
00:52:53,930 --> 00:52:55,490
other ones that doing binary encoding

1399
00:52:55,490 --> 00:52:59,150
has a case of of dB - I don't know why

1400
00:52:59,150 --> 00:53:02,270
this is slow we'll see in the next slide

1401
00:53:02,270 --> 00:53:03,920
it's more pronounced but at least his

1402
00:53:03,920 --> 00:53:05,390
oracle and db2 they have their own

1403
00:53:05,390 --> 00:53:07,760
confirmation message that the client

1404
00:53:07,760 --> 00:53:09,140
sends to the server and say hey i got

1405
00:53:09,140 --> 00:53:10,910
what you just sent me send me more and

1406
00:53:10,910 --> 00:53:12,320
think that's sort of redundant over top

1407
00:53:12,320 --> 00:53:15,140
of TCP tcp but you know maybes from a

1408
00:53:15,140 --> 00:53:16,520
day where you in one of that kind of

1409
00:53:16,520 --> 00:53:20,840
extra extra security right extra safe

1410
00:53:20,840 --> 00:53:23,720
teenis and then hive I said just sending

1411
00:53:23,720 --> 00:53:28,700
way more data so for this one again

1412
00:53:28,700 --> 00:53:30,440
this is only one tuple at a time so the

1413
00:53:30,440 --> 00:53:32,510
way to avoid all the overhead of like

1414
00:53:32,510 --> 00:53:34,850
parsing the sequel statement and and

1415
00:53:34,850 --> 00:53:36,410
running him the optimizer and running

1416
00:53:36,410 --> 00:53:37,820
the query they're gonna run the query

1417
00:53:37,820 --> 00:53:39,619
multiple times and then had the

1418
00:53:39,619 --> 00:53:42,380
babysittin cache at least the query plan

1419
00:53:42,380 --> 00:53:43,580
not that was all belief the query plan

1420
00:53:43,580 --> 00:53:44,990
so this is just saying what's the

1421
00:53:44,990 --> 00:53:47,450
overhead of constructing the packet that

1422
00:53:47,450 --> 00:53:49,850
we sent over the wire protocol in the

1423
00:53:49,850 --> 00:53:51,170
next experiment they're gonna then send

1424
00:53:51,170 --> 00:53:54,020
back a million tuples and so the first

1425
00:53:54,020 --> 00:53:56,480
two results to point out though is with

1426
00:53:56,480 --> 00:53:58,940
my sequel so this is my so this is when

1427
00:53:58,940 --> 00:54:01,160
the the along the x-axis we're gonna

1428
00:54:01,160 --> 00:54:03,020
vary the latency of these Network

1429
00:54:03,020 --> 00:54:04,850
messages so when your network is really

1430
00:54:04,850 --> 00:54:07,940
fast up into this point here the regular

1431
00:54:07,940 --> 00:54:09,890
my sequel protocol without any

1432
00:54:09,890 --> 00:54:13,220
compression is is gonna be better but

1433
00:54:13,220 --> 00:54:14,720
once obviously the network gets slower

1434
00:54:14,720 --> 00:54:18,260
then you know doing that extra CPU work

1435
00:54:18,260 --> 00:54:20,900
to compress the data actually pays off

1436
00:54:20,900 --> 00:54:23,240
in this case here my secret with

1437
00:54:23,240 --> 00:54:25,490
compression it always gets the same

1438
00:54:25,490 --> 00:54:27,109
performance because the dominant cost

1439
00:54:27,109 --> 00:54:30,619
here is it's calling gzip for all the

1440
00:54:30,619 --> 00:54:32,600
other ones in the the curves look all

1441
00:54:32,600 --> 00:54:34,550
about the same right obviously when

1442
00:54:34,550 --> 00:54:36,140
they're faster when the network is

1443
00:54:36,140 --> 00:54:37,550
faster they do better but it hasn't

1444
00:54:37,550 --> 00:54:40,220
network gets slower they do worse which

1445
00:54:40,220 --> 00:54:41,869
engine you point out though over here is

1446
00:54:41,869 --> 00:54:44,630
that Oracle is is the second fastest one

1447
00:54:44,630 --> 00:54:46,369
after my sequel here when the network is

1448
00:54:46,369 --> 00:54:48,980
fast but then up here it actually ends

1449
00:54:48,980 --> 00:54:52,070
up being one of the slowest ones I don't

1450
00:54:52,070 --> 00:54:53,990
remember what the paper said that why

1451
00:54:53,990 --> 00:54:56,390
this was the case I mean db2 here is an

1452
00:54:56,390 --> 00:54:58,100
order magnitude off of like propose

1453
00:54:58,100 --> 00:55:00,020
graphs right the db2 is like doing like

1454
00:55:00,020 --> 00:55:01,490
five

1455
00:55:01,490 --> 00:55:04,460
is that 500 up there and Oracle or so

1456
00:55:04,460 --> 00:55:07,640
postcards right below it is around 1050

1457
00:55:07,640 --> 00:55:10,339
seconds so that's just an example of

1458
00:55:10,339 --> 00:55:11,750
like how that confirmation message that

1459
00:55:11,750 --> 00:55:13,280
they're sending over is super

1460
00:55:13,280 --> 00:55:15,079
inefficient with a network of slow they

1461
00:55:15,079 --> 00:55:17,030
can't send the next batch of tuples to

1462
00:55:17,030 --> 00:55:18,589
the client until you get that second

1463
00:55:18,589 --> 00:55:21,220
round trip and say hey send me warm

1464
00:55:21,220 --> 00:55:26,589
alright so any questions about this yes

1465
00:55:29,170 --> 00:55:32,569
sorry this like this one here why is

1466
00:55:32,569 --> 00:55:34,760
this faster than this because I'm

1467
00:55:34,760 --> 00:55:37,099
standing back a million two bullets and

1468
00:55:37,099 --> 00:55:38,359
I'm gonna think exact size of that but

1469
00:55:38,359 --> 00:55:40,130
like when the networks really fast I

1470
00:55:40,130 --> 00:55:41,180
don't want to pay the penalty to

1471
00:55:41,180 --> 00:55:42,680
compress it I just want to shove it over

1472
00:55:42,680 --> 00:55:44,960
the wire as fast as possible and this

1473
00:55:44,960 --> 00:55:47,569
one here the dominant cost is the CPU

1474
00:55:47,569 --> 00:55:48,680
overhead of compressing and

1475
00:55:48,680 --> 00:55:50,690
decompressing so that's why again it's

1476
00:55:50,690 --> 00:55:52,849
basically flatline so no matter how slow

1477
00:55:52,849 --> 00:55:55,220
they never get gets the benefit you're

1478
00:55:55,220 --> 00:55:57,859
getting from sending less data over a

1479
00:55:57,859 --> 00:55:59,510
slower Network is negated by the

1480
00:55:59,510 --> 00:56:02,150
computational cost miss now they could

1481
00:56:02,150 --> 00:56:03,859
have used snappy and that might that

1482
00:56:03,859 --> 00:56:05,660
might change the curves a bit but it

1483
00:56:05,660 --> 00:56:07,880
basically this is basically saying and

1484
00:56:07,880 --> 00:56:09,230
why I highlighted this one first is that

1485
00:56:09,230 --> 00:56:11,089
when the network is fast you don't want

1486
00:56:11,089 --> 00:56:12,260
to do any compression these ones shove

1487
00:56:12,260 --> 00:56:14,270
data out fast as possible but as they

1488
00:56:14,270 --> 00:56:16,640
never get slower you do want to do this

1489
00:56:16,640 --> 00:56:18,290
soon a say alright well in what case

1490
00:56:18,290 --> 00:56:19,579
would the network get be the hunter

1491
00:56:19,579 --> 00:56:20,900
milliseconds well if I'm running in

1492
00:56:20,900 --> 00:56:22,339
different data centers the application

1493
00:56:22,339 --> 00:56:24,079
servers running one data center the data

1494
00:56:24,079 --> 00:56:25,730
servers running another one then you

1495
00:56:25,730 --> 00:56:27,050
know I can get up to hundred millisecond

1496
00:56:27,050 --> 00:56:31,000
latency yes

1497
00:56:45,099 --> 00:56:47,599
your statement is should they be

1498
00:56:47,599 --> 00:56:49,190
shouldn't they be varying the bandwidth

1499
00:56:49,190 --> 00:56:51,650
and not the latency because I'm gonna

1500
00:56:51,650 --> 00:56:53,030
related it to each other but I think

1501
00:56:53,030 --> 00:56:57,530
like the like in the case of like db2

1502
00:56:57,530 --> 00:56:59,589
like sending those confirmation messages

1503
00:56:59,589 --> 00:57:01,670
that's not a bandwidth issue that's a

1504
00:57:01,670 --> 00:57:32,569
week yeah you statement is that let's

1505
00:57:32,569 --> 00:57:35,480
take this offline but good cuz I don't

1506
00:57:35,480 --> 00:57:38,660
know exactly like I remember the exact

1507
00:57:38,660 --> 00:57:40,940
setup was in terms of like I think the

1508
00:57:40,940 --> 00:57:42,230
the client has to get the result and

1509
00:57:42,230 --> 00:57:43,400
immediately throw it away but in this

1510
00:57:43,400 --> 00:57:46,630
case here the client so that the cost of

1511
00:57:46,630 --> 00:57:48,680
decompressing on the client side is

1512
00:57:48,680 --> 00:57:50,060
being measured in this as well

1513
00:57:50,060 --> 00:57:54,500
so I think that's why the leave the you

1514
00:57:54,500 --> 00:57:55,490
can't hide it I think that's why the

1515
00:57:55,490 --> 00:58:00,069
latency matters wait a min bandwidth but

1516
00:58:00,069 --> 00:58:05,599
that one offline okay we have 20 minutes

1517
00:58:05,599 --> 00:58:10,940
um I'm actually gonna skip replication

1518
00:58:10,940 --> 00:58:12,730
protocols I think we covered this in the

1519
00:58:12,730 --> 00:58:15,290
we basically covered this in the intro

1520
00:58:15,290 --> 00:58:17,540
class already the only got to say too is

1521
00:58:17,540 --> 00:58:23,119
like that the sort of relating to what

1522
00:58:23,119 --> 00:58:24,109
we talked about last class with like

1523
00:58:24,109 --> 00:58:26,390
logging and recovery sometimes you do

1524
00:58:26,390 --> 00:58:27,980
logical logging sometimes you do

1525
00:58:27,980 --> 00:58:30,380
physical logging right and that's an

1526
00:58:30,380 --> 00:58:32,930
internal protocol that the data system

1527
00:58:32,930 --> 00:58:34,579
uses that's can be separate than the

1528
00:58:34,579 --> 00:58:35,990
client protocol you would use to

1529
00:58:35,990 --> 00:58:37,839
communicate with it to be seen a JDBC

1530
00:58:37,839 --> 00:58:40,730
and some of the optimizations you can do

1531
00:58:40,730 --> 00:58:42,530
again for doing compression and other

1532
00:58:42,530 --> 00:58:44,750
things or how you batch up the the log

1533
00:58:44,750 --> 00:58:46,790
records depends on what the consistency

1534
00:58:46,790 --> 00:58:48,319
guarantees you want for your your your

1535
00:58:48,319 --> 00:58:51,500
your systems so that one will

1536
00:58:51,500 --> 00:58:52,580
there's not much more to say other than

1537
00:58:52,580 --> 00:58:55,130
other than that but when you tell me

1538
00:58:55,130 --> 00:58:57,590
that offline if you want as well all

1539
00:58:57,590 --> 00:58:59,720
right so just to finish up real quick

1540
00:58:59,720 --> 00:59:01,250
because this is something I think I do

1541
00:59:01,250 --> 00:59:03,160
won't expose you guys to um

1542
00:59:03,160 --> 00:59:07,180
the in the experiments with with with

1543
00:59:07,180 --> 00:59:10,369
from the the duck TV guys paper like as

1544
00:59:10,369 --> 00:59:11,990
it was showing like their merit their

1545
00:59:11,990 --> 00:59:14,180
varying the network latency but that's

1546
00:59:14,180 --> 00:59:15,619
not the only bottleneck you're gonna

1547
00:59:15,619 --> 00:59:17,660
have their network layer itself is not

1548
00:59:17,660 --> 00:59:18,710
the only bottom like you're gonna have

1549
00:59:18,710 --> 00:59:20,240
in your in your app and your database

1550
00:59:20,240 --> 00:59:22,150
server to communicate with the client

1551
00:59:22,150 --> 00:59:25,010
oftentimes the the OS is gonna cause

1552
00:59:25,010 --> 00:59:27,680
problems especially if you're doing oak

1553
00:59:27,680 --> 00:59:28,849
tree applications where you're sending a

1554
00:59:28,849 --> 00:59:31,010
lot of small packets instead of you know

1555
00:59:31,010 --> 00:59:33,470
giant giant buffers of things the reason

1556
00:59:33,470 --> 00:59:34,520
why it could be expensive is because

1557
00:59:34,520 --> 00:59:36,080
communicating with the OS is always

1558
00:59:36,080 --> 00:59:37,369
gonna be a nightmare for us as the data

1559
00:59:37,369 --> 00:59:39,109
system right it's our frenemy we need it

1560
00:59:39,109 --> 00:59:40,900
to survive but it always gets in our way

1561
00:59:40,900 --> 00:59:44,530
so if we were gonna lie on the OS TCP

1562
00:59:44,530 --> 00:59:47,420
excuse me tcp/ip stack then we have to

1563
00:59:47,420 --> 00:59:48,920
have context switches handle through

1564
00:59:48,920 --> 00:59:50,359
inner area through interrupts in order

1565
00:59:50,359 --> 00:59:52,040
to get you know to be notified that we

1566
00:59:52,040 --> 00:59:53,240
have now a packet that we want to get

1567
00:59:53,240 --> 00:59:55,760
copying data out from our buffers and

1568
00:59:55,760 --> 00:59:58,160
the database server down into the tcp/ip

1569
00:59:58,160 --> 00:59:59,960
buffers that we send into the kernel

1570
00:59:59,960 --> 01:00:02,270
that's to me expensive and of course the

1571
01:00:02,270 --> 01:00:03,890
OS is gonna maintain its own latches to

1572
01:00:03,890 --> 01:00:05,570
protect its internal data structures and

1573
01:00:05,570 --> 01:00:07,310
those are gonna get in our way if we

1574
01:00:07,310 --> 01:00:08,390
have a lot of threads trying to write to

1575
01:00:08,390 --> 01:00:11,690
date at the same time so one way to

1576
01:00:11,690 --> 01:00:13,280
avoid all this is to what's called it

1577
01:00:13,280 --> 01:00:15,440
kernel bypass methods the idea here is

1578
01:00:15,440 --> 01:00:16,730
that we're gonna have the database

1579
01:00:16,730 --> 01:00:18,170
system we're gonna implement it so that

1580
01:00:18,170 --> 01:00:20,599
we're gonna be able to write data

1581
01:00:20,599 --> 01:00:22,970
directly to the NIC to the actual you

1582
01:00:22,970 --> 01:00:26,869
know the harbor the network device by

1583
01:00:26,869 --> 01:00:30,410
going around the OS right and so the

1584
01:00:30,410 --> 01:00:31,790
idea is that we can now have a buffer of

1585
01:00:31,790 --> 01:00:35,089
data that we can fill in with with the

1586
01:00:35,089 --> 01:00:36,470
results of a query or the packets we

1587
01:00:36,470 --> 01:00:37,700
want to send over using our wire

1588
01:00:37,700 --> 01:00:39,680
protocol but that buffer actually now

1589
01:00:39,680 --> 01:00:41,960
lives down in the NIC so we don't have

1590
01:00:41,960 --> 01:00:43,820
to do any copying to tan it off to the

1591
01:00:43,820 --> 01:00:46,010
hardware the harbor can get fill up a

1592
01:00:46,010 --> 01:00:47,119
buffer and we say all right we're done

1593
01:00:47,119 --> 01:00:48,770
with it and then now we can meet Lee go

1594
01:00:48,770 --> 01:00:50,750
over the wire and send over our messages

1595
01:00:50,750 --> 01:00:52,460
so the OS doesn't get in the way at all

1596
01:00:52,460 --> 01:00:55,700
so there's two ways to do this there's

1597
01:00:55,700 --> 01:00:57,230
the the data plane development kit and

1598
01:00:57,230 --> 01:00:58,880
the DP DK and then there's through

1599
01:00:58,880 --> 01:01:01,070
through our DMA or remote direct memory

1600
01:01:01,070 --> 01:01:03,920
access so they're not exactly it's not

1601
01:01:03,920 --> 01:01:05,210
true apples to apples can

1602
01:01:05,210 --> 01:01:07,610
Harrison because like the DB DK is a

1603
01:01:07,610 --> 01:01:10,760
library you can download originally from

1604
01:01:10,760 --> 01:01:13,760
Intel that provides this kernel bypass

1605
01:01:13,760 --> 01:01:17,030
method our DMA is sort of a category of

1606
01:01:17,030 --> 01:01:19,130
hardware and software libraries that you

1607
01:01:19,130 --> 01:01:21,650
can get for your system so there's a

1608
01:01:21,650 --> 01:01:23,360
bunch of because there's a specific

1609
01:01:23,360 --> 01:01:25,040
thing you can download called the DB DK

1610
01:01:25,040 --> 01:01:27,830
but that is a library there's no like

1611
01:01:27,830 --> 01:01:29,450
single library called already may you

1612
01:01:29,450 --> 01:01:32,620
can download it's a broader contact ok

1613
01:01:32,620 --> 01:01:36,520
so with the DVD K the idea here is that

1614
01:01:36,520 --> 01:01:38,660
it's it's just live where the Intel

1615
01:01:38,660 --> 01:01:40,400
originally developed in order to help

1616
01:01:40,400 --> 01:01:42,020
them sell their Intel's hardware but

1617
01:01:42,020 --> 01:01:43,970
they eventually donated the software to

1618
01:01:43,970 --> 01:01:46,550
the Linux Foundation and the idea here

1619
01:01:46,550 --> 01:01:47,960
is that it's a bunch of libraries that

1620
01:01:47,960 --> 01:01:51,440
are API calls that allows us to access

1621
01:01:51,440 --> 01:01:53,300
the NIC directly we can say give us a

1622
01:01:53,300 --> 01:01:54,770
buffer that's on the NIC we can then

1623
01:01:54,770 --> 01:01:57,560
fill it up and then we can then tell the

1624
01:01:57,560 --> 01:01:59,090
the NIC to go ahead and write write our

1625
01:01:59,090 --> 01:02:00,800
data to this location so ron was

1626
01:02:00,800 --> 01:02:02,540
treating like the the nick is like a

1627
01:02:02,540 --> 01:02:07,700
bare metal device yes this question

1628
01:02:07,700 --> 01:02:09,490
where's the buffer actually live I

1629
01:02:09,490 --> 01:02:12,530
actually don't know I mean the NIC has

1630
01:02:12,530 --> 01:02:16,130
its own memory buffer I I think you can

1631
01:02:16,130 --> 01:02:18,290
I think when you say give me a 2d PK

1632
01:02:18,290 --> 01:02:20,690
when you get a buffer for it I mean when

1633
01:02:20,690 --> 01:02:22,100
you Josh - you're right I think it lives

1634
01:02:22,100 --> 01:02:24,140
in the CPU cache because it has to

1635
01:02:24,140 --> 01:02:25,070
because that's when you write everything

1636
01:02:25,070 --> 01:02:26,810
but then when it gets flushed it does

1637
01:02:26,810 --> 01:02:28,310
get flushed 2d Ram it gets flushed to

1638
01:02:28,310 --> 01:02:32,140
the neck I think that's how it works

1639
01:02:32,950 --> 01:02:40,010
like does the NIC nice question oh yeah

1640
01:02:40,010 --> 01:02:42,230
so if i if i'm if my process is writing

1641
01:02:42,230 --> 01:02:45,260
to this the cache lines that are backed

1642
01:02:45,260 --> 01:02:47,540
by the NIC if I get a context which does

1643
01:02:47,540 --> 01:02:49,130
that then get flushed I think so yes

1644
01:02:49,130 --> 01:02:52,970
like the OS the OS doesn't control any

1645
01:02:52,970 --> 01:02:54,620
of this data movement it's it's the

1646
01:02:54,620 --> 01:02:55,970
harbor's actually providing this

1647
01:02:55,970 --> 01:02:58,940
functionality for us right and Intel and

1648
01:02:58,940 --> 01:02:59,990
they're in their world they're trying to

1649
01:02:59,990 --> 01:03:02,150
sell hardware so that they're making it

1650
01:03:02,150 --> 01:03:03,110
easier for you to write to their

1651
01:03:03,110 --> 01:03:06,650
hardware I for the DVD K I don't mean

1652
01:03:06,650 --> 01:03:09,710
until you know it came out of Intel but

1653
01:03:09,710 --> 01:03:11,210
now it's opposed to be this there's this

1654
01:03:11,210 --> 01:03:13,430
broader thing that other vendors can

1655
01:03:13,430 --> 01:03:15,260
implement I don't know whether you can

1656
01:03:15,260 --> 01:03:16,400
get this with other anything else that's

1657
01:03:16,400 --> 01:03:18,950
not our Intel Nick

1658
01:03:18,950 --> 01:03:21,589
so again there's no data copying because

1659
01:03:21,589 --> 01:03:22,970
we can write them into the buffers that

1660
01:03:22,970 --> 01:03:25,819
are on the neck and there's no system

1661
01:03:25,819 --> 01:03:27,260
calls to send any messages we're

1662
01:03:27,260 --> 01:03:28,819
basically going directly from our

1663
01:03:28,819 --> 01:03:30,470
database over to the harbor and saying

1664
01:03:30,470 --> 01:03:32,630
send our messages to this location OS

1665
01:03:32,630 --> 01:03:34,309
doesn't get involved at all it's awesome

1666
01:03:34,309 --> 01:03:38,029
so for as amazing as this sounds there's

1667
01:03:38,029 --> 01:03:39,740
only one database system that I'm aware

1668
01:03:39,740 --> 01:03:41,960
of that actually uses this and it's

1669
01:03:41,960 --> 01:03:44,420
called Scalia D beam so they implemented

1670
01:03:44,420 --> 01:03:47,029
this framework called C star which is a

1671
01:03:47,029 --> 01:03:49,160
networking framework that uses the DB D

1672
01:03:49,160 --> 01:03:51,529
K and then Scalia DB is built on top of

1673
01:03:51,529 --> 01:03:51,799
it

1674
01:03:51,799 --> 01:03:54,230
Scalia DB is a steep applause free

1675
01:03:54,230 --> 01:03:56,180
implementation of Cassandra Cassandra is

1676
01:03:56,180 --> 01:03:59,450
really visually written in Java this is

1677
01:03:59,450 --> 01:04:02,240
really now written in C++ and using DB

1678
01:04:02,240 --> 01:04:07,420
DK to get faster messages right so

1679
01:04:07,420 --> 01:04:09,769
amazing as it sounds as I said this is

1680
01:04:09,769 --> 01:04:11,869
not that common if you you can get

1681
01:04:11,869 --> 01:04:14,390
instances on ec2 that do support the DB

1682
01:04:14,390 --> 01:04:16,309
DK but it's not like you know the the

1683
01:04:16,309 --> 01:04:17,720
cheapo ones that we were running on this

1684
01:04:17,720 --> 01:04:20,809
class they don't support this the other

1685
01:04:20,809 --> 01:04:23,180
tricky thing too is like this sounds

1686
01:04:23,180 --> 01:04:25,400
amazing and it's constitutive but

1687
01:04:25,400 --> 01:04:28,700
someone tweeted at me once about the by

1688
01:04:28,700 --> 01:04:31,460
using SPD k is the storage one this is

1689
01:04:31,460 --> 01:04:34,069
the data one like this comment I think

1690
01:04:34,069 --> 01:04:35,839
it's fantastic like it seems like it's

1691
01:04:35,839 --> 01:04:38,119
gonna be a really good idea but then

1692
01:04:38,119 --> 01:04:39,680
when you really start pushing it then

1693
01:04:39,680 --> 01:04:42,140
it's all these nuances of it that trip

1694
01:04:42,140 --> 01:04:43,849
you up all right it's not something you

1695
01:04:43,849 --> 01:04:45,049
can just like pop in like link in a

1696
01:04:45,049 --> 01:04:46,880
library and you automatically get it you

1697
01:04:46,880 --> 01:04:48,140
have to rewrite your database server

1698
01:04:48,140 --> 01:04:50,059
application or database server to use

1699
01:04:50,059 --> 01:04:52,039
this right and that could be a major

1700
01:04:52,039 --> 01:04:54,230
change change in case of Scalia TB

1701
01:04:54,230 --> 01:04:56,390
they're built top of C star so all the

1702
01:04:56,390 --> 01:04:59,210
employee the complexities of the DVD K

1703
01:04:59,210 --> 01:05:01,250
are hidden under covers so for this

1704
01:05:01,250 --> 01:05:04,279
reason as I said like because your

1705
01:05:04,279 --> 01:05:04,730
server

1706
01:05:04,730 --> 01:05:07,009
I don't not many David subsection use

1707
01:05:07,009 --> 01:05:11,930
this the other one is the RDMA and the

1708
01:05:11,930 --> 01:05:15,680
idea here is that the if I have multiple

1709
01:05:15,680 --> 01:05:20,839
machines I can have the I can have the

1710
01:05:20,839 --> 01:05:24,109
client or the server write and read and

1711
01:05:24,109 --> 01:05:25,549
write the memory location of that remote

1712
01:05:25,549 --> 01:05:28,490
machine so the way you think about this

1713
01:05:28,490 --> 01:05:30,710
is like if my application server if my

1714
01:05:30,710 --> 01:05:32,240
client driver for my database server

1715
01:05:32,240 --> 01:05:32,760
room

1716
01:05:32,760 --> 01:05:35,370
new of the memory layout of the of the

1717
01:05:35,370 --> 01:05:38,160
data and on the database server then

1718
01:05:38,160 --> 01:05:40,890
instead of sending now siegel query to

1719
01:05:40,890 --> 01:05:43,380
go have that be parsed executed and and

1720
01:05:43,380 --> 01:05:46,410
then presented results that I could if I

1721
01:05:46,410 --> 01:05:48,540
know how the data's laid out I could

1722
01:05:48,540 --> 01:05:51,090
just read directly into memory and get

1723
01:05:51,090 --> 01:05:53,030
the date get the result I want back

1724
01:05:53,030 --> 01:05:55,170
that's actually super hard right because

1725
01:05:55,170 --> 01:05:56,910
now if I start moving them around and

1726
01:05:56,910 --> 01:05:57,810
everything everything is gonna get

1727
01:05:57,810 --> 01:06:03,030
messed up so the only two systems that

1728
01:06:03,030 --> 01:06:04,380
I'm aware of that actually use our DMA

1729
01:06:04,380 --> 01:06:06,870
the most famous one is Oracle RAC right

1730
01:06:06,870 --> 01:06:08,430
or it's basically you know a

1731
01:06:08,430 --> 01:06:12,900
multi-million dollar cabinet of high-end

1732
01:06:12,900 --> 01:06:15,660
servers that use already May just to

1733
01:06:15,660 --> 01:06:17,400
talk to each other within the rack right

1734
01:06:17,400 --> 01:06:19,920
in that case all okhla has designed this

1735
01:06:19,920 --> 01:06:22,170
system specifically do to do shared

1736
01:06:22,170 --> 01:06:25,350
memory buffers using our DMA farm is a

1737
01:06:25,350 --> 01:06:26,850
distributed transactional system at a

1738
01:06:26,850 --> 01:06:28,290
Microsoft Research I don't think it's

1739
01:06:28,290 --> 01:06:30,480
actually running production but the

1740
01:06:30,480 --> 01:06:32,280
tricky thing about our DMA is like you

1741
01:06:32,280 --> 01:06:34,440
don't know whether someone's accessing

1742
01:06:34,440 --> 01:06:36,870
your memory or you know or writing your

1743
01:06:36,870 --> 01:06:39,330
memory right because it's all handled

1744
01:06:39,330 --> 01:06:40,350
through the hardware it's all hidden

1745
01:06:40,350 --> 01:06:41,940
from you it from the OS so it's not like

1746
01:06:41,940 --> 01:06:44,700
I get interrupt to say oh someone wrote

1747
01:06:44,700 --> 01:06:47,820
to memory at this location I don't know

1748
01:06:47,820 --> 01:06:50,280
so in order to do transactions correctly

1749
01:06:50,280 --> 01:06:52,590
and farm when you have we know one

1750
01:06:52,590 --> 01:06:53,730
server running into a memory or another

1751
01:06:53,730 --> 01:06:55,200
server they basically have to do four

1752
01:06:55,200 --> 01:06:57,240
phase commit over our DMA which is

1753
01:06:57,240 --> 01:06:58,830
faster but it's four phase commit to be

1754
01:06:58,830 --> 01:07:00,120
it'll say all right I've made these

1755
01:07:00,120 --> 01:07:04,880
changes are you okay with that right so

1756
01:07:04,880 --> 01:07:07,830
again for this reason you won't think

1757
01:07:07,830 --> 01:07:09,290
you would you only use our DMA

1758
01:07:09,290 --> 01:07:11,610
internally to communicate between

1759
01:07:11,610 --> 01:07:13,530
servers of the same database instance I

1760
01:07:13,530 --> 01:07:15,210
don't know no I

1761
01:07:15,210 --> 01:07:17,460
there's been no work as far as I know of

1762
01:07:17,460 --> 01:07:20,760
about doing our DMA from the client to

1763
01:07:20,760 --> 01:07:23,070
the through the server because if memory

1764
01:07:23,070 --> 01:07:25,290
gets moved around it then then you're

1765
01:07:25,290 --> 01:07:28,860
screwed so I want you one quick raffled

1766
01:07:28,860 --> 01:07:31,110
s so this is an experiment that a former

1767
01:07:31,110 --> 01:07:34,020
student of mine did on the honor system

1768
01:07:34,020 --> 01:07:37,200
where we just want to see how how fast

1769
01:07:37,200 --> 01:07:40,230
we can get seven gigabytes of tuples out

1770
01:07:40,230 --> 01:07:46,170
of our TPC from TPC see the

1771
01:07:46,170 --> 01:07:47,789
the protocol is that the client is

1772
01:07:47,789 --> 01:07:50,069
actually reading into memory it knows

1773
01:07:50,069 --> 01:07:52,559
where the layout starting and starting

1774
01:07:52,559 --> 01:07:53,730
and stopping justice for all the blocks

1775
01:07:53,730 --> 01:07:55,260
of data that it wants to read it's sort

1776
01:07:55,260 --> 01:07:57,140
of how fast can we get everything out so

1777
01:07:57,140 --> 01:07:59,369
that's a low end you have if you have

1778
01:07:59,369 --> 01:08:00,720
post graphs where you actually iterating

1779
01:08:00,720 --> 01:08:01,799
and going through the post plus quite a

1780
01:08:01,799 --> 01:08:05,190
protocol if you then do what the duck DB

1781
01:08:05,190 --> 01:08:06,869
guy supposed in the paper you read about

1782
01:08:06,869 --> 01:08:08,549
vectorizing the Polacks you send back

1783
01:08:08,549 --> 01:08:11,010
you can do a little bit better aero

1784
01:08:11,010 --> 01:08:14,760
flight is a G RPC implementation or RPC

1785
01:08:14,760 --> 01:08:16,319
implementation of getting roll plots of

1786
01:08:16,319 --> 01:08:19,770
data out from the Aero guys but the RTA

1787
01:08:19,770 --> 01:08:21,600
is like the bare-bones like if I know

1788
01:08:21,600 --> 01:08:23,149
exactly the memory address that I want

1789
01:08:23,149 --> 01:08:25,469
and I can jump to that location on the

1790
01:08:25,469 --> 01:08:26,880
row machine and get all the data back I

1791
01:08:26,880 --> 01:08:29,100
need so this shows you again your your

1792
01:08:29,100 --> 01:08:30,238
you can get about an order magnitude

1793
01:08:30,238 --> 01:08:32,399
performance improvement if you don't

1794
01:08:32,399 --> 01:08:33,988
worry about going through any of that

1795
01:08:33,988 --> 01:08:36,738
sort of any other davis server software

1796
01:08:36,738 --> 01:08:39,049
okay

1797
01:08:39,049 --> 01:08:40,948
alright so this is a bit rushed at the

1798
01:08:40,948 --> 01:08:43,529
end but and I've covered most of this

1799
01:08:43,529 --> 01:08:45,149
already right so that the network

1800
01:08:45,149 --> 01:08:47,488
protocol is is something that we sort of

1801
01:08:47,488 --> 01:08:49,109
take advantage of but I think there's a

1802
01:08:49,109 --> 01:08:50,759
lot of opportunity for performance

1803
01:08:50,759 --> 01:08:52,799
improvements and this is what the duck

1804
01:08:52,799 --> 01:08:54,810
TB guys showed the problem is though you

1805
01:08:54,810 --> 01:08:56,810
have all these drivers out in the wild

1806
01:08:56,810 --> 01:08:59,880
and in some ways now the protocol is

1807
01:08:59,880 --> 01:09:02,069
sort of set in stone maybe a major

1808
01:09:02,069 --> 01:09:05,189
change to go back and and have everyone

1809
01:09:05,189 --> 01:09:06,479
linking new libraries that's never gonna

1810
01:09:06,479 --> 01:09:08,219
happen but now if you want to be to

1811
01:09:08,219 --> 01:09:10,649
update your protocol and support more

1812
01:09:10,649 --> 01:09:12,569
some of these optimizations you you

1813
01:09:12,569 --> 01:09:14,670
essentially need to support both because

1814
01:09:14,670 --> 01:09:15,630
you never know when a client's going to

1815
01:09:15,630 --> 01:09:17,009
show up and connect with the old

1816
01:09:17,009 --> 01:09:21,179
protocol the some external breaker told

1817
01:09:21,179 --> 01:09:22,529
me that when they were building vertical

1818
01:09:22,529 --> 01:09:24,060
one of the things that big things they

1819
01:09:24,060 --> 01:09:25,198
spent a lot of time alone because they

1820
01:09:25,198 --> 01:09:27,210
want to be Postgres compatible is that

1821
01:09:27,210 --> 01:09:28,799
they basically found every single jar

1822
01:09:28,799 --> 01:09:30,149
file they could of the Postgres wire

1823
01:09:30,149 --> 01:09:32,370
protocol that was out there and just ran

1824
01:09:32,370 --> 01:09:33,540
every single test over and over again

1825
01:09:33,540 --> 01:09:35,130
and like because there's so many just a

1826
01:09:35,130 --> 01:09:36,929
one-off variances although them they

1827
01:09:36,929 --> 01:09:38,429
spend a lot of time making it just be

1828
01:09:38,429 --> 01:09:40,229
post cut JDBC compatible because it's

1829
01:09:40,229 --> 01:09:42,060
super hard and the kernel bypassed

1830
01:09:42,060 --> 01:09:43,139
methods we saw again these are the

1831
01:09:43,139 --> 01:09:45,210
optimizations to avoid the OS avoid

1832
01:09:45,210 --> 01:09:46,229
having go through the front end layer

1833
01:09:46,229 --> 01:09:50,399
but it's more it's usually more work

1834
01:09:50,399 --> 01:09:53,790
than it's actually worth okay all right

1835
01:09:53,790 --> 01:09:57,600
so quickly project two so the plan for

1836
01:09:57,600 --> 01:09:58,770
project two is that everyone's going to

1837
01:09:58,770 --> 01:09:59,780
implement and the team

1838
01:09:59,780 --> 01:10:02,690
your own B+ tree in memory B+ tree it

1839
01:10:02,690 --> 01:10:04,700
has to be thread safe the means you have

1840
01:10:04,700 --> 01:10:06,050
to support splits and merges and have

1841
01:10:06,050 --> 01:10:08,780
multiple threads accessing the index at

1842
01:10:08,780 --> 01:10:11,210
the same time so the basic API you're at

1843
01:10:11,210 --> 01:10:13,220
the implement is insert get delete ring

1844
01:10:13,220 --> 01:10:15,020
and range scans you also have two

1845
01:10:15,020 --> 01:10:18,050
conditional inserts in a way that works

1846
01:10:18,050 --> 01:10:20,570
is I call insert with the key but I also

1847
01:10:20,570 --> 01:10:22,040
pass you a lambda function that says

1848
01:10:22,040 --> 01:10:24,170
that you need to evaluate on the key and

1849
01:10:24,170 --> 01:10:26,060
if that land up function evaluates to

1850
01:10:26,060 --> 01:10:27,230
true then you're allowed to insert

1851
01:10:27,230 --> 01:10:29,240
otherwise you can't write that's

1852
01:10:29,240 --> 01:10:31,310
basically how you do like I don't think

1853
01:10:31,310 --> 01:10:33,560
a parent swap I'd like to to replace a

1854
01:10:33,560 --> 01:10:36,500
value at a replace a key value pair

1855
01:10:36,500 --> 01:10:38,390
without having to do multiple traversals

1856
01:10:38,390 --> 01:10:40,430
or lock the whole thing you need to

1857
01:10:40,430 --> 01:10:42,740
support forward reverse range scans that

1858
01:10:42,740 --> 01:10:44,600
means you need sibling pointers and you

1859
01:10:44,600 --> 01:10:46,990
guys support unique and non unique keys

1860
01:10:46,990 --> 01:10:49,610
so that's all we're going to tell you

1861
01:10:49,610 --> 01:10:51,770
you have to do delete will be some some

1862
01:10:51,770 --> 01:10:53,930
some stuff api's or sub files class

1863
01:10:53,930 --> 01:10:55,940
files will give you how you actually

1864
01:10:55,940 --> 01:10:57,620
want to implement this is love up to

1865
01:10:57,620 --> 01:11:00,170
left up entirely to you right you can't

1866
01:11:00,170 --> 01:11:02,270
do something stupid like go take STL map

1867
01:11:02,270 --> 01:11:04,550
put a latch in front of it and just have

1868
01:11:04,550 --> 01:11:06,620
that you know be your tree it has to be

1869
01:11:06,620 --> 01:11:08,930
a real B+ tree but all whatever

1870
01:11:08,930 --> 01:11:10,310
optimizations you want to do for like

1871
01:11:10,310 --> 01:11:13,610
compression if you want to do make a

1872
01:11:13,610 --> 01:11:17,210
latch free or not latch free or how you

1873
01:11:17,210 --> 01:11:18,950
actually implement the traversal itself

1874
01:11:18,950 --> 01:11:21,590
and and do the search within the node

1875
01:11:21,590 --> 01:11:26,810
that's up to entirely to you yes the key

1876
01:11:26,810 --> 01:11:28,970
type will be we already pro that provide

1877
01:11:28,970 --> 01:11:29,510
that for you

1878
01:11:29,510 --> 01:11:32,060
so it's templatized alright so there'll

1879
01:11:32,060 --> 01:11:34,130
be there's two types is compacting ski

1880
01:11:34,130 --> 01:11:35,990
and generic a generic key is just say a

1881
01:11:35,990 --> 01:11:37,460
byte array so you don't the writing the

1882
01:11:37,460 --> 01:11:39,140
code to do the evaluation of keys we

1883
01:11:39,140 --> 01:11:40,880
handled all that for you and the key

1884
01:11:40,880 --> 01:11:44,450
type is you'll know the size of it so

1885
01:11:44,450 --> 01:11:46,190
you just you just pack that in to how

1886
01:11:46,190 --> 01:11:48,860
you want to sorting each node I thought

1887
01:11:48,860 --> 01:11:49,880
what's all that staying car and you're

1888
01:11:49,880 --> 01:11:51,200
basically just building the data

1889
01:11:51,200 --> 01:11:55,310
structure okay is it already what I said

1890
01:11:55,310 --> 01:11:56,450
so we'll provide you with the header

1891
01:11:56,450 --> 01:11:57,980
file and the API you have to build and

1892
01:11:57,980 --> 01:11:59,870
then all this other crap will do for you

1893
01:11:59,870 --> 01:12:00,800
so you don't to worry about how to

1894
01:12:00,800 --> 01:12:01,910
sterilize the keys or gonna mount

1895
01:12:01,910 --> 01:12:04,040
actually comparisons all that is handled

1896
01:12:04,040 --> 01:12:06,320
so as I said there's a bunch of design

1897
01:12:06,320 --> 01:12:07,430
decisions you're going to make and

1898
01:12:07,430 --> 01:12:09,920
there's no right answer sometimes

1899
01:12:09,920 --> 01:12:11,540
they'll be wrong answers like if I know

1900
01:12:11,540 --> 01:12:13,469
should I write everything the dev know

1901
01:12:13,469 --> 01:12:16,290
no that's wrong but like you don't need

1902
01:12:16,290 --> 01:12:17,670
to come and ask us like can I do this

1903
01:12:17,670 --> 01:12:19,620
can I do this at every single step it's

1904
01:12:19,620 --> 01:12:21,090
up for you guys to decide how you

1905
01:12:21,090 --> 01:12:22,980
actually want implement this and I can

1906
01:12:22,980 --> 01:12:25,290
point you to you know a couple there's a

1907
01:12:25,290 --> 01:12:28,230
book on B plus trees it's not specific

1908
01:12:28,230 --> 01:12:30,270
to in Mary P Plus trees but there's a

1909
01:12:30,270 --> 01:12:31,350
books and some papers I could show you

1910
01:12:31,350 --> 01:12:32,610
like here's some other things you can do

1911
01:12:32,610 --> 01:12:35,780
to potentially make this go faster okay

1912
01:12:35,780 --> 01:12:39,120
so we'll provide you with a basic C plus

1913
01:12:39,120 --> 01:12:40,650
unit test for implementation it's

1914
01:12:40,650 --> 01:12:42,510
basically the same unit test we have for

1915
01:12:42,510 --> 01:12:44,520
the BW tree and we just did a search in

1916
01:12:44,520 --> 01:12:46,130
replace and replace it with P plus tree

1917
01:12:46,130 --> 01:12:48,210
right but it's not gonna be that

1918
01:12:48,210 --> 01:12:49,830
exhaustive it's certainly not going to

1919
01:12:49,830 --> 01:12:52,590
test the internal data structure

1920
01:12:52,590 --> 01:12:55,469
correctness or integrity that that you

1921
01:12:55,469 --> 01:12:56,760
wanted want to have right it's done at a

1922
01:12:56,760 --> 01:12:59,310
logical level like if I insert this key

1923
01:12:59,310 --> 01:13:01,380
do I get that key back but how do I know

1924
01:13:01,380 --> 01:13:04,350
that my you know that I don't have any

1925
01:13:04,350 --> 01:13:06,420
empty nose hanging around right well

1926
01:13:06,420 --> 01:13:07,620
trouble check for memory leaks and

1927
01:13:07,620 --> 01:13:09,989
things like that but like I you're gonna

1928
01:13:09,989 --> 01:13:11,310
want to write your own test that

1929
01:13:11,310 --> 01:13:13,110
actually tests at the low level data

1930
01:13:13,110 --> 01:13:14,610
structure right because we don't know

1931
01:13:14,610 --> 01:13:15,630
how your thing is implemented so we

1932
01:13:15,630 --> 01:13:17,610
can't provide you with things we will

1933
01:13:17,610 --> 01:13:20,850
also do a will do a leaderboard to see

1934
01:13:20,850 --> 01:13:22,469
who has the fastest one it's gonna run

1935
01:13:22,469 --> 01:13:23,850
on grey scope which is not ideal because

1936
01:13:23,850 --> 01:13:25,860
it's single-threaded but at least we see

1937
01:13:25,860 --> 01:13:27,480
how how fast you are compared to that

1938
01:13:27,480 --> 01:13:29,250
and then we'll give extra bonus points

1939
01:13:29,250 --> 01:13:32,430
for the top three implementations the

1940
01:13:32,430 --> 01:13:33,449
other thing you have to do is also write

1941
01:13:33,449 --> 01:13:35,040
documentation about what your code is

1942
01:13:35,040 --> 01:13:36,719
actually doing and explain what you did

1943
01:13:36,719 --> 01:13:37,949
in all the different parts of the system

1944
01:13:37,949 --> 01:13:40,590
so for this there is a basic check in

1945
01:13:40,590 --> 01:13:42,510
doxygen we use the opportunity to make

1946
01:13:42,510 --> 01:13:43,680
sure that you actually have like

1947
01:13:43,680 --> 01:13:45,840
comments for every single function but

1948
01:13:45,840 --> 01:13:47,160
obviously doxygen you can't read the

1949
01:13:47,160 --> 01:13:48,510
comments and see what what you're saying

1950
01:13:48,510 --> 01:13:50,010
is actually correct so Matt and I would

1951
01:13:50,010 --> 01:13:51,239
go through and inspect all of these

1952
01:13:51,239 --> 01:13:55,260
manually so again we will plan is to run

1953
01:13:55,260 --> 01:13:58,530
some additional stress tests for for

1954
01:13:58,530 --> 01:14:00,960
your your your implementation beyond

1955
01:14:00,960 --> 01:14:02,730
what we're gonna give you already and

1956
01:14:02,730 --> 01:14:04,760
then it will give you extra points for

1957
01:14:04,760 --> 01:14:08,219
whoever is the fastest and didn't make

1958
01:14:08,219 --> 01:14:09,540
sure again all your code has to follow

1959
01:14:09,540 --> 01:14:11,730
the the formatter and linter stuff one

1960
01:14:11,730 --> 01:14:14,430
of the things we did actually do in and

1961
01:14:14,430 --> 01:14:15,690
another student actually made the linter

1962
01:14:15,690 --> 01:14:17,489
go faster so now you don't think you

1963
01:14:17,489 --> 01:14:19,050
know take all the course your machine

1964
01:14:19,050 --> 01:14:20,580
and look at every single file the Lynch

1965
01:14:20,580 --> 01:14:21,989
are only looks at what to put files you

1966
01:14:21,989 --> 01:14:24,270
change so that should run faster as well

1967
01:14:24,270 --> 01:14:26,340
okay

1968
01:14:26,340 --> 01:14:28,460
I posted this on Piazza last night

1969
01:14:28,460 --> 01:14:31,619
everyone it's a group project so be with

1970
01:14:31,619 --> 01:14:33,480
35 students there to be three groups or

1971
01:14:33,480 --> 01:14:35,310
there are 12 groups or three people and

1972
01:14:35,310 --> 01:14:37,679
then one two-person group project

1973
01:14:37,679 --> 01:14:40,199
don't assume you will be that two-person

1974
01:14:40,199 --> 01:14:42,840
project but we only have one so so

1975
01:14:42,840 --> 01:14:45,449
please start finding a form a group and

1976
01:14:45,449 --> 01:14:47,550
then on the on the sign up there's that

1977
01:14:47,550 --> 01:14:49,020
list for free agents if you don't have a

1978
01:14:49,020 --> 01:14:51,030
group to be in add yourself there and

1979
01:14:51,030 --> 01:14:53,130
then you know teams can reach out to you

1980
01:14:53,130 --> 01:14:57,650
and try to get you to join them okay so

1981
01:14:57,650 --> 01:14:59,909
the websites not up yet we'll take care

1982
01:14:59,909 --> 01:15:00,360
of that today

1983
01:15:00,360 --> 01:15:03,000
I think Matt push the stub files to to

1984
01:15:03,000 --> 01:15:04,409
github so you can pull down the latest

1985
01:15:04,409 --> 01:15:06,510
version of our new project branch and

1986
01:15:06,510 --> 01:15:09,570
then this will be due on on March 15 the

1987
01:15:09,570 --> 01:15:11,400
goal is obviously have great scoop up as

1988
01:15:11,400 --> 01:15:13,739
soon as possible so you know it's not

1989
01:15:13,739 --> 01:15:14,820
like a week or two before the deadline

1990
01:15:14,820 --> 01:15:20,369
okay any questions about this alright

1991
01:15:20,369 --> 01:15:24,270
this might be fun right it's for you

1992
01:15:24,270 --> 01:15:26,489
guys to be a creative and do whatever

1993
01:15:26,489 --> 01:15:28,500
you want to do and see who see who has

1994
01:15:28,500 --> 01:15:32,820
the fastest one okay alright so next

1995
01:15:32,820 --> 01:15:34,920
week we'll start talking about actually

1996
01:15:34,920 --> 01:15:36,750
now I start executing queries and this

1997
01:15:36,750 --> 01:15:37,980
is where I actually spend a lot of our

1998
01:15:37,980 --> 01:15:40,710
time for the rest of the semester we'll

1999
01:15:40,710 --> 01:15:41,610
talk a little bit how we're gonna

2000
01:15:41,610 --> 01:15:43,949
organize and schedule threads and then

2001
01:15:43,949 --> 01:15:46,080
our processing models for queries then

2002
01:15:46,080 --> 01:15:48,449
we'll talk about coding compilation but

2003
01:15:48,449 --> 01:15:49,590
at this point it's really we're focusing

2004
01:15:49,590 --> 01:15:52,080
on now we know that how to index things

2005
01:15:52,080 --> 01:15:53,880
and stored things and send things over

2006
01:15:53,880 --> 01:15:55,349
the network how do we actually execute

2007
01:15:55,349 --> 01:15:56,310
query so that's the whole point of a

2008
01:15:56,310 --> 01:15:57,810
database system you want to get sequel

2009
01:15:57,810 --> 01:15:58,800
queries and maybe I'll run them in

2010
01:15:58,800 --> 01:16:01,830
produce answers okay all right guys

2011
01:16:01,830 --> 01:16:03,690
enjoy your weekend see ya Bank it in the

2012
01:16:03,690 --> 01:16:04,469
side park

2013
01:16:04,469 --> 01:16:07,420
what is this some fools

2014
01:16:07,420 --> 01:16:08,700
[Music]

2015
01:16:08,700 --> 01:16:11,250
especially with that here called the Oh

2016
01:16:11,250 --> 01:16:14,040
it cuz I mochi ice you down with the

2017
01:16:14,040 --> 01:16:17,460
testy my you look and it was go grab me

2018
01:16:17,460 --> 01:16:20,010
a forty just to get my buzz Oh cuz I

2019
01:16:20,010 --> 01:16:24,810
needed just a little more kick to my

2020
01:16:24,810 --> 01:16:28,560
lips and blow the truck the same as hot

2021
01:16:28,560 --> 01:16:31,500
and my heart wants me to say I've nice

2022
01:16:31,500 --> 01:16:35,450
you take a saint I said of pray

