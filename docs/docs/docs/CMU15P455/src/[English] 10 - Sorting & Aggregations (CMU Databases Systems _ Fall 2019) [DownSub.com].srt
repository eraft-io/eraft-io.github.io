1
00:00:06,920 --> 00:00:18,140
Oh guys let's start it what the

2
00:00:18,140 --> 00:00:20,359
president again Thank You DJ drop tables

3
00:00:20,359 --> 00:00:23,380
or keeps keeping everything for us

4
00:00:23,380 --> 00:00:26,779
alright so before we get into today's

5
00:00:26,779 --> 00:00:28,699
lecture just go through real quickly

6
00:00:28,699 --> 00:00:30,320
what's on the schedule for you guys

7
00:00:30,320 --> 00:00:32,540
coming up in the next two weeks so

8
00:00:32,540 --> 00:00:35,810
homework three is out today it should be

9
00:00:35,810 --> 00:00:38,270
on the website well we'll set up great

10
00:00:38,270 --> 00:00:39,440
scripts so you can submit later today

11
00:00:39,440 --> 00:00:41,690
and so that'll be due next week on

12
00:00:41,690 --> 00:00:45,500
Wednesday the 9th in two weeks we will

13
00:00:45,500 --> 00:00:48,859
have the the midterm exam project tubes

14
00:00:48,859 --> 00:00:49,879
going out today

15
00:00:49,879 --> 00:00:51,260
so I'll talk about a little I'll talk

16
00:00:51,260 --> 00:00:52,789
about that at the end of this miss

17
00:00:52,789 --> 00:00:54,859
lecture but that'll be due after the

18
00:00:54,859 --> 00:00:56,750
midterm the midterm will be on Wednesday

19
00:00:56,750 --> 00:01:00,949
the 16th in this room at the normal

20
00:01:00,949 --> 00:01:02,870
class time it'll be you know an hour and

21
00:01:02,870 --> 00:01:04,879
20 minute exam so this will cover

22
00:01:04,879 --> 00:01:07,760
everything up to and including next

23
00:01:07,760 --> 00:01:10,310
week's lectures so on Wednesday the 9th

24
00:01:10,310 --> 00:01:12,439
the midterm will cover that lecture and

25
00:01:12,439 --> 00:01:16,490
everything prior to that ok any

26
00:01:16,490 --> 00:01:17,180
questions about any of these

27
00:01:17,180 --> 00:01:20,900
expectations so homework number three

28
00:01:20,900 --> 00:01:22,579
knock that out before the midterm and

29
00:01:22,579 --> 00:01:25,100
then this thing project two it'll

30
00:01:25,100 --> 00:01:28,040
encompass some of the material that we

31
00:01:28,040 --> 00:01:29,119
talked about that'll be relevant to the

32
00:01:29,119 --> 00:01:31,159
midterm but it won't we do officially

33
00:01:31,159 --> 00:01:33,530
until after after the midterm so you

34
00:01:33,530 --> 00:01:37,090
space space things out for you guys okay

35
00:01:37,090 --> 00:01:40,520
okay so where we're at now in the

36
00:01:40,520 --> 00:01:43,909
semester is that we've again going up to

37
00:01:43,909 --> 00:01:46,280
this architecture layers we know how to

38
00:01:46,280 --> 00:01:49,189
store things on disk in pages we know

39
00:01:49,189 --> 00:01:50,689
how to then copy them into memory into

40
00:01:50,689 --> 00:01:52,789
our buffer pool manager as needed then

41
00:01:52,789 --> 00:01:54,350
we talked about how we actually access

42
00:01:54,350 --> 00:01:56,689
them so we can build indexes on top of

43
00:01:56,689 --> 00:01:58,549
them or we can do sequential scans and

44
00:01:58,549 --> 00:02:01,700
so now where we're at is up above now we

45
00:02:01,700 --> 00:02:03,170
actually want to start executing queries

46
00:02:03,170 --> 00:02:05,119
we actually want to be able to take

47
00:02:05,119 --> 00:02:07,670
sequel queries generate query plans for

48
00:02:07,670 --> 00:02:10,520
them and then have them use the access

49
00:02:10,520 --> 00:02:12,200
methods to get access to the data that

50
00:02:12,200 --> 00:02:16,040
we need okay so for the next two weeks

51
00:02:16,040 --> 00:02:17,480
we're going to first talk about how what

52
00:02:17,480 --> 00:02:19,310
how we actually implement the algorithms

53
00:02:19,310 --> 00:02:21,019
for our operators and our

54
00:02:21,019 --> 00:02:22,700
then we'll talk about different ways to

55
00:02:22,700 --> 00:02:25,040
process queries themselves like it's the

56
00:02:25,040 --> 00:02:27,500
how to remove data from one operator to

57
00:02:27,500 --> 00:02:29,540
the next and then we'll talk about also

58
00:02:29,540 --> 00:02:32,180
to the more system architecture was the

59
00:02:32,180 --> 00:02:34,340
runtime architecture of the system for

60
00:02:34,340 --> 00:02:35,840
threads or processes and how do we

61
00:02:35,840 --> 00:02:37,760
organize them to run you know queries in

62
00:02:37,760 --> 00:02:41,480
parallel so I'm not gonna go into detail

63
00:02:41,480 --> 00:02:43,970
what a query plan looks like just yet I

64
00:02:43,970 --> 00:02:45,590
just want to show you what one

65
00:02:45,590 --> 00:02:47,510
potentially looks like just to frame

66
00:02:47,510 --> 00:02:48,889
that a conversation where we're going

67
00:02:48,889 --> 00:02:51,379
today and the next class and then we'll

68
00:02:51,379 --> 00:02:53,329
go into way more detail about what query

69
00:02:53,329 --> 00:02:55,430
plan and execution looks like next week

70
00:02:55,430 --> 00:02:56,420
and then when we talk about query

71
00:02:56,420 --> 00:02:59,139
optimization query planning further so a

72
00:02:59,139 --> 00:03:01,510
query planet is essentially the the

73
00:03:01,510 --> 00:03:03,859
instructions or the high-level direction

74
00:03:03,859 --> 00:03:06,829
of how the database system is going to

75
00:03:06,829 --> 00:03:09,200
execute a given query and we're gonna

76
00:03:09,200 --> 00:03:11,870
organize the query plan into an in a

77
00:03:11,870 --> 00:03:14,060
tree tree structure or an acyclic

78
00:03:14,060 --> 00:03:16,730
directed graph so we take the sequel

79
00:03:16,730 --> 00:03:18,200
query like this or doing a join with a

80
00:03:18,200 --> 00:03:20,450
filter on table a and B we can represent

81
00:03:20,450 --> 00:03:22,939
it as a query plan like this where at

82
00:03:22,939 --> 00:03:25,190
the leaf nodes we're doing our scans or

83
00:03:25,190 --> 00:03:27,680
accessing the the tables and then we

84
00:03:27,680 --> 00:03:29,510
were moving tuples up to the next

85
00:03:29,510 --> 00:03:31,699
operator to do whatever it wants to do

86
00:03:31,699 --> 00:03:34,370
so in this case here we scan a and since

87
00:03:34,370 --> 00:03:35,659
we don't have any filter on it we just

88
00:03:35,659 --> 00:03:37,159
feed it right into our joint operator

89
00:03:37,159 --> 00:03:39,290
and then for the scan on B well first

90
00:03:39,290 --> 00:03:43,040
apply the filter to limit out any values

91
00:03:43,040 --> 00:03:44,989
less than F at 100 and then we feed that

92
00:03:44,989 --> 00:03:46,699
into our join operator and then this now

93
00:03:46,699 --> 00:03:48,229
produces some output that's then fed

94
00:03:48,229 --> 00:03:52,699
into the projection operator so what I'm

95
00:03:52,699 --> 00:03:54,769
showing here is what what we call it as

96
00:03:54,769 --> 00:03:58,430
a logical plan meaning I'm not saying

97
00:03:58,430 --> 00:04:00,859
anything about how we're what albs are

98
00:04:00,859 --> 00:04:02,720
we're gonna use to implement all these

99
00:04:02,720 --> 00:04:04,099
different operators I'm just saying this

100
00:04:04,099 --> 00:04:05,720
is at a high low what I want to do is

101
00:04:05,720 --> 00:04:07,340
the most like a direct translation of

102
00:04:07,340 --> 00:04:09,109
the relational algebra I want to do a

103
00:04:09,109 --> 00:04:11,000
join I'm not telling you how I want what

104
00:04:11,000 --> 00:04:12,379
to do to join us I just want to do one

105
00:04:12,379 --> 00:04:14,479
on a and B I want to get to pull some a

106
00:04:14,479 --> 00:04:16,039
I didn't tell you whether to do scruncho

107
00:04:16,039 --> 00:04:17,720
scan or index scan I'm just saying just

108
00:04:17,720 --> 00:04:20,509
get tuples from a so what we're focusing

109
00:04:20,509 --> 00:04:22,699
on today is now to talk about what these

110
00:04:22,699 --> 00:04:24,949
algorithms actually are and then we'll

111
00:04:24,949 --> 00:04:25,909
put it all together when we talk about

112
00:04:25,909 --> 00:04:27,530
query planning query optimization to say

113
00:04:27,530 --> 00:04:29,240
now we need to make a decision of here

114
00:04:29,240 --> 00:04:30,440
the different choices of algorithms I

115
00:04:30,440 --> 00:04:31,700
could use or different access methods I

116
00:04:31,700 --> 00:04:33,470
could use for my query which

117
00:04:33,470 --> 00:04:35,750
is gonna be the best for me so today's

118
00:04:35,750 --> 00:04:36,860
lecture is really focusing on

119
00:04:36,860 --> 00:04:38,600
and-and-and and for Wednesday's lecture

120
00:04:38,600 --> 00:04:40,130
as well for this week what are the

121
00:04:40,130 --> 00:04:41,420
different algorithms we can implement

122
00:04:41,420 --> 00:04:44,210
for the physical operators in our query

123
00:04:44,210 --> 00:04:46,130
plan but at a high level we're assuming

124
00:04:46,130 --> 00:04:47,420
that it's in this tree structure where

125
00:04:47,420 --> 00:04:49,580
we're moving two bulls one Operator to

126
00:04:49,580 --> 00:04:53,720
the next so this Clara hi this is

127
00:04:53,720 --> 00:04:55,280
essentially what what you know what any

128
00:04:55,280 --> 00:04:58,220
any query engine is going to do right

129
00:04:58,220 --> 00:04:59,570
they're gonna represent as a treat as a

130
00:04:59,570 --> 00:05:01,790
dataflow tree and they moving tuples

131
00:05:01,790 --> 00:05:05,120
between them so the tricky thing though

132
00:05:05,120 --> 00:05:08,150
now that for us when we start deciding

133
00:05:08,150 --> 00:05:09,380
what we know how do we actually

134
00:05:09,380 --> 00:05:10,970
implement the algorithms for these

135
00:05:10,970 --> 00:05:14,750
operators is that again we this entire

136
00:05:14,750 --> 00:05:17,060
semester is focusing on the system

137
00:05:17,060 --> 00:05:19,250
that's assuming that data doesn't fit

138
00:05:19,250 --> 00:05:22,040
entirely in memory so just like within

139
00:05:22,040 --> 00:05:23,750
our disk or new database system just

140
00:05:23,750 --> 00:05:25,490
like we can't assume that tables fit

141
00:05:25,490 --> 00:05:27,470
entirely memory where indexes can't fit

142
00:05:27,470 --> 00:05:29,990
tiredly memory we now need to be worried

143
00:05:29,990 --> 00:05:31,940
about that the intermediate results

144
00:05:31,940 --> 00:05:34,370
between those operators cannot actually

145
00:05:34,370 --> 00:05:37,160
fit entirely in main memory so therefore

146
00:05:37,160 --> 00:05:38,870
when we design the algorithms we're

147
00:05:38,870 --> 00:05:42,110
going to use to execute you know the

148
00:05:42,110 --> 00:05:44,570
operator we need we need to pick ones

149
00:05:44,570 --> 00:05:46,580
that actually know how to write data at

150
00:05:46,580 --> 00:05:47,990
the disk and be mindful that we may have

151
00:05:47,990 --> 00:05:49,190
to read and write data from disk and

152
00:05:49,190 --> 00:05:50,720
therefore we'll make certain design

153
00:05:50,720 --> 00:05:52,790
decision in those algorithms to to

154
00:05:52,790 --> 00:05:55,430
accommodate them right so just as a

155
00:05:55,430 --> 00:05:57,440
quick example I'm doing a joint here on

156
00:05:57,440 --> 00:06:00,830
a and B the hash table or depending what

157
00:06:00,830 --> 00:06:02,210
you know what what joint album I'm going

158
00:06:02,210 --> 00:06:04,610
to use I may have to spill the disk like

159
00:06:04,610 --> 00:06:06,650
a doesn't fit in memory B doesn't fit in

160
00:06:06,650 --> 00:06:08,150
memory so I need to join algorithm that

161
00:06:08,150 --> 00:06:10,790
can handle you know inputs where the

162
00:06:10,790 --> 00:06:11,990
entire data set may not fit in memory

163
00:06:11,990 --> 00:06:14,150
furthermore the output also may not fit

164
00:06:14,150 --> 00:06:16,430
entirely main memory so again we're

165
00:06:16,430 --> 00:06:17,990
gonna use our buffer pool manager that

166
00:06:17,990 --> 00:06:20,270
we built in the first project we talked

167
00:06:20,270 --> 00:06:22,400
about before that's how we're gonna be

168
00:06:22,400 --> 00:06:24,590
able to accommodate algorithms that need

169
00:06:24,590 --> 00:06:26,890
more memory than is actually available

170
00:06:26,890 --> 00:06:29,360
so we're not using for tables not using

171
00:06:29,360 --> 00:06:32,750
it for for for indexes we can use it for

172
00:06:32,750 --> 00:06:34,610
intermediate results and this again goes

173
00:06:34,610 --> 00:06:36,680
back to why I was saying before this is

174
00:06:36,680 --> 00:06:38,720
why the you know if the database system

175
00:06:38,720 --> 00:06:40,400
ends just a memory instead of letting

176
00:06:40,400 --> 00:06:42,770
the OS do it the OS can oh oh this page

177
00:06:42,770 --> 00:06:45,140
is for an ephemeral data structure to do

178
00:06:45,140 --> 00:06:46,880
whatever my query is and I'm gonna throw

179
00:06:46,880 --> 00:06:48,740
immediately after the queries over and

180
00:06:48,740 --> 00:06:50,570
maybe I want to do different things or

181
00:06:50,570 --> 00:06:51,860
have different replacement policies or

182
00:06:51,860 --> 00:06:54,050
different strategies for those kind of

183
00:06:54,050 --> 00:06:56,330
pages and those kind of data versus the

184
00:06:56,330 --> 00:06:58,640
data coming from from the underlying

185
00:06:58,640 --> 00:07:00,890
tables whereas the OS doesn't see that

186
00:07:00,890 --> 00:07:01,940
it always doesn't know anything about

187
00:07:01,940 --> 00:07:03,500
what's inside these pages or how they're

188
00:07:03,500 --> 00:07:07,160
being used so again we're gonna use our

189
00:07:07,160 --> 00:07:08,810
puffle manager Bureau of scope Islands a

190
00:07:08,810 --> 00:07:10,550
disk and therefore we're gonna design

191
00:07:10,550 --> 00:07:12,710
algorithms of prefer algorithms they're

192
00:07:12,710 --> 00:07:14,960
gonna maximize the amount of sequential

193
00:07:14,960 --> 00:07:17,330
i/o that we can do and this is gonna be

194
00:07:17,330 --> 00:07:18,680
different than any algorithms course

195
00:07:18,680 --> 00:07:20,780
you've taken potentially before where

196
00:07:20,780 --> 00:07:22,190
you assume that you're just reading

197
00:07:22,190 --> 00:07:23,600
writing into memory and everything has

198
00:07:23,600 --> 00:07:26,420
uniform access and now we need be

199
00:07:26,420 --> 00:07:28,040
mindful of what's actually in memory

200
00:07:28,040 --> 00:07:32,450
when we design these approaches so we're

201
00:07:32,450 --> 00:07:33,590
gonna first start off talking about the

202
00:07:33,590 --> 00:07:37,370
external merge sort algorithm and what

203
00:07:37,370 --> 00:07:38,720
will come out of this discussion you

204
00:07:38,720 --> 00:07:40,550
will see some high-level strategies for

205
00:07:40,550 --> 00:07:42,530
essentially doing divide and conquer

206
00:07:42,530 --> 00:07:45,350
that allow us to then that we can apply

207
00:07:45,350 --> 00:07:47,120
to other methods or other operators we

208
00:07:47,120 --> 00:07:48,800
want to implement and then we'll finish

209
00:07:48,800 --> 00:07:50,920
up talking about how to do aggregations

210
00:07:50,920 --> 00:07:53,990
which can rely on sorting algorithm but

211
00:07:53,990 --> 00:07:57,170
then it also sort of Segway and into the

212
00:07:57,170 --> 00:07:58,430
joint album stuff we talked about next

213
00:07:58,430 --> 00:08:00,590
week about hash joins so there's sort of

214
00:08:00,590 --> 00:08:02,180
this trade-off between sorting versus

215
00:08:02,180 --> 00:08:03,710
hashing as the two different methods you

216
00:08:03,710 --> 00:08:05,840
can used to exude algorithms in your

217
00:08:05,840 --> 00:08:07,400
database system we're going to first

218
00:08:07,400 --> 00:08:10,460
talk about sorting and then we'll add in

219
00:08:10,460 --> 00:08:14,870
hashing at the end okay all right so

220
00:08:14,870 --> 00:08:18,140
it's sort of obvious that you know why

221
00:08:18,140 --> 00:08:19,850
we need to sort but just make sure that

222
00:08:19,850 --> 00:08:21,440
everyone puts this in the correct

223
00:08:21,440 --> 00:08:25,130
context the in relational model the

224
00:08:25,130 --> 00:08:27,380
tuples in our relations are inherently

225
00:08:27,380 --> 00:08:30,710
unsorted right it's set algebra there's

226
00:08:30,710 --> 00:08:32,500
no sort order so we can't assume that

227
00:08:32,500 --> 00:08:35,419
the the data as we read them is gonna in

228
00:08:35,419 --> 00:08:36,919
any one particular order now there's

229
00:08:36,919 --> 00:08:38,150
clustering indexes that we talked about

230
00:08:38,150 --> 00:08:40,039
before it was talked about again today

231
00:08:40,039 --> 00:08:44,470
which then you know provide you a

232
00:08:44,470 --> 00:08:46,460
enforces of sort order based on some

233
00:08:46,460 --> 00:08:48,590
index but in general we can't assume

234
00:08:48,590 --> 00:08:49,640
that's always gonna be the case and

235
00:08:49,640 --> 00:08:52,370
furthermore we could have an index our

236
00:08:52,370 --> 00:08:53,510
table could be clustered on one

237
00:08:53,510 --> 00:08:54,800
particular key but now we need to sort

238
00:08:54,800 --> 00:08:57,290
it on another key so that you know being

239
00:08:57,290 --> 00:08:58,610
pre-sorted doesn't actually help us in

240
00:08:58,610 --> 00:09:00,180
that scenario

241
00:09:00,180 --> 00:09:03,930
so in addition to also now being able to

242
00:09:03,930 --> 00:09:05,700
you know someone calls an order by and

243
00:09:05,700 --> 00:09:08,190
we want to sort the output we if our

244
00:09:08,190 --> 00:09:10,020
data is sorted there's a bunch of other

245
00:09:10,020 --> 00:09:11,430
optimizations we can do for other

246
00:09:11,430 --> 00:09:13,380
utility things we want to do or queries

247
00:09:13,380 --> 00:09:14,430
we want to execute in our database

248
00:09:14,430 --> 00:09:18,240
system so if our table is sorted or

249
00:09:18,240 --> 00:09:20,490
outputs or keys are sorted then it's

250
00:09:20,490 --> 00:09:23,370
really easy to do duplicate elimination

251
00:09:23,370 --> 00:09:25,290
because now I just scan through the

252
00:09:25,290 --> 00:09:26,610
table once and if I see that's the thing

253
00:09:26,610 --> 00:09:28,050
I'm looking at is the same as when I saw

254
00:09:28,050 --> 00:09:29,970
the last thing I looked at that I know

255
00:09:29,970 --> 00:09:31,170
is a duplicate and I just throw it away

256
00:09:31,170 --> 00:09:34,290
for group eyes this is the same thing I

257
00:09:34,290 --> 00:09:36,240
can if everything is pre-sorted then I

258
00:09:36,240 --> 00:09:37,890
can generate the aggregations by just

259
00:09:37,890 --> 00:09:38,940
scanning through the table once and

260
00:09:38,940 --> 00:09:41,070
computing the running totals as needed

261
00:09:41,070 --> 00:09:43,260
and then we talked about optimization of

262
00:09:43,260 --> 00:09:45,240
doing bulk so bulk loading in a P plus

263
00:09:45,240 --> 00:09:47,820
tree where you pre sort all the data

264
00:09:47,820 --> 00:09:49,380
along the leaf nodes and then you build

265
00:09:49,380 --> 00:09:51,030
the index from the from the bottom up

266
00:09:51,030 --> 00:09:53,400
rather than top down and that's way more

267
00:09:53,400 --> 00:09:57,570
efficient so again sorting is a as a as

268
00:09:57,570 --> 00:09:59,220
a useful utility operation grid need in

269
00:09:59,220 --> 00:10:00,600
our database system but we need to be

270
00:10:00,600 --> 00:10:02,010
able to accommodate one where we doesn't

271
00:10:02,010 --> 00:10:04,680
fit entirely in memory because it fits

272
00:10:04,680 --> 00:10:06,750
in memory then we just pick whatever

273
00:10:06,750 --> 00:10:08,400
your favorite sorting algorithm that you

274
00:10:08,400 --> 00:10:09,960
you know and love from your intro

275
00:10:09,960 --> 00:10:12,320
classes and that works just fine for us

276
00:10:12,320 --> 00:10:13,950
quicksort heapsort

277
00:10:13,950 --> 00:10:16,800
if you crazy bubble sort right but we

278
00:10:16,800 --> 00:10:18,960
don't care it's in memory so all the

279
00:10:18,960 --> 00:10:21,060
things that we learned before in intro

280
00:10:21,060 --> 00:10:24,360
to albums class work just fine but then

281
00:10:24,360 --> 00:10:25,890
the issues now if it doesn't fit in

282
00:10:25,890 --> 00:10:27,840
memory quick sorts can be terrible for

283
00:10:27,840 --> 00:10:29,640
us because what does quicksort doing

284
00:10:29,640 --> 00:10:30,870
quicksort is doing bunch of random

285
00:10:30,870 --> 00:10:32,730
pivots jumping around to memory in

286
00:10:32,730 --> 00:10:34,860
different locations that's random i/o

287
00:10:34,860 --> 00:10:37,080
and our role because those pages we're

288
00:10:37,080 --> 00:10:39,270
jumping into may not actually fit in

289
00:10:39,270 --> 00:10:41,430
memory and the worst case scenario we're

290
00:10:41,430 --> 00:10:44,400
having one IO cost per you know per

291
00:10:44,400 --> 00:10:49,830
change to the the data set so instead we

292
00:10:49,830 --> 00:10:53,190
want an algorithm that is mindful of the

293
00:10:53,190 --> 00:10:54,750
potential cost of reading writing dated

294
00:10:54,750 --> 00:10:57,660
disk and therefore make certain the

295
00:10:57,660 --> 00:10:59,820
design decisions that try to maximize

296
00:10:59,820 --> 00:11:01,530
the amount of squinch IO sequential i/o

297
00:11:01,530 --> 00:11:04,230
even on faster SSDs is to be more

298
00:11:04,230 --> 00:11:07,680
efficient than than random i/o because

299
00:11:07,680 --> 00:11:09,090
you can bring a lot more data in with a

300
00:11:09,090 --> 00:11:12,120
single and there's no seek in an SSD but

301
00:11:12,120 --> 00:11:13,980
within a single you know

302
00:11:13,980 --> 00:11:15,779
with a single read operation or write

303
00:11:15,779 --> 00:11:17,910
operation down into the device you can

304
00:11:17,910 --> 00:11:21,990
get more data coming back right so the

305
00:11:21,990 --> 00:11:25,170
I'm going to use and and at a high level

306
00:11:25,170 --> 00:11:27,899
this is what every is what every single

307
00:11:27,899 --> 00:11:30,449
database and does that supports atom

308
00:11:30,449 --> 00:11:32,279
memory sorting is a called the external

309
00:11:32,279 --> 00:11:34,949
merge sort alright sometimes it's a you

310
00:11:34,949 --> 00:11:37,170
seek external sort merge and it be

311
00:11:37,170 --> 00:11:38,279
really confusing because they'll be

312
00:11:38,279 --> 00:11:39,779
there's the external merge sort

313
00:11:39,779 --> 00:11:42,089
algorithm and then we'll see a sort

314
00:11:42,089 --> 00:11:43,740
merge join which could use the merge

315
00:11:43,740 --> 00:11:46,769
sort algorithm right but I'll try to

316
00:11:46,769 --> 00:11:47,910
make it more clear when we talk about

317
00:11:47,910 --> 00:11:50,250
joins what we're actually doing so as I

318
00:11:50,250 --> 00:11:51,630
said this is a divide and conquer

319
00:11:51,630 --> 00:11:52,620
approach where we're gonna basically

320
00:11:52,620 --> 00:11:54,899
split the data set that we want to sort

321
00:11:54,899 --> 00:11:57,990
up into these smaller chunks called runs

322
00:11:57,990 --> 00:12:00,570
and then we're going to sort those runs

323
00:12:00,570 --> 00:12:03,720
individually write all the keys within a

324
00:12:03,720 --> 00:12:06,870
given run or are sorted and this the

325
00:12:06,870 --> 00:12:09,360
runs are disjoint subsets of the entire

326
00:12:09,360 --> 00:12:11,820
Keys that we want to sort and so then

327
00:12:11,820 --> 00:12:13,019
we're gonna sort these little these

328
00:12:13,019 --> 00:12:16,019
little runs and then we're gonna start

329
00:12:16,019 --> 00:12:18,060
combining them together to create create

330
00:12:18,060 --> 00:12:21,209
larger sorted runs and we keep doing

331
00:12:21,209 --> 00:12:22,529
this and doing this until we get the

332
00:12:22,529 --> 00:12:24,660
full data set the full key set that we

333
00:12:24,660 --> 00:12:27,660
want sorted so there's two phases for

334
00:12:27,660 --> 00:12:29,399
this so the first phase again we're

335
00:12:29,399 --> 00:12:31,170
gonna take as many blocks as we can fit

336
00:12:31,170 --> 00:12:33,360
in memory sort them and then write them

337
00:12:33,360 --> 00:12:35,970
back out the disk then in the second

338
00:12:35,970 --> 00:12:37,350
phase again that's when you go combine

339
00:12:37,350 --> 00:12:40,560
these sub sort sorted runs into larger

340
00:12:40,560 --> 00:12:41,910
sort of runs and then write them out and

341
00:12:41,910 --> 00:12:43,440
you keep doing this over and over until

342
00:12:43,440 --> 00:12:45,810
you have the entire things sorted so

343
00:12:45,810 --> 00:12:47,220
this is gonna end to end up taking

344
00:12:47,220 --> 00:12:49,920
potentially multiple passes through the

345
00:12:49,920 --> 00:12:52,410
data set that we're trying to sort but

346
00:12:52,410 --> 00:12:53,940
in the end we end up with a complete

347
00:12:53,940 --> 00:12:57,300
sort of run so let's start with a simple

348
00:12:57,300 --> 00:13:00,180
example called a 2-way merge sort it's a

349
00:13:00,180 --> 00:13:02,160
2-way means that were where the number

350
00:13:02,160 --> 00:13:03,480
two is that it's the number of sort of

351
00:13:03,480 --> 00:13:05,310
runs we're gonna merge together for

352
00:13:05,310 --> 00:13:08,010
every single pass alright so within a

353
00:13:08,010 --> 00:13:10,860
pass we're gonna go grab two runs merge

354
00:13:10,860 --> 00:13:13,470
them together and produce a new path a

355
00:13:13,470 --> 00:13:15,480
new run that's that's the combination of

356
00:13:15,480 --> 00:13:17,720
the two smaller ones that were our input

357
00:13:17,720 --> 00:13:20,069
so our data set is gonna be broken up

358
00:13:20,069 --> 00:13:22,589
into n pages and then what's now

359
00:13:22,589 --> 00:13:24,269
important for us when we consider what

360
00:13:24,269 --> 00:13:25,860
how algorithms going to work is that we

361
00:13:25,860 --> 00:13:27,449
need to know how much memory is

362
00:13:27,449 --> 00:13:28,140
available

363
00:13:28,140 --> 00:13:32,070
to us to buffer things in memory to do

364
00:13:32,070 --> 00:13:34,110
our sorting because again if everything

365
00:13:34,110 --> 00:13:36,030
fits in memory then we don't need to do

366
00:13:36,030 --> 00:13:38,220
any of this we just do quicksort but we

367
00:13:38,220 --> 00:13:40,500
need to be told ahead of time how much

368
00:13:40,500 --> 00:13:42,240
memory we're allowed to use for sorting

369
00:13:42,240 --> 00:13:44,310
and this is actually something you can

370
00:13:44,310 --> 00:13:46,020
configure in database systems so in

371
00:13:46,020 --> 00:13:47,460
Postgres it's called working memory

372
00:13:47,460 --> 00:13:50,300
you basically say how much memory the

373
00:13:50,300 --> 00:13:53,610
one particularly is allowed to use for

374
00:13:53,610 --> 00:13:55,260
whatever kind of intermediate operation

375
00:13:55,260 --> 00:13:57,510
wants to do building a hash table doing

376
00:13:57,510 --> 00:13:59,760
sorting and other things like that so

377
00:13:59,760 --> 00:14:01,350
we're told this we're always told this

378
00:14:01,350 --> 00:14:05,250
be ahead of time so let's look at sort

379
00:14:05,250 --> 00:14:08,070
of visual examples so in past 0 you're

380
00:14:08,070 --> 00:14:09,990
gonna read every B pages from the table

381
00:14:09,990 --> 00:14:11,880
into memory and then you're gonna sort

382
00:14:11,880 --> 00:14:14,610
them in place in memory and then write

383
00:14:14,610 --> 00:14:17,580
them out so let's really say for example

384
00:14:17,580 --> 00:14:19,830
I have a disk on disk I have my data set

385
00:14:19,830 --> 00:14:22,380
I have two pages so let's say this case

386
00:14:22,380 --> 00:14:25,470
here I can only have I can I can bring

387
00:14:25,470 --> 00:14:27,780
in the first page sort that in place and

388
00:14:27,780 --> 00:14:29,850
now that's a sort of run and then I

389
00:14:29,850 --> 00:14:31,980
write that sort of run out the disk and

390
00:14:31,980 --> 00:14:33,870
I'm gonna do this one at a time assuming

391
00:14:33,870 --> 00:14:35,730
I must have a single thread I'm gonna do

392
00:14:35,730 --> 00:14:36,900
this one at a time for all my other

393
00:14:36,900 --> 00:14:40,980
pages right so now so this is sort of

394
00:14:40,980 --> 00:14:42,780
step one and then now we're here I'm

395
00:14:42,780 --> 00:14:44,490
reading the other page I bring that into

396
00:14:44,490 --> 00:14:47,510
memory sort it and then I write that out

397
00:14:47,510 --> 00:14:50,460
so now that's the end of past zero that

398
00:14:50,460 --> 00:14:52,410
I've taken all the the my sort of runs

399
00:14:52,410 --> 00:14:56,550
sorry all my my I grab a run that's the

400
00:14:56,550 --> 00:14:59,490
size of B pages I sort that in memory

401
00:14:59,490 --> 00:15:00,870
because IB pages I'm allowed to use a

402
00:15:00,870 --> 00:15:02,430
memory so I'm sorting that in place and

403
00:15:02,430 --> 00:15:04,080
then I'm writing it back out and then I

404
00:15:04,080 --> 00:15:06,240
go to the next run once after that's

405
00:15:06,240 --> 00:15:10,320
done so now in the subsequent passes

406
00:15:10,320 --> 00:15:13,560
we're going to recur submerges of all

407
00:15:13,560 --> 00:15:15,690
the runs we sorted so far and we're

408
00:15:15,690 --> 00:15:16,920
gonna combine them together to produce

409
00:15:16,920 --> 00:15:18,570
runs that are double the size of my

410
00:15:18,570 --> 00:15:21,570
input right and so for this approach I

411
00:15:21,570 --> 00:15:25,160
need I need at least three buffer pages

412
00:15:25,160 --> 00:15:29,280
because I need to have one to buffer

413
00:15:29,280 --> 00:15:30,900
pages for each of the two runs that I'm

414
00:15:30,900 --> 00:15:32,940
bringing into memory and then another

415
00:15:32,940 --> 00:15:35,160
buffer page for the output that I'm

416
00:15:35,160 --> 00:15:38,820
writing out so in this case here I could

417
00:15:38,820 --> 00:15:41,279
say I want to sort these these that you

418
00:15:41,279 --> 00:15:43,290
sorta guys so I bring those in memory

419
00:15:43,290 --> 00:15:45,569
and now I have one other page where I

420
00:15:45,569 --> 00:15:47,490
can write out the the combination of

421
00:15:47,490 --> 00:15:50,279
these two guys but I you know this is

422
00:15:50,279 --> 00:15:51,959
two pages long but I only have one page

423
00:15:51,959 --> 00:15:54,329
so I'm just gonna scan through each of

424
00:15:54,329 --> 00:15:56,670
these and compare them one by one to see

425
00:15:56,670 --> 00:15:58,319
which one is greater than the other

426
00:15:58,319 --> 00:15:59,519
sorry which was less than the other

427
00:15:59,519 --> 00:16:00,899
depending what order you're going and

428
00:16:00,899 --> 00:16:03,600
then I just write that out into a sorted

429
00:16:03,600 --> 00:16:05,939
page like this and then once that's full

430
00:16:05,939 --> 00:16:09,509
then I write that out the disk and then

431
00:16:09,509 --> 00:16:12,089
my merging continues where I keep going

432
00:16:12,089 --> 00:16:13,589
down think of leagues - cursors are

433
00:16:13,589 --> 00:16:14,819
scanning through these guys comparing

434
00:16:14,819 --> 00:16:16,589
them one by one then I continue down

435
00:16:16,589 --> 00:16:17,939
with the other data set and I write that

436
00:16:17,939 --> 00:16:20,879
write that page out and then once I've

437
00:16:20,879 --> 00:16:22,769
reached the end then I have then I'm

438
00:16:22,769 --> 00:16:37,499
done this is this clip yes so her

439
00:16:37,499 --> 00:16:39,480
question is if if the memory in this

440
00:16:39,480 --> 00:16:40,620
case here memory can hold three pages

441
00:16:40,620 --> 00:16:42,600
why not is do exactly what I just did

442
00:16:42,600 --> 00:16:44,899
here first

443
00:16:44,899 --> 00:16:47,910
yeah you could think of like and then

444
00:16:47,910 --> 00:16:49,139
this is sort of simple example you can

445
00:16:49,139 --> 00:16:51,750
think of like I could bring I could

446
00:16:51,750 --> 00:16:53,879
bring the two sort of pages unsorted

447
00:16:53,879 --> 00:16:57,329
pages in memory sort them in place then

448
00:16:57,329 --> 00:16:58,800
do the combination without having to

449
00:16:58,800 --> 00:17:01,110
write them back out of the disk yes but

450
00:17:01,110 --> 00:17:02,339
in general that's like that

451
00:17:02,339 --> 00:17:03,660
this is a trilogy upon general that's

452
00:17:03,660 --> 00:17:09,569
not you can't do that this is also sort

453
00:17:09,569 --> 00:17:13,079
of oversimplification to because think

454
00:17:13,079 --> 00:17:15,209
of these are like the data pages of the

455
00:17:15,209 --> 00:17:17,309
tuple or the table right there these up

456
00:17:17,309 --> 00:17:19,349
tuples in them you're actually really

457
00:17:19,349 --> 00:17:21,780
can't kind of do this the the in-place

458
00:17:21,780 --> 00:17:23,220
sorting like this because that would be

459
00:17:23,220 --> 00:17:24,809
modifying the actual table itself and

460
00:17:24,809 --> 00:17:27,569
you don't want to do that so in general

461
00:17:27,569 --> 00:17:29,610
usually like you're not going to do this

462
00:17:29,610 --> 00:17:31,620
one step here where I was sorting them

463
00:17:31,620 --> 00:17:32,309
in place

464
00:17:32,309 --> 00:17:33,870
you'd make another copy and then write

465
00:17:33,870 --> 00:17:35,940
that out so in that case that wouldn't

466
00:17:35,940 --> 00:17:38,159
work because you would need you would

467
00:17:38,159 --> 00:17:45,520
need at most four pages in memory okay

468
00:17:45,520 --> 00:17:48,520
so so this is sort again this is a sort

469
00:17:48,520 --> 00:17:50,410
of a simplification but looks like you

470
00:17:50,410 --> 00:17:51,429
work through the math now see what

471
00:17:51,429 --> 00:17:52,390
actually what happens so let's go

472
00:17:52,390 --> 00:17:55,570
through a more a more fine-grain example

473
00:17:55,570 --> 00:17:58,750
here so the way the math works out is

474
00:17:58,750 --> 00:18:00,190
the number of passes we need for this

475
00:18:00,190 --> 00:18:02,890
two-way merge sort is 1 plus the ceiling

476
00:18:02,890 --> 00:18:06,790
of log 2n right and the first one here

477
00:18:06,790 --> 00:18:08,320
the one that's 4

478
00:18:08,320 --> 00:18:11,140
that's for the first pass and then the

479
00:18:11,140 --> 00:18:15,340
log 2n is is as you as you keep dividing

480
00:18:15,340 --> 00:18:19,630
up the in each pass you're sort of

481
00:18:19,630 --> 00:18:21,309
getting a larger and larger runs until

482
00:18:21,309 --> 00:18:23,410
you reach the total size of the data set

483
00:18:23,410 --> 00:18:27,790
right the last pass the two runs that

484
00:18:27,790 --> 00:18:31,179
you're sorting will will be you know at

485
00:18:31,179 --> 00:18:33,370
most half the size of the total data

486
00:18:33,370 --> 00:18:37,300
data set so the total ioio calls to

487
00:18:37,300 --> 00:18:39,429
joining sure number sword is 2m times

488
00:18:39,429 --> 00:18:41,260
the number of passes and this is 2n

489
00:18:41,260 --> 00:18:43,000
because I always have to read it in and

490
00:18:43,000 --> 00:18:45,850
write it out right for every pass it's

491
00:18:45,850 --> 00:18:48,700
one read in and then one right out so

492
00:18:48,700 --> 00:18:50,830
and means also in every pass at most I'm

493
00:18:50,830 --> 00:18:53,350
reading I'm reading and writing every

494
00:18:53,350 --> 00:18:55,179
record every key that I'm trying to sort

495
00:18:55,179 --> 00:18:58,890
exactly once once in and once back out

496
00:18:58,890 --> 00:19:01,120
so let's look at an example like this

497
00:19:01,120 --> 00:19:03,580
alright so we have a bunch of pages and

498
00:19:03,580 --> 00:19:06,220
each page we have two keys in them so

499
00:19:06,220 --> 00:19:07,960
yeah and then this little marker to say

500
00:19:07,960 --> 00:19:11,110
here's the end of file so in the first

501
00:19:11,110 --> 00:19:14,490
pass we're just gonna read in every page

502
00:19:14,490 --> 00:19:17,980
sort it and then write it back out so

503
00:19:17,980 --> 00:19:19,390
we're not examining data across

504
00:19:19,390 --> 00:19:21,309
different pages or these are actually

505
00:19:21,309 --> 00:19:24,400
runs but it's it's a one page run then

506
00:19:24,400 --> 00:19:26,940
in the next pass I'm gonna go grab two

507
00:19:26,940 --> 00:19:29,320
to two sort of runs that are next to

508
00:19:29,320 --> 00:19:32,380
each other bring them to memory sort

509
00:19:32,380 --> 00:19:34,750
them globally within within the two

510
00:19:34,750 --> 00:19:36,730
pages and then write those guys out so

511
00:19:36,730 --> 00:19:38,140
in this case here the output of the

512
00:19:38,140 --> 00:19:40,510
second pass will be runs of size two

513
00:19:40,510 --> 00:19:42,750
pages

514
00:19:43,830 --> 00:19:46,260
and then I do this keep is going down

515
00:19:46,260 --> 00:19:47,850
second page now I have four rot four

516
00:19:47,850 --> 00:19:49,740
page runs and the last one I have an

517
00:19:49,740 --> 00:19:51,510
eight page run and then here point I'm

518
00:19:51,510 --> 00:19:54,750
done because now my output run is the

519
00:19:54,750 --> 00:19:58,500
total size of of the number of keys that

520
00:19:58,500 --> 00:20:08,400
I have okay so what I've shown you so

521
00:20:08,400 --> 00:20:10,890
far all right for the two a merge sort

522
00:20:10,890 --> 00:20:13,680
as I said it only requires three buffer

523
00:20:13,680 --> 00:20:16,110
pages two for the input one for the

524
00:20:16,110 --> 00:20:18,870
output so back going back here when I

525
00:20:18,870 --> 00:20:21,780
was creating this this you know now

526
00:20:21,780 --> 00:20:24,480
creating a run that's two pages actually

527
00:20:24,480 --> 00:20:26,190
use this example so now I'm creating a

528
00:20:26,190 --> 00:20:28,290
run that has four pages I can only have

529
00:20:28,290 --> 00:20:30,840
three pages in memory all right so I

530
00:20:30,840 --> 00:20:32,790
have I'm gonna have one for the the

531
00:20:32,790 --> 00:20:34,830
right side or the left side one for the

532
00:20:34,830 --> 00:20:36,450
right side so again you think I'll just

533
00:20:36,450 --> 00:20:38,730
have a cursor I'm just scanning through

534
00:20:38,730 --> 00:20:41,160
each of the pages on the two sides and

535
00:20:41,160 --> 00:20:42,780
then compare to see whether one is

536
00:20:42,780 --> 00:20:45,150
greater than the other and if the one is

537
00:20:45,150 --> 00:20:46,410
less than the other then that's what I

538
00:20:46,410 --> 00:20:48,180
write out to my output and then move

539
00:20:48,180 --> 00:20:50,070
that cursor down and then I do the same

540
00:20:50,070 --> 00:20:52,920
comparison right so I keep going

541
00:20:52,920 --> 00:20:55,710
step by step until I reach the end the

542
00:20:55,710 --> 00:20:56,790
cursor reach to the ends of both of them

543
00:20:56,790 --> 00:21:01,920
yes a question is and what is my what am

544
00:21:01,920 --> 00:21:02,910
i showing here are these numbers

545
00:21:02,910 --> 00:21:04,950
consider tuples yes

546
00:21:04,950 --> 00:21:06,120
I'm showing the simplification their

547
00:21:06,120 --> 00:21:09,390
keys but in actuality in a real system

548
00:21:09,390 --> 00:21:10,740
you'd have like the key you trying to

549
00:21:10,740 --> 00:21:12,780
sort on and then the record idea where

550
00:21:12,780 --> 00:21:13,760
it came from

551
00:21:13,760 --> 00:21:20,340
yes in this example here each square is

552
00:21:20,340 --> 00:21:23,790
a page right but I'm there's only two

553
00:21:23,790 --> 00:21:28,970
keys in the page for simplicity yeah

554
00:21:30,070 --> 00:21:36,379
okay so again for this example here we

555
00:21:36,379 --> 00:21:39,559
only have we only need two pages but the

556
00:21:39,559 --> 00:21:41,389
problem is say I said I'll give you more

557
00:21:41,389 --> 00:21:44,990
pages and what I'm showing so far you're

558
00:21:44,990 --> 00:21:49,269
not actually gonna get any better right

559
00:21:49,269 --> 00:21:56,000
why he's right the i/o remains the same

560
00:21:56,000 --> 00:21:57,710
because what am i doing I'm going

561
00:21:57,710 --> 00:21:59,840
fetching two pages and then I have this

562
00:21:59,840 --> 00:22:01,159
cursor it's gonna walk through them and

563
00:22:01,159 --> 00:22:04,850
then whatever one has the you has the

564
00:22:04,850 --> 00:22:06,559
lower key that gets written out to the

565
00:22:06,559 --> 00:22:09,649
third page having more pages in memory

566
00:22:09,649 --> 00:22:12,049
doesn't really help us because you know

567
00:22:12,049 --> 00:22:13,850
eventually I'm only can doing comparison

568
00:22:13,850 --> 00:22:18,080
you know two pages at a time so a really

569
00:22:18,080 --> 00:22:21,500
simple optimization to to minimize this

570
00:22:21,500 --> 00:22:25,909
this this i/o cost is to do prefetching

571
00:22:25,909 --> 00:22:27,889
so this technique is called double

572
00:22:27,889 --> 00:22:30,980
buffering the idea is that when you go

573
00:22:30,980 --> 00:22:33,529
and start merging say two other pages

574
00:22:33,529 --> 00:22:35,509
you have a bunch of shadow pages or

575
00:22:35,509 --> 00:22:37,610
shadow buffers where you start fetching

576
00:22:37,610 --> 00:22:40,610
in the the next runs you need to sort or

577
00:22:40,610 --> 00:22:43,669
the next pages you need to sort so it

578
00:22:43,669 --> 00:22:45,409
requires you to have deuce asynchronous

579
00:22:45,409 --> 00:22:46,820
i/o to have something in the background

580
00:22:46,820 --> 00:22:49,279
go and fetch the the next pages you're

581
00:22:49,279 --> 00:22:50,899
going to need so that when the cursor

582
00:22:50,899 --> 00:22:52,039
reads that reaches the end of the

583
00:22:52,039 --> 00:22:54,740
current page that's operating on the

584
00:22:54,740 --> 00:22:57,259
next page that it needs is there if it's

585
00:22:57,259 --> 00:22:58,669
single threaded and every everything

586
00:22:58,669 --> 00:23:00,289
synchronous then you have this ping-pong

587
00:23:00,289 --> 00:23:02,809
effect where I'm gonna be CPU bound and

588
00:23:02,809 --> 00:23:04,490
disk bound and CPU bound the disk bound

589
00:23:04,490 --> 00:23:06,320
because I'm gonna bring the page in and

590
00:23:06,320 --> 00:23:08,210
wait for that then do my sorting that's

591
00:23:08,210 --> 00:23:10,639
all CPU then I'm done that doing that

592
00:23:10,639 --> 00:23:12,110
sorting or done doing the merging and

593
00:23:12,110 --> 00:23:13,669
now I have to get to the next page and

594
00:23:13,669 --> 00:23:16,250
I'm I'm blocked on that right so really

595
00:23:16,250 --> 00:23:18,200
simple example here I want to sort one

596
00:23:18,200 --> 00:23:20,450
and then while I'm doing that in the

597
00:23:20,450 --> 00:23:23,840
background I go fetch page two and then

598
00:23:23,840 --> 00:23:25,789
by the time I'm sorting this one then

599
00:23:25,789 --> 00:23:28,669
when that's done then when this guy's

600
00:23:28,669 --> 00:23:31,389
ready to go for me

601
00:23:33,410 --> 00:23:39,210
okay right so this is this you know the

602
00:23:39,210 --> 00:23:41,490
to a merge sort is a sort of most simple

603
00:23:41,490 --> 00:23:44,370
way to consider this we need to consider

604
00:23:44,370 --> 00:23:46,200
that what how this works with a general

605
00:23:46,200 --> 00:23:49,320
you know general anyway sort or k way

606
00:23:49,320 --> 00:23:57,870
sort yes sorry so this question is how

607
00:23:57,870 --> 00:24:00,330
do you how do you do this optimization

608
00:24:00,330 --> 00:24:04,340
here how do you can have the thread

609
00:24:04,730 --> 00:24:07,380
student sorting while on the background

610
00:24:07,380 --> 00:24:09,570
there's it's going fetching data well

611
00:24:09,570 --> 00:24:10,590
this is actually the operating system

612
00:24:10,590 --> 00:24:12,660
helps us right so we make a request from

613
00:24:12,660 --> 00:24:14,340
the operating system go read this for us

614
00:24:14,340 --> 00:24:16,740
and then there has another thread that's

615
00:24:16,740 --> 00:24:18,630
called any synchronous i/o in the

616
00:24:18,630 --> 00:24:20,130
background it goes fetch the data we

617
00:24:20,130 --> 00:24:22,640
need we tell it where we're to put it

618
00:24:22,640 --> 00:24:25,140
and then that way I through I can do all

619
00:24:25,140 --> 00:24:26,820
the computation as well actually the

620
00:24:26,820 --> 00:24:27,750
data says we can do this well you

621
00:24:27,750 --> 00:24:29,550
actually don't need the OS in a real

622
00:24:29,550 --> 00:24:31,800
system you would have like a IO

623
00:24:31,800 --> 00:24:34,290
dispatcher thread so you say I want this

624
00:24:34,290 --> 00:24:35,760
request get me this page and then give

625
00:24:35,760 --> 00:24:37,920
me you know here's a call up to tell me

626
00:24:37,920 --> 00:24:39,630
when it's actually ready then it goes

627
00:24:39,630 --> 00:24:41,040
and does that your thread can do

628
00:24:41,040 --> 00:24:42,360
whatever computation at once and then

629
00:24:42,360 --> 00:24:44,780
when it's done it's available for you

630
00:24:44,780 --> 00:24:49,340
yeah yeah they have two threads yeah

631
00:24:49,580 --> 00:24:52,440
okay so let's quickly go over how to

632
00:24:52,440 --> 00:24:53,700
generalize this algorithm beyond just

633
00:24:53,700 --> 00:24:57,120
having just do two you know standard two

634
00:24:57,120 --> 00:24:59,820
ways sort so with the general K way sort

635
00:24:59,820 --> 00:25:02,670
it's still the same we're to use remai

636
00:25:02,670 --> 00:25:05,430
be buffer pools and then in the first

637
00:25:05,430 --> 00:25:07,320
pass we're gonna produce and divide it

638
00:25:07,320 --> 00:25:09,120
be the ceiling of that sort of runs of

639
00:25:09,120 --> 00:25:11,310
size B because that's what we're doing

640
00:25:11,310 --> 00:25:13,590
the in-place sorting and then in the

641
00:25:13,590 --> 00:25:15,780
subsequent passes we're gonna do we're

642
00:25:15,780 --> 00:25:17,760
gonna generate B minus one runs at a

643
00:25:17,760 --> 00:25:20,100
time right and it's always minus one

644
00:25:20,100 --> 00:25:21,540
because we always need one buffer for

645
00:25:21,540 --> 00:25:23,280
the output having additional output

646
00:25:23,280 --> 00:25:24,990
buffers doesn't help us because you

647
00:25:24,990 --> 00:25:26,820
really only write to one with one thread

648
00:25:26,820 --> 00:25:28,110
but only write the one output buffer at

649
00:25:28,110 --> 00:25:31,710
a time so that's why it's B minus one so

650
00:25:31,710 --> 00:25:33,390
the way the math works out is just an

651
00:25:33,390 --> 00:25:35,130
extension of what we showed before we're

652
00:25:35,130 --> 00:25:38,100
set up now saying log 2n or law to it's

653
00:25:38,100 --> 00:25:40,380
log B minus one and then you take the

654
00:25:40,380 --> 00:25:43,080
ceiling of n divided by B but still the

655
00:25:43,080 --> 00:25:45,420
the i/o cost is two n times the number

656
00:25:45,420 --> 00:25:46,410
passes

657
00:25:46,410 --> 00:25:48,700
so this is very plugging chuggy you'll

658
00:25:48,700 --> 00:25:51,130
see this when you do the homework right

659
00:25:51,130 --> 00:25:53,440
you fill in the bees fill in the ends

660
00:25:53,440 --> 00:25:56,980
and the numbers work out so let's just

661
00:25:56,980 --> 00:25:58,210
walk through a really quick example here

662
00:25:58,210 --> 00:26:00,820
so we're gonna sort 108 pages with with

663
00:26:00,820 --> 00:26:05,350
five five buffers pages we can use 2n

664
00:26:05,350 --> 00:26:08,260
equals 108 P equals five so in the first

665
00:26:08,260 --> 00:26:11,140
pass write the the amount of i/o that

666
00:26:11,140 --> 00:26:14,260
we're going to do is we're trying to

667
00:26:14,260 --> 00:26:15,160
compute how many runs we're going to

668
00:26:15,160 --> 00:26:17,110
generate so it's the ceiling of 108

669
00:26:17,110 --> 00:26:18,910
divided by five so that's gonna generate

670
00:26:18,910 --> 00:26:22,060
two twenty three sort of runs of five

671
00:26:22,060 --> 00:26:24,850
pages each right and then the last page

672
00:26:24,850 --> 00:26:27,370
the last run is only three pages so

673
00:26:27,370 --> 00:26:29,340
that's why you have to take the ceiling

674
00:26:29,340 --> 00:26:31,030
right because you don't want a

675
00:26:31,030 --> 00:26:33,910
fractional cost and then going down in

676
00:26:33,910 --> 00:26:35,200
the subsequent passes now you're taking

677
00:26:35,200 --> 00:26:37,420
the the number of runs you want you

678
00:26:37,420 --> 00:26:38,890
generate at the previous pass and

679
00:26:38,890 --> 00:26:42,250
dividing that by the number of the size

680
00:26:42,250 --> 00:26:43,270
of the run you're going to generate

681
00:26:43,270 --> 00:26:46,210
before right so now it was two now it's

682
00:26:46,210 --> 00:26:48,310
four so this generates six sort of runs

683
00:26:48,310 --> 00:26:50,260
of twenty pages where the last page is

684
00:26:50,260 --> 00:26:51,970
the last run is only eight pages and

685
00:26:51,970 --> 00:26:54,610
then just sort of going down just keep

686
00:26:54,610 --> 00:26:56,290
applying over and over again until you

687
00:26:56,290 --> 00:26:59,250
reach the very end where you have now a

688
00:26:59,250 --> 00:27:02,440
the data set is exactly the same size as

689
00:27:02,440 --> 00:27:09,040
the original one yes these questions are

690
00:27:09,040 --> 00:27:10,660
assuming here this sort of done in place

691
00:27:10,660 --> 00:27:12,730
for the first pass yes for the

692
00:27:12,730 --> 00:27:16,090
subsequent passes now but as if this is

693
00:27:16,090 --> 00:27:18,190
what the textbook does in a real system

694
00:27:18,190 --> 00:27:19,930
you wouldn't do that because again the

695
00:27:19,930 --> 00:27:22,870
the depending on how where you're

696
00:27:22,870 --> 00:27:24,670
reading the data from it could if it's

697
00:27:24,670 --> 00:27:26,170
coming directly from the table itself

698
00:27:26,170 --> 00:27:29,380
then you can't modify that if it's

699
00:27:29,380 --> 00:27:31,930
coming from another operator then you

700
00:27:31,930 --> 00:27:38,620
can do that yes yeah the -1 close it

701
00:27:38,620 --> 00:27:39,670
because you always have the one one

702
00:27:39,670 --> 00:27:46,180
buffer page for the output yeah so yeah

703
00:27:46,180 --> 00:27:51,540
indeed in the general case it was three

704
00:27:51,540 --> 00:27:54,760
right good one whatever it's two for the

705
00:27:54,760 --> 00:27:58,860
input one for the upload yeah

706
00:28:04,100 --> 00:28:06,389
this question is why am I using five

707
00:28:06,389 --> 00:28:14,129
here so you're sorting yes sorry it

708
00:28:14,129 --> 00:28:18,720
makes it so before I was sorting two

709
00:28:18,720 --> 00:28:21,779
runs at a time this is now sorting

710
00:28:21,779 --> 00:28:24,620
multiple runs at a time right so I'm so

711
00:28:24,620 --> 00:28:27,570
say with B equals five I bought five

712
00:28:27,570 --> 00:28:30,269
buffer pages so for each of the sort of

713
00:28:30,269 --> 00:28:32,549
runs I'm gonna five sort of runs I'm

714
00:28:32,549 --> 00:28:33,840
gonna try to merge at the same time and

715
00:28:33,840 --> 00:28:35,309
again all I need to do is just have a

716
00:28:35,309 --> 00:28:37,919
cursor sit at each one and walk through

717
00:28:37,919 --> 00:28:39,570
them one by one and just do a comparison

718
00:28:39,570 --> 00:28:41,690
across all that and say which one is the

719
00:28:41,690 --> 00:28:44,340
which one is the smallest write that out

720
00:28:44,340 --> 00:28:47,159
and then now we have four cursors and

721
00:28:47,159 --> 00:28:50,129
one applet yes yeah I should visualize

722
00:28:50,129 --> 00:28:53,940
that sorry again this wife record Excel

723
00:28:53,940 --> 00:28:58,769
remember to do that next year or is this

724
00:28:58,769 --> 00:29:04,679
clear okay so that's external merge sort

725
00:29:04,679 --> 00:29:07,350
they said this is this is the exact

726
00:29:07,350 --> 00:29:08,970
details of how you actually implement

727
00:29:08,970 --> 00:29:10,759
this will vary from system to system

728
00:29:10,759 --> 00:29:12,330
there's obviously some other

729
00:29:12,330 --> 00:29:14,639
optimizations we can think about like

730
00:29:14,639 --> 00:29:17,100
some hints to say oh I know the min

731
00:29:17,100 --> 00:29:18,690
value of the max value if my sort of run

732
00:29:18,690 --> 00:29:21,269
is is this an that and my min max value

733
00:29:21,269 --> 00:29:22,409
for this other sort of run is that so

734
00:29:22,409 --> 00:29:25,110
therefore if I know that the the min

735
00:29:25,110 --> 00:29:27,929
value is is greater than the max value

736
00:29:27,929 --> 00:29:29,610
this other sort of run I don't need to

737
00:29:29,610 --> 00:29:31,919
do the merge I disappear on top of Java

738
00:29:31,919 --> 00:29:34,350
right so there's some optimizations you

739
00:29:34,350 --> 00:29:38,460
can do like that but in general what

740
00:29:38,460 --> 00:29:41,639
I've shown here today is works you know

741
00:29:41,639 --> 00:29:44,850
works well for for for most data sets

742
00:29:44,850 --> 00:29:46,259
assuming uniform distribution of the

743
00:29:46,259 --> 00:29:49,649
values there's no sort of there's no

744
00:29:49,649 --> 00:29:51,059
locality to enter the data it's just

745
00:29:51,059 --> 00:29:54,240
completely random this works fine if you

746
00:29:54,240 --> 00:29:55,620
know that something more about my your

747
00:29:55,620 --> 00:29:57,059
data like it's skewed in a certain way

748
00:29:57,059 --> 00:29:59,370
then you can apply some simple

749
00:29:59,370 --> 00:30:01,259
techniques to speed this thing up but

750
00:30:01,259 --> 00:30:02,850
this is what I've shown today is just

751
00:30:02,850 --> 00:30:04,350
like the pickup truck version of it a

752
00:30:04,350 --> 00:30:09,440
general-purpose version of it so

753
00:30:09,789 --> 00:30:11,320
instead of actually just doing the sort

754
00:30:11,320 --> 00:30:13,559
of brute first brute force mergesort

755
00:30:13,559 --> 00:30:15,850
that I showed here sure now

756
00:30:15,850 --> 00:30:18,129
there may be some cases where we can

757
00:30:18,129 --> 00:30:20,830
actually use the B plus tree to speed up

758
00:30:20,830 --> 00:30:24,429
our sorting operation so in general the

759
00:30:24,429 --> 00:30:26,739
sorting and joint algorithms those are

760
00:30:26,739 --> 00:30:28,239
actually the most expensive things to do

761
00:30:28,239 --> 00:30:31,119
oh so if there's any way we can speed

762
00:30:31,119 --> 00:30:32,859
these things up this is always gonna be

763
00:30:32,859 --> 00:30:36,789
a good choice for us so what did the B

764
00:30:36,789 --> 00:30:38,769
plus tree essentially doing well it's

765
00:30:38,769 --> 00:30:42,190
maintaining the sort order for our keys

766
00:30:42,190 --> 00:30:43,989
in the data structure so we're paying

767
00:30:43,989 --> 00:30:46,509
you know the penalty to maintain update

768
00:30:46,509 --> 00:30:48,940
do splits emerges as needed on our B

769
00:30:48,940 --> 00:30:52,599
plus tree as the table gets modified but

770
00:30:52,599 --> 00:30:54,399
now we can then possibly piggyback off

771
00:30:54,399 --> 00:30:56,590
of that work we've already done to speed

772
00:30:56,590 --> 00:30:58,269
up by sorting but not having to do

773
00:30:58,269 --> 00:31:00,999
sorting at all so if our sorting

774
00:31:00,999 --> 00:31:03,099
operation that we need if the keys we

775
00:31:03,099 --> 00:31:05,049
want to sort on are the same keys that

776
00:31:05,049 --> 00:31:07,570
are B plus tree is indexed on then we

777
00:31:07,570 --> 00:31:09,249
can potentially just reuse the B plus

778
00:31:09,249 --> 00:31:10,899
tree and not go through that whole looks

779
00:31:10,899 --> 00:31:12,489
from merge sort and with multiple passes

780
00:31:12,489 --> 00:31:16,379
that I just showed but it only works if

781
00:31:16,379 --> 00:31:20,259
we have a cluster B plus tree again we

782
00:31:20,259 --> 00:31:22,090
showed an example of that I think two

783
00:31:22,090 --> 00:31:24,909
classes ago but now we showed it more

784
00:31:24,909 --> 00:31:27,340
visual cable what actually is going on

785
00:31:27,340 --> 00:31:28,779
and you'll see why this makes sense for

786
00:31:28,779 --> 00:31:31,529
sorting but not for the uncluttered one

787
00:31:31,529 --> 00:31:34,029
so the clustered B plus tree a clustered

788
00:31:34,029 --> 00:31:37,389
index just means that the the sort order

789
00:31:37,389 --> 00:31:41,529
or the physical location of the tuples

790
00:31:41,529 --> 00:31:45,519
on our pages will match the sort order

791
00:31:45,519 --> 00:31:49,869
defined in the index so if I have a

792
00:31:49,869 --> 00:31:53,859
index on key foo then along my pages

793
00:31:53,859 --> 00:31:57,059
will be the the the tuples we sorted in

794
00:31:57,059 --> 00:32:00,929
pages based based on that order of foo

795
00:32:00,929 --> 00:32:04,840
so now if I want to do a sort on that

796
00:32:04,840 --> 00:32:07,389
key I don't need to do external merge

797
00:32:07,389 --> 00:32:09,220
sort because all I need to do is is get

798
00:32:09,220 --> 00:32:11,379
down to my leaf pages and IB plus tree

799
00:32:11,379 --> 00:32:14,440
because now the the sort order of the

800
00:32:14,440 --> 00:32:17,349
key will match the sort order of the of

801
00:32:17,349 --> 00:32:20,730
how the data is B is found

802
00:32:20,730 --> 00:32:21,870
so I don't need you any extra

803
00:32:21,870 --> 00:32:25,590
computation to to go sort it it's

804
00:32:25,590 --> 00:32:27,140
already sorted for me

805
00:32:27,140 --> 00:32:29,160
so this again this is another example

806
00:32:29,160 --> 00:32:30,780
where the database system the query

807
00:32:30,780 --> 00:32:32,370
planner that we'll talk about after the

808
00:32:32,370 --> 00:32:34,860
midterm or the class before the midterm

809
00:32:34,860 --> 00:32:37,050
the the query optimizer can figure out

810
00:32:37,050 --> 00:32:39,240
oh you want to do a sort on this key I

811
00:32:39,240 --> 00:32:40,800
already have a clustered index on that

812
00:32:40,800 --> 00:32:43,170
key let me go use that to generate the

813
00:32:43,170 --> 00:32:45,000
corrects whole order and not even bother

814
00:32:45,000 --> 00:32:49,680
running external merge sort but as we

815
00:32:49,680 --> 00:32:51,300
saw in the case of Postgres they can't

816
00:32:51,300 --> 00:32:52,740
they don't enforce this you tell me I

817
00:32:52,740 --> 00:32:54,870
want a complete cluster on an index on a

818
00:32:54,870 --> 00:32:56,400
given key they're not gonna maintain

819
00:32:56,400 --> 00:32:57,870
that's what ordering other systems will

820
00:32:57,870 --> 00:33:00,810
do this so now if you have an

821
00:33:00,810 --> 00:33:02,940
uncluttered index on custom P plus

822
00:33:02,940 --> 00:33:04,680
trading this is actually the worst

823
00:33:04,680 --> 00:33:07,620
possible thing to use for trying to

824
00:33:07,620 --> 00:33:10,230
generate a sort order and we think I

825
00:33:10,230 --> 00:33:14,130
guess why it should be obvious what's

826
00:33:14,130 --> 00:33:15,950
that

827
00:33:15,950 --> 00:33:18,240
great you have one eye open record so

828
00:33:18,240 --> 00:33:20,670
again I traverse the index to be gentle

829
00:33:20,670 --> 00:33:22,290
to the left side of the tree and I want

830
00:33:22,290 --> 00:33:24,600
scan across and because that's how my my

831
00:33:24,600 --> 00:33:27,470
keys are sorted but the data has no

832
00:33:27,470 --> 00:33:30,330
connection to how it's being sorted in

833
00:33:30,330 --> 00:33:33,720
the index so for every single record I

834
00:33:33,720 --> 00:33:35,700
got to go get and generate as my output

835
00:33:35,700 --> 00:33:37,950
I may be doing another disk i/o because

836
00:33:37,950 --> 00:33:40,650
the page I need is not in memory I go to

837
00:33:40,650 --> 00:33:42,360
disco get it bring my brother poll and

838
00:33:42,360 --> 00:33:43,920
then now that very next key it I look at

839
00:33:43,920 --> 00:33:45,600
is in another page and it's a victim one

840
00:33:45,600 --> 00:33:47,550
I just brought in and bring him the next

841
00:33:47,550 --> 00:33:58,290
one yes the question is what does it

842
00:33:58,290 --> 00:34:01,920
mean for tree to be you wouldn't say it

843
00:34:01,920 --> 00:34:04,500
is a you don't say the trees clustered

844
00:34:04,500 --> 00:34:07,500
the tables clustered again I wouldn't

845
00:34:07,500 --> 00:34:09,060
call it that like if I was writing you

846
00:34:09,060 --> 00:34:10,050
know coming with those terms I would

847
00:34:10,050 --> 00:34:12,060
call it oh it's a sorted table for

848
00:34:12,060 --> 00:34:13,020
whatever reason they call it a cluster

849
00:34:13,020 --> 00:34:14,219
table right because it's basically the

850
00:34:14,219 --> 00:34:15,989
the tuples that are that are similar to

851
00:34:15,989 --> 00:34:16,679
each other

852
00:34:16,679 --> 00:34:18,600
are clustered together on the page right

853
00:34:18,600 --> 00:34:21,900
so again back here this the sort order

854
00:34:21,900 --> 00:34:23,520
of the how the two was actually being

855
00:34:23,520 --> 00:34:26,760
stored matches the sort order the key so

856
00:34:26,760 --> 00:34:28,260
this is this would be a clustered index

857
00:34:28,260 --> 00:34:29,449
all right all right

858
00:34:29,449 --> 00:34:31,710
in this case here we just call create

859
00:34:31,710 --> 00:34:34,110
index this is what you normally get the

860
00:34:34,110 --> 00:34:35,850
or just you know the actual where the

861
00:34:35,850 --> 00:34:37,830
records actually being sword has no

862
00:34:37,830 --> 00:34:41,510
relation to how they're being sorted

863
00:34:42,800 --> 00:34:44,580
questions what is the information in the

864
00:34:44,580 --> 00:34:45,810
tree it's just the B+ tree we talked

865
00:34:45,810 --> 00:34:48,179
about before right so create index on on

866
00:34:48,179 --> 00:34:51,510
on key foo so to build that index I'm

867
00:34:51,510 --> 00:34:53,280
doing special scan looking at every

868
00:34:53,280 --> 00:34:55,020
single tuple getting their value of foo

869
00:34:55,020 --> 00:34:57,450
inserting that into my tree and the key

870
00:34:57,450 --> 00:35:00,240
value pair is the value of fee of foo

871
00:35:00,240 --> 00:35:03,330
and then the the value is the record I

872
00:35:03,330 --> 00:35:06,420
need a pointer to the tuple all right

873
00:35:06,420 --> 00:35:07,500
this is different than the index

874
00:35:07,500 --> 00:35:10,710
organized indexes or any index organized

875
00:35:10,710 --> 00:35:12,540
tables we talked about where the two

876
00:35:12,540 --> 00:35:13,530
will pages are actually in the leaf

877
00:35:13,530 --> 00:35:15,990
nodes themselves in that case that is a

878
00:35:15,990 --> 00:35:18,390
clustered index but it's also in its

879
00:35:18,390 --> 00:35:21,300
organized table this is like if there's

880
00:35:21,300 --> 00:35:22,380
they're not you're not storing the data

881
00:35:22,380 --> 00:35:24,600
in the leaf nodes themselves if it's

882
00:35:24,600 --> 00:35:28,700
disconnected then it's either cluster

883
00:35:47,030 --> 00:35:50,910
yeah so David is instead of actually

884
00:35:50,910 --> 00:35:53,550
every single time I encounter a key

885
00:35:53,550 --> 00:35:56,160
immediately go fetch it what if I get

886
00:35:56,160 --> 00:35:59,070
all the keys that I need and their

887
00:35:59,070 --> 00:36:02,040
record IDs and then now do combine the

888
00:36:02,040 --> 00:36:03,750
lookup so that I get all the ones from

889
00:36:03,750 --> 00:36:05,580
page 101 first and all the ones on page

890
00:36:05,580 --> 00:36:08,250
one or two yes there we'll talk about

891
00:36:08,250 --> 00:36:11,190
two weeks or next week right

892
00:36:11,190 --> 00:36:14,480
four scans that's a common optimization

893
00:36:14,480 --> 00:36:17,040
but that assumes that you can fit like

894
00:36:17,040 --> 00:36:23,250
the yeah the key set and there are some

895
00:36:23,250 --> 00:36:24,570
algorithms where you actually can start

896
00:36:24,570 --> 00:36:26,040
producing outputs sooner rather than

897
00:36:26,040 --> 00:36:27,780
later

898
00:36:27,780 --> 00:36:29,520
this is like an all-or-nothing this is

899
00:36:29,520 --> 00:36:31,740
like what I've shown so far is I'm gonna

900
00:36:31,740 --> 00:36:33,570
get all you know this operator asked me

901
00:36:33,570 --> 00:36:35,790
to get this data in sort of order so I'm

902
00:36:35,790 --> 00:36:37,890
gonna get it all now and then I don't

903
00:36:37,890 --> 00:36:39,990
move on to the next operator until I get

904
00:36:39,990 --> 00:36:41,700
everything there are some streaming

905
00:36:41,700 --> 00:36:42,930
operators where you could say all right

906
00:36:42,930 --> 00:36:45,120
to start streaming data out as you get

907
00:36:45,120 --> 00:36:47,520
it because I'd rather have it sooner

908
00:36:47,520 --> 00:36:48,010
rather than

909
00:36:48,010 --> 00:36:49,450
like there's other optimizations that I

910
00:36:49,450 --> 00:36:51,250
can do up in the tree so in that case

911
00:36:51,250 --> 00:36:52,900
you're you know your best approach won't

912
00:36:52,900 --> 00:36:55,390
work won't work in that environment but

913
00:36:55,390 --> 00:36:56,920
that that is a common opposition we'll

914
00:36:56,920 --> 00:37:05,200
see this in like next week okay all

915
00:37:05,200 --> 00:37:07,330
right so again the main takeaway of this

916
00:37:07,330 --> 00:37:10,140
is if it's a cluster index and and the

917
00:37:10,140 --> 00:37:12,970
query needs it to be sorted on the key

918
00:37:12,970 --> 00:37:14,800
that the index is based on then you just

919
00:37:14,800 --> 00:37:16,870
you just use the clustered index if it's

920
00:37:16,870 --> 00:37:19,270
not a clustered index then you just

921
00:37:19,270 --> 00:37:23,380
almost never want to use it all right so

922
00:37:23,380 --> 00:37:25,000
that's basically it for discussing

923
00:37:25,000 --> 00:37:27,610
sorting so let's talk about do some

924
00:37:27,610 --> 00:37:31,870
other operations so imitator we're now

925
00:37:31,870 --> 00:37:34,000
going to focus on aggregations because

926
00:37:34,000 --> 00:37:35,650
for aggregations is another good is

927
00:37:35,650 --> 00:37:38,800
another good example of or it is an

928
00:37:38,800 --> 00:37:41,710
example of a type of operator where we

929
00:37:41,710 --> 00:37:44,500
can make you a choice between sorting

930
00:37:44,500 --> 00:37:47,140
versus hashing as our for our algorithm

931
00:37:47,140 --> 00:37:49,000
and then have different trade-offs and

932
00:37:49,000 --> 00:37:49,930
have different performance

933
00:37:49,930 --> 00:37:52,900
characteristics because one is

934
00:37:52,900 --> 00:37:54,370
essentially you know trying to do a lot

935
00:37:54,370 --> 00:37:55,690
of switch will access someone's trying

936
00:37:55,690 --> 00:37:57,610
to do random access so maybe certain

937
00:37:57,610 --> 00:37:59,230
scenarios where one might be better than

938
00:37:59,230 --> 00:38:02,140
another in general as a spoiler what

939
00:38:02,140 --> 00:38:04,270
I'll say is that and no one was always

940
00:38:04,270 --> 00:38:07,600
in the case no matter how fast the disk

941
00:38:07,600 --> 00:38:10,300
is oftentimes the the hashing approach

942
00:38:10,300 --> 00:38:12,190
will work better and we'll see an

943
00:38:12,190 --> 00:38:14,940
example of how we can actually make the

944
00:38:14,940 --> 00:38:17,620
hashing aggregation do more sequential

945
00:38:17,620 --> 00:38:21,190
i/o rather than random i/o all right so

946
00:38:21,190 --> 00:38:22,630
if you take the advanced class in the

947
00:38:22,630 --> 00:38:24,520
spring this is another big thing too is

948
00:38:24,520 --> 00:38:27,100
like hashing always works super fast

949
00:38:27,100 --> 00:38:29,380
because everything is in memory all

950
00:38:29,380 --> 00:38:31,420
right so how would you use sorting do an

951
00:38:31,420 --> 00:38:32,920
aggregation well again what does an

952
00:38:32,920 --> 00:38:34,000
aggregation doing you're basically

953
00:38:34,000 --> 00:38:36,010
taking a bunch of values and you're

954
00:38:36,010 --> 00:38:37,660
coalescing them to produce a single

955
00:38:37,660 --> 00:38:41,710
scalar value so with sorting the nice

956
00:38:41,710 --> 00:38:43,090
thing about it is that because the data

957
00:38:43,090 --> 00:38:45,070
is sorted as I said when we take a pass

958
00:38:45,070 --> 00:38:47,770
now through the sorted output we don't

959
00:38:47,770 --> 00:38:49,480
have to backtrack to computer

960
00:38:49,480 --> 00:38:51,190
aggregation and we only do one pass to

961
00:38:51,190 --> 00:38:52,900
find to compute whatever the answer it

962
00:38:52,900 --> 00:38:55,750
is that we want so let's see a real

963
00:38:55,750 --> 00:38:58,090
simple query here we want to do it we're

964
00:38:58,090 --> 00:39:00,490
doing we're doing a scan on the enrolled

965
00:39:00,490 --> 00:39:01,780
table all right

966
00:39:01,780 --> 00:39:03,310
students rolled in the classes the

967
00:39:03,310 --> 00:39:05,740
database classes at CMU and we would we

968
00:39:05,740 --> 00:39:08,290
always want to get the all the distinct

969
00:39:08,290 --> 00:39:10,000
course IDs from any class where a

970
00:39:10,000 --> 00:39:12,640
student either got a B or C in it and we

971
00:39:12,640 --> 00:39:13,930
want the output to be sorted based on

972
00:39:13,930 --> 00:39:16,990
the course ID so the very first thing

973
00:39:16,990 --> 00:39:18,370
we're going to do in our query plan tree

974
00:39:18,370 --> 00:39:20,860
is do the filter so we're gonna first

975
00:39:20,860 --> 00:39:23,800
filter out all the tuples where the

976
00:39:23,800 --> 00:39:26,950
grade is not B or C then the next step

977
00:39:26,950 --> 00:39:28,600
we're going to do is remove all the

978
00:39:28,600 --> 00:39:30,480
columns we don't need in our output

979
00:39:30,480 --> 00:39:33,190
right we only need the course ID we only

980
00:39:33,190 --> 00:39:35,350
need the course ID to do the order by

981
00:39:35,350 --> 00:39:37,660
and for the stink clause because for our

982
00:39:37,660 --> 00:39:40,420
filter it access the grade table at that

983
00:39:40,420 --> 00:39:41,860
point we know in our query plan we don't

984
00:39:41,860 --> 00:39:43,720
need to ever look at the great the great

985
00:39:43,720 --> 00:39:45,460
column anymore we don't need to look up

986
00:39:45,460 --> 00:39:47,200
a student ID anymore so if we can strip

987
00:39:47,200 --> 00:39:49,030
all that out before we move on to the

988
00:39:49,030 --> 00:39:52,510
next operator and then we finish off now

989
00:39:52,510 --> 00:39:56,320
by sorting on sample column here and

990
00:39:56,320 --> 00:39:58,170
because we're doing a distinct

991
00:39:58,170 --> 00:40:01,420
aggregation or distinct clause we want

992
00:40:01,420 --> 00:40:03,880
to remove any duplicate values so all we

993
00:40:03,880 --> 00:40:05,590
need to do is just have our cursor scan

994
00:40:05,590 --> 00:40:07,600
through this and any time it finds a

995
00:40:07,600 --> 00:40:10,210
value where that was same same as the

996
00:40:10,210 --> 00:40:12,280
one I just looked at that knows it can

997
00:40:12,280 --> 00:40:15,190
throw it away and strip that out and

998
00:40:15,190 --> 00:40:19,690
that's our final output so we'll go into

999
00:40:19,690 --> 00:40:23,560
this more next week when we talk about

1000
00:40:23,560 --> 00:40:25,960
query planning but just one obvious

1001
00:40:25,960 --> 00:40:27,430
thing during this in this pipeline we

1002
00:40:27,430 --> 00:40:29,860
make students query that I did was I try

1003
00:40:29,860 --> 00:40:32,020
to strip out as much useless data as

1004
00:40:32,020 --> 00:40:34,570
possible sooner in my in my pipeline

1005
00:40:34,570 --> 00:40:37,150
rather than later so the very first

1006
00:40:37,150 --> 00:40:38,800
thing I did was the filter so say you

1007
00:40:38,800 --> 00:40:41,020
know say this table had a billion

1008
00:40:41,020 --> 00:40:44,440
records in it but only five of them

1009
00:40:44,440 --> 00:40:46,920
match or for them match for my predicate

1010
00:40:46,920 --> 00:40:49,690
so rather than me sorting a billion

1011
00:40:49,690 --> 00:40:51,520
records first then going back and

1012
00:40:51,520 --> 00:40:53,470
filtering it it was better for me to

1013
00:40:53,470 --> 00:40:55,990
filter it first then move that movie to

1014
00:40:55,990 --> 00:40:57,630
move the data on to the next operators

1015
00:40:57,630 --> 00:41:00,430
same thing for the projection right this

1016
00:41:00,430 --> 00:41:01,990
is a row stored it's not a column store

1017
00:41:01,990 --> 00:41:04,510
in my example so in order for me to go

1018
00:41:04,510 --> 00:41:06,820
get the data I need to do you know

1019
00:41:06,820 --> 00:41:08,050
whatever the sorting I want to do I

1020
00:41:08,050 --> 00:41:10,090
gotta go get the entire I mean the

1021
00:41:10,090 --> 00:41:11,170
entire record because that's gonna be

1022
00:41:11,170 --> 00:41:13,240
packed together in a single page but if

1023
00:41:13,240 --> 00:41:14,740
I can do a projection

1024
00:41:14,740 --> 00:41:16,270
you strip out all the columns I don't

1025
00:41:16,270 --> 00:41:17,440
need or the attributes they don't need

1026
00:41:17,440 --> 00:41:19,869
and then now when I'm doing my sorting

1027
00:41:19,869 --> 00:41:21,849
I'm not copying around a bunch of extra

1028
00:41:21,849 --> 00:41:24,130
data so my sort of sort of simple

1029
00:41:24,130 --> 00:41:26,290
examples and was related to her question

1030
00:41:26,290 --> 00:41:29,740
the you know what a might be actually

1031
00:41:29,740 --> 00:41:31,420
passing around it could be the record ID

1032
00:41:31,420 --> 00:41:33,070
it could actually be the entire tuple

1033
00:41:33,070 --> 00:41:35,800
itself depending on how I want to

1034
00:41:35,800 --> 00:41:38,109
materialize things so the projection

1035
00:41:38,109 --> 00:41:39,490
here allows me to throw away coms I

1036
00:41:39,490 --> 00:41:41,140
don't need so now when I'm when I'm

1037
00:41:41,140 --> 00:41:44,200
doing my sorting I'm I'm only you know

1038
00:41:44,200 --> 00:41:46,330
I'm copying things that just related to

1039
00:41:46,330 --> 00:41:47,560
what's needed for the rest of the query

1040
00:41:47,560 --> 00:42:15,910
plan yes so his question is I mean it's

1041
00:42:15,910 --> 00:42:17,050
not really this query you're talking

1042
00:42:17,050 --> 00:42:19,530
like a count query so this question is

1043
00:42:19,530 --> 00:42:23,589
the the grey column is has a fixed

1044
00:42:23,589 --> 00:42:27,099
domain meaning it's a B C D or E I don't

1045
00:42:27,099 --> 00:42:29,320
think see me as s does it you have an

1046
00:42:29,320 --> 00:42:31,240
completes right but it's fixed oh

1047
00:42:31,240 --> 00:42:34,510
there's another one that's whatever tom

1048
00:42:34,510 --> 00:42:36,070
is when I go putting your grades I can't

1049
00:42:36,070 --> 00:42:37,950
tell whether you're an undergrad or

1050
00:42:37,950 --> 00:42:40,480
graduate student so I'm like oh this

1051
00:42:40,480 --> 00:42:41,859
student got you know did awesome to get

1052
00:42:41,859 --> 00:42:43,359
an a-plus but then it throws an error

1053
00:42:43,359 --> 00:42:44,500
because they're an undergrad undergrads

1054
00:42:44,500 --> 00:42:46,540
can get a pluses unless you're ECE which

1055
00:42:46,540 --> 00:42:47,349
I think you can

1056
00:42:47,349 --> 00:42:51,099
it's a nightmare but anyway so his

1057
00:42:51,099 --> 00:42:53,320
question is all right so couldn't I have

1058
00:42:53,320 --> 00:42:56,770
some kind of side table that has a tally

1059
00:42:56,770 --> 00:42:58,570
that keeps track of every single time I

1060
00:42:58,570 --> 00:43:00,130
inserted a tuple with one of these

1061
00:43:00,130 --> 00:43:02,380
values and I'm trying to maintain an

1062
00:43:02,380 --> 00:43:03,820
accountant I increment that counter by

1063
00:43:03,820 --> 00:43:06,030
one

1064
00:43:09,870 --> 00:43:13,020
[Music]

1065
00:43:14,020 --> 00:43:27,530
within a page all right so what he's

1066
00:43:27,530 --> 00:43:32,200
saying is say this was stored in a page

1067
00:43:32,200 --> 00:43:35,120
this this little example here is in one

1068
00:43:35,120 --> 00:43:37,610
page and then for the grade column I

1069
00:43:37,610 --> 00:43:38,930
could keep track of the min and Max

1070
00:43:38,930 --> 00:43:42,530
value so this case B or C so now if I'm

1071
00:43:42,530 --> 00:43:44,030
say I'm looking for all people that have

1072
00:43:44,030 --> 00:43:47,390
the grade A if I get to that page and I

1073
00:43:47,390 --> 00:43:49,580
look say oh why it's only between B and

1074
00:43:49,580 --> 00:43:52,250
C because nobody has an A in that page I

1075
00:43:52,250 --> 00:43:53,570
don't mean even bother looking at the

1076
00:43:53,570 --> 00:43:55,990
column that's what you're saying right

1077
00:43:55,990 --> 00:43:58,820
okay I I think we are - I want the same

1078
00:43:58,820 --> 00:44:01,460
thing what you're describing called zone

1079
00:44:01,460 --> 00:44:04,310
maps right well we will talk about this

1080
00:44:04,310 --> 00:44:07,850
I think next week or this week I forget

1081
00:44:07,850 --> 00:44:09,830
when but basically there's a way to keep

1082
00:44:09,830 --> 00:44:11,990
track of yourself on auxiliary data

1083
00:44:11,990 --> 00:44:13,820
structure on the side that he looked at

1084
00:44:13,820 --> 00:44:16,280
that first and then you then you check

1085
00:44:16,280 --> 00:44:19,100
the page yes so that's a zone map you

1086
00:44:19,100 --> 00:44:20,570
can you could or could not be in the

1087
00:44:20,570 --> 00:44:21,890
same page you could have a separate page

1088
00:44:21,890 --> 00:44:24,290
but within the page but it's basically a

1089
00:44:24,290 --> 00:44:26,390
precomputed information to say the data

1090
00:44:26,390 --> 00:44:28,010
you here's the range of data that could

1091
00:44:28,010 --> 00:44:29,690
possibly exist for each attribute and

1092
00:44:29,690 --> 00:44:31,250
you refer to that first and make

1093
00:44:31,250 --> 00:44:32,540
decisions whether you didn't even go

1094
00:44:32,540 --> 00:44:32,930
further

1095
00:44:32,930 --> 00:44:35,120
yes so those are called zone maps

1096
00:44:35,120 --> 00:44:37,760
they're called pre oracles and zone maps

1097
00:44:37,760 --> 00:44:40,780
tremendous a call a pre computed

1098
00:44:40,780 --> 00:44:43,430
pre-computer materialized aggregation

1099
00:44:43,430 --> 00:44:45,350
sometimes different systems do different

1100
00:44:45,350 --> 00:44:45,770
things

1101
00:44:45,770 --> 00:44:47,330
but that does exist we'll cover that

1102
00:44:47,330 --> 00:44:57,410
later yes that's an index right that's

1103
00:44:57,410 --> 00:44:59,000
what it index does here's how my

1104
00:44:59,000 --> 00:45:01,280
something more fine like like not an in

1105
00:45:01,280 --> 00:45:03,620
Excel I think right yeah that's a zone

1106
00:45:03,620 --> 00:45:06,820
map when you're ascribing is in index

1107
00:45:07,060 --> 00:45:11,480
and again the the beauty of a

1108
00:45:11,480 --> 00:45:13,580
declarative language like sequel is that

1109
00:45:13,580 --> 00:45:15,500
I write my sequel query like this I

1110
00:45:15,500 --> 00:45:17,570
don't know whether I'm using zone maps I

1111
00:45:17,570 --> 00:45:19,760
don't know whether I'm using an index I

1112
00:45:19,760 --> 00:45:21,800
don't care the databases won't figure

1113
00:45:21,800 --> 00:45:22,910
out what's the best strategy for me to

1114
00:45:22,910 --> 00:45:24,380
go find the data that I want right so

1115
00:45:24,380 --> 00:45:26,540
just trying to try never move is

1116
00:45:26,540 --> 00:45:29,990
is crap quickly as possible that's the

1117
00:45:29,990 --> 00:45:34,220
whole goal of all this alright so that

1118
00:45:34,220 --> 00:45:36,830
was a change about zone maps we'll cover

1119
00:45:36,830 --> 00:45:40,520
that later the main point I want the

1120
00:45:40,520 --> 00:45:42,290
main takeaway from this was if I'm

1121
00:45:42,290 --> 00:45:44,750
sorted I do one pass and I can eliminate

1122
00:45:44,750 --> 00:45:47,480
the duplicates all right in this example

1123
00:45:47,480 --> 00:45:48,890
here this worked out great for us

1124
00:45:48,890 --> 00:45:51,560
because the output need to be sorted on

1125
00:45:51,560 --> 00:45:54,530
a course ID so I was it was two for one

1126
00:45:54,530 --> 00:45:56,210
I did my sorting because that's the

1127
00:45:56,210 --> 00:45:58,040
output I needed but then I'm also in the

1128
00:45:58,040 --> 00:46:01,880
sort order I need for my output right so

1129
00:46:01,880 --> 00:46:03,590
in this case here doing a sorting based

1130
00:46:03,590 --> 00:46:06,980
aggregation is a definite win for us but

1131
00:46:06,980 --> 00:46:08,810
in many cases we don't actually need the

1132
00:46:08,810 --> 00:46:12,680
output to be sorted right so again you

1133
00:46:12,680 --> 00:46:14,870
still can use sorting for this like you

1134
00:46:14,870 --> 00:46:17,330
can do foregrip eyes and and and doing

1135
00:46:17,330 --> 00:46:19,550
distinct stuff but if you don't need to

1136
00:46:19,550 --> 00:46:20,840
be sorted then this actually might be

1137
00:46:20,840 --> 00:46:23,000
more expensive because again the sorting

1138
00:46:23,000 --> 00:46:26,420
process itself is not cheap so this is

1139
00:46:26,420 --> 00:46:30,290
where hashing can help us so hashing is

1140
00:46:30,290 --> 00:46:35,090
a way for us to be able to sort of again

1141
00:46:35,090 --> 00:46:36,140
another divide and conquer approach

1142
00:46:36,140 --> 00:46:38,950
where we can split up the data set and

1143
00:46:38,950 --> 00:46:42,500
guide our the the tuples or the keys

1144
00:46:42,500 --> 00:46:44,750
that were examining to particular pages

1145
00:46:44,750 --> 00:46:47,480
and then do our processing and memory on

1146
00:46:47,480 --> 00:46:51,050
those pages but again hashing removes

1147
00:46:51,050 --> 00:46:54,860
all all locality all any sort ordering

1148
00:46:54,860 --> 00:46:57,350
because it's taking any key and do you

1149
00:46:57,350 --> 00:46:58,880
know doing some hash function on it and

1150
00:46:58,880 --> 00:47:00,050
now it's going to jump to some random

1151
00:47:00,050 --> 00:47:02,960
location so we this works great if we

1152
00:47:02,960 --> 00:47:04,940
don't need sorting we don't think don't

1153
00:47:04,940 --> 00:47:08,330
need things to be ordered so the way we

1154
00:47:08,330 --> 00:47:10,220
can do a hashing aggregate is we're

1155
00:47:10,220 --> 00:47:12,410
gonna populate at a femoral hash table

1156
00:47:12,410 --> 00:47:14,840
as the date of some scans the table or

1157
00:47:14,840 --> 00:47:18,440
scans whatever our input is hey and then

1158
00:47:18,440 --> 00:47:22,190
say we you know when we do our lookup

1159
00:47:22,190 --> 00:47:24,020
depending on what kind of aggregation

1160
00:47:24,020 --> 00:47:26,750
we're doing if we do an insert and the

1161
00:47:26,750 --> 00:47:28,430
key is not there then we populate it if

1162
00:47:28,430 --> 00:47:30,410
it is there then we may want to modify

1163
00:47:30,410 --> 00:47:33,170
it or modify its value to compute

1164
00:47:33,170 --> 00:47:34,820
whatever the aggregation that it is that

1165
00:47:34,820 --> 00:47:37,820
we want right for distinct it just a

1166
00:47:37,820 --> 00:47:40,040
hash see whether it's in there if it's

1167
00:47:40,040 --> 00:47:41,930
is then I know it's already I it's a

1168
00:47:41,930 --> 00:47:44,270
duplicate so I don't bother inserting it

1169
00:47:44,270 --> 00:47:46,100
for the group like queries for the

1170
00:47:46,100 --> 00:47:48,410
others other aggregations you may have

1171
00:47:48,410 --> 00:47:49,940
to update a running total and what we'll

1172
00:47:49,940 --> 00:47:53,180
see an example of this so this approach

1173
00:47:53,180 --> 00:47:55,940
is fantastic if everything fits in

1174
00:47:55,940 --> 00:47:59,570
memory so the key thing I'm saying up

1175
00:47:59,570 --> 00:48:01,160
above I'm saying it's an ephemeral hash

1176
00:48:01,160 --> 00:48:03,350
table not an emery hash table so

1177
00:48:03,350 --> 00:48:05,690
ephemeral or transient means that this

1178
00:48:05,690 --> 00:48:07,250
is a hash table I'm gonna build through

1179
00:48:07,250 --> 00:48:10,010
my one query and then when that query is

1180
00:48:10,010 --> 00:48:11,900
done I throw it all away I'm gonna do

1181
00:48:11,900 --> 00:48:14,840
this for every single query I said that

1182
00:48:14,840 --> 00:48:16,400
we said in the very beginning we use

1183
00:48:16,400 --> 00:48:17,840
data structures and different ways of

1184
00:48:17,840 --> 00:48:19,040
the database system so there's the

1185
00:48:19,040 --> 00:48:20,540
example of a transy data structure I

1186
00:48:20,540 --> 00:48:21,830
need it for just my one query I do

1187
00:48:21,830 --> 00:48:24,500
whatever I want then I throw it away so

1188
00:48:24,500 --> 00:48:25,850
if everything is in memory the hash

1189
00:48:25,850 --> 00:48:28,040
tables fantastic because it's oh one

1190
00:48:28,040 --> 00:48:31,940
book UPS to go update things right in

1191
00:48:31,940 --> 00:48:33,380
this case you're also not doing deletes

1192
00:48:33,380 --> 00:48:35,270
right it's just inserting things or

1193
00:48:35,270 --> 00:48:38,870
updating things if we need to spill a

1194
00:48:38,870 --> 00:48:41,120
disk though now we're screwed because

1195
00:48:41,120 --> 00:48:43,250
now that this random randomness is gonna

1196
00:48:43,250 --> 00:48:45,200
hurt us because now I'm jumping around

1197
00:48:45,200 --> 00:48:46,970
to different different pages or blocks

1198
00:48:46,970 --> 00:48:49,070
in my hash table and each one could be

1199
00:48:49,070 --> 00:48:52,160
incurring an i/o so we want to be a bit

1200
00:48:52,160 --> 00:48:53,930
smarter about this and trying to

1201
00:48:53,930 --> 00:48:56,360
maximize the amount of work we can do

1202
00:48:56,360 --> 00:48:57,620
for every single page we bring into

1203
00:48:57,620 --> 00:49:01,550
memory so this is what external hash me

1204
00:49:01,550 --> 00:49:03,800
aggregate does and it's again the high

1205
00:49:03,800 --> 00:49:06,020
level is the same way as the same

1206
00:49:06,020 --> 00:49:07,850
technique that we did for external merge

1207
00:49:07,850 --> 00:49:10,270
sort it's a divide and conquer approach

1208
00:49:10,270 --> 00:49:12,320
so the first thing we're to go through

1209
00:49:12,320 --> 00:49:13,610
to take a pass through our data and

1210
00:49:13,610 --> 00:49:15,620
we're to split it up into a partition

1211
00:49:15,620 --> 00:49:18,170
into buckets where so that all the

1212
00:49:18,170 --> 00:49:22,250
tuples that are either the same that all

1213
00:49:22,250 --> 00:49:23,780
tubes that are the same had the same key

1214
00:49:23,780 --> 00:49:28,070
will land in the same same partition and

1215
00:49:28,070 --> 00:49:29,930
then we go back through in the second

1216
00:49:29,930 --> 00:49:32,270
phase and now for each partition we're

1217
00:49:32,270 --> 00:49:34,120
gonna build an in-memory hash table that

1218
00:49:34,120 --> 00:49:36,560
we can then do whatever it is that the

1219
00:49:36,560 --> 00:49:38,450
aggregation that we want to do then we

1220
00:49:38,450 --> 00:49:40,670
produce our final output throw that that

1221
00:49:40,670 --> 00:49:42,800
a memory hash table way and then move on

1222
00:49:42,800 --> 00:49:46,310
to the next partition ok we're

1223
00:49:46,310 --> 00:49:47,660
maximizing the amount of sequential i/o

1224
00:49:47,660 --> 00:49:49,640
that we're doing and for every single

1225
00:49:49,640 --> 00:49:51,620
page we every single i/o we have to do

1226
00:49:51,620 --> 00:49:53,390
to bring something into memory then we

1227
00:49:53,390 --> 00:49:54,050
do all

1228
00:49:54,050 --> 00:49:55,550
the work we need to do on that one page

1229
00:49:55,550 --> 00:49:57,560
before we move on to the to the next

1230
00:49:57,560 --> 00:49:59,780
ones so we never again never we never

1231
00:49:59,780 --> 00:50:02,870
have to backtrack so let's go through

1232
00:50:02,870 --> 00:50:04,910
these two phases so in the first phase

1233
00:50:04,910 --> 00:50:06,080
again what we're trying to do is we're

1234
00:50:06,080 --> 00:50:07,160
going to split the tuples up into

1235
00:50:07,160 --> 00:50:09,020
partitions that we can then write out

1236
00:50:09,020 --> 00:50:11,720
the disk as needed so we're gonna use

1237
00:50:11,720 --> 00:50:13,010
our first hash function it's just to

1238
00:50:13,010 --> 00:50:15,050
split things up and again we use member

1239
00:50:15,050 --> 00:50:18,050
hash city hash xx - 3 whatever it

1240
00:50:18,050 --> 00:50:20,540
doesn't matter and so the reason why

1241
00:50:20,540 --> 00:50:23,240
we're doing this is that because our

1242
00:50:23,240 --> 00:50:24,470
hash table hash function is

1243
00:50:24,470 --> 00:50:26,750
deterministic meaning the same key will

1244
00:50:26,750 --> 00:50:28,550
always be given the same hashed value

1245
00:50:28,550 --> 00:50:31,220
output that means that tuples that have

1246
00:50:31,220 --> 00:50:33,200
the same key will land in the same

1247
00:50:33,200 --> 00:50:35,330
partition and we don't need to hunt

1248
00:50:35,330 --> 00:50:37,280
around for other parts of the the

1249
00:50:37,280 --> 00:50:39,560
tablespace at the table to find the same

1250
00:50:39,560 --> 00:50:41,150
key they're always gonna be in our one

1251
00:50:41,150 --> 00:50:44,270
partition our partitions can just build

1252
00:50:44,270 --> 00:50:46,550
a disk using the buffer manager when

1253
00:50:46,550 --> 00:50:48,800
they when they get full so so we have a

1254
00:50:48,800 --> 00:50:51,530
page that we're storing the the current

1255
00:50:51,530 --> 00:50:53,330
partition data and when that gets full

1256
00:50:53,330 --> 00:50:54,890
we just write that out to disk and start

1257
00:50:54,890 --> 00:50:57,800
filling in the next page so in this case

1258
00:50:57,800 --> 00:50:59,390
here we're gonna assume we have B

1259
00:50:59,390 --> 00:51:01,600
buffers and we're gonna use B - buffers

1260
00:51:01,600 --> 00:51:04,400
for the partitions and at least one

1261
00:51:04,400 --> 00:51:07,460
buffer for the input so I'm gonna bring

1262
00:51:07,460 --> 00:51:09,890
in one page from my table and I'm going

1263
00:51:09,890 --> 00:51:11,420
to ask winchell scan on that page look

1264
00:51:11,420 --> 00:51:12,800
at every single tuple and then it's

1265
00:51:12,800 --> 00:51:14,780
gonna write it out to be minus 1

1266
00:51:14,780 --> 00:51:18,800
partitions alright because you need to

1267
00:51:18,800 --> 00:51:20,090
have at least one buffer in memory for

1268
00:51:20,090 --> 00:51:29,960
each partition yes so so if if say I'm

1269
00:51:29,960 --> 00:51:31,580
doing I'm gonna doing a group I on the

1270
00:51:31,580 --> 00:51:35,750
course ID here next like I'm doing a

1271
00:51:35,750 --> 00:51:38,270
group I on the course ID I'm doing

1272
00:51:38,270 --> 00:51:41,120
aggregation so I'm gonna hash this

1273
00:51:41,120 --> 00:51:44,300
course ID for every single tuple if I

1274
00:51:44,300 --> 00:51:45,740
had the same course ID it's gonna Lane

1275
00:51:45,740 --> 00:51:47,090
that in the same partition so it's gonna

1276
00:51:47,090 --> 00:51:50,840
live there right reside live stored and

1277
00:51:50,840 --> 00:51:52,790
then that way when I want to go now do

1278
00:51:52,790 --> 00:51:54,230
that in this case the duplicate

1279
00:51:54,230 --> 00:51:56,330
elimination when I come back the second

1280
00:51:56,330 --> 00:51:59,690
time I know that the the tuples that go

1281
00:51:59,690 --> 00:52:01,730
have the same key has to be in the same

1282
00:52:01,730 --> 00:52:03,200
partition there's not gonna be some

1283
00:52:03,200 --> 00:52:05,839
other random place

1284
00:52:05,839 --> 00:52:07,729
this question it's partition to page no

1285
00:52:07,729 --> 00:52:10,400
partition would be like a it's a little

1286
00:52:10,400 --> 00:52:14,089
logical thing take the hash value Matta

1287
00:52:14,089 --> 00:52:15,769
by the number of partitions and that

1288
00:52:15,769 --> 00:52:17,239
were you write into and these partition

1289
00:52:17,239 --> 00:52:21,349
can have multiple pages alright so again

1290
00:52:21,349 --> 00:52:24,170
we do our filter do as we did before we

1291
00:52:24,170 --> 00:52:26,059
remove our projection columns and then

1292
00:52:26,059 --> 00:52:29,059
now we take our all the output of here

1293
00:52:29,059 --> 00:52:30,469
we're gonna run it through our hash

1294
00:52:30,469 --> 00:52:34,009
function and we write it out to the

1295
00:52:34,009 --> 00:52:36,079
partition pages so in this case here I'd

1296
00:52:36,079 --> 00:52:38,420
be -1 so say there's like four or five

1297
00:52:38,420 --> 00:52:40,910
I'm showing three here so all the 15 for

1298
00:52:40,910 --> 00:52:44,809
45 keys land here all the 1588 26 land

1299
00:52:44,809 --> 00:52:48,469
here at 15 7 21 lens here so again you

1300
00:52:48,469 --> 00:52:50,509
could be smart about this and say

1301
00:52:50,509 --> 00:52:51,890
alright well I know I'm doing doing

1302
00:52:51,890 --> 00:52:54,979
distinct so within my page if I see the

1303
00:52:54,979 --> 00:52:57,529
same thing then don't bother putting it

1304
00:52:57,529 --> 00:52:59,359
into it but for simplicity reasons we're

1305
00:52:59,359 --> 00:53:01,039
just we're just we're blindly just

1306
00:53:01,039 --> 00:53:06,769
putting it in yes question is what is it

1307
00:53:06,769 --> 00:53:08,599
what is it partition you can think of

1308
00:53:08,599 --> 00:53:11,329
like a partition is thinking like it's

1309
00:53:11,329 --> 00:53:14,119
like the the bucket chain and the chain

1310
00:53:14,119 --> 00:53:17,269
hash table you just have within a within

1311
00:53:17,269 --> 00:53:18,709
a chain you could have multiple pages

1312
00:53:18,709 --> 00:53:21,140
but I only have one page in memory as

1313
00:53:21,140 --> 00:53:23,689
I'm populating this because again for

1314
00:53:23,689 --> 00:53:25,489
everything every single time I'm gonna

1315
00:53:25,489 --> 00:53:27,229
catch something and insert it into this

1316
00:53:27,229 --> 00:53:29,359
I'm only inserting into one page and

1317
00:53:29,359 --> 00:53:30,650
when this gets full I guess again

1318
00:53:30,650 --> 00:53:33,259
written out to disk and I now allocate

1319
00:53:33,259 --> 00:53:35,569
another one that I start filling up so

1320
00:53:35,569 --> 00:53:37,009
within memory why I'm doing this first

1321
00:53:37,009 --> 00:53:39,380
days I only need B minus 1 pages because

1322
00:53:39,380 --> 00:53:42,519
I'd be minus 1 partitions

1323
00:53:51,280 --> 00:53:52,900
so this question is what if the number

1324
00:53:52,900 --> 00:54:00,550
of distinct course IDs you do because

1325
00:54:00,550 --> 00:54:02,800
you're hashing it right you're dating -

1326
00:54:02,800 --> 00:54:06,130
mod to take this hash value mont by b

1327
00:54:06,130 --> 00:54:09,490
minus 1 so in this example here I'm only

1328
00:54:09,490 --> 00:54:11,530
showing three distinct keys but like I

1329
00:54:11,530 --> 00:54:14,470
have another class 15 for ten back at

1330
00:54:14,470 --> 00:54:17,670
land in the same bucket as 15 for 45 I

1331
00:54:17,670 --> 00:54:20,200
don't need to have a partition for every

1332
00:54:20,200 --> 00:54:23,800
sting every stinky the hashing allows

1333
00:54:23,800 --> 00:54:27,400
them to go into the same thing your face

1334
00:54:27,400 --> 00:54:29,290
looks like you'd like this confused by

1335
00:54:29,290 --> 00:54:35,590
this right again so I have 15 for 10 I'm

1336
00:54:35,590 --> 00:54:38,380
gonna hash it I'm on it by B minus 1 it

1337
00:54:38,380 --> 00:54:41,950
lands in partition 0 and so I just

1338
00:54:41,950 --> 00:54:45,700
append it to this to this page right and

1339
00:54:45,700 --> 00:54:48,070
then the main thing is that 15 for 10

1340
00:54:48,070 --> 00:54:50,560
can't exist in any other page because

1341
00:54:50,560 --> 00:54:52,150
the hash function always guarantee that

1342
00:54:52,150 --> 00:54:57,580
it's always gonna point to this one if

1343
00:54:57,580 --> 00:54:59,860
the partition the current page with this

1344
00:54:59,860 --> 00:55:01,720
partition overflows I write it out the

1345
00:55:01,720 --> 00:55:03,790
disk and I allocate a new page and start

1346
00:55:03,790 --> 00:55:11,950
filling that up yeah you first plus the

1347
00:55:11,950 --> 00:55:15,340
page allocate a new one yes and again

1348
00:55:15,340 --> 00:55:18,100
like at this phase all we're doing is

1349
00:55:18,100 --> 00:55:21,100
this partitioning so I don't care like I

1350
00:55:21,100 --> 00:55:22,450
can be smart and say oh I'm doing

1351
00:55:22,450 --> 00:55:24,280
duplicate elimination I know I already

1352
00:55:24,280 --> 00:55:25,800
have 1545 over here I don't put it in

1353
00:55:25,800 --> 00:55:28,150
ignore that for now right

1354
00:55:28,150 --> 00:55:30,370
it's just I'm blindly putting things

1355
00:55:30,370 --> 00:55:32,890
into this to the pages and writing them

1356
00:55:32,890 --> 00:55:45,190
out yes yes so so this question is it's

1357
00:55:45,190 --> 00:55:47,380
getting written out the disk where am i

1358
00:55:47,380 --> 00:55:48,730
storing the metadata that says oh

1359
00:55:48,730 --> 00:55:51,280
partition 0 has these pages you had that

1360
00:55:51,280 --> 00:55:53,920
in memory data structure you keep track

1361
00:55:53,920 --> 00:55:56,110
of like partition 0 here's the pages for

1362
00:55:56,110 --> 00:55:57,460
our partition 1 here's the pages for it

1363
00:55:57,460 --> 00:55:59,500
but that's small right that's like

1364
00:55:59,500 --> 00:56:02,490
that's nothing

1365
00:56:02,520 --> 00:56:04,570
this question is are we not considering

1366
00:56:04,570 --> 00:56:08,640
collisions we don't care at this point

1367
00:56:08,670 --> 00:56:09,910
right

1368
00:56:09,910 --> 00:56:12,880
it's in actually maybe use another table

1369
00:56:12,880 --> 00:56:13,960
than indistinct maybe that's following

1370
00:56:13,960 --> 00:56:16,300
people but if I'm doing a you know a

1371
00:56:16,300 --> 00:56:20,380
count again you can do that more

1372
00:56:20,380 --> 00:56:21,760
efficiently as well but like like I

1373
00:56:21,760 --> 00:56:24,070
don't care putting in inside of this I

1374
00:56:24,070 --> 00:56:25,240
don't care this collision scope because

1375
00:56:25,240 --> 00:56:27,160
I'm gonna resolve that in the second

1376
00:56:27,160 --> 00:56:36,310
phase when I rehash things your question

1377
00:56:36,310 --> 00:56:39,070
is where is this number coming from B

1378
00:56:39,070 --> 00:56:41,320
minus one so that's the database system

1379
00:56:41,320 --> 00:56:43,360
telling this query that's whatever

1380
00:56:43,360 --> 00:56:44,740
thread or worker that's exiting these

1381
00:56:44,740 --> 00:56:46,390
queries you have this amount of memory

1382
00:56:46,390 --> 00:56:58,000
to use for query processing yeah so like

1383
00:56:58,000 --> 00:56:59,470
the data system says you're allowed to

1384
00:56:59,470 --> 00:57:02,680
have B equals 100 pages to do whatever

1385
00:57:02,680 --> 00:57:04,420
you want to do for next to the query to

1386
00:57:04,420 --> 00:57:07,630
execute this algorithm I I'm gonna use B

1387
00:57:07,630 --> 00:57:10,390
minus 1 to store my part I'll be minus 1

1388
00:57:10,390 --> 00:57:11,530
partitions because these partition will

1389
00:57:11,530 --> 00:57:15,970
have one page yeah it sucks yeah your

1390
00:57:15,970 --> 00:57:17,950
question is if B is really small

1391
00:57:17,950 --> 00:57:22,150
you're yes right there's nothing you can

1392
00:57:22,150 --> 00:57:23,619
do it's not it's not like you might you

1393
00:57:23,619 --> 00:57:25,690
know you can't magically just add more

1394
00:57:25,690 --> 00:57:27,160
memory right justifying that resource

1395
00:57:27,160 --> 00:57:30,760
the database system you know is the is

1396
00:57:30,760 --> 00:57:32,200
is doing resource management it's

1397
00:57:32,200 --> 00:57:34,030
deciding oh I have a lot of queries that

1398
00:57:34,030 --> 00:57:36,040
need to execute at the same time so

1399
00:57:36,040 --> 00:57:37,060
therefore I can't let them all have a

1400
00:57:37,060 --> 00:57:38,800
lot of memory so this gets into the

1401
00:57:38,800 --> 00:57:40,330
tuning side of things which is actually

1402
00:57:40,330 --> 00:57:53,230
very difficult as well yes ok so he says

1403
00:57:53,230 --> 00:57:54,369
and I don't have slides with this we'll

1404
00:57:54,369 --> 00:57:59,440
do it next class he said that you're

1405
00:57:59,440 --> 00:58:01,680
screwed let me rephrase what you said

1406
00:58:01,680 --> 00:58:04,720
you're screwed are you better if

1407
00:58:04,720 --> 00:58:07,720
everything hashes is this bucket so say

1408
00:58:07,720 --> 00:58:09,220
this is this is most popular course

1409
00:58:09,220 --> 00:58:12,940
McAmis everyone's taking 1545 right then

1410
00:58:12,940 --> 00:58:14,030
as I hash

1411
00:58:14,030 --> 00:58:15,830
everyone lands there then I'm screwed

1412
00:58:15,830 --> 00:58:18,380
right but again this gets into the query

1413
00:58:18,380 --> 00:58:19,640
planning side of things the database

1414
00:58:19,640 --> 00:58:22,040
system could look at and say oh I know

1415
00:58:22,040 --> 00:58:23,900
what the distribution of values are for

1416
00:58:23,900 --> 00:58:26,450
for this column and everyone is taken 15

1417
00:58:26,450 --> 00:58:28,940
40 45 so therefore if I do this

1418
00:58:28,940 --> 00:58:32,480
technique then I'm it's not gonna get

1419
00:58:32,480 --> 00:58:33,650
any benefit because everything's gonna

1420
00:58:33,650 --> 00:58:35,210
hash to this and it's always to work I

1421
00:58:35,210 --> 00:58:38,650
might as well just do ask Winchell scan

1422
00:58:39,550 --> 00:58:41,810
this question is you always don't know

1423
00:58:41,810 --> 00:58:44,570
about the data like you know a good

1424
00:58:44,570 --> 00:58:47,150
decision will know something it won't be

1425
00:58:47,150 --> 00:58:49,130
entirely accurate but it'll know

1426
00:58:49,130 --> 00:59:05,840
something so this table is like with the

1427
00:59:05,840 --> 00:59:06,830
full data set

1428
00:59:06,830 --> 00:59:08,780
these can be this be unskilled but then

1429
00:59:08,780 --> 00:59:11,210
this is skewed again this is this is

1430
00:59:11,210 --> 00:59:15,440
next week or two weeks the daily ISM can

1431
00:59:15,440 --> 00:59:17,450
maintain metadata about every single

1432
00:59:17,450 --> 00:59:21,170
column histogram sketches I do an

1433
00:59:21,170 --> 00:59:22,310
approximation of what the dish being

1434
00:59:22,310 --> 00:59:25,970
about looked like again for skewed

1435
00:59:25,970 --> 00:59:28,250
workloads that's harder you got a call

1436
00:59:28,250 --> 00:59:30,770
all right he's got a call yeah all right

1437
00:59:30,770 --> 00:59:31,940
sorry

1438
00:59:31,940 --> 00:59:33,920
he's out on parole says what he's got a

1439
00:59:33,920 --> 00:59:36,980
call his parole officer all right so for

1440
00:59:36,980 --> 00:59:39,020
simplicity I'm just saying assume

1441
00:59:39,020 --> 00:59:42,470
uniform distribution okay for skewed

1442
00:59:42,470 --> 00:59:44,330
work again they'll be assert up to a

1443
00:59:44,330 --> 00:59:45,920
certain point where this technique won't

1444
00:59:45,920 --> 00:59:47,750
work in a squinter scam will be the

1445
00:59:47,750 --> 00:59:54,140
better approach yes this question is

1446
00:59:54,140 --> 00:59:56,230
what is the overhead of removing columns

1447
00:59:56,230 --> 01:00:03,410
so in in this example here I'm showing

1448
01:00:03,410 --> 01:00:06,770
this as like discrete steps like filter

1449
01:00:06,770 --> 01:00:09,170
and then remove you can inline a combine

1450
01:00:09,170 --> 01:00:11,870
these together but again this is another

1451
01:00:11,870 --> 01:00:14,300
great example there's a trade-off so if

1452
01:00:14,300 --> 01:00:18,380
my table is massive and I know that I

1453
01:00:18,380 --> 01:00:21,440
don't need all the columns up up above

1454
01:00:21,440 --> 01:00:24,050
an entry then it's totally worth it to

1455
01:00:24,050 --> 01:00:25,730
me to pay the penalty to do this

1456
01:00:25,730 --> 01:00:26,920
projection because there

1457
01:00:26,920 --> 01:00:29,049
copping datum but if I only have one

1458
01:00:29,049 --> 01:00:33,099
tuple then I'll delay that that may be

1459
01:00:33,099 --> 01:00:34,210
the projection as late as possible

1460
01:00:34,210 --> 01:00:36,430
because that's gonna be it's just

1461
01:00:36,430 --> 01:00:38,619
cheaper to do at the very end all right

1462
01:00:38,619 --> 01:00:41,650
there's a trip how wide and how tall the

1463
01:00:41,650 --> 01:00:43,750
table is and again the data system can

1464
01:00:43,750 --> 01:00:44,640
figure this out

1465
01:00:44,640 --> 01:00:50,440
attempt to ok so what we're doing here

1466
01:00:50,440 --> 01:00:52,059
in the first phase where we're taking

1467
01:00:52,059 --> 01:00:53,950
the course ID we're hashing it we're

1468
01:00:53,950 --> 01:00:55,839
putting into these these pages for the

1469
01:00:55,839 --> 01:00:59,109
partitions so now in the second phase we

1470
01:00:59,109 --> 01:01:03,280
rehash for every single partition now

1471
01:01:03,280 --> 01:01:04,780
we're gonna bring them bring bring the

1472
01:01:04,780 --> 01:01:08,020
the pages in right and then we're gonna

1473
01:01:08,020 --> 01:01:11,770
build a named memory hash table that we

1474
01:01:11,770 --> 01:01:15,180
can then use to find that the same keys

1475
01:01:15,180 --> 01:01:17,230
so we don't have to do this we could

1476
01:01:17,230 --> 01:01:18,579
just bring in every single partition and

1477
01:01:18,579 --> 01:01:21,190
do scratch or scan on them but because

1478
01:01:21,190 --> 01:01:23,200
we're doing aggregations we know that we

1479
01:01:23,200 --> 01:01:26,470
don't need we don't need to have all of

1480
01:01:26,470 --> 01:01:30,250
the duplicate keys in memory at the same

1481
01:01:30,250 --> 01:01:32,680
time so we're using a hash table to

1482
01:01:32,680 --> 01:01:35,530
summarize it and could condense it down

1483
01:01:35,530 --> 01:01:37,390
to just the bare minimum information

1484
01:01:37,390 --> 01:01:39,690
that we need to compute our result and

1485
01:01:39,690 --> 01:01:41,770
again the reason why we did the

1486
01:01:41,770 --> 01:01:43,599
partitioning first is that when we go

1487
01:01:43,599 --> 01:01:45,069
back in the second phase and we do

1488
01:01:45,069 --> 01:01:47,290
rehashing we know that all the keys that

1489
01:01:47,290 --> 01:01:49,359
are the same will exist in the same

1490
01:01:49,359 --> 01:01:52,660
partition so once we go through all the

1491
01:01:52,660 --> 01:01:55,180
pages within that partition we compute

1492
01:01:55,180 --> 01:01:56,410
whatever the answer that is that we want

1493
01:01:56,410 --> 01:01:58,720
we can we can potentially throw it at

1494
01:01:58,720 --> 01:02:00,790
that hash table away because we know

1495
01:02:00,790 --> 01:02:02,049
that there's or at least produce it as

1496
01:02:02,049 --> 01:02:04,420
an output there's no that it's the keys

1497
01:02:04,420 --> 01:02:06,250
that we've updated so far through that

1498
01:02:06,250 --> 01:02:07,599
one partition will never get updated

1499
01:02:07,599 --> 01:02:11,140
again from any other partition because

1500
01:02:11,140 --> 01:02:13,829
the hashing guarantees locality for us

1501
01:02:13,829 --> 01:02:16,599
all right so back here right these are

1502
01:02:16,599 --> 01:02:17,740
all the buckets we generated in the

1503
01:02:17,740 --> 01:02:20,290
first phase so let's say now that we can

1504
01:02:20,290 --> 01:02:23,020
bring in you know we can bring in you

1505
01:02:23,020 --> 01:02:24,520
know these two pages or all the

1506
01:02:24,520 --> 01:02:27,250
partitions for well we can process these

1507
01:02:27,250 --> 01:02:29,260
two partitions in memory at the same

1508
01:02:29,260 --> 01:02:31,660
time so all we're gonna do is just have

1509
01:02:31,660 --> 01:02:34,240
a cursor that can just scan through them

1510
01:02:34,240 --> 01:02:36,339
and every single key you're gonna hash

1511
01:02:36,339 --> 01:02:39,079
it and populate the hash table

1512
01:02:39,079 --> 01:02:40,910
and I keep the scanning down and do the

1513
01:02:40,910 --> 01:02:43,489
same thing for everything else and then

1514
01:02:43,489 --> 01:02:46,029
now I produce this as my final result

1515
01:02:46,029 --> 01:02:48,799
again for some realize that may be

1516
01:02:48,799 --> 01:02:50,599
confusing the final result of this hash

1517
01:02:50,599 --> 01:02:53,150
table or the is the same as this one but

1518
01:02:53,150 --> 01:02:55,130
you know and the main takeaway is that

1519
01:02:55,130 --> 01:02:57,049
we're gonna throw this away when we move

1520
01:02:57,049 --> 01:02:59,420
on to the next the next partitions right

1521
01:02:59,420 --> 01:03:03,410
and this one we keep around distinct is

1522
01:03:03,410 --> 01:03:05,150
like a little bit too simple but like I

1523
01:03:05,150 --> 01:03:06,499
was trying to pick something I just

1524
01:03:06,499 --> 01:03:08,930
distill down the core ideas alright so

1525
01:03:08,930 --> 01:03:10,789
now we got this other partition here so

1526
01:03:10,789 --> 01:03:12,349
again we blow away that the hash table

1527
01:03:12,349 --> 01:03:14,630
from the first the first set of

1528
01:03:14,630 --> 01:03:16,369
partitions we do the same thing build a

1529
01:03:16,369 --> 01:03:18,380
Ameri hash table for this guy and then

1530
01:03:18,380 --> 01:03:19,729
we just when it's done with minutes

1531
01:03:19,729 --> 01:03:28,549
populate this thing yes a question her

1532
01:03:28,549 --> 01:03:29,930
statement is assuming we're not gonna

1533
01:03:29,930 --> 01:03:31,219
have collisions in the second hash

1534
01:03:31,219 --> 01:03:45,319
function you yes that we can write her

1535
01:03:45,319 --> 01:03:47,420
so her statement is question is what

1536
01:03:47,420 --> 01:03:50,890
does that mean you be overriding this

1537
01:03:52,180 --> 01:03:55,130
but it so that that does the collision

1538
01:03:55,130 --> 01:03:56,390
handling schemes that we talked about we

1539
01:03:56,390 --> 01:03:57,890
talked about hash tables so it's either

1540
01:03:57,890 --> 01:04:00,920
linear probing cuckoo hash whatever the

1541
01:04:00,920 --> 01:04:03,440
Robin Hood stuff right that's all the

1542
01:04:03,440 --> 01:04:05,809
internal to the hash table we're sort of

1543
01:04:05,809 --> 01:04:07,489
above it now we're saying your hash

1544
01:04:07,489 --> 01:04:09,170
table I can write things into key value

1545
01:04:09,170 --> 01:04:11,349
pairs and it'll it'll store them for me

1546
01:04:11,349 --> 01:04:14,779
I don't know and I don't really care at

1547
01:04:14,779 --> 01:04:16,359
this point how it handles collisions

1548
01:04:16,359 --> 01:04:21,410
okay again distinctive is a really

1549
01:04:21,410 --> 01:04:23,599
stupid simple example but you know going

1550
01:04:23,599 --> 01:04:26,119
through those processes is it was main

1551
01:04:26,119 --> 01:04:30,739
thing I what you guys get okay a

1552
01:04:30,739 --> 01:04:32,539
statement is the question is how is this

1553
01:04:32,539 --> 01:04:36,319
faster than then sorting for this

1554
01:04:36,319 --> 01:04:43,819
particular query probably not it depends

1555
01:04:43,819 --> 01:04:49,869
on the turns on the size of the data

1556
01:04:51,940 --> 01:04:54,740
I'll cover those let me leave really

1557
01:04:54,740 --> 01:04:56,720
punt on that question until next week

1558
01:04:56,720 --> 01:04:58,250
and be more clear when you start seeing

1559
01:04:58,250 --> 01:05:02,350
like the different joint algorithms yes

1560
01:05:03,760 --> 01:05:06,980
yeah so again because this is these

1561
01:05:06,980 --> 01:05:08,330
question is why do we need this when

1562
01:05:08,330 --> 01:05:09,860
it's just this one is right into this

1563
01:05:09,860 --> 01:05:12,590
and that example yes but like I was

1564
01:05:12,590 --> 01:05:14,360
trying to show that you look you have an

1565
01:05:14,360 --> 01:05:15,710
ephemeral hash table as you bill and

1566
01:05:15,710 --> 01:05:17,150
populate and then when you're done then

1567
01:05:17,150 --> 01:05:18,830
you shove it into this thing four

1568
01:05:18,830 --> 01:05:20,630
distinct it's stupid doesn't make sense

1569
01:05:20,630 --> 01:05:23,840
for aggregations fraud aggregations you

1570
01:05:23,840 --> 01:05:26,200
could potentially do that as well right

1571
01:05:26,200 --> 01:05:29,480
because again this like this may not fit

1572
01:05:29,480 --> 01:05:39,620
in memory yes oh so yes so I should be

1573
01:05:39,620 --> 01:05:41,780
clear this is this is a different seed

1574
01:05:41,780 --> 01:05:43,700
same so you know remember half of the

1575
01:05:43,700 --> 01:05:54,830
difference seat this question is like

1576
01:05:54,830 --> 01:05:57,920
say I built this first hash table and I

1577
01:05:57,920 --> 01:06:00,800
use that one C for the hash function now

1578
01:06:00,800 --> 01:06:03,470
down here do I need to use can I use a

1579
01:06:03,470 --> 01:06:05,200
different seed I don't think it matters

1580
01:06:05,200 --> 01:06:06,530
right

1581
01:06:06,530 --> 01:06:08,690
if you're writing into this if you're

1582
01:06:08,690 --> 01:06:09,920
writing into the same hash table you

1583
01:06:09,920 --> 01:06:11,240
have to be have to use the same seed if

1584
01:06:11,240 --> 01:06:13,040
you're just gonna merge that in later on

1585
01:06:13,040 --> 01:06:15,950
it doesn't matter now

1586
01:06:15,950 --> 01:06:25,280
yeah yes yes the final result farmers on

1587
01:06:25,280 --> 01:06:26,780
the database

1588
01:06:26,780 --> 01:06:28,610
I've sent a final result of an operator

1589
01:06:28,610 --> 01:06:33,590
is always gonna be a relation so this is

1590
01:06:33,590 --> 01:06:35,720
it could be a hash table it could be

1591
01:06:35,720 --> 01:06:38,270
just a buffer of pages depends on

1592
01:06:38,270 --> 01:06:41,270
implementation I realized that like it's

1593
01:06:41,270 --> 01:06:46,150
the same shapes yeah sorry

1594
01:06:46,150 --> 01:06:49,400
alright so finish up

1595
01:06:49,400 --> 01:06:50,300
let's talk about it do something more

1596
01:06:50,300 --> 01:06:53,000
complicated it's actually had to do you

1597
01:06:53,000 --> 01:06:55,940
know a grens were you know the actual

1598
01:06:55,940 --> 01:06:58,670
producing a real result so for this one

1599
01:06:58,670 --> 01:07:01,310
they the intermediate hash-table after

1600
01:07:01,310 --> 01:07:04,340
ever using for the the second phase

1601
01:07:04,340 --> 01:07:06,200
we're actually going to use that to

1602
01:07:06,200 --> 01:07:09,020
maintain the running total of whatever

1603
01:07:09,020 --> 01:07:10,640
it is the competition we're trying to do

1604
01:07:10,640 --> 01:07:12,400
in our aggregate from aggregate function

1605
01:07:12,400 --> 01:07:15,350
right and so this running value would

1606
01:07:15,350 --> 01:07:18,290
depend on what the aggregation you're

1607
01:07:18,290 --> 01:07:21,200
actually trying to do so it's going back

1608
01:07:21,200 --> 01:07:24,050
here so saying all of these guys now I'm

1609
01:07:24,050 --> 01:07:25,970
doing a I'm getting the the course ID

1610
01:07:25,970 --> 01:07:29,450
and I'm doing the average GPA so in the

1611
01:07:29,450 --> 01:07:30,890
hash table that I could be generating

1612
01:07:30,890 --> 01:07:33,860
for all of these I'm gonna have the the

1613
01:07:33,860 --> 01:07:36,650
key map to this like topple value that's

1614
01:07:36,650 --> 01:07:38,330
going to keep the running count of the

1615
01:07:38,330 --> 01:07:41,420
number of keys that I've seen with there

1616
01:07:41,420 --> 01:07:42,740
sorry number two was I've seen with the

1617
01:07:42,740 --> 01:07:45,470
same key and then just the summation of

1618
01:07:45,470 --> 01:07:50,390
of their GPAs right and then I just take

1619
01:07:50,390 --> 01:07:52,820
this thing and then when I went to

1620
01:07:52,820 --> 01:07:54,200
compute its produced a final output I

1621
01:07:54,200 --> 01:07:56,000
take the running total divided by the

1622
01:07:56,000 --> 01:07:57,710
number of tuples and that's how I get my

1623
01:07:57,710 --> 01:08:00,320
average so for all the different hash

1624
01:08:00,320 --> 01:08:02,030
different aggregation functions and

1625
01:08:02,030 --> 01:08:04,780
generally just keep track of you know a

1626
01:08:04,780 --> 01:08:07,430
single scalar value account you're just

1627
01:08:07,430 --> 01:08:08,660
adding one every single time you see

1628
01:08:08,660 --> 01:08:11,420
your new key or key of the same value

1629
01:08:11,420 --> 01:08:13,220
and then for some you just keep adding

1630
01:08:13,220 --> 01:08:14,990
values together for the average you you

1631
01:08:14,990 --> 01:08:18,380
can compute that with with the number of

1632
01:08:18,380 --> 01:08:20,210
the count plus the sum standard

1633
01:08:20,210 --> 01:08:22,279
deviation or other other aggregation

1634
01:08:22,279 --> 01:08:24,500
functions you you maintain a little more

1635
01:08:24,500 --> 01:08:26,000
information so now basically what

1636
01:08:26,000 --> 01:08:27,740
happens in our hash table when we want

1637
01:08:27,740 --> 01:08:30,859
when we want to update the hash table we

1638
01:08:30,859 --> 01:08:32,359
do an insert if it's not there we just

1639
01:08:32,359 --> 01:08:34,550
add it if it is there then we need to be

1640
01:08:34,550 --> 01:08:37,760
able to modify this in place or do a

1641
01:08:37,760 --> 01:08:39,620
delete followed by an insert to update

1642
01:08:39,620 --> 01:08:46,189
it so this time and again if you were

1643
01:08:46,189 --> 01:08:47,540
doing this with sorting you could do the

1644
01:08:47,540 --> 01:08:48,710
same thing you would have this on the

1645
01:08:48,710 --> 01:08:51,740
side and then as your scan through and

1646
01:08:51,740 --> 01:08:53,870
in the final sort of output you wouldn't

1647
01:08:53,870 --> 01:08:55,250
you could update these totals and

1648
01:08:55,250 --> 01:08:57,970
produce the final output

1649
01:08:59,309 --> 01:09:04,099
all right so I'm gonna skip this for now

1650
01:09:04,099 --> 01:09:06,299
this will this will make more sense for

1651
01:09:06,299 --> 01:09:08,309
next week we do hash trends essentially

1652
01:09:08,309 --> 01:09:09,389
a hash joins would be essentially do the

1653
01:09:09,389 --> 01:09:11,368
same thing that we're gonna build this

1654
01:09:11,368 --> 01:09:14,609
ephemeral hash table with on on the keys

1655
01:09:14,609 --> 01:09:16,500
we want to do a join one and then we

1656
01:09:16,500 --> 01:09:17,729
probe in that and see whether we have a

1657
01:09:17,729 --> 01:09:19,589
match and we produce our final output or

1658
01:09:19,589 --> 01:09:23,250
the operator okay so let's let's get

1659
01:09:23,250 --> 01:09:26,158
this and then we'll focus well we'll

1660
01:09:26,158 --> 01:09:28,288
discuss this again next week when we or

1661
01:09:28,288 --> 01:09:29,609
next to next Wednesday we do hash lines

1662
01:09:29,609 --> 01:09:32,460
okay all right

1663
01:09:32,460 --> 01:09:36,259
so in conclusion so what I show today is

1664
01:09:36,259 --> 01:09:39,000
this sort of the trade-offs between

1665
01:09:39,000 --> 01:09:41,038
sorting and hashing and again we'll go

1666
01:09:41,038 --> 01:09:42,569
to more details about which one is

1667
01:09:42,569 --> 01:09:44,368
better than the other when we talk about

1668
01:09:44,368 --> 01:09:49,259
joins next week the high level

1669
01:09:49,259 --> 01:09:50,520
techniques that we talked about here are

1670
01:09:50,520 --> 01:09:51,658
we applicable for all the parts of the

1671
01:09:51,658 --> 01:09:53,719
database system so this partitioning

1672
01:09:53,719 --> 01:09:55,559
approach this divide and conquer

1673
01:09:55,559 --> 01:09:57,630
approach all that is useful for other

1674
01:09:57,630 --> 01:09:59,309
algorithms other methods we have we we

1675
01:09:59,309 --> 01:10:01,110
care about in our system so we'll see

1676
01:10:01,110 --> 01:10:02,520
this recurring theme throughout the rest

1677
01:10:02,520 --> 01:10:04,349
of semester that splitting things up

1678
01:10:04,349 --> 01:10:06,329
into smaller units of work and trying to

1679
01:10:06,329 --> 01:10:08,130
operate on that small small chunk of

1680
01:10:08,130 --> 01:10:10,349
data or small problem is gonna be very

1681
01:10:10,349 --> 01:10:14,489
very useful technique okay all right so

1682
01:10:14,489 --> 01:10:17,699
let's know what project two so project

1683
01:10:17,699 --> 01:10:19,440
two you are going to be building a

1684
01:10:19,440 --> 01:10:22,530
thread safe linear probing hash table so

1685
01:10:22,530 --> 01:10:24,420
this is me built on top of a buffer pool

1686
01:10:24,420 --> 01:10:26,309
you built in the first project so it's

1687
01:10:26,309 --> 01:10:27,690
not an in-memory hash table it has we

1688
01:10:27,690 --> 01:10:30,630
backed by disk pages so we're not gonna

1689
01:10:30,630 --> 01:10:32,849
do anything that we talked about here in

1690
01:10:32,849 --> 01:10:34,110
this class we're doing trying to

1691
01:10:34,110 --> 01:10:36,030
maximize crunch why oh it's just you do

1692
01:10:36,030 --> 01:10:38,250
random i/o and you go grab pages and

1693
01:10:38,250 --> 01:10:40,380
from your buffle manager as needed right

1694
01:10:40,380 --> 01:10:43,739
to do to do inserts and deletes so your

1695
01:10:43,739 --> 01:10:45,480
are going to support resizing so again

1696
01:10:45,480 --> 01:10:47,670
linear probing hash table assumes it's a

1697
01:10:47,670 --> 01:10:49,679
static hash table but when it gets full

1698
01:10:49,679 --> 01:10:51,480
then you need to take a latch on it and

1699
01:10:51,480 --> 01:10:53,429
then resize the entire thing so you need

1700
01:10:53,429 --> 01:10:55,440
to support resizing as well and you need

1701
01:10:55,440 --> 01:10:57,449
to support doing this resizing when

1702
01:10:57,449 --> 01:10:59,520
multiple threads could be accessing the

1703
01:10:59,520 --> 01:11:02,219
the hash table at the same time so the

1704
01:11:02,219 --> 01:11:05,190
the website is up the it's not announced

1705
01:11:05,190 --> 01:11:05,880
yet on Piazza

1706
01:11:05,880 --> 01:11:09,420
what will remain there's some final

1707
01:11:09,420 --> 01:11:10,769
adjustments we're doing for the source

1708
01:11:10,769 --> 01:11:12,449
code before release to you guys but we

1709
01:11:12,449 --> 01:11:12,800
hope to

1710
01:11:12,800 --> 01:11:16,850
this will be later today I don't know

1711
01:11:16,850 --> 01:11:18,650
let's our animations alright so there's

1712
01:11:18,650 --> 01:11:20,720
four tests you're gonna have to do the

1713
01:11:20,720 --> 01:11:22,010
first is that you're responsible for

1714
01:11:22,010 --> 01:11:24,500
designing the page layout of the

1715
01:11:24,500 --> 01:11:27,380
hash-table blocks so this is the header

1716
01:11:27,380 --> 01:11:29,480
page and then the actual block page is

1717
01:11:29,480 --> 01:11:30,730
where the actual key values are stored

1718
01:11:30,730 --> 01:11:33,050
so this is a useful exercise to get you

1719
01:11:33,050 --> 01:11:36,040
to understand what it means to take a

1720
01:11:36,040 --> 01:11:38,510
you know a page from the buffer pool

1721
01:11:38,510 --> 01:11:40,910
manager and then be able to interpret it

1722
01:11:40,910 --> 01:11:41,960
in such a way that stores the data

1723
01:11:41,960 --> 01:11:44,150
exactly that you want all right it's not

1724
01:11:44,150 --> 01:11:45,470
your just malloc in some space you're

1725
01:11:45,470 --> 01:11:46,940
going to bump Amanda he says give me a

1726
01:11:46,940 --> 01:11:48,950
page and you say oh this is a this is a

1727
01:11:48,950 --> 01:11:51,320
hash table block page here's the offsets

1728
01:11:51,320 --> 01:11:52,400
to find the data that I'm looking for

1729
01:11:52,400 --> 01:11:54,770
how do you do a reinterpret cast on that

1730
01:11:54,770 --> 01:11:55,100
data

1731
01:11:55,100 --> 01:11:56,930
so your first implement those two

1732
01:11:56,930 --> 01:11:58,670
classes they do the header page and then

1733
01:11:58,670 --> 01:12:00,470
the block pages then you want to

1734
01:12:00,470 --> 01:12:02,620
implement the basic hash table itself

1735
01:12:02,620 --> 01:12:06,800
right to do inserts and deletes and they

1736
01:12:06,800 --> 01:12:08,840
get also support concurrent operations

1737
01:12:08,840 --> 01:12:11,390
using a reader writer latch which we

1738
01:12:11,390 --> 01:12:13,190
provide you and then also support

1739
01:12:13,190 --> 01:12:15,680
resizing you take a latch in the entire

1740
01:12:15,680 --> 01:12:17,630
table double the size of it and then

1741
01:12:17,630 --> 01:12:19,550
rehash everything so you need you need

1742
01:12:19,550 --> 01:12:23,360
to be able to support that so you should

1743
01:12:23,360 --> 01:12:26,360
follow the the textbook semantics and

1744
01:12:26,360 --> 01:12:29,210
algorithms for how they do you know do

1745
01:12:29,210 --> 01:12:31,070
the various operations

1746
01:12:31,070 --> 01:12:33,800
I think the lecture I gave on milena

1747
01:12:33,800 --> 01:12:35,360
hash table follows the textbook pretty

1748
01:12:35,360 --> 01:12:37,070
closely and the later hash table doesn't

1749
01:12:37,070 --> 01:12:38,870
have that many you know different design

1750
01:12:38,870 --> 01:12:40,040
decisions you have to make it's just

1751
01:12:40,040 --> 01:12:43,300
sort of going through these X steps I

1752
01:12:43,300 --> 01:12:45,680
advise you to first obviously work on

1753
01:12:45,680 --> 01:12:47,000
the page layout because you know you

1754
01:12:47,000 --> 01:12:47,900
can't have a hash table that you can

1755
01:12:47,900 --> 01:12:49,700
stored in pages anyway but you should

1756
01:12:49,700 --> 01:12:51,650
make sure that your pages work perfectly

1757
01:12:51,650 --> 01:12:54,110
before you move on to actually building

1758
01:12:54,110 --> 01:12:56,150
the hash table itself so we'll provide

1759
01:12:56,150 --> 01:12:59,210
you some basic tests test cases again to

1760
01:12:59,210 --> 01:13:00,710
do some rudimentary checks for your page

1761
01:13:00,710 --> 01:13:02,510
layouts but it's up for you to guys to

1762
01:13:02,510 --> 01:13:04,160
make sure that it's actually you know do

1763
01:13:04,160 --> 01:13:05,840
you simply more rigorous because if your

1764
01:13:05,840 --> 01:13:08,300
page layout gets up and then now

1765
01:13:08,300 --> 01:13:09,500
you start doing your hash table on that

1766
01:13:09,500 --> 01:13:10,820
it's like building a house on sand

1767
01:13:10,820 --> 01:13:12,410
because now you're like my hash table is

1768
01:13:12,410 --> 01:13:14,120
not working and it could it could

1769
01:13:14,120 --> 01:13:15,800
because the your pages aren't working

1770
01:13:15,800 --> 01:13:18,500
correctly so get this down solid before

1771
01:13:18,500 --> 01:13:22,220
moving to the next thing then when you

1772
01:13:22,220 --> 01:13:23,900
when you actually build the hash table

1773
01:13:23,900 --> 01:13:25,970
itself don't worry about making it

1774
01:13:25,970 --> 01:13:26,570
thread safe

1775
01:13:26,570 --> 01:13:30,170
focus on the honest single-threaded

1776
01:13:30,170 --> 01:13:32,780
support first this is a common design

1777
01:13:32,780 --> 01:13:34,520
approach in database systems this is the

1778
01:13:34,520 --> 01:13:35,989
approach I take with my own research and

1779
01:13:35,989 --> 01:13:39,110
in practice I think this is not every

1780
01:13:39,110 --> 01:13:40,730
company follows this he's wearing the

1781
01:13:40,730 --> 01:13:41,900
shirt for the company that does not

1782
01:13:41,900 --> 01:13:47,030
follow this the focus on correctness

1783
01:13:47,030 --> 01:13:50,480
first don't worry about it being slow so

1784
01:13:50,480 --> 01:13:51,860
make it you know make sure that it works

1785
01:13:51,860 --> 01:13:53,090
exactly what you think it should work

1786
01:13:53,090 --> 01:13:55,280
then go back and now start doing up the

1787
01:13:55,280 --> 01:13:56,449
optimizations that some of the things he

1788
01:13:56,449 --> 01:13:57,590
suggested some things we talked about in

1789
01:13:57,590 --> 01:14:00,949
class to be you know to do optimistic

1790
01:14:00,949 --> 01:14:02,929
latching be more more crafty on how you

1791
01:14:02,929 --> 01:14:05,510
release latches right make sure it works

1792
01:14:05,510 --> 01:14:07,010
correct force have test cases to prove

1793
01:14:07,010 --> 01:14:08,599
that it works correctly for you then

1794
01:14:08,599 --> 01:14:09,710
when you go start trying to make it go

1795
01:14:09,710 --> 01:14:11,239
faster because we'll have a leaderboard

1796
01:14:11,239 --> 01:14:12,790
to see who has the fastest hash-table

1797
01:14:12,790 --> 01:14:15,770
then you know then you know that you're

1798
01:14:15,770 --> 01:14:17,329
working with a again a solid

1799
01:14:17,329 --> 01:14:23,570
implementation okay all right so just

1800
01:14:23,570 --> 01:14:25,099
like before you don't need to change any

1801
01:14:25,099 --> 01:14:27,079
other files in the system other than the

1802
01:14:27,079 --> 01:14:28,250
ones that you have to spit on great

1803
01:14:28,250 --> 01:14:30,469
scope this is what we're working on now

1804
01:14:30,469 --> 01:14:32,599
so Wilson announced on Piazza that you

1805
01:14:32,599 --> 01:14:34,909
want to rebase your existing code on top

1806
01:14:34,909 --> 01:14:36,139
of the latest master because that I'll

1807
01:14:36,139 --> 01:14:38,719
bring in the new the sample header files

1808
01:14:38,719 --> 01:14:41,020
and the sample test cases before you

1809
01:14:41,020 --> 01:14:43,670
will provide instruction exactly what

1810
01:14:43,670 --> 01:14:44,900
you need to need to do the rebase

1811
01:14:44,900 --> 01:14:46,820
obviously makes you know since you can

1812
01:14:46,820 --> 01:14:48,909
blow away your source code on github

1813
01:14:48,909 --> 01:14:53,020
very easily with a Porsche push force

1814
01:14:53,020 --> 01:14:55,219
make sure you make a backup of your if

1815
01:14:55,219 --> 01:14:57,710
your copy but first before you start

1816
01:14:57,710 --> 01:15:00,560
doing the rebase and then as always post

1817
01:15:00,560 --> 01:15:03,889
your questions on Piazza and and come to

1818
01:15:03,889 --> 01:15:14,239
come to office hours yes this question

1819
01:15:14,239 --> 01:15:15,829
is if we assume if you get a hundred

1820
01:15:15,829 --> 01:15:17,510
cent score on the first project and you

1821
01:15:17,510 --> 01:15:19,699
assume that you're your buff elimination

1822
01:15:19,699 --> 01:15:24,500
is solid to support hashable yes I could

1823
01:15:24,500 --> 01:15:28,480
be wrong but we we think we tested

1824
01:15:29,440 --> 01:15:33,590
right but I would say like there was a

1825
01:15:33,590 --> 01:15:35,690
blog last year that that exact problem

1826
01:15:35,690 --> 01:15:38,000
showed up that's all the unresolved so I

1827
01:15:38,000 --> 01:15:39,500
think if you've passed our test it

1828
01:15:39,500 --> 01:15:44,450
should be solid this question is coming

1829
01:15:44,450 --> 01:15:45,680
now releases a skirt I cannot do that

1830
01:15:45,680 --> 01:15:47,060
because there's some people that are

1831
01:15:47,060 --> 01:15:54,260
still haven't submitted yet let's take

1832
01:15:54,260 --> 01:16:03,170
that all fine in the back yes for the

1833
01:16:03,170 --> 01:16:05,180
sorry for the first project you can

1834
01:16:05,180 --> 01:16:06,020
submit as much as you want

1835
01:16:06,020 --> 01:16:08,420
yeah yeah what is the whatever whenever

1836
01:16:08,420 --> 01:16:10,160
whatever the highest score you got from

1837
01:16:10,160 --> 01:16:12,410
the last I see great scope of let you

1838
01:16:12,410 --> 01:16:13,880
activate what you scored you want try it

1839
01:16:13,880 --> 01:16:15,530
I think but it's whatever the highest

1840
01:16:15,530 --> 01:16:18,200
score up into the deadline is what we'll

1841
01:16:18,200 --> 01:16:18,620
use

1842
01:16:18,620 --> 01:16:22,280
yeah yeah you submitted is all you want

1843
01:16:22,280 --> 01:16:23,930
you like if you get if you had an eighty

1844
01:16:23,930 --> 01:16:25,100
before and have a hunter after the

1845
01:16:25,100 --> 01:16:27,590
deadline you have an eighty score you

1846
01:16:27,590 --> 01:16:29,170
play the game with it like the late days

1847
01:16:29,170 --> 01:16:40,820
but that you know yeah again your

1848
01:16:40,820 --> 01:16:41,990
question is what if you change your

1849
01:16:41,990 --> 01:16:44,360
invitation after the fact for from

1850
01:16:44,360 --> 01:16:47,210
project one the it would still be you so

1851
01:16:47,210 --> 01:16:48,860
people Schmitt on great scope the old

1852
01:16:48,860 --> 01:16:53,210
project for project one we could just

1853
01:16:53,210 --> 01:16:54,890
have it throw in the first test as well

1854
01:16:54,890 --> 01:16:56,810
if you want to that make it easier like

1855
01:16:56,810 --> 01:16:58,580
it'll run all the tests from the first

1856
01:16:58,580 --> 01:17:00,620
project you won't get a score for that

1857
01:17:00,620 --> 01:17:02,570
but it does be there we could do that

1858
01:17:02,570 --> 01:17:07,490
well fix that okay what's that you know

1859
01:17:07,490 --> 01:17:09,100
make it slower that's the only thing

1860
01:17:09,100 --> 01:17:11,659
[Music]

1861
01:17:11,659 --> 01:17:14,429
yeah but you can still be able to submit

1862
01:17:14,429 --> 01:17:19,369
for the first one okay do not plagiarize

1863
01:17:19,369 --> 01:17:21,659
we won that we're gonna run this emboss

1864
01:17:21,659 --> 01:17:23,489
this is we're doing that this week for

1865
01:17:23,489 --> 01:17:24,839
your first project if you plagiarize

1866
01:17:24,839 --> 01:17:26,849
well ever worn a hole you'd be

1867
01:17:26,849 --> 01:17:27,749
kicked out okay

1868
01:17:27,749 --> 01:17:30,239
don't do that next class we're doing

1869
01:17:30,239 --> 01:17:31,800
joints next live joining partners

1870
01:17:31,800 --> 01:17:34,979
joining to hash coins okay alright he's

1871
01:17:34,979 --> 01:18:00,659
got a call here guys ricochet jelly hit

1872
01:18:00,659 --> 01:18:03,659
the deli put one naturally rap is like

1873
01:18:03,659 --> 01:18:11,069
the bottle don't fill out drink it only

1874
01:18:11,069 --> 01:18:14,639
to you can't and if the sink don't know

1875
01:18:14,639 --> 01:18:17,569
you for can't pay

1876
01:18:17,600 --> 01:18:20,649
[Music]

