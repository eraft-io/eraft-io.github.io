1
00:00:03,640 --> 00:00:13,140
[音乐]

2
00:00:14,770 --> 00:00:18,010
让我们开始吧，

3
00:00:18,010 --> 00:00:22,070
所以今天DJ不在场 他

4
00:00:22,070 --> 00:00:24,949
应该下周来 他在这里有点

5
00:00:24,949 --> 00:00:28,070
吵闹 所以他

6
00:00:28,070 --> 00:00:30,079
这周是他女朋友的生日 他

7
00:00:30,079 --> 00:00:33,440
上周在维加斯吹了钱 所以他

8
00:00:33,440 --> 00:00:35,300
撒谎告诉她 他将在

9
00:00:35,300 --> 00:00:38,000
感恩节探望他的家人，所以

10
00:00:38,000 --> 00:00:39,320
这就是他本周离开的原因，

11
00:00:39,320 --> 00:00:40,969
但这真的是

12
00:00:40,969 --> 00:00:43,850
为了给他买礼物的诡计，所以他下周会回来的，

13
00:00:43,850 --> 00:00:45,920
所以再次

14
00:00:45,920 --> 00:00:47,300
提醒你有什么事情

15
00:00:47,300 --> 00:00:50,239
要做 伙计们作业 5 下周到期

16
00:00:50,239 --> 00:00:53,269
项目 4 我们在此之后做的，

17
00:00:53,269 --> 00:00:55,129
反馈提交的额外功劳是

18
00:00:55,129 --> 00:00:56,690
昨晚

19
00:00:56,690 --> 00:00:59,089
有些人通过电子邮件发送关于错误的邮件，

20
00:00:59,089 --> 00:01:02,239
因为一些时髦的 Unicode 问题，但

21
00:01:02,239 --> 00:01:04,400
其他人应该提交

22
00:01:04,400 --> 00:01:06,580
期末考试实际上是在 12 月 9 日

23
00:01:06,580 --> 00:01:08,510
他们宣布了房间，但我

24
00:01:08,510 --> 00:01:10,340
已经看了看

25
00:01:10,340 --> 00:01:12,890
有人看过它的位置没关系

26
00:01:12,890 --> 00:01:16,070
我们会弄清楚然后

27
00:01:16,070 --> 00:01:17,900
下周再次甲骨文谈话将

28
00:01:17,900 --> 00:01:20,630
在星期一举行，助手 popery 和 t

29
00:01:20,630 --> 00:01:23,750
最终审查将在周三进行，

30
00:01:23,750 --> 00:01:25,310
因此我们将在开始时进行最终审查

31
00:01:25,310 --> 00:01:28,009
，然后我们将涵盖

32
00:01:28,009 --> 00:01:29,270


33
00:01:29,270 --> 00:01:31,430
你们投票的三到四个不同的数据库系统，我会

34
00:01:31,430 --> 00:01:32,750
告诉你们 用 10 分钟

35
00:01:32,750 --> 00:01:34,670
时间讨论你的有趣之处

36
00:01:34,670 --> 00:01:36,350
为什么它好 为什么它不好等等

37
00:01:36,350 --> 00:01:37,969
所以如果你还没有投票，

38
00:01:37,969 --> 00:01:40,939
请到这里投票 数字

39
00:01:40,939 --> 00:01:45,649
看起来与往年相似啊 所以

40
00:01:45,649 --> 00:01:47,299
你可以再去看看视频

41
00:01:47,299 --> 00:01:48,020
去年看看我们要讨论什么，

42
00:01:48,020 --> 00:01:50,509
但先投票然后再查

43
00:01:50,509 --> 00:01:53,420
一下，正如我在下周一周二说的，

44
00:01:53,420 --> 00:01:54,710
我们的朋友，我们的甲骨文

45
00:01:54,710 --> 00:01:57,049
要来了，

46
00:01:57,049 --> 00:01:59,840
所以周一的课上会有三场不同的演讲

47
00:01:59,840 --> 00:02:03,229
他们会让 Shashank

48
00:02:03,229 --> 00:02:05,450
来谈论你知道

49
00:02:05,450 --> 00:02:07,310
他的团队正在建设的东西

50
00:02:07,310 --> 00:02:08,930
这不是招聘演讲 这

51
00:02:08,930 --> 00:02:11,270
就像你

52
00:02:11,270 --> 00:02:13,670
知道他们正在建设的东西的科学或助理讨论

53
00:02:13,670 --> 00:02:15,410
基本上他会使用 所有

54
00:02:15,410 --> 00:02:16,760
相同的关键词和 b 我整个学期都在使用的流行语，所以

55
00:02:16,760 --> 00:02:18,170


56
00:02:18,170 --> 00:02:19,800
你意识到，我

57
00:02:19,800 --> 00:02:22,410
不是不确定，所以他会来

58
00:02:22,410 --> 00:02:23,700
谈论他们的系统 有一个更多

59
00:02:23,700 --> 00:02:25,980
面向招聘的系统谈话将在

60
00:02:25,980 --> 00:02:28,770
周一 4:30 在大门 那

61
00:02:28,770 --> 00:02:30,780
将是比萨饼，然后

62
00:02:30,780 --> 00:02:33,360


63
00:02:33,360 --> 00:02:35,520
在第二天的 12 月 3 日星期二中午 12 点进行一次纯粹的研究谈话 和

64
00:02:35,520 --> 00:02:38,870
CICU 楼层，所以 Hideaki Kimura

65
00:02:38,870 --> 00:02:42,570
就像我在 Piazza 上提到的那样 我

66
00:02:42,570 --> 00:02:46,110
和他一起读了研究生 我他可能是我一生中遇到

67
00:02:46,110 --> 00:02:48,900
的最铁杆的系统程序员

68
00:02:48,900 --> 00:02:50,970
之一 他也是

69
00:02:50,970 --> 00:02:52,290
我见过的最固执的人 我的

70
00:02:52,290 --> 00:02:56,100
生活，当我们在第

71
00:02:56,100 --> 00:02:58,230
一个夏天建造 H 商店时，他

72
00:02:58,230 --> 00:03:00,210
希望我们必须建立表达式

73
00:03:00,210 --> 00:03:02,310
树，例如 where 子句我有

74
00:03:02,310 --> 00:03:04,110
我的方式他有他的方式我们

75
00:03:04,110 --> 00:03:05,730
实际上进行了四个小时的辩论 我的

76
00:03:05,730 --> 00:03:07,050
办公室只是大喊大叫

77
00:03:07,050 --> 00:03:08,280
要做什么，他只是让我失望，

78
00:03:08,280 --> 00:03:10,800
说他错了，我们

79
00:03:10,800 --> 00:03:12,390
把他后来做的事情脱掉了，我的外套

80
00:03:12,390 --> 00:03:14,520
还在那里，所以我是对的，但

81
00:03:14,520 --> 00:03:16,440
总的来说他很棒，所以他会来

82
00:03:16,440 --> 00:03:19,020
谈谈 关于一些他只是来谈谈

83
00:03:19,020 --> 00:03:20,340


84
00:03:20,340 --> 00:03:21,660
他们一直在为系统工作的非易失性存储器的东西，

85
00:03:21,660 --> 00:03:23,520
因为他是 shashank 小组的一员，

86
00:03:23,520 --> 00:03:24,530
所以如果你有兴趣与他们一起

87
00:03:24,530 --> 00:03:27,000
实习或全职职位，

88
00:03:27,000 --> 00:03:27,390


89
00:03:27,390 --> 00:03:29,040
他会来的 告诉你那种

90
00:03:29,040 --> 00:03:30,750
薄 gs你可以工作得很好，

91
00:03:30,750 --> 00:03:32,820
我会提醒你

92
00:03:32,820 --> 00:03:35,250
关于广场上的所有这些事情以及关于这些事情的

93
00:03:35,250 --> 00:03:38,970
任何问题，然后我也会

94
00:03:38,970 --> 00:03:39,870
安排你如果你想一对一地吃这些家伙

95
00:03:39,870 --> 00:03:42,360
谈论实习和

96
00:03:42,360 --> 00:03:43,980
也有全职职位 我会

97
00:03:43,980 --> 00:03:47,760
发送那封电子邮件 好的 所以最后一节课是

98
00:03:47,760 --> 00:03:49,680
我们关于分布式数据库的第二堂课

99
00:03:49,680 --> 00:03:51,450
第一节课只是

100
00:03:51,450 --> 00:03:53,040


101
00:03:53,040 --> 00:03:54,390
从架构的角度定义分布式数据库系统的样子

102
00:03:54,390 --> 00:03:56,400
你知道什么是

103
00:03:56,400 --> 00:03:58,970
数据相关的 到计算机

104
00:03:58,970 --> 00:04:00,840
混淆的地方实际上会在它上面运行，

105
00:04:00,840 --> 00:04:02,730
然后上一堂课是

106
00:04:02,730 --> 00:04:04,830
关于在您想要进行交易时进行这些到 Stata 基地的旅行，

107
00:04:04,830 --> 00:04:06,180
并

108
00:04:06,180 --> 00:04:09,060
确保我们

109
00:04:09,060 --> 00:04:11,070
在单个节点上提供我们想要的所有资产保证

110
00:04:11,070 --> 00:04:12,720
系统，但现在在分布式环境中执行此操作，

111
00:04:12,720 --> 00:04:14,730


112
00:04:14,730 --> 00:04:16,470
我们大部分时间都在讨论

113
00:04:16,470 --> 00:04:17,760
关于复制的原子提交协议，

114
00:04:17,760 --> 00:04:19,620
因为这又是

115
00:04:19,620 --> 00:04:20,730
您遇到问题的应用程序的难点

116
00:04:20,730 --> 00:04:22,350
当事情被拆分并且现在您

117
00:04:22,350 --> 00:04:23,730
在

118
00:04:23,730 --> 00:04:24,780
一堆不同的节点上

119
00:04:24,780 --> 00:04:27,120
同时拥有事务处理权限时，您的数据库的数据如何保持同步

120
00:04:27,120 --> 00:04:28,680
如何避免丢失数据如何

121
00:04:28,680 --> 00:04:30,870
读取如果您看不到过时的数据

122
00:04:30,870 --> 00:04:33,630
关心这些事情，所以今天的

123
00:04:33,630 --> 00:04:35,610
课程现在我们要整理一下，

124
00:04:35,610 --> 00:04:39,090
不要管，或者你知道留下

125
00:04:39,090 --> 00:04:40,140
我们之前和现在谈论的所有交易内容

126
00:04:40,140 --> 00:04:42,060
，所以我正在谈论如何

127
00:04:42,060 --> 00:04:43,920
在我们没有做很多事情的情况下进行分析 的

128
00:04:43,920 --> 00:04:45,390
权利，我们不做交易，

129
00:04:45,390 --> 00:04:48,150
我们主要是做读取，

130
00:04:48,150 --> 00:04:49,140
但我们要

131
00:04:49,140 --> 00:04:52,650
读取的数据量比上一堂课的旧交易要大得多，

132
00:04:52,650 --> 00:04:54,360


133
00:04:54,360 --> 00:04:57,890
所以我想展示什么 一种

134
00:04:57,890 --> 00:05:00,960
典型的设置是在分析

135
00:05:00,960 --> 00:05:02,220
数据库中，这

136
00:05:02,220 --> 00:05:04,140
不一定是分布式

137
00:05:04,140 --> 00:05:05,640
数据库，但这是一种常见的

138
00:05:05,640 --> 00:05:07,980
安排，因此在前端，您可以使用

139
00:05:07,980 --> 00:05:09,930
旧的数据库，这

140
00:05:09,930 --> 00:05:11,190
就是您的地方 '正在摄取新信息

141
00:05:11,190 --> 00:05:14,220
fr  om 外部世界，这可能是

142
00:05:14,220 --> 00:05:15,330
分布式的 可能是单注

143
00:05:15,330 --> 00:05:17,370
没关系 然后您希望将

144
00:05:17,370 --> 00:05:18,870
这些前端数据

145
00:05:18,870 --> 00:05:21,210
孤岛中的所有数据放入您的后端分析

146
00:05:21,210 --> 00:05:22,920
数据库中，有时称为数据

147
00:05:22,920 --> 00:05:26,430
仓库，所以有这个过程 称为

148
00:05:26,430 --> 00:05:28,650
ETL 提取转换负载，

149
00:05:28,650 --> 00:05:30,570
因此您可以购买工具来

150
00:05:30,570 --> 00:05:32,160
执行此操作，我们只编写 Python 脚本或

151
00:05:32,160 --> 00:05:34,140
手动执行任何操作，但其想法

152
00:05:34,140 --> 00:05:36,210
是从这些

153
00:05:36,210 --> 00:05:38,100
不同的前端 OTP 数据库中获取所有数据

154
00:05:38,100 --> 00:05:41,970
并将其放入

155
00:05:41,970 --> 00:05:44,430
数据仓库中的通用模式，例如，

156
00:05:44,430 --> 00:05:47,040
假设您有一个应用程序的前端数据库

157
00:05:47,040 --> 00:05:48,600
，您知道它们

158
00:05:48,600 --> 00:05:50,760
都有不同的客户名称，但这个应用程序

159
00:05:50,760 --> 00:05:52,650
的第一个名称有 FM 这个

160
00:05:52,650 --> 00:05:55,170
第一个下划线名称，因此您可以“

161
00:05:55,170 --> 00:05:56,430
不要只是将所有这些都放入一个

162
00:05:56,430 --> 00:05:57,720
数据库中，因为数据库不

163
00:05:57,720 --> 00:05:59,820
知道 F 名称等于名字，所以

164
00:05:59,820 --> 00:06:01,140
这是您

165
00:06:01,140 --> 00:06:04,710
在 ETL 世界中执行清理过程的地方，所以这是

166
00:06:04,710 --> 00:06:06,600
一个非常常见的集合 如果

167
00:06:06,600 --> 00:06:08,610
你要建立一个初创公司，你

168
00:06:08,610 --> 00:06:10,140
通常会从这个开始，因为你

169
00:06:10,140 --> 00:06:12,240
需要先获取数据，然后一旦你

170
00:06:12,240 --> 00:06:13,830
有很多数据，你就想把

171
00:06:13,830 --> 00:06:15,870
它放到你的后端数据仓库中

172
00:06:15,870 --> 00:06:17,040
我们的想法是，我们不想

173
00:06:17,040 --> 00:06:18,090
在前端进行分析，因为

174
00:06:18,090 --> 00:06:19,680
这会减慢我们的速度或减慢

175
00:06:19,680 --> 00:06:21,330
我们的交易速度，因此您可以将其

176
00:06:21,330 --> 00:06:23,310
放入我们的后端数据仓库，这

177
00:06:23,310 --> 00:06:24,570
就是我们今天关注的重点

178
00:06:24,570 --> 00:06:29,820
我们是否真的这样做了，所以我使用术语

179
00:06:29,820 --> 00:06:32,430
OLAP 在线和本地处理

180
00:06:32,430 --> 00:06:34,410
有时你会看到这些类型的

181
00:06:34,410 --> 00:06:35,850
系统被称为数据仓库

182
00:06:35,850 --> 00:06:37,770
或更传统地有时他们

183
00:06:37,770 --> 00:06:40,500
称之为决策支持系统 DSS

184
00:06:40,500 --> 00:06:42,650
再次的想法是这些是

185
00:06:42,650 --> 00:06:45,419
我们现在要

186
00:06:45,419 --> 00:06:47,580
在后端 dip 数据仓库中使用的应用程序

187
00:06:47,580 --> 00:06:51,270
它将分析

188
00:06:51,270 --> 00:06:53,430
我们从 OTP 端保留的数据 推断

189
00:06:53,430 --> 00:06:55,770
新信息，然后指导我们

190
00:06:55,770 --> 00:06:57,990
为组织的业务制定决策流程

191
00:06:57,990 --> 00:06:59,670
或为

192
00:06:59,670 --> 00:07:02,310
旧的分配是正确的，所以非常

193
00:07:02,310 --> 00:07:04,080
常见的设置是他们一直

194
00:07:04,080 --> 00:07:06,690
喜欢使用的，就像 zinga

195
00:07:06,690 --> 00:07:08,460
zinga 把他们所有愚蠢的 Farmville 游戏都放在了这里，

196
00:07:08,460 --> 00:07:09,870
这些都是旧

197
00:07:09,870 --> 00:07:11,580
的游戏中每个派系的数据库，这是

198
00:07:11,580 --> 00:07:12,990
另一笔交易 或对数据库进行另一次更新

199
00:07:12,990 --> 00:07:14,790
，然后将

200
00:07:14,790 --> 00:07:18,090
所有这些点击推入后端数据

201
00:07:18,090 --> 00:07:21,060
仓库，对此进行一些分析，

202
00:07:21,060 --> 00:07:22,680
无论是您的决策支持系统还是

203
00:07:22,680 --> 00:07:24,330
机器学习，以试图找出

204
00:07:24,330 --> 00:07:25,440
一些关于如何让您购买

205
00:07:25,440 --> 00:07:28,470
更多东西的废话 前端

206
00:07:28,470 --> 00:07:31,430
就像我一直听到的一个例子一样，

207
00:07:31,430 --> 00:07:34,380
如果你

208
00:07:34,380 --> 00:07:36,450
玩糖果粉碎游戏，那么它就是糖果粉碎游戏，所以你

209
00:07:36,450 --> 00:07:38,700
在 OTP 方面获得所有这些更新，然后

210
00:07:38,700 --> 00:07:40,500
这是一个难题，你

211
00:07:40,500 --> 00:07:42,600
无法击败 这是对的，所以你

212
00:07:42,600 --> 00:07:44,340
放下游戏，所以他们会收集所有

213
00:07:44,340 --> 00:07:45,720
这些点击流来看看你

214
00:07:45,720 --> 00:07:47,820
是如何玩游戏的，然后他们会知道哦，

215
00:07:47,820 --> 00:07:50,220
如果你在一天没玩游戏后回来，

216
00:07:50,220 --> 00:07:51,720
因为你 得到了

217
00:07:51,720 --> 00:07:53,490
沮丧他们确保你他们给

218
00:07:53,490 --> 00:07:54,900
你一个简单的谜题，你可以

219
00:07:54,900 --> 00:07:57,150
马上解决，所以你再次被迷住

220
00:07:57,150 --> 00:07:58,380
，然后继续玩它，因为他们

221
00:07:58,380 --> 00:07:59,340
知道如果他们给你一个困难的谜题，

222
00:07:59,340 --> 00:08:00,600
你会感到沮丧，永远不会

223
00:08:00,600 --> 00:08:01,340
再回来了。

224
00:08:01,340 --> 00:08:03,990
以便推断该

225
00:08:03,990 --> 00:08:05,610
信息，哦，这就是我如何让

226
00:08:05,610 --> 00:08:07,980
您知道您认识游戏的人，

227
00:08:07,980 --> 00:08:09,540
他们将能够击败您

228
00:08:09,540 --> 00:08:12,030
在这一方面弄清楚，然后您将

229
00:08:12,030 --> 00:08:17,520
更新推送到 OTP 方面，因此通常

230
00:08:17,520 --> 00:08:19,170
在 高层次 有两种不同的方法

231
00:08:19,170 --> 00:08:23,370
可以在后端数据仓库或分析数据库上对数据库应用程序建模，

232
00:08:23,370 --> 00:08:24,960


233
00:08:24,960 --> 00:08:27,240
因此您可以采用

234
00:08:27,240 --> 00:08:29,880
您知道应用程序

235
00:08:29,880 --> 00:08:31,230
将具有的标准架构，通常它通常是

236
00:08:31,230 --> 00:08:32,130
树架构，因为您有这个

237
00:08:32,130 --> 00:08:33,929
层次结构我有 客户 客户

238
00:08:33,929 --> 00:08:37,770
有订单 订单有项目，但这些

239
00:08:37,770 --> 00:08:39,360
模式可能非常混乱，而且它们

240
00:08:39,360 --> 00:08:41,010
对于分析查询的效率不会很高，

241
00:08:41,010 --> 00:08:44,490
因此您可以

242
00:08:44,490 --> 00:08:46,080
使用 eit 对数据库进行建模 她

243
00:08:46,080 --> 00:08:47,460
所谓的星型模式或雪花

244
00:08:47,460 --> 00:08:49,560
模式，有时你会看到分析

245
00:08:49,560 --> 00:08:52,170
数据库，他们会说嘿我们只

246
00:08:52,170 --> 00:08:53,940
支持星型模式你不能做

247
00:08:53,940 --> 00:08:55,980
雪花模式你会看到这

248
00:08:55,980 --> 00:08:58,290
基本上是这个的一个子集，但你明白

249
00:08:58,290 --> 00:09:00,360
为什么 让我们讨论一下为什么这种匹配

250
00:09:00,360 --> 00:09:01,270
可能对它更好

251
00:09:01,270 --> 00:09:06,670
一些分析 所以一个非常常见的

252
00:09:06,670 --> 00:09:08,560
安排是这样的

253
00:09:08,560 --> 00:09:10,720
所以这是一个星型模式 星型模式中

254
00:09:10,720 --> 00:09:12,040
有两种类型的表

255
00:09:12,040 --> 00:09:13,450
你有事实表和

256
00:09:13,450 --> 00:09:15,370
维度表 所以中间

257
00:09:15,370 --> 00:09:17,950
明星是事实表 想想这

258
00:09:17,950 --> 00:09:19,930
就像你试图建模的每个城市事件

259
00:09:19,930 --> 00:09:22,120
这是你存储所有

260
00:09:22,120 --> 00:09:23,830
事件的地方 所以如果你像

261
00:09:23,830 --> 00:09:26,620
沃尔玛一样，你的数据仓库会

262
00:09:26,620 --> 00:09:28,330
跟踪 emam 的每一个项目 我

263
00:09:28,330 --> 00:09:30,670
没有人在任何特定时间在任何沃尔玛购买过

264
00:09:30,670 --> 00:09:32,620
所有

265
00:09:32,620 --> 00:09:34,330
这些物品都在现金

266
00:09:34,330 --> 00:09:36,670
支票或结账柜台进行扫描，这

267
00:09:36,670 --> 00:09:38,290
是我们已放入事实表的另一个事件，

268
00:09:38,290 --> 00:09:40,510
因此这件事将成为 mas

269
00:09:40,510 --> 00:09:42,580
就像数千亿条记录

270
00:09:42,580 --> 00:09:44,560
亚马逊一样

271
00:09:44,560 --> 00:09:46,270
任何人在亚马逊上购买过的每件商品都

272
00:09:46,270 --> 00:09:48,280
在您的事实表中，但我们

273
00:09:48,280 --> 00:09:50,200
实际上不会存储

274
00:09:50,200 --> 00:09:51,910
有关这些商品是什么的任何信息，有人

275
00:09:51,910 --> 00:09:54,130
不会购买 坚持并拥有

276
00:09:54,130 --> 00:09:57,690
对我们的外部维度表的外键引用

277
00:09:57,690 --> 00:09:59,650
，他们将在其中维护

278
00:09:59,650 --> 00:10:02,230
附加信息，因为

279
00:10:02,230 --> 00:10:04,120
这是我们庞大的事情，我们

280
00:10:04,120 --> 00:10:06,850
希望尽可能地修剪它，

281
00:10:06,850 --> 00:10:08,830
因为我们有数十亿行，所以我们

282
00:10:08,830 --> 00:10:10,630
把所有的 维度表中的实际元数据，

283
00:10:10,630 --> 00:10:12,820
但

284
00:10:12,820 --> 00:10:15,910
在星型模式中很少见，您只能

285
00:10:15,910 --> 00:10:18,070
从星形右侧的中心拥有一个一级维度表，

286
00:10:18,070 --> 00:10:21,310


287
00:10:21,310 --> 00:10:23,170
因此这里没有其他表

288
00:10:23,170 --> 00:10:25,510
可供这些人加入

289
00:10:25,510 --> 00:10:27,040
在这种情况下，我有一个

290
00:10:27,040 --> 00:10:29,830
名为类别描述的类别，因此我可以将其

291
00:10:29,830 --> 00:10:31,720
提取出来并规范化该

292
00:10:31,720 --> 00:10:33,220
存储，该存储具有另一个维度表

293
00:10:33,220 --> 00:10:34,480
，另一个外键来自该维度表

294
00:10:34,480 --> 00:10:37,030
对此，但在星型模式下，

295
00:10:37,030 --> 00:10:38,560
您知道您不允许这样做

296
00:10:38,560 --> 00:10:48,160
，我们猜测为什么是这样，

297
00:10:48,160 --> 00:10:49,540
所以您说

298
00:10:49,540 --> 00:10:52,210
多样化或加入这些不同表

299
00:10:52,210 --> 00:10:53,800
所花费的时间将是昂贵的，因为再次

300
00:10:53,800 --> 00:10:55,870
我们并没有像我们所说的那样精细和轻松

301
00:10:55,870 --> 00:10:56,350


302
00:10:56,350 --> 00:10:59,500
的项目找到

303
00:10:59,500 --> 00:11:01,240
您知道宾夕法尼亚州

304
00:11:01,240 --> 00:11:03,400
在此日期范围内购买的所有项目可能

305
00:11:03,400 --> 00:11:05,770
只有数亿行，因此

306
00:11:05,770 --> 00:11:08,110
我们希望避免尽可能多的 做

307
00:11:08,110 --> 00:11:11,380
尽可能多的连接，所以雪花

308
00:11:11,380 --> 00:11:12,760
模式是允许你在

309
00:11:12,760 --> 00:11:13,560


310
00:11:13,560 --> 00:11:15,720
它之外有多个维度的地方，所以再次

311
00:11:15,720 --> 00:11:18,029
回到这里我现在可以打破

312
00:11:18,029 --> 00:11:19,620
我的类别信息我

313
00:11:19,620 --> 00:11:21,029
在产品维度中有一个外键 表，

314
00:11:21,029 --> 00:11:22,830
然后我现在有一个查找

315
00:11:22,830 --> 00:11:25,380
表，它是提到表之外的东西

316
00:11:25,380 --> 00:11:27,170
，我将

317
00:11:27,170 --> 00:11:29,930
标准化信息作为输出，

318
00:11:29,930 --> 00:11:33,750
正如我所说的一些数据库系统，一些

319
00:11:33,750 --> 00:11:35,580
OLAP 系统会明确地说你

320
00:11:35,580 --> 00:11:37,710
不能有厕所 k-up 表你不能

321
00:11:37,710 --> 00:11:39,450
在第一个维度表之外有多个级别，

322
00:11:39,450 --> 00:11:45,089
所以

323
00:11:45,089 --> 00:11:46,920
这个世界上的两个主要问题，正如她

324
00:11:46,920 --> 00:11:49,350
所说，其中一个是性能，

325
00:11:49,350 --> 00:11:51,570
另一个实际上

326
00:11:51,570 --> 00:11:53,430
是完整性

327
00:11:53,430 --> 00:11:58,110
再次存储的数据，所以如果

328
00:11:58,110 --> 00:12:00,180
我将查找表折叠成一个

329
00:12:00,180 --> 00:12:01,920
单一的维度表，那么返回这里我将

330
00:12:01,920 --> 00:12:03,660
一遍又一遍地重复类别名称，

331
00:12:03,660 --> 00:12:06,089
所以现在如果类别名称

332
00:12:06,089 --> 00:12:07,710
发生变化，我需要确保 我的

333
00:12:07,710 --> 00:12:10,529
应用程序代码会更新所有

334
00:12:10,529 --> 00:12:12,029
具有相同类别名称的记录，

335
00:12:12,029 --> 00:12:13,920
这样如果

336
00:12:13,920 --> 00:12:16,380
我在雪花模式中像这样标准化，一切都会同步

337
00:12:16,380 --> 00:12:17,400
我没有这个

338
00:12:17,400 --> 00:12:18,660
问题，因为我没有一个

339
00:12:18,660 --> 00:12:22,730
条目 类别正确，因此如果您使用

340
00:12:22,730 --> 00:12:24,839
星型模式，那么

341
00:12:24,839 --> 00:12:26,460
您必须在应用程序中执行这项额外工作以

342
00:12:26,460 --> 00:12:29,160
确保您的非规范化

343
00:12:29,160 --> 00:12:32,339
表是一致的，您现在

344
00:12:32,339 --> 00:12:34,020
实际上可能存储更多

345
00:12:34,020 --> 00:12:35,490
不必要的冗余信息，

346
00:12:35,490 --> 00:12:37,770
并且 o 你的数据库可能

347
00:12:37,770 --> 00:12:39,810
更大，这没什么大不了的，

348
00:12:39,810 --> 00:12:41,790
因为事实表是主要

349
00:12:41,790 --> 00:12:44,430
的，在这个模型中是主要的主宰

350
00:12:44,430 --> 00:12:47,400
，我们将有办法压缩

351
00:12:47,400 --> 00:12:50,190
它，因此

352
00:12:50,190 --> 00:12:52,140
非规范化表的存储开销是 没什么

353
00:12:52,140 --> 00:12:53,820
大不了的，更重要的是完整性的东西

354
00:12:53,820 --> 00:12:55,710
，然后正如她

355
00:12:55,710 --> 00:12:58,830
所说，

356
00:12:58,830 --> 00:13:02,430
星型模式查询的复杂性将大大低于雪花模式中

357
00:13:02,430 --> 00:13:04,170
查询的复杂性，

358
00:13:04,170 --> 00:13:06,420
因为

359
00:13:06,420 --> 00:13:09,209
只有这么多连接我 可能我

360
00:13:09,209 --> 00:13:11,120
只需要

361
00:13:11,120 --> 00:13:13,050
像我们讨论的那样深入一层，我们讨论了一个

362
00:13:13,050 --> 00:13:15,570
夸脱应用程序，当我们必须弄清楚联合排序时，拥有更多的

363
00:13:15,570 --> 00:13:17,310
表或加入反对只会让

364
00:13:17,310 --> 00:13:18,720
一切变得更加困难

365
00:13:18,720 --> 00:13:21,420
，因此通过

366
00:13:21,420 --> 00:13:23,040
限制自己 到星型模式，

367
00:13:23,040 --> 00:13:25,320
但最终可能会找到最佳

368
00:13:25,320 --> 00:13:27,240
计划，而雪花模式

369
00:13:27,240 --> 00:13:31,290
，

370
00:13:31,290 --> 00:13:32,519
当您在现实世界中

371
00:13:32,519 --> 00:13:33,959
遇到数据仓库时，我们可能无法再次这样做 您可能会

372
00:13:33,959 --> 00:13:36,929
看到这两种方法中的任何一种，因为

373
00:13:36,929 --> 00:13:39,360
它们更适合分析，

374
00:13:39,360 --> 00:13:42,389
而维度

375
00:13:42,389 --> 00:13:43,829
表和事实表之间的这种区别将

376
00:13:43,829 --> 00:13:45,569
在我们开始讨论连接时出现，

377
00:13:45,569 --> 00:13:47,639
因为我们需要决定我们

378
00:13:47,639 --> 00:13:50,040
将如何进行 如果我们

379
00:13:50,040 --> 00:13:51,839
不能进行任何本地连接，则在节点之间移动数据 一个城镇的

380
00:13:51,839 --> 00:13:56,579
机器没问题所以让我们

381
00:13:56,579 --> 00:13:57,329
谈谈我们今天试图解决的问题

382
00:13:57,329 --> 00:14:00,959
，我刚才已经简单地

383
00:14:00,959 --> 00:14:02,850
提到过，所以我们的查询

384
00:14:02,850 --> 00:14:04,230
出现在 一个想要加入我们 NS 的主节点，假设

385
00:14:04,230 --> 00:14:07,920


386
00:14:07,920 --> 00:14:10,829
两个表 R 和 s 只是均匀地

387
00:14:10,829 --> 00:14:12,119
分布在不同节点上的不同分区上，

388
00:14:12,119 --> 00:14:16,139
那么在此设置

389
00:14:16,139 --> 00:14:17,550
中执行此查询的最愚蠢的方法

390
00:14:17,550 --> 00:14:29,069
是什么是完全正确的

391
00:14:29,069 --> 00:14:31,019
我能做的最愚蠢的事情，它

392
00:14:31,019 --> 00:14:32,339
会起作用，它仍然是正确的

393
00:14:32,339 --> 00:14:34,529
，我知道我需要触摸数据集

394
00:14:34,529 --> 00:14:36,420
分区二三和四，所以我

395
00:14:36,420 --> 00:14:38,819
只是将它们全部复制到

396
00:14:38,819 --> 00:14:41,100
分区一所在的节点中 现在

397
00:14:41,100 --> 00:14:43,499
我所有的数据都是本地的 我做我的关节并

398
00:14:43,499 --> 00:14:47,329
吐出结果 为什么那个愚蠢

399
00:14:47,329 --> 00:14:51,959
是的 他说我你可能不需要所有的

400
00:14:51,959 --> 00:14:54,299
数据

401
00:14:54,299 --> 00:15:00,720


402
00:15:00,720 --> 00:15:01,949


403
00:15:01,949 --> 00:15:04,199
这样就违背了

404
00:15:04,199 --> 00:15:06,420
让你的愚蠢数据库一切正常的全部目的

405
00:15:06,420 --> 00:15:07,589
想想我做了什么我买了

406
00:15:07,589 --> 00:15:09,420
一堆机器我

407
00:15:09,420 --> 00:15:11,249
在这些机器上划分我在桌子上的日期但是然后我的

408
00:15:11,249 --> 00:15:12,779
查询出现了我只是把东西复制

409
00:15:12,779 --> 00:15:14,429
回唱歌

410
00:15:14,429 --> 00:15:16,259
无论如何，我敢打赌，最好

411
00:15:16,259 --> 00:15:17,939
只购买这台机器并在

412
00:15:17,939 --> 00:15:21,660
那里进行连接，这就是

413
00:15:21,660 --> 00:15:22,649
我们今天要解决的问题，

414
00:15:22,649 --> 00:15:24,569
如果出现查询

415
00:15:24,569 --> 00:15:26,129
并且它想要 要进行连接，我们

416
00:15:26,129 --> 00:15:27,689
需要访问现在跨多个资源放置的数据

417
00:15:27,689 --> 00:15:30,929


418
00:15:30,929 --> 00:15:31,980
我们如何实际操作 如何有效地执行此

419
00:15:31,980 --> 00:15:33,389
操作 我们要做什么

420
00:15:33,389 --> 00:15:36,089
我们在决定是移动数据

421
00:15:36,089 --> 00:15:38,549
还是复制数据或推送查询时需要注意什么 或拉

422
00:15:38,549 --> 00:15:40,769
你知道把结果拉出来

423
00:15:40,769 --> 00:15:41,500
这些都是

424
00:15:41,500 --> 00:15:43,300
我们必须处理的威胁 这

425
00:15:43,300 --> 00:15:45,250
在这个例子中也假设我的

426
00:15:45,250 --> 00:15:46,780
数据库可以放在一个

427
00:15:46,780 --> 00:15:49,630
节点上 再次想想像

428
00:15:49,630 --> 00:15:51,670
沃尔玛数据库它是

429
00:15:51,670 --> 00:15:53,680
数百 PB 它不适合一

430
00:15:53,680 --> 00:15:55,720
台机器，所以我们会运行

431
00:15:55,720 --> 00:15:57,040
属性环境以

432
00:15:57,040 --> 00:15:58,500
完成任何工作

433
00:15:58,500 --> 00:16:00,790
OTP 这对孩子们来说又不是问题

434
00:16:00,790 --> 00:16:03,340
哦 OTP 我只接触 andis 数据，

435
00:16:03,340 --> 00:16:05,950
E 的数据可能是几百个

436
00:16:05,950 --> 00:16:09,100
千字节或兆字节，这不是我

437
00:16:09,100 --> 00:16:10,870
可以轻松地将它放在一个盒子上，

438
00:16:10,870 --> 00:16:12,460
并在分析中的那个盒子上完成我的所有交易

439
00:16:12,460 --> 00:16:14,890
我试图触摸

440
00:16:14,890 --> 00:16:16,600
整个桌子或桌子的大部分

441
00:16:16,600 --> 00:16:18,370
我将无法

442
00:16:18,370 --> 00:16:21,130
在单个节点上做所有事情，所以今天我们的

443
00:16:21,130 --> 00:16:22,510
重点将首先讨论

444
00:16:22,510 --> 00:16:24,460
我们在

445
00:16:24,460 --> 00:16:25,870
分布式数据库系统中用于

446
00:16:25,870 --> 00:16:26,410
分析的模型的借口

447
00:16:26,410 --> 00:16:27,940
我们已经

448
00:16:27,940 --> 00:16:29,260
在第一讲中简要介绍了这一点，但现在

449
00:16:29,260 --> 00:16:30,910
我们将  更具体地谈谈

450
00:16:30,910 --> 00:16:32,710
它，看看它为什么重要 然后让我们

451
00:16:32,710 --> 00:16:34,240
简要谈谈做

452
00:16:34,240 --> 00:16:35,950
查询计划的问题 然后我们将谈谈

453
00:16:35,950 --> 00:16:38,050
我们如何进行分布式连接 剧

454
00:16:38,050 --> 00:16:39,520
透是我们

455
00:16:39,520 --> 00:16:40,780
在学期早期谈论的所有算法

456
00:16:40,780 --> 00:16:42,550
仍然存在 剩下的我们仍然在做

457
00:16:42,550 --> 00:16:44,890
，没有神奇的分布式连接

458
00:16:44,890 --> 00:16:47,680
在单个节点上不存在它

459
00:16:47,680 --> 00:16:48,940
只是问题再次是我们在哪里移动

460
00:16:48,940 --> 00:16:51,250
数据或我们在哪里

461
00:16:51,250 --> 00:16:53,170
移动计算然后我将

462
00:16:53,170 --> 00:16:56,080
完成排序 快速了解

463
00:16:56,080 --> 00:16:57,370


464
00:16:57,370 --> 00:16:59,730
当今世界上这种最先进的云数据库是什么样的

465
00:16:59,730 --> 00:17:03,310
，只要您再次了解它，您就会

466
00:17:03,310 --> 00:17:05,140
看到如何仅仅因为它在云

467
00:17:05,140 --> 00:17:06,760
中并不意味着我们仍然不关心

468
00:17:06,760 --> 00:17:08,050
我们整个学期讨论的所有事情

469
00:17:08,050 --> 00:17:12,099
都可以，所以正如我

470
00:17:12,099 --> 00:17:13,689
所说的，我简要地谈到

471
00:17:13,689 --> 00:17:16,510
了执行模型的第一个问题，或者当我们

472
00:17:16,510 --> 00:17:18,160
谈到了分布式数据库的介绍时，

473
00:17:18,160 --> 00:17:22,480
但是

474
00:17:22,480 --> 00:17:23,980
我们有两种方法 执行

475
00:17:23,980 --> 00:17:27,880
查询要么是推送要么是池，

476
00:17:27,880 --> 00:17:30,310
所以推送的想法是我们希望

477
00:17:30,310 --> 00:17:32,860
将查询或查询的一部分（

478
00:17:32,860 --> 00:17:35,590
如计划片段）发送到

479
00:17:35,590 --> 00:17:38,410
数据所在的位置，

480
00:17:38,410 --> 00:17:40,780
然后运行该部分

481
00:17:40,780 --> 00:17:44,260
对该本地数据的查询，然后现在只需将

482
00:17:44,260 --> 00:17:46,390
结果发送回请求它的人，

483
00:17:46,390 --> 00:17:49,150
例如主节点或

484
00:17:49,150 --> 00:17:52,600
协调查询的基本注释这里的想法

485
00:17:52,600 --> 00:17:55,419
是我们想要就像

486
00:17:55,419 --> 00:17:57,879
我们做投影下推或谓词下推一样

487
00:17:57,879 --> 00:18:00,009
在单节点系统上，我们

488
00:18:00,009 --> 00:18:02,289
希望在通过网络发送任何内容之前尽可能早地过滤掉并删除尽可能多的

489
00:18:02,289 --> 00:18:06,279
无用数据，

490
00:18:06,279 --> 00:18:08,950
因此如果

491
00:18:08,950 --> 00:18:10,359
我们可以将查询的一部分发送到

492
00:18:10,359 --> 00:18:12,940
数据所在的位置，那么

493
00:18:12,940 --> 00:18:14,649
就尽早做一些 过滤，然后

494
00:18:14,649 --> 00:18:15,969
当我们将数据传输回

495
00:18:15,969 --> 00:18:17,979
另一个节点时，我们不仅仅是盲目地

496
00:18:17,979 --> 00:18:20,229
复制该节点拥有的所有数据，

497
00:18:20,229 --> 00:18:22,359
我们只是将其限制为

498
00:18:22,359 --> 00:18:23,709
我们实际需要的

499
00:18:23,709 --> 00:18:27,549
特定查询的子集，现在我们将看到 一

500
00:18:27,549 --> 00:18:30,159
秒钟 线条变得模糊，我

501
00:18:30,159 --> 00:18:31,450
分享了这个系统，无论你是在做

502
00:18:31,450 --> 00:18:32,649
一个还是另一个，因为在

503
00:18:32,649 --> 00:18:34,869
与系统的共享距离中，你

504
00:18:34,869 --> 00:18:36,369
不能做任何过滤，因为它

505
00:18:36,369 --> 00:18:37,989
只是你知道读写一个

506
00:18:37,989 --> 00:18:40,599
你不能的页面 做任何特别的事情，但

507
00:18:40,599 --> 00:18:42,669
对于共享磁盘系统，线条再次

508
00:18:42,669 --> 00:18:45,369
变得模糊，另一种方法是

509
00:18:45,369 --> 00:18:46,779
在查询中提取数据，这就是

510
00:18:46,779 --> 00:18:49,289
我共享这个系统通常会做的事情

511
00:18:49,289 --> 00:18:52,450
，我们获取我们实际需要的任何数据，我们

512
00:18:52,450 --> 00:18:54,070


513
00:18:54,070 --> 00:18:57,039
基于此查询识别 查询计划你知道这些

514
00:18:57,039 --> 00:18:58,989
是我想要访问的页面我们

515
00:18:58,989 --> 00:19:00,519
提取数据制作它的副本

516
00:19:00,519 --> 00:19:02,139
通过网络传输将它带到

517
00:19:02,139 --> 00:19:04,089
我们查询所在的节点

518
00:19:04,089 --> 00:19:05,940
然后我们可以处理它并处理

519
00:19:05,940 --> 00:19:08,289
它当然 再次，这里的问题

520
00:19:08,289 --> 00:19:11,379
是，在分析系统中

521
00:19:11,379 --> 00:19:13,779
，数据量与查询的大小相关的数据量

522
00:19:13,779 --> 00:19:15,579


523
00:19:15,579 --> 00:19:17,889
将非常饥饿等同于

524
00:19:17,889 --> 00:19:19,959
不同的查询，说它只是一个

525
00:19:19,959 --> 00:19:23,440
续集查询耦合

526
00:19:23,440 --> 00:19:26,249
我从谷歌或 Facebook 那里听到的最多的千字节

527
00:19:26,249 --> 00:19:28,269
是，有时他们的

528
00:19:28,269 --> 00:19:29,409
查询就像续集

529
00:19:29,409 --> 00:19:31,859
文本本身就像 10 兆字节一样

530
00:19:31,859 --> 00:19:34,299
，这是一个很大的查询，但

531
00:19:34,299 --> 00:19:36,219
与读取 1 TB

532
00:19:36,219 --> 00:19:39,519
的数据相比仍然如此 没什么，所以我们

533
00:19:39,519 --> 00:19:40,749
必须注意的是，无论您想要

534
00:19:40,749 --> 00:19:42,190
一个还是另一个，您都

535
00:19:42,190 --> 00:19:43,899
知道数据位于何处，我如何访问它，

536
00:19:43,899 --> 00:19:45,940
以及我的查询大小会更大或

537
00:19:45,940 --> 00:19:48,759
更小以通过

538
00:19:48,759 --> 00:19:50,079
网络传输然后是数据 我正在尝试

539
00:19:50,079 --> 00:19:52,570
访问并且在分析中

540
00:19:52,570 --> 00:19:54,009
总是这样你试图处理的数据

541
00:19:54,009 --> 00:19:57,039
更大所以让我们

542
00:19:57,039 --> 00:19:59,109
在无共享系统的上下文中看到这一点

543
00:19:59,109 --> 00:20:00,940
所以无共享系统

544
00:20:00,940 --> 00:20:03,249
通常是推送数据来推送数据

545
00:20:03,249 --> 00:20:05,589
查询节点所以我的查询在这里显示到这个

546
00:20:05,589 --> 00:20:07,179
节点它负责

547
00:20:07,179 --> 00:20:09,309
与另一个节点协调

548
00:20:09,309 --> 00:20:11,740
处理连接所以我们要做我们的

549
00:20:11,740 --> 00:20:15,249
查询计划器我想在这个节点上说

550
00:20:15,249 --> 00:20:16,990
如果我们已经认识到哦我们需要

551
00:20:16,990 --> 00:20:20,889
访问我们 NS 表的 ID 字段

552
00:20:20,889 --> 00:20:23,289
，我知道这里的这个节点

553
00:20:23,289 --> 00:20:26,019
有一个我想访问的分区，

554
00:20:26,019 --> 00:20:27,879
所以我只发送信息

555
00:20:27,879 --> 00:20:30,039
我将查询计划片段发送

556
00:20:30,039 --> 00:20:31,960
给这个人并说嘿我知道 您拥有

557
00:20:31,960 --> 00:20:34,960
101 和 201 之间的这些数据 chievous

558
00:20:34,960 --> 00:20:36,999
join 然后将结果发回给我

559
00:20:36,999 --> 00:20:39,669
，上面的节点负责

560
00:20:39,669 --> 00:20:42,009
获取这个人发送

561
00:20:42,009 --> 00:20:44,710
的结果加上它的本地结果将它们组合

562
00:20:44,710 --> 00:20:46,450
在一起然后产生一个唱歌结果

563
00:20:46,450 --> 00:20:49,179
返回给应用程序 所以我们再次遇到了

564
00:20:49,179 --> 00:20:50,950
这个透明度问题或透明度

565
00:20:50,950 --> 00:20:53,619
保证，其中应用程序不

566
00:20:53,619 --> 00:20:55,779
知道并不关心查询

567
00:20:55,779 --> 00:20:56,710
实际执行的位置，

568
00:20:56,710 --> 00:21:02,019
只要它返回单个结果，因此

569
00:21:02,019 --> 00:21:03,639
在无共享系统中很

570
00:21:03,639 --> 00:21:05,919
明显你想要做 推动

571
00:21:05,919 --> 00:21:07,149
数据的勇气，因为这

572
00:21:07,149 --> 00:21:08,379
对我们来说实际上

573
00:21:08,379 --> 00:21:09,940
必须复制这些数据并在

574
00:21:09,940 --> 00:21:11,919
那里处理它没有任何意义，只是发送

575
00:21:11,919 --> 00:21:15,129
查询在本地进行处理这个

576
00:21:15,129 --> 00:21:16,419
例子我们会看到一些 sc  enarios 那里

577
00:21:16,419 --> 00:21:21,840
也许您确实想做一些复制 是的，

578
00:21:22,860 --> 00:21:24,999
您的问题是如果 s 也是

579
00:21:24,999 --> 00:21:27,730
分布式的，那么在

580
00:21:27,730 --> 00:21:29,230
这种情况下它是分布式的怎么样 我只是

581
00:21:29,230 --> 00:21:30,850
说它只是分区，但它的分区

582
00:21:30,850 --> 00:21:31,570


583
00:21:31,570 --> 00:21:33,820
对您的问题很常见

584
00:21:33,820 --> 00:21:39,009
稍后我们将讨论正确的内容

585
00:21:39,009 --> 00:21:40,809
，在这个简单的示例中，

586
00:21:40,809 --> 00:21:43,570
假设 R 和 s 都是 IDE 上

587
00:21:43,570 --> 00:21:46,600
的分区，此分区的值范围

588
00:21:46,600 --> 00:21:48,429
完全相同，

589
00:21:48,429 --> 00:21:49,899
因此我知道何时进行联合

590
00:21:49,899 --> 00:21:51,820
在这个节点上，我不需要查看集群中的任何

591
00:21:51,820 --> 00:21:54,009
其他分区，

592
00:21:54,009 --> 00:21:55,960
我需要

593
00:21:55,960 --> 00:22:00,240
在 R 中拥有单个元组的计算机节点的所有东西都位于此处，

594
00:22:00,240 --> 00:22:02,350
但是是的，完全正确，我正在加入

595
00:22:02,350 --> 00:22:03,700
分区键，请参阅中的那些

596
00:22:03,700 --> 00:22:07,559
场景 第二个是的

597
00:22:14,169 --> 00:22:18,500
问题，问题是在我的例子中，我的

598
00:22:18,500 --> 00:22:21,080
表在我的联合键上分区，

599
00:22:21,080 --> 00:22:22,669
这是最好的情况

600
00:22:22,669 --> 00:22:30,860
，对于事实表，这种情况发生的频率通常是多少，

601
00:22:30,860 --> 00:22:36,340
就像我

602
00:22:36,970 --> 00:22:40,549
会说的，这很常见，让我

603
00:22:40,549 --> 00:22:42,169
想想 就像在一个真实的系统中

604
00:22:42,169 --> 00:22:44,500
一样，所以我想分区我

605
00:22:44,500 --> 00:22:49,970
根据用户 ID 进行分区，你知道

606
00:22:49,970 --> 00:22:52,340
事实表可以说这是这个

607
00:22:52,340 --> 00:22:57,409
人买了这个项目，所以这是一个

608
00:22:57,409 --> 00:23:00,110
不好的例子，所以说我想

609
00:23:00,110 --> 00:23:02,510
在像这里这样的之间进行连接 这是用户 ID

610
00:23:02,510 --> 00:23:03,860
，这是他们购买的所有物品，然后是

611
00:23:03,860 --> 00:23:05,809


612
00:23:05,809 --> 00:23:08,539
他们如何访问网页的会话，只是为了

613
00:23:08,539 --> 00:23:09,769
弄清楚我在购买某些东西之前看过哪些物品

614
00:23:09,769 --> 00:23:11,059
任何人

615
00:23:11,059 --> 00:23:13,220
都想弄清楚，如果他们去

616
00:23:13,220 --> 00:23:15,320
看看 这么多项目，他们

617
00:23:15,320 --> 00:23:17,000
更有可能买东西，所以在

618
00:23:17,000 --> 00:23:18,470
这种情况下，用户 ID 将是

619
00:23:18,470 --> 00:23:19,580
分区键，这会

620
00:23:19,580 --> 00:23:21,350
很好地解决问题，所以情况并非总是如此，但我

621
00:23:21,350 --> 00:23:23,360
会说它很常见，但我们会

622
00:23:23,360 --> 00:23:24,620
看到 第二，我们如何处理

623
00:23:24,620 --> 00:23:27,049
不是这样的情况，我

624
00:23:27,049 --> 00:23:29,630
在这里强调的主要内容是我们可以将查询推

625
00:23:29,630 --> 00:23:32,690
送到数据，这对我们更好，

626
00:23:32,690 --> 00:23:34,490
因为这个数据会

627
00:23:34,490 --> 00:23:36,769
比这里的这个人大，而且我们

628
00:23:36,769 --> 00:23:38,450
也可以 得到 额外的好处

629
00:23:38,450 --> 00:23:39,889
是我们使计算瘫痪，

630
00:23:39,889 --> 00:23:41,899
因为现在顶部节点

631
00:23:41,899 --> 00:23:44,269
不必全部加入这个人可以做加入你

632
00:23:44,269 --> 00:23:45,649
知道的部分加入这个人可以

633
00:23:45,649 --> 00:23:46,940
做另一部分的加入我们

634
00:23:46,940 --> 00:23:48,139
只是把它

635
00:23:48,139 --> 00:23:50,149
组合在一起 部分更便宜 它

636
00:23:50,149 --> 00:23:54,980
相对于联合成本便宜 所以另

637
00:23:54,980 --> 00:23:56,450
一种方法是将数据再次池化到

638
00:23:56,450 --> 00:23:57,980
查询中 这是我

639
00:23:57,980 --> 00:23:59,389
在共享磁盘系统中所说的线条

640
00:23:59,389 --> 00:24:02,750
模糊 所以我们将查询发送到这个

641
00:24:02,750 --> 00:24:05,240
节点 这里这个节点 会认识到

642
00:24:05,240 --> 00:24:07,279
我们已经对数据进行了逻辑分区，

643
00:24:07,279 --> 00:24:08,899
使得这里的这个节点

644
00:24:08,899 --> 00:24:11,240
负责这个范围，那个节点在

645
00:24:11,240 --> 00:24:13,909
那个范围之上，然后他们

646
00:24:13,909 --> 00:24:17,360
去共享磁盘去访问那些

647
00:24:17,360 --> 00:24:20,270
页面拉回结果或者拉

648
00:24:20,270 --> 00:24:22,160
回来 他们需要的页面

649
00:24:22,160 --> 00:24:23,930
，他们计算他们的本地连接，

650
00:24:23,930 --> 00:24:26,570
然后这个人将结果显示给

651
00:24:26,570 --> 00:24:30,140
另一个人，所以这里的这一步会再次

652
00:24:30,140 --> 00:24:34,370
将数据拉到查询中，因为

653
00:24:34,370 --> 00:24:35,990
我只是盲目地询问

654
00:24:35,990 --> 00:24:37,910
它所在的页面 重新，我必须将它复制

655
00:24:37,910 --> 00:24:39,890
到这里，但当然这部分

656
00:24:39,890 --> 00:24:41,780
是将查询推送到数据，

657
00:24:41,780 --> 00:24:43,760
因为这个人能够知道

658
00:24:43,760 --> 00:24:45,650
在本地计算连接并发送

659
00:24:45,650 --> 00:24:46,310
结果，

660
00:24:46,310 --> 00:24:49,160
所以你会说这是一个池还是一个池

661
00:24:49,160 --> 00:24:55,520
再推一下，很好

662
00:24:55,520 --> 00:25:00,140
看，我不认为我有

663
00:25:00,140 --> 00:25:03,770
关于这个的幻灯片，但是云供应商

664
00:25:03,770 --> 00:25:06,500
意识到有一个哑盘，如果

665
00:25:06,500 --> 00:25:07,910
你想称它为

666
00:25:07,910 --> 00:25:09,920
Indy 共享只是数据库是一个坏主意，

667
00:25:09,920 --> 00:25:11,720
因为我再次 我只是总是复制

668
00:25:11,720 --> 00:25:13,880
这个页面而不检查

669
00:25:13,880 --> 00:25:15,110
是否真的需要结束页面上的日期

670
00:25:15,110 --> 00:25:16,790
我只知道我认为我

671
00:25:16,790 --> 00:25:18,170
需要查看它所以我只是说去给我

672
00:25:18,170 --> 00:25:20,510
这个页面就像 Amazon s3 他们现在

673
00:25:20,510 --> 00:25:22,070
有一个过滤器 命令，您实际上可以在其中

674
00:25:22,070 --> 00:25:24,380
执行谓词下推，甚至当

675
00:25:24,380 --> 00:25:25,850
您说去获取此页面时，您也可以

676
00:25:25,850 --> 00:25:27,740
说像 oh 但它还会

677
00:25:27,740 --> 00:25:28,850
为我检查此过滤器以查看

678
00:25:28,850 --> 00:25:30,740
页面内的所有内容是否实际匹配，如果

679
00:25:30,740 --> 00:25:33,220
是，则将其发送给我，如果 不，那就不要

680
00:25:33,220 --> 00:25:35,900
再写了，这是在推动 对数据的查询

681
00:25:35,900 --> 00:25:38,870
再次模糊了线条，

682
00:25:38,870 --> 00:25:45,080
所以我们谈论的一件事

683
00:25:45,080 --> 00:25:48,950
是我说上一堂课我们

684
00:25:48,950 --> 00:25:52,610
做了一件大事，如果我们有一个

685
00:25:52,610 --> 00:25:54,500
事务提交并且它涉及

686
00:25:54,500 --> 00:25:56,810
多个节点我想确保

687
00:25:56,810 --> 00:25:58,730
每个人 同意所有节点都

688
00:25:58,730 --> 00:25:59,990
必须同意

689
00:25:59,990 --> 00:26:02,030
在向外界零售之前允许此事务提交

690
00:26:02,030 --> 00:26:04,190
然后它提交没

691
00:26:04,190 --> 00:26:05,060
问题因为因为我们正在

692
00:26:05,060 --> 00:26:06,410
修改数据库我们不想丢失任何

693
00:26:06,410 --> 00:26:10,430
更改但在 OLAP 数据库中很奇怪

694
00:26:10,430 --> 00:26:13,730
进行只读查询，因此我们并不

695
00:26:13,730 --> 00:26:15,830
真正担心

696
00:26:15,830 --> 00:26:16,940
将数据状态更新到多个位置

697
00:26:16,940 --> 00:26:18,680
并保持同步，但现在我们

698
00:26:18,680 --> 00:26:20,420
必须处理在处理查询时节点可能崩溃的情况，

699
00:26:20,420 --> 00:26:22,190


700
00:26:22,190 --> 00:26:24,050
以及 我们必须弄清楚如何

701
00:26:24,050 --> 00:26:27,350
处理，所以要理解的重要一点

702
00:26:27,350 --> 00:26:29,840
是，当我们

703
00:26:29,840 --> 00:26:32,570
从另一台机器或共享

704
00:26:32,570 --> 00:26:34,760
磁盘请求数据时，我们会得到该数据的副本

705
00:26:34,760 --> 00:26:35,660


706
00:26:35,660 --> 00:26:37,340
存储在

707
00:26:37,340 --> 00:26:39,260
缓冲池中，就像

708
00:26:39,260 --> 00:26:42,020
我们从磁盘读取的任何其他数据一样，但它

709
00:26:42,020 --> 00:26:44,240
存储在一个临时的临时

710
00:26:44,240 --> 00:26:47,750
缓冲区空间中，这意味着它可能会

711
00:26:47,750 --> 00:26:49,790
因为空间不足而对磁盘进行分页，但是

712
00:26:49,790 --> 00:26:51,800
如果我们崩溃或重新启动

713
00:26:51,800 --> 00:26:54,140
系统 备份所有临时置换的

714
00:26:54,140 --> 00:26:55,280
磁盘都被吹走了，

715
00:26:55,280 --> 00:26:57,770
因为受保护的查询或事务

716
00:26:57,770 --> 00:26:58,820


717
00:26:58,820 --> 00:27:01,280
正在运行的查询需要该数据

718
00:27:01,280 --> 00:27:03,560
现在消失了，因为我崩溃了，所以我

719
00:27:03,560 --> 00:27:05,500
不需要保留任何东西，

720
00:27:05,500 --> 00:27:10,130
所以这些 OLAP 查询 对于真正的大型

721
00:27:10,130 --> 00:27:13,970
数据库可能需要很长时间，

722
00:27:13,970 --> 00:27:15,860
查询可能

723
00:27:15,860 --> 00:27:18,530
需要数小时的情况并非闻所未闻 我也听说过

724
00:27:18,530 --> 00:27:22,850
列存储需要数天的查询，这

725
00:27:22,850 --> 00:27:24,140
已经变得更好了，但在过去，

726
00:27:24,140 --> 00:27:26,180
这当然很

727
00:27:26,180 --> 00:27:28,370
常见 一个季度需要几天的时间，就像

728
00:27:28,370 --> 00:27:29,870
您希望每月运行一次报告

729
00:27:29,870 --> 00:27:33,230
一样，需要一个星期才能运行它，所以如果我们

730
00:27:33,230 --> 00:27:34,610
有这个长时间运行的查询并且我们的节点

731
00:27:34,610 --> 00:27:38,090
崩溃了我们应该怎么做，这不是

732
00:27:38,090 --> 00:27:39,200
正确的 起诉，因为我们没有

733
00:27:39,200 --> 00:27:41,150
更新任何东西，但最好是好的

734
00:27:41,150 --> 00:27:43,430
，如果这需要几天时间，我们可能不必

735
00:27:43,430 --> 00:27:44,600
从头开始重新启动整个过程，

736
00:27:44,600 --> 00:27:50,990
因此

737
00:27:50,990 --> 00:27:54,370
大多数无共享

738
00:27:54,370 --> 00:27:56,960
分布式数据库做出的设计决定是

739
00:27:56,960 --> 00:27:59,060
它们不是 实际上会支持查询

740
00:27:59,060 --> 00:28:01,370
容错，这意味着如果您的

741
00:28:01,370 --> 00:28:03,380
长时间运行的查询崩溃，如果一个节点

742
00:28:03,380 --> 00:28:04,820
在您的查询运行期间崩溃，

743
00:28:04,820 --> 00:28:06,560
除非有一个包含

744
00:28:06,560 --> 00:28:09,980
您需要的数据的副本，您是否知道

745
00:28:09,980 --> 00:28:11,330
根据您在查询中的位置填写一些缺失的部分

746
00:28:11,330 --> 00:28:13,220
计划他们只是

747
00:28:13,220 --> 00:28:15,080
要中止查询并返回一个

748
00:28:15,080 --> 00:28:18,160
错误并告诉您重新启动它

749
00:28:18,160 --> 00:28:20,240
我们猜测他们为什么做出这个

750
00:28:20,240 --> 00:28:22,690
决定

751
00:28:25,530 --> 00:28:27,270
它很昂贵对我

752
00:28:27,270 --> 00:28:29,400
在查询中运行了很长时间它开始产生

753
00:28:29,400 --> 00:28:31,800
一堆敌人 结果，现在我必须

754
00:28:31,800 --> 00:28:33,330
确保我完全刷新它们以

755
00:28:33,330 --> 00:28:34,350
安装磁盘并确保

756
00:28:34,350 --> 00:28:35,700
跨副本具有持久性，以防万一

757
00:28:35,700 --> 00:28:38,700
发生崩溃会使您的

758
00:28:38,700 --> 00:28:39,780
查询运行得更慢，因为 t 他的

759
00:28:39,780 --> 00:28:44,000
磁盘非常慢，所以

760
00:28:44,000 --> 00:28:46,260
在这种传统的数据

761
00:28:46,260 --> 00:28:48,420
仓库世界中，他们会说哦，你

762
00:28:48,420 --> 00:28:50,880
只需要付我一千万美元来购买

763
00:28:50,880 --> 00:28:52,110
这个非常昂贵的数据库系统

764
00:28:52,110 --> 00:28:54,150
软件，我假设你没有在

765
00:28:54,150 --> 00:28:56,400
你在 Goodwill I 找到的机器上运行 我

766
00:28:56,400 --> 00:28:57,330
假设您购买的是高端

767
00:28:57,330 --> 00:28:59,280
硬件，那么

768
00:28:59,280 --> 00:29:00,210
高端港口的心脏可能会发生

769
00:29:00,210 --> 00:29:02,040
灾难性故障，您知道它

770
00:29:02,040 --> 00:29:03,470
会在查询过程中崩溃的可能性

771
00:29:03,470 --> 00:29:06,120
会很低，因此我宁愿不

772
00:29:06,120 --> 00:29:08,940
付钱 在我运行时拍摄快照

773
00:29:08,940 --> 00:29:11,610
或向我写入有关磁盘的结果的惩罚，

774
00:29:11,610 --> 00:29:16,020
所以一般来说

775
00:29:16,020 --> 00:29:18,240
，如果查询 Fano

776
00:29:18,240 --> 00:29:20,970
在 Cori 执行期间崩溃，系统将会这样做，并且

777
00:29:20,970 --> 00:29:22,590
假设它不仅仅是从

778
00:29:22,590 --> 00:29:23,940
您拥有副本的磁盘读取 就像

779
00:29:23,940 --> 00:29:25,470
它是查询的中间部分，

780
00:29:25,470 --> 00:29:27,300
我们有敌人的结果，你说

781
00:29:27,300 --> 00:29:31,140
查询失败是当 Hadoop 在

782
00:29:31,140 --> 00:29:33,780
2000 年代中期问世时，他们实际上正在拍摄

783
00:29:33,780 --> 00:29:35,130
快照，他们实际上正在拍摄你

784
00:29:35,130 --> 00:29:37,020
知道的每一次写作 查询计划的 ep 将其

785
00:29:37,020 --> 00:29:38,970
写出磁盘，但这

786
00:29:38,970 --> 00:29:41,480
使它变得非常慢，因为

787
00:29:41,480 --> 00:29:44,580
它在过去甚至

788
00:29:44,580 --> 00:29:47,010
现在仍然存在，但就像谷歌正在

789
00:29:47,010 --> 00:29:48,750
构建他们谈论的

790
00:29:48,750 --> 00:29:51,210
在你知道便宜的硬件上运行的产品一样，如果你知道便宜的硬件在哪里

791
00:29:51,210 --> 00:29:52,500
'正在运行一千个节点

792
00:29:52,500 --> 00:29:54,330
集群并且您的查询在

793
00:29:54,330 --> 00:29:55,470
1,000 个节点上运行

794
00:29:55,470 --> 00:29:56,910
在那段时间内任何笔记崩溃的可能性都

795
00:29:56,910 --> 00:29:58,920
非常高，所以他们很好，他们

796
00:29:58,920 --> 00:30:00,270
宁愿拍摄快照以避免

797
00:30:00,270 --> 00:30:11,010
这种情况是的，我们不是那么多 事务

798
00:30:11,010 --> 00:30:13,860
在这里只读查询分析

799
00:30:13,860 --> 00:30:19,260
查询，所以如果它是

800
00:30:19,260 --> 00:30:20,190
从我上一堂课中说的

801
00:30:20,190 --> 00:30:21,600


802
00:30:21,600 --> 00:30:24,330
如果一个节点失败

803
00:30:24,330 --> 00:30:27,420
，那么当我们退出事务时，我们

804
00:30:27,420 --> 00:30:29,130
只是中止该事务，因为谁

805
00:30:29,130 --> 00:30:31,020
在乎该事务 什么运行了

806
00:30:31,020 --> 00:30:34,770
50 毫秒 谁在乎现在我是否有

807
00:30:34,770 --> 00:30:36,150
分析

808
00:30:36,150 --> 00:30:38,640
如果需要五天才能运行它需要几天

809
00:30:38,640 --> 00:30:39,470
才能运行 我

810
00:30:39,470 --> 00:30:40,940
第四天哭了晚上的浪费

811
00:30:40,940 --> 00:30:42,950
四天的工作实际上有些人会为此感到

812
00:30:42,950 --> 00:30:44,000
生气，因为现在

813
00:30:44,000 --> 00:30:45,500
您必须知道启动它并

814
00:30:45,500 --> 00:30:48,350
重新运行，因此您可以

815
00:30:48,350 --> 00:30:49,940
拍摄快照 有些系统允许

816
00:30:49,940 --> 00:30:51,770
您在 oleg 上运行查询时拍摄快照

817
00:30:51,770 --> 00:30:53,990
一个查询计划的输出

818
00:30:53,990 --> 00:30:56,059
被输入到下一个操作符中，我也将

819
00:30:56,059 --> 00:30:57,470
所有这些都写到磁盘上，

820
00:30:57,470 --> 00:30:59,120
这样如果我在那个时候崩溃，我可以

821
00:30:59,120 --> 00:31:00,830
把它带回来，有一些方法可以打开它

822
00:31:00,830 --> 00:31:02,799
，但默认情况下大多数系统都这样做 不是

823
00:31:02,799 --> 00:31:04,280
因为他们不想支付

824
00:31:04,280 --> 00:31:07,970
性能损失开销所以再次

825
00:31:07,970 --> 00:31:09,530
在共享您的系统上很

826
00:31:09,530 --> 00:31:11,059
容易可视化并且我们正在执行

827
00:31:11,059 --> 00:31:12,799
相同的连接我们将计划时间发送到

828
00:31:12,799 --> 00:31:15,110
这里然后在它计算连接

829
00:31:15,110 --> 00:31:17,030
结果时 它将把它写到

830
00:31:17,030 --> 00:31:20,059
共享磁盘 有一些通知

831
00:31:20,059 --> 00:31:21,860
给协调员说嘿 如果你正在

832
00:31:21,860 --> 00:31:24,200
寻找这个连接结果 这里是

833
00:31:24,200 --> 00:31:25,580
去共享磁盘

834
00:31:25,580 --> 00:31:27,620
上的地方 那样这家伙崩溃然后

835
00:31:27,620 --> 00:31:29,390
离开 这家伙知道他 可以拉它

836
00:31:29,390 --> 00:31:31,429
从那里开始，不用担心你

837
00:31:31,429 --> 00:31:36,110
知道如何阅读好的东西，所以

838
00:31:36,110 --> 00:31:37,820
这又是一个重要的设计

839
00:31:37,820 --> 00:31:39,140
决策，分布式 Avis

840
00:31:39,140 --> 00:31:41,840
将在那里实现它们

841
00:31:41,840 --> 00:31:43,880
不会为你提供有时称为

842
00:31:43,880 --> 00:31:46,220
查询弹性或容错的东西

843
00:31:46,220 --> 00:31:47,240
，其中 查询执行，

844
00:31:47,240 --> 00:31:50,360
他们可能会为您重新启动查询，但

845
00:31:50,360 --> 00:31:52,370
他们不会尝试获取崩溃

846
00:31:52,370 --> 00:31:54,590
时在米勒运行的节点的位置，

847
00:31:54,590 --> 00:32:01,340
好吧，所以

848
00:32:01,340 --> 00:32:02,990
您现在要担心的另一件事也是有

849
00:32:02,990 --> 00:32:06,470
新的查询计划，所以 我们

850
00:32:06,470 --> 00:32:08,240
在加入排序之前遇到了所有相同的问题

851
00:32:08,240 --> 00:32:09,890
如何进行谓词下推

852
00:32:09,890 --> 00:32:11,750
或预测所有

853
00:32:11,750 --> 00:32:13,760
我们必须在单节点系统上做的相同决策

854
00:32:13,760 --> 00:32:15,530
我们必须在分布式

855
00:32:15,530 --> 00:32:17,570
系统中做但现在我们有一定的额外

856
00:32:17,570 --> 00:32:20,270
级别 规划我们需要在

857
00:32:20,270 --> 00:32:23,179
哪里推理我们的数据所在的位置

858
00:32:23,179 --> 00:32:25,309
如何分区或复制，

859
00:32:25,309 --> 00:32:28,130
现在考虑我们算法的网络

860
00:32:28,130 --> 00:32:33,280
通信成本

861
00:32:33,760 --> 00:32:35,990
，这更有意义，

862
00:32:35,990 --> 00:32:37,070
因为 第二，当我们谈论不同的

863
00:32:37,070 --> 00:32:40,190
场景时，但就像联合排序

864
00:32:40,190 --> 00:32:42,740
仍然很重要，但现在它也

865
00:32:42,740 --> 00:32:44,179
很好，我需要它我应该先加入

866
00:32:44,179 --> 00:32:46,190
这两个表，因为它们

867
00:32:46,190 --> 00:32:47,960
在同一个节点上，分区以相同的

868
00:32:47,960 --> 00:32:49,070
方式，因此可以 非常

869
00:32:49,070 --> 00:32:51,649
快，即使我在单个

870
00:32:51,649 --> 00:32:52,789
节点上，我可能不想先加入这两个

871
00:32:52,789 --> 00:32:53,149
选项卡，

872
00:32:53,149 --> 00:32:55,969
以便现在可以将其包含在

873
00:32:55,969 --> 00:32:57,469
您的成本模型中，让您帮助我

874
00:32:57,469 --> 00:32:57,979
再次决定

875
00:32:57,979 --> 00:33:00,440
此查询计划最正确的是什么

876
00:33:00,440 --> 00:33:01,999


877
00:33:01,999 --> 00:33:04,999
再次为系统优化查询计划，正如我

878
00:33:04,999 --> 00:33:07,399
在对单个音符进行查询优化之前所说的那样

879
00:33:07,399 --> 00:33:09,049
很难，这

880
00:33:09,049 --> 00:33:16,729
更难，就像我们知道的那样，

881
00:33:16,729 --> 00:33:17,989
有时您可以在单个节点上做出决定，有时您可以

882
00:33:17,989 --> 00:33:19,399
将位置集中

883
00:33:19,399 --> 00:33:20,479
可以让它

884
00:33:20,479 --> 00:33:22,609
分布在所有节点上，但现在

885
00:33:22,609 --> 00:33:24,559
又一次，你必须确保

886
00:33:24,559 --> 00:33:25,879
你的所有统计数据和所有节点

887
00:33:25,879 --> 00:33:27,649
都尽可能地更新，以帮助

888
00:33:27,649 --> 00:33:29,149
你做出关于什么的决定 t

889
00:33:29,149 --> 00:33:31,190
plan 可能只是

890
00:33:31,190 --> 00:33:33,489
当它分布式时一切都变得更加困难，

891
00:33:33,489 --> 00:33:37,729
但现在以同样的方式，我们现在有了一个查询

892
00:33:37,729 --> 00:33:40,369
计划，我们实际上想要将什么发送到

893
00:33:40,369 --> 00:33:42,109


894
00:33:42,109 --> 00:33:43,609
将参与执行

895
00:33:43,609 --> 00:33:46,759
联合查询的不同节点，所以有两个 方法

896
00:33:46,759 --> 00:33:49,099
之一是我们实际上可以将

897
00:33:49,099 --> 00:33:53,779
物理计划或计划片段发送到

898
00:33:53,779 --> 00:33:57,440
节点以供它执行，只需采用

899
00:33:57,440 --> 00:33:58,969


900
00:33:58,969 --> 00:34:00,379
我们在主节点的基本注释上生成的查询计划

901
00:34:00,379 --> 00:34:02,179
，然后将其分割为 好吧，

902
00:34:02,179 --> 00:34:03,649
我知道查询计划的这一部分

903
00:34:03,649 --> 00:34:05,509
需要在此节点上执行

904
00:34:05,509 --> 00:34:06,859
查询计划程序

905
00:34:06,859 --> 00:34:08,329
实际上需要在该节点上执行的另一部分 您只需将

906
00:34:08,329 --> 00:34:09,918
这些物理运算符共享给其他

907
00:34:09,918 --> 00:34:11,750
节点，他们只需将它们取出并

908
00:34:11,750 --> 00:34:12,918
立即执行它们，而

909
00:34:12,918 --> 00:34:14,659
无需考虑这是否是

910
00:34:14,659 --> 00:34:17,179
对本地数据做的最好的事情，然后

911
00:34:17,179 --> 00:34:20,089
发回结果，据

912
00:34:20,089 --> 00:34:23,539
他们所知，大多数

913
00:34:23,539 --> 00:34:25,159
正在进行分析的 ribbity 数据库都

914
00:34:25,159 --> 00:34:27,799
很好地完成了第一种方法 te

915
00:34:27,799 --> 00:34:29,059
通过优化器运行查询计划一次

916
00:34:29,059 --> 00:34:31,129
为查询生成整个集群的全局计划，

917
00:34:31,129 --> 00:34:33,799
然后将其

918
00:34:33,799 --> 00:34:37,089
分成两个计划片段并将其划分

919
00:34:37,089 --> 00:34:40,909
另一种方法是实际采用

920
00:34:40,909 --> 00:34:43,489
进来的 Seco 查询，然后将

921
00:34:43,489 --> 00:34:46,309
其重写为 让它在每个分区的

922
00:34:46,309 --> 00:34:48,679
基础上对每个单独的分区进行 C 查询

923
00:34:48,679 --> 00:34:52,010
，然后将其发送出去，然后

924
00:34:52,010 --> 00:34:54,199
当分区所在的节点获取该

925
00:34:54,199 --> 00:34:55,429


926
00:34:55,429 --> 00:34:57,200
后续查询时，它会通过

927
00:34:57,200 --> 00:34:59,480
自己的查询优化器运行它以生成

928
00:34:59,480 --> 00:35:01,630
它想要执行的物理计划

929
00:35:01,630 --> 00:35:05,370
的想法是，

930
00:35:05,370 --> 00:35:08,550
如果我们可以假设如果我们

931
00:35:08,550 --> 00:35:11,220
在单个节点上执行全局计划，那么

932
00:35:11,220 --> 00:35:12,930
关于每个分区最好的统计信息和信息

933
00:35:12,930 --> 00:35:15,570


934
00:35:15,570 --> 00:35:18,480
将不会是最新的，或者你知道 或

935
00:35:18,480 --> 00:35:20,850
新鲜，因此而不是我

936
00:35:20,850 --> 00:35:23,340
试图在我的主节点上推理

937
00:35:23,340 --> 00:35:24,690
在这个其他节点上做什么最好的事情，

938
00:35:24,690 --> 00:35:26,640
我只会对这个其他节点说

939
00:35:26,640 --> 00:35:28,560


940
00:35:28,560 --> 00:35:30,120
对我进行此查询，

941
00:35:30,120 --> 00:35:32,550
然后该节点可以在该心理查询到达时执行所有

942
00:35:32,550 --> 00:35:34,080
本地优化和所有本地

943
00:35:34,080 --> 00:35:37,760
规划，

944
00:35:37,760 --> 00:35:40,950
因此再次查看示例here，这是

945
00:35:40,950 --> 00:35:44,400
我的查询，因此我可以在

946
00:35:44,400 --> 00:35:45,600
这种情况下，您知道有

947
00:35:45,600 --> 00:35:49,470
没有联合气味啊，它

948
00:35:49,470 --> 00:35:51,630
是 RS 或 SR，但我只是说好吧，

949
00:35:51,630 --> 00:35:53,160
我知道我实际上查询并

950
00:35:53,160 --> 00:35:54,690
需要这三个分区的此类数据，

951
00:35:54,690 --> 00:35:57,780
因此我将重写我的续集语句，

952
00:35:57,780 --> 00:35:59,520
现在包含一个 where 子句，说明

953
00:35:59,520 --> 00:36:01,920
这里是这里的

954
00:36:01,920 --> 00:36:03,870
您需要查看

955
00:36:03,870 --> 00:36:05,520
与分区键或

956
00:36:05,520 --> 00:36:08,490
分区范围匹配的数据部分，然后节点获取

957
00:36:08,490 --> 00:36:10,050
此信息，每个节点

958
00:36:10,050 --> 00:36:11,730
通过

959
00:36:11,730 --> 00:36:13,140
其自己的优化器获取这些单独的查询计划，然后他们可以

960
00:36:13,140 --> 00:36:15,660
根据数据做出决定 我在这里

961
00:36:15,660 --> 00:36:17,730
是加入我们的比 SRS 更好然后

962
00:36:17,730 --> 00:36:19,920
我们关闭你一个散列连接所以做一个排序

963
00:36:19,920 --> 00:36:22,290
合并连接我可以在这里做出本地决定

964
00:36:22,290 --> 00:36:23,940
因为我可以最好地了解

965
00:36:23,940 --> 00:36:25,200
我实际存储的日期在

966
00:36:25,200 --> 00:36:27,210
哪里 s 主节点可能再次

967
00:36:27,210 --> 00:36:33,810
过时，所以唯一的数据库

968
00:36:33,810 --> 00:36:34,740
，我知道，

969
00:36:34,740 --> 00:36:36,150
实际上做这样的事情是

970
00:36:36,150 --> 00:36:40,260
mem 续集，每个人都

971
00:36:40,260 --> 00:36:44,160
发送物理计划我不是我的意思

972
00:36:44,160 --> 00:36:45,630
对我来说这似乎令人信服 你

973
00:36:45,630 --> 00:36:47,400
可以做到这一点我认为你仍然需要

974
00:36:47,400 --> 00:36:49,890
对可能的连接顺序做出更高级别的决定，

975
00:36:49,890 --> 00:36:52,650
你知道如果你

976
00:36:52,650 --> 00:36:54,300
有两个以上的表，比如

977
00:36:54,300 --> 00:36:56,970
I 5r s 和 T 我应该

978
00:36:56,970 --> 00:36:59,250
像我认为的那样首先加入 RNs 或 TNS

979
00:36:59,250 --> 00:37:00,540
那里有一些信息，你可能

980
00:37:00,540 --> 00:37:02,370
在上层有理由，

981
00:37:02,370 --> 00:37:04,770
但是当本地节点需要

982
00:37:04,770 --> 00:37:05,430
做出这个决定时，

983
00:37:05,430 --> 00:37:07,620
你知道一切它不

984
00:37:07,620 --> 00:37:10,280
担心与其他任何人通信

985
00:37:10,280 --> 00:37:12,630
我不是说一个比 其他

986
00:37:12,630 --> 00:37:13,740
我认为这有一些有趣的

987
00:37:13,740 --> 00:37:15,750
影响，在研究中没有探索过

988
00:37:15,750 --> 00:37:18,320
，

989
00:37:18,760 --> 00:37:22,700
所以现在我们想再次讨论连接

990
00:37:22,700 --> 00:37:25,039
连接是

991
00:37:25,039 --> 00:37:26,420
你必须在单节点数据库中做的那些昂贵的最重要的事情

992
00:37:26,420 --> 00:37:28,309
，只要你

993
00:37:28,309 --> 00:37:31,220
知道 同样在用于

994
00:37:31,220 --> 00:37:34,039
分析工作负载的东芝数据库

995
00:37:34,039 --> 00:37:36,049
中，系统将

996
00:37:36,049 --> 00:37:37,880
花费大部分时间来执行查询，其中我

997
00:37:37,880 --> 00:37:40,160
从磁盘读取数据或执行

998
00:37:40,160 --> 00:37:43,069
我们所说的从磁盘读取数据的联合操作，

999
00:37:43,069 --> 00:37:45,170
你知道

1000
00:37:45,170 --> 00:37:46,490
有 您可以采取一些方法来加快速度

1001
00:37:46,490 --> 00:37:48,289
，但在一天结束时，您

1002
00:37:48,289 --> 00:37:49,970
通常会受制于

1003
00:37:49,970 --> 00:37:52,059
从物理设备上取下东西的速度，

1004
00:37:52,059 --> 00:37:54,950
但是对于连接，我们可以对事情很聪明，

1005
00:37:54,950 --> 00:37:58,730
所以正如我在第一个中展示的那样

1006
00:37:58,730 --> 00:38:01,910
例如，进行连接的最简单方法

1007
00:38:01,910 --> 00:38:04,700
是获取我们需要进行连接的所有数据，

1008
00:38:04,700 --> 00:38:07,069
将它们放在单个节点上并运行

1009
00:38:07,069 --> 00:38:09,740
我们的联合专辑，但正如我所说，通过将数据划分，您将失去

1010
00:38:09,740 --> 00:38:11,539
所有额外的并行实际

1011
00:38:11,539 --> 00:38:13,099
资源

1012
00:38:13,099 --> 00:38:15,200
多个节点你失去了所有这些

1013
00:38:15,200 --> 00:38:18,170
好处，你也知道你

1014
00:38:18,170 --> 00:38:19,130
实际上可能无法将所有东西都

1015
00:38:19,130 --> 00:38:21,549
放在内存中来快速运行，

1016
00:38:21,549 --> 00:38:24,140
所以在不同的方法之前

1017
00:38:24,140 --> 00:38:26,480
我们实际上如何或负担得起

1018
00:38:26,480 --> 00:38:28,190
你需要处理的场景 我们

1019
00:38:28,190 --> 00:38:30,020
想要做的应该是加入，

1020
00:38:30,020 --> 00:38:32,869
并且分发者加入将

1021
00:38:32,869 --> 00:38:35,210
与我们在单节点系统上进行加入完全相同，

1022
00:38:35,210 --> 00:38:37,400
但我们的想法是

1023
00:38:37,400 --> 00:38:39,230
我们需要弄清楚如何获取

1024
00:38:39,230 --> 00:38:42,440
我们想要的数据

1025
00:38:42,440 --> 00:38:44,599
在一个节点上连接在一起，它可以是一个节点成为

1026
00:38:44,599 --> 00:38:46,910
多个节点，这样我们就可以在

1027
00:38:46,910 --> 00:38:48,650
本地进行连接，而无需

1028
00:38:48,650 --> 00:38:50,630
在我们进行连接时与任何其他节点进行协调，

1029
00:38:50,630 --> 00:38:53,809
所以当我们进行

1030
00:38:53,809 --> 00:38:55,460
本地连接时，一切都结束了 相同的

1031
00:38:55,460 --> 00:38:56,930
算法 服务器的连接嵌套循环连接

1032
00:38:56,930 --> 00:38:57,890
我们在应用所有相同优化之前讨论过的哈希连接

1033
00:38:57,890 --> 00:39:00,470
这是

1034
00:39:00,470 --> 00:39:02,240
您在执行连接之前必须处理的步骤

1035
00:39:02,240 --> 00:39:04,250
，了解如何将数据发送

1036
00:39:04,250 --> 00:39:08,599
到需要它的节点

1037
00:39:08,599 --> 00:39:09,410


1038
00:39:09,410 --> 00:39:10,970
如果您

1039
00:39:10,970 --> 00:39:12,940
已经在我们之前的示例中出现过

1040
00:39:12,940 --> 00:39:15,319
，我们将再次讨论四种不同的场景，我们将看到我们实际上想要如何

1041
00:39:15,319 --> 00:39:17,359
处理它们，并且主要的收获

1042
00:39:17,359 --> 00:39:18,770
是这里没有我们

1043
00:39:18,770 --> 00:39:19,940
实际上可以做到的魔法 没有魔法

1044
00:39:19,940 --> 00:39:21,680
行业可以加入 将

1045
00:39:21,680 --> 00:39:24,440
形成比单个节点好得多

1046
00:39:24,440 --> 00:39:26,660
的算法它是关于如何将数据

1047
00:39:26,660 --> 00:39:29,559
送到需要的地方

1048
00:39:30,170 --> 00:39:31,730
我说最好的情况是

1049
00:39:31,730 --> 00:39:35,930


1050
00:39:35,930 --> 00:39:37,760
表是加入我们分区的表之一

1051
00:39:37,760 --> 00:39:40,640
加入团队，然后在每个节点上完整复制另一个表，

1052
00:39:40,640 --> 00:39:43,940


1053
00:39:43,940 --> 00:39:46,789
因此在这种情况下，我们的

1054
00:39:46,789 --> 00:39:49,519
表在 ID 上分区，

1055
00:39:49,519 --> 00:39:51,289
它的 ID 字段位于我们的 join

1056
00:39:51,289 --> 00:39:53,420
子句中，然后复制 s 表

1057
00:39:53,420 --> 00:39:55,730
再次在每个节点中，这

1058
00:39:55,730 --> 00:39:57,440
可能是事实表 这可能

1059
00:39:57,440 --> 00:39:59,809
是维度表，它足够小

1060
00:39:59,809 --> 00:40:01,190
，我们可以将其拆分，或者

1061
00:40:01,190 --> 00:40:02,750
足够小，我们可以

1062
00:40:02,750 --> 00:40:05,960
在每台机器上复制它，因此在这种情况下，

1063
00:40:05,960 --> 00:40:08,599
我们再次需要做的 是让

1064
00:40:08,599 --> 00:40:11,630
每个节点都进行本地连接以

1065
00:40:11,630 --> 00:40:13,970


1066
00:40:13,970 --> 00:40:16,369
生成您知道存储和本地存储的数据的结果，

1067
00:40:16,369 --> 00:40:19,579
然后我们只需要将

1068
00:40:19,579 --> 00:40:22,460
连接一个节点之一的输出传输到

1069
00:40:22,460 --> 00:40:24,170
某个集中位置，以便我们可以

1070
00:40:24,170 --> 00:40:25,279
组合 ne

1071
00:40:25,279 --> 00:40:28,720
对我们的应用程序产生单个答案的结果

1072
00:40:28,720 --> 00:40:30,619
再次正确这是最好的

1073
00:40:30,619 --> 00:40:32,750
情况是这种将

1074
00:40:32,750 --> 00:40:34,670
连接结果从该节点到该节点的转移

1075
00:40:34,670 --> 00:40:37,609
是不可避免的我们必须这样做但是当

1076
00:40:37,609 --> 00:40:38,900
我们应该得到 join 我们

1077
00:40:38,900 --> 00:40:40,099
不需要协调器或与任何

1078
00:40:40,099 --> 00:40:41,720
其他节点通信，因为我们需要的一切对我们来说

1079
00:40:41,720 --> 00:40:44,329
都是本地的，所以这给了我们

1080
00:40:44,329 --> 00:40:45,859
分布式数据库的好处，

1081
00:40:45,859 --> 00:40:47,960
因为现在我们可以在

1082
00:40:47,960 --> 00:40:50,539
没有任何协调的情况下在每个节点上并行运行这个 join

1083
00:40:50,539 --> 00:40:52,880
，然后 每个人都只是

1084
00:40:52,880 --> 00:40:57,880
将结果发送回头节点

1085
00:40:59,990 --> 00:41:03,040
下一个最好的情况是，

1086
00:41:03,040 --> 00:41:06,260
两个键都

1087
00:41:06,260 --> 00:41:07,550
在表上方进行分区，再次在连接键上进行分区，

1088
00:41:07,550 --> 00:41:10,490
在这种情况下

1089
00:41:10,490 --> 00:41:12,650
，在最后一张幻灯片上进行了再次分区

1090
00:41:12,650 --> 00:41:15,770
的 ID 今天被复制了这个是

1091
00:41:15,770 --> 00:41:17,690
在ID字段上分区

1092
00:41:17,690 --> 00:41:19,610
的，在这个分区

1093
00:41:19,610 --> 00:41:22,460
中的范围与

1094
00:41:22,460 --> 00:41:24,980
s的范围相同抱歉s的分区

1095
00:41:24,980 --> 00:41:27,980
范围与pos的范围相同 再次在 R 上进行 ition

1096
00:41:27,980 --> 00:41:29,660
就像在我们计算我们的本地

1097
00:41:29,660 --> 00:41:31,520
连接之前给我一个哈希将被嵌套

1098
00:41:31,520 --> 00:41:32,690
循环可以是排序合并它

1099
00:41:32,690 --> 00:41:35,119
无关紧要然后这个人将

1100
00:41:35,119 --> 00:41:36,890
结果传输到我们

1101
00:41:36,890 --> 00:41:55,400
将它组合在一起的另一个节点是的所以这个 问题

1102
00:41:55,400 --> 00:41:58,910
他的问题是关于数据偏斜，所以在

1103
00:41:58,910 --> 00:42:01,610
这个例子中，我向你

1104
00:42:01,610 --> 00:42:03,710
展示范围是相同的 1 到 100 和

1105
00:42:03,710 --> 00:42:06,530
101 到 200，但它不一定

1106
00:42:06,530 --> 00:42:10,250
告诉你这个

1107
00:42:10,250 --> 00:42:12,859
范围或这个分区中存在多少元组，比如 说这个

1108
00:42:12,859 --> 00:42:15,140
ID 是 R 的主键，所以

1109
00:42:15,140 --> 00:42:17,510
R 正好有一百个元组，但说

1110
00:42:17,510 --> 00:42:19,510
这是 ID 不是 ID 的主键，

1111
00:42:19,510 --> 00:42:23,330
我可以

1112
00:42:23,330 --> 00:42:24,980
在这个范围内有十亿

1113
00:42:24,980 --> 00:42:26,930
个条目，然后在那个范围内有十亿个条目，我该怎么做 处理

1114
00:42:26,930 --> 00:42:28,940
好在那种情况下你

1115
00:42:28,940 --> 00:42:30,890
不希望拥有与

1116
00:42:30,890 --> 00:42:32,720
ID 字段相同的范围所以在这种情况下你将

1117
00:42:32,720 --> 00:42:34,490
不得不在一秒钟内随机播放一些数据，

1118
00:42:34,490 --> 00:42:36,800
这是最好的情况，

1119
00:42:36,800 --> 00:42:39,710
这些都是统一的

1120
00:42:39,710 --> 00:42:41,750
分布完全相同的范围 e 我

1121
00:42:41,750 --> 00:42:45,320
不需要老套 我确定这不是

1122
00:42:45,320 --> 00:42:46,640
我同意但它不会有一个真实世界

1123
00:42:46,640 --> 00:42:49,280
我说的是最坏情况的最佳

1124
00:42:49,280 --> 00:42:50,990
情况，我们将看看如何

1125
00:42:50,990 --> 00:42:58,790
处理 变得更糟，所以

1126
00:42:58,790 --> 00:43:00,560
与他相关 所以下一个问题将是

1127
00:43:00,560 --> 00:43:02,960
假设我们的一个表没有

1128
00:43:02,960 --> 00:43:06,230
在我们想要加入的相同属性上进行分区

1129
00:43:06,230 --> 00:43:07,970
，所以在这种情况下，

1130
00:43:07,970 --> 00:43:10,900
这里 s 是值字段上的分区，

1131
00:43:10,900 --> 00:43:13,700
所以 在这种情况下

1132
00:43:13,700 --> 00:43:15,920
无法计算我们的本地连接，因为对于

1133
00:43:15,920 --> 00:43:18,440
我们 ID 的每一个值，我

1134
00:43:18,440 --> 00:43:22,010
不知道是不是你知道

1135
00:43:22,010 --> 00:43:23,870
我的本地分区上将存在匹配的大号，

1136
00:43:23,870 --> 00:43:25,790
然后可能不会在这里

1137
00:43:25,790 --> 00:43:29,330
使用相同的 ID，所以 在这种

1138
00:43:29,330 --> 00:43:31,130
情况下，这称为广播连接

1139
00:43:31,130 --> 00:43:35,210
，基本思想是将每个分区

1140
00:43:35,210 --> 00:43:37,780
中缺少的表部分复制

1141
00:43:37,780 --> 00:43:41,480
到每个其他

1142
00:43:41,480 --> 00:43:44,750
分区，以便现在该节点具有

1143
00:43:44,750 --> 00:43:49,160
表的完整副本，然后现在

1144
00:43:49,160 --> 00:43:50,750
您只需计算您的本地连接，

1145
00:43:50,750 --> 00:43:52,610
然后将结果再次发送给另一个

1146
00:43:52,610 --> 00:43:56,240
人，这假设 at s 足够小

1147
00:43:56,240 --> 00:43:57,920
，以至于您可以驻留在

1148
00:43:57,920 --> 00:44:00,230
内存中或不做饭而不会使

1149
00:44:00,230 --> 00:44:02,090
这台机器不堪

1150
00:44:02,090 --> 00:44:07,550


1151
00:44:07,550 --> 00:44:09,260


1152
00:44:09,260 --> 00:44:10,310


1153
00:44:10,310 --> 00:44:13,370
重负 该表有时

1154
00:44:13,370 --> 00:44:14,180
只是看到您听说过，因为

1155
00:44:14,180 --> 00:44:16,460
广播公司拥有广播

1156
00:44:16,460 --> 00:44:18,980
合作伙伴加入它只是意味着他们正在

1157
00:44:18,980 --> 00:44:21,170
执行此初始步骤，

1158
00:44:21,170 --> 00:44:23,000
将数据传输到不同的

1159
00:44:23,000 --> 00:44:24,410
笔记，每个人都有完整的副本

1160
00:44:24,410 --> 00:44:30,710
，然后您加入 最后

1161
00:44:30,710 --> 00:44:32,000
一种情况绝对是最糟糕的

1162
00:44:32,000 --> 00:44:34,490
情况，两个表都没有

1163
00:44:34,490 --> 00:44:36,460
在我们的连接键上进行分区，

1164
00:44:36,460 --> 00:44:40,250
现在我们需要重新组织

1165
00:44:40,250 --> 00:44:42,890
数据的布局，以便我们更有效地计算我们的连接，

1166
00:44:42,890 --> 00:44:45,230
因此这将被

1167
00:44:45,230 --> 00:44:47,860
称为随机连接 麻烦散列连接

1168
00:44:47,860 --> 00:44:50,600
所以基本上我们认识到我们

1169
00:44:50,600 --> 00:44:52,190
真的希望在 ID 字段上对事物进行分区，

1170
00:44:52,190 --> 00:44:54,260
所以让我开始

1171
00:44:54,260 --> 00:44:56,300
从这两个表中复制我需要的数据

1172
00:44:56,300 --> 00:44:57,830
以进行倾斜 这两个不同的

1173
00:44:57,830 --> 00:45:00,710
节点，如果这必须溢出到磁盘

1174
00:45:00,710 --> 00:45:03,170
，这是不可避免的空间不足，所以

1175
00:45:03,170 --> 00:45:04,760
我们继续这样做，然后一旦

1176
00:45:04,760 --> 00:45:06,110
我知道我已经

1177
00:45:06,110 --> 00:45:07,970
按照我想要的方式购买了所有东西，那么我可以

1178
00:45:07,970 --> 00:45:10,280
保留我的本地连接并生成

1179
00:45:10,280 --> 00:45:15,550
结果是的

1180
00:45:15,730 --> 00:45:23,060
，所以他的问题是什么，而且空间

1181
00:45:23,060 --> 00:45:23,930
有限，你能做什么，

1182
00:45:23,930 --> 00:45:24,950
所以我想在这里提出的观点

1183
00:45:24,950 --> 00:45:30,050
就像提莫一样，你最终在这里做了什么，

1184
00:45:30,050 --> 00:45:31,910
所以我现在必须制作

1185
00:45:31,910 --> 00:45:35,990
我们的另一个副本，你知道 并将它存储在

1186
00:45:35,990 --> 00:45:38,660
这个节点上，所以如果它不适合

1187
00:45:38,660 --> 00:45:40,910
内存，就像我说的那样，它

1188
00:45:40,910 --> 00:45:42,590
会被溢出，因为查询的临时结果

1189
00:45:42,590 --> 00:45:44,300
可能会溢出一个

1190
00:45:44,300 --> 00:45:48,440
不可避免的磁盘，但更

1191
00:45:48,440 --> 00:45:50,030
重要的是现在当 我

1192
00:45:50,030 --> 00:45:51,650
计算连接我希望它尽可能快

1193
00:45:51,650 --> 00:45:52,670
，因为这是最

1194
00:45:52,670 --> 00:45:54,710
昂贵的事情，所以通过

1195
00:45:54,710 --> 00:45:57,530
在我进行连接时复制数据，一切都

1196
00:45:57,530 --> 00:45:58,790
按照我想要的方式很好地分区，

1197
00:45:58,790 --> 00:46:05,540
而且效率更高，我们这个问题是

1198
00:46:05,540 --> 00:46:06,680
我们总是假设 磁盘

1199
00:46:06,680 --> 00:46:16,190
对我们的班级来说已经足够了，在现实

1200
00:46:16,190 --> 00:46:18,860
世界中是的，没有数据库会发生什么，

1201
00:46:18,860 --> 00:46:21,140
并认识到如果我到达

1202
00:46:21,140 --> 00:46:25,190
这里并且我无法将更多数据复制到

1203
00:46:25,190 --> 00:46:27,260
这里的这个节点，查询将失败，

1204
00:46:27,260 --> 00:46:29,240
只是说我用完了交换 停留 10 个

1205
00:46:29,240 --> 00:46:31,460
空间，你抛出一个差事，查询

1206
00:46:31,460 --> 00:46:35,780
失败，实际上与他的问题有关，

1207
00:46:35,780 --> 00:46:37,010
但关于数据的分散，

1208
00:46:37,010 --> 00:46:41,330
如果说它是在 ID 字段上分区的，

1209
00:46:41,330 --> 00:46:43,970
但分布是

1210
00:46:43,970 --> 00:46:45,230
高度偏斜的姐妹，大部分

1211
00:46:45,230 --> 00:46:47,450
数据都在这个节点上 对于 s 而不是

1212
00:46:47,450 --> 00:46:49,400
那个节点，我仍然可以

1213
00:46:49,400 --> 00:46:52,760
重新洗牌以重新对齐我的数据，也许可以

1214
00:46:52,760 --> 00:46:54,560
将一些数据从 R 和 s 移到这里，

1215
00:46:54,560 --> 00:46:57,560
以便事情甚至得到平衡，但

1216
00:46:57,560 --> 00:46:59,140
它仍然被称为洗牌过程

1217
00:46:59,140 --> 00:47:06,140
问题如何更紧凑哦

1218
00:47:06,140 --> 00:47:08,290
对不起

1219
00:47:13,980 --> 00:47:25,400
是的，当然，您如何管理先生，

1220
00:47:32,660 --> 00:47:35,099
我们的问题是我如何

1221
00:47:35,099 --> 00:47:36,990
决定要发送的数据，因为

1222
00:47:36,990 --> 00:47:38,310
如果复制了内容，我不想

1223
00:47:38,310 --> 00:47:39,180
浪费

1224
00:47:39,180 --> 00:47:41,010
您知道发送数据的浪费网络传输，

1225
00:47:41,010 --> 00:47:42,570
那是我不知道的

1226
00:47:42,570 --> 00:47:44,550
需要提前向您发送知道所有内容

1227
00:47:44,550 --> 00:47:46,859
正确的续集是声明性的 我们

1228
00:47:46,859 --> 00:47:48,210
知道查询是什么 我们知道

1229
00:47:48,210 --> 00:47:49,980
正在尝试访问哪些数据 然后查看我们的

1230
00:47:49,980 --> 00:47:51,570
系统目录 我们的系统 Callao

1231
00:47:51,570 --> 00:47:53,640
将告诉我们这些数据实际上是如何

1232
00:47:53,640 --> 00:47:55,410
分区的 我们知道这一点 提前

1233
00:47:55,410 --> 00:47:57,810
所以查询计划器可以做出决定

1234
00:47:57,810 --> 00:48:00,390
哦，这个数据分区是这样的，

1235
00:48:00,390 --> 00:48:02,490
它是这个大小，它在这个节点上

1236
00:48:02,490 --> 00:48:04,260
，所以要么移动或不移动

1237
00:48:04,260 --> 00:48:06,329
它，要么复制这里，不要复制那里我可以

1238
00:48:06,329 --> 00:48:07,710
做所有这些 提前它

1239
00:48:07,710 --> 00:48:10,230
不像我说的那样我说哦好吧

1240
00:48:10,230 --> 00:48:12,390
也许我应该复制这个你

1241
00:48:12,390 --> 00:48:14,820
提前弄清楚除了

1242
00:48:14,820 --> 00:48:16,140
他提出的问题或者我用完了

1243
00:48:16,140 --> 00:48:19,410
磁盘空间你知道你

1244
00:48:19,410 --> 00:48:25,980
什么都没失败 你可以做，然后

1245
00:48:25,980 --> 00:48:28,530
数据库系统在

1246
00:48:28,530 --> 00:48:30,270
做出关于

1247
00:48:30,270 --> 00:48:32,369
副本不是副本的决定方面的效率取决于

1248
00:48:32,369 --> 00:48:34,800
你的查询优化器有多好，这就是

1249
00:48:34,800 --> 00:48:36,329
为什么人们花很多钱让

1250
00:48:36,329 --> 00:48:38,270
人们喜欢在查询上工作 优化器 s

1251
00:48:38,270 --> 00:48:43,950
问题你的问题是，如果

1252
00:48:43,950 --> 00:48:45,359
数据事先按分区 ID 排序，

1253
00:48:45,359 --> 00:48:47,369
但它是分区 ID 或

1254
00:48:47,369 --> 00:48:53,099
联合 ID，那么如果它按我在这里展示的内容排序，

1255
00:48:53,099 --> 00:48:56,670
谁在乎，因为我

1256
00:48:56,670 --> 00:48:58,410
关心的是我需要的数据的位置

1257
00:48:58,410 --> 00:49:01,800
在 s ID 上加入我们的 ID 所以

1258
00:49:01,800 --> 00:49:03,119
我想确保当我在本地加入时

1259
00:49:03,119 --> 00:49:05,540
我拥有我需要的所有数据

1260
00:49:05,540 --> 00:49:08,430
你知道因为你知道在我的本地节点上加入

1261
00:49:08,430 --> 00:49:10,290
内部表的外部表

1262
00:49:10,290 --> 00:49:12,240
不能在

1263
00:49:12,240 --> 00:49:13,619
我不知道的其他节点，这

1264
00:49:13,619 --> 00:49:15,569
可能最终导致假阴性或

1265
00:49:15,569 --> 00:49:18,900
假阳性，因此

1266
00:49:18,900 --> 00:49:20,880
排序无关紧要 当我们可以决定是否要进行证书时，排序很重要

1267
00:49:20,880 --> 00:49:22,560


1268
00:49:22,560 --> 00:49:25,349
合并为散列连接词就像

1269
00:49:25,349 --> 00:49:26,849
上面的一步 我们正在设计我们如何

1270
00:49:26,849 --> 00:49:27,360
移动数据

1271
00:49:27,360 --> 00:49:40,260
或

1272
00:49:40,260 --> 00:49:41,840


1273
00:49:41,840 --> 00:49:44,490


1274
00:49:44,490 --> 00:49:46,530
不移动 分隔线所以这是

1275
00:49:46,530 --> 00:49:48,900
这个节点上的永久数据它

1276
00:49:48,900 --> 00:49:50,850
不会去任何地方我只是说 额外的副本

1277
00:49:50,850 --> 00:49:52,500
作为临时临时数据来做我的

1278
00:49:52,500 --> 00:49:53,760
联合，然后当我的查询结束时我把它扔掉

1279
00:49:53,760 --> 00:49:55,770
，所以即使我

1280
00:49:55,770 --> 00:49:58,770
在 ID 上洗牌，我仍然

1281
00:49:58,770 --> 00:50:00,510
在分区或名称和

1282
00:50:00,510 --> 00:50:03,780
值的末尾去这个这个 保持不变，但您的

1283
00:50:03,780 --> 00:50:05,610
另一个问题是我实际上在传输什么是

1284
00:50:05,610 --> 00:50:07,680
我传输整个

1285
00:50:07,680 --> 00:50:10,500
元组还是我传输峰会

1286
00:50:10,500 --> 00:50:13,710
一些标识符下一张幻灯片好的我们会

1287
00:50:13,710 --> 00:50:26,760
得到是的，如果数据未排序，您的问题是在

1288
00:50:26,760 --> 00:50:29,220
本地节点上

1289
00:50:29,220 --> 00:50:30,210
我如何确保没有

1290
00:50:30,210 --> 00:50:34,140
重复的重复

1291
00:50:34,140 --> 00:50:43,110
项 ha 是分区 ID

1292
00:50:43,110 --> 00:50:58,070
主键或唯一 ID

1293
00:50:58,070 --> 00:51:01,860


1294
00:51:01,860 --> 00:51:03,510


1295
00:51:03,510 --> 00:51:05,400
我有一个主键然后我需要

1296
00:51:05,400 --> 00:51:07,260
保证它是唯一的但是我的

1297
00:51:07,260 --> 00:51:10,440
分区键不是主键

1298
00:51:10,440 --> 00:51:13,590
我如何确保我强制执行它

1299
00:51:13,590 --> 00:51:18,060
以便这是一个交易权而

1300
00:51:18,060 --> 00:51:19,620
不是我们我们只是在做

1301
00:51:19,620 --> 00:51:23,040
我们假设的分析查询 我们不喜欢我们

1302
00:51:23,040 --> 00:51:25,170
假设 当其他人

1303
00:51:25,170 --> 00:51:27,150
将数据作为事务的一部分注入和存储时，他们已经为我们解决了这个问题，

1304
00:51:27,150 --> 00:51:29,520
因此在

1305
00:51:29,520 --> 00:51:31,650
您的示例中，如果我有一个

1306
00:51:31,650 --> 00:51:33,030
与主键不同的分区键，

1307
00:51:33,030 --> 00:51:35,340
那么我插入一条新记录

1308
00:51:35,340 --> 00:51:37,350
我如何确保 这是独一无二的，而我

1309
00:51:37,350 --> 00:51:40,200
吃 IVA 需要维护一种

1310
00:51:40,200 --> 00:51:41,339
集中式索引，我会

1311
00:51:41,339 --> 00:51:42,930
查找并查看该密钥是否

1312
00:51:42,930 --> 00:51:45,210
存在，或者在

1313
00:51:45,210 --> 00:51:46,769
向每个节点广播查询时说嘿，我

1314
00:51:46,769 --> 00:51:49,349
确定您是否已经拥有该密钥

1315
00:51:49,349 --> 00:51:54,319
它的副本我是说你可以

1316
00:51:54,319 --> 00:51:57,989
写帮助我怎么进来我

1317
00:51:57,989 --> 00:52:00,690
怎么可能那怎么可能是ID这里有

1318
00:52:00,690 --> 00:52:04,019
一个索引我们正在构建白痴我们

1319
00:52:04,019 --> 00:52:07,249
确实拥有每个权利我们可以

1320
00:52:09,200 --> 00:52:13,859
像我一样再次这样做 在这个

1321
00:52:13,859 --> 00:52:15,329
世界上不关心这些查询 我没有

1322
00:52:15,329 --> 00:52:18,660
强制执行完整性约束 我只是

1323
00:52:18,660 --> 00:52:20,460
运行这个读取查询是分析

1324
00:52:20,460 --> 00:52:22,739
查询，以确定您知道如何

1325
00:52:22,739 --> 00:52:24,029
在大型数据语料库上有效地计算联合

1326
00:52:24,029 --> 00:52:27,690


1327
00:52:27,690 --> 00:52:29,519
它关心的事务方面 关于完整性

1328
00:52:29,519 --> 00:52:31,079
约束，当你 因为

1329
00:52:31,079 --> 00:52:32,190
你正在修改数据库的状态，所以

1330
00:52:32,190 --> 00:52:43,799
没有通知所以回到

1331
00:52:43,799 --> 00:52:51,779
我这里的初始示例，比如

1332
00:52:51,779 --> 00:52:56,339
这个 ETL 事情，所以

1333
00:52:56,339 --> 00:52:58,410
像批量加载这样的一堆数据这样的

1334
00:52:58,410 --> 00:52:59,969
事情是一种流媒体，它不是 很高兴

1335
00:52:59,969 --> 00:53:02,160
这不是一下子这里有

1336
00:53:02,160 --> 00:53:03,210
一堆数据，但是您正在将

1337
00:53:03,210 --> 00:53:06,150
更新从前端以增量方式流式传输

1338
00:53:06,150 --> 00:53:08,519
到后端数据仓库，

1339
00:53:08,519 --> 00:53:10,349
后端数据仓库可以选择或

1340
00:53:10,349 --> 00:53:12,119
不选择强制执行这些完整性

1341
00:53:12,119 --> 00:53:15,779
压力，但是 但它

1342
00:53:15,779 --> 00:53:18,869
不会在我们执行查询的关键路径上，

1343
00:53:18,869 --> 00:53:20,039
因为我正在

1344
00:53:20,039 --> 00:53:21,329
运行选择 David 我没有检查

1345
00:53:21,329 --> 00:53:23,789
我的主键是否唯一，所以现在

1346
00:53:23,789 --> 00:53:25,469
您如何在摄取数据时强制执行该完整性

1347
00:53:25,469 --> 00:53:27,479
约束

1348
00:53:27,479 --> 00:53:29,160
回到脚趾仓库

1349
00:53:29,160 --> 00:53:30,479
，这与我们在上一

1350
00:53:30,479 --> 00:53:32,219
堂课上讨论的如何进行交易是一样的

1351
00:53:32,219 --> 00:53:34,739
，因为这是一种您知道的交易类型

1352
00:53:34,739 --> 00:53:36,239
插入一些东西 确保它是独一无二的 我

1353
00:53:36,239 --> 00:53:37,799
需要跨多个节点进行协调，

1354
00:53:37,799 --> 00:53:39,660
如果 我不是所有的东西都不是在一个

1355
00:53:39,660 --> 00:53:42,599
节点上进行检查，每个人都

1356
00:53:42,599 --> 00:53:43,799
同意我们可以继续进行这种

1357
00:53:43,799 --> 00:53:46,529
更改，所以很多时候在这些

1358
00:53:46,529 --> 00:53:48,599
分析数据仓库中，

1359
00:53:48,599 --> 00:53:52,229
他们将拥有一个单独的

1360
00:53:52,229 --> 00:53:55,230
引擎或

1361
00:53:55,230 --> 00:53:57,390
旨在提高效率的可怜的峡谷区域

1362
00:53:57,390 --> 00:53:59,100


1363
00:53:59,100 --> 00:54:01,859
比您知道的

1364
00:54:01,859 --> 00:54:03,990
传统通信存储数据系统

1365
00:54:03,990 --> 00:54:07,050
在您参加高级

1366
00:54:07,050 --> 00:54:08,280
课程时会

1367
00:54:08,280 --> 00:54:12,210
做的更新更有效 今天在这里

1368
00:54:12,210 --> 00:54:13,890
我们不关心执行

1369
00:54:13,890 --> 00:54:15,869
完整性训练 我们假设它

1370
00:54:15,869 --> 00:54:18,090
已经为我们处理了一些数据库

1371
00:54:18,090 --> 00:54:20,070
系统 我的意思是一些数据仓库 他们

1372
00:54:20,070 --> 00:54:21,480
只是关闭所有这些垃圾 他们

1373
00:54:21,480 --> 00:54:23,730
关闭外键 他们关闭唯一

1374
00:54:23,730 --> 00:54:26,430
键 你的数据是一个 小脏谁

1375
00:54:26,430 --> 00:54:46,320
关心分析，所以这个

1376
00:54:46,320 --> 00:54:51,960
问题是你有你的银行账户，

1377
00:54:51,960 --> 00:54:54,750
或者不管你的游戏

1378
00:54:54,750 --> 00:54:57,030
信息是什么，你在前端更新你的用户

1379
00:54:57,030 --> 00:54:58,140
账户 o 成为

1380
00:54:58,140 --> 00:54:59,490
数据库，因为 th 这就是

1381
00:54:59,490 --> 00:55:01,260
用户接触这部分的原因 他们不会

1382
00:55:01,260 --> 00:55:02,250
接触数据或房屋的背面 他们

1383
00:55:02,250 --> 00:55:04,350
在此处进行更新 更新被

1384
00:55:04,350 --> 00:55:05,850
传播并且您想在

1385
00:55:05,850 --> 00:55:08,280
此处更新记录 已发生的高级

1386
00:55:08,280 --> 00:55:10,170
课程 一般我会说的是 就像

1387
00:55:10,170 --> 00:55:13,320
您在这些数据仓库中的

1388
00:55:13,320 --> 00:55:15,180
某种正确优化的存储层或

1389
00:55:15,180 --> 00:55:17,010
执行引擎中缓冲一堆更改

1390
00:55:17,010 --> 00:55:18,960
，然后它们会定期将

1391
00:55:18,960 --> 00:55:23,070
更改合并到数据仓库中，或者

1392
00:55:23,070 --> 00:55:24,990
像用于新分析的主列存储表一样

1393
00:55:24,990 --> 00:55:27,830


1394
00:55:27,830 --> 00:55:31,640
不同的系统可以做不同的事情，

1395
00:55:34,580 --> 00:55:37,580


1396
00:55:39,450 --> 00:55:44,200
所以关于这个东西的任何其他问题

1397
00:55:44,200 --> 00:55:44,819
在这里

1398
00:55:44,819 --> 00:56:02,859
是的，继续是的，她的问题是我

1399
00:56:02,859 --> 00:56:05,049
在这里说的，如果当我们

1400
00:56:05,049 --> 00:56:07,269
为了这个特定的查询而在这里复制这个东西时，如果

1401
00:56:07,269 --> 00:56:11,920
我们运行一个磁盘库并且查询崩溃

1402
00:56:11,920 --> 00:56:14,619
不能 不是查询优化器

1403
00:56:14,619 --> 00:56:16,119
提前说哦我不会

1404
00:56:16,119 --> 00:56:18,670
有磁盘空间让我让我

1405
00:56:18,670 --> 00:56:21,309
确保可能不会以某种方式

1406
00:56:21,309 --> 00:56:24,549
在这里运行查询优化器通常

1407
00:56:24,549 --> 00:56:26,920
不会 关于我们同时运行的其他查询的内容

1408
00:56:26,920 --> 00:56:29,740
，它假设您的

1409
00:56:29,740 --> 00:56:36,279
查询是独立运行的，并且它

1410
00:56:36,279 --> 00:56:38,549
可以推理某些事情，例如

1411
00:56:38,549 --> 00:56:40,630
某些系统，您可以

1412
00:56:40,630 --> 00:56:42,789
指定允许使用多少临时缓冲区空间

1413
00:56:42,789 --> 00:56:44,589
或临时替换查询

1414
00:56:44,589 --> 00:56:46,299
，以及 然后，如果

1415
00:56:46,299 --> 00:56:47,829
您在查询中超过该值失败并且它会将

1416
00:56:47,829 --> 00:56:49,509
您退回，嘿，您知道 creases 参数，

1417
00:56:49,509 --> 00:56:51,970
如果您想继续运行，那么它

1418
00:56:51,970 --> 00:56:53,859
可能会在计划时间弄清楚

1419
00:56:53,859 --> 00:56:56,380
哦，我将复制比我

1420
00:56:56,380 --> 00:56:57,880
有空间的更多数据 特定查询

1421
00:56:57,880 --> 00:57:00,640
并抛出错误，但如果像你一样

1422
00:57:00,640 --> 00:57:02,829
物理上耗尽空间，即使

1423
00:57:02,829 --> 00:57:04,890
你不在那个范围内，你知道

1424
00:57:04,890 --> 00:57:07,690
你没有超过每个查询的限制，

1425
00:57:07,690 --> 00:57:09,609
查询优化器通常

1426
00:57:09,609 --> 00:57:11,650
不会考虑或不能

1427
00:57:11,650 --> 00:57:12,640
关于哪些查询同时运行的原因

1428
00:57:12,640 --> 00:57:13,960
，因为这只会让你的生活

1429
00:57:13,960 --> 00:57:16,809
变得更艰难，因为像这个查询一样，第一

1430
00:57:16,809 --> 00:57:18,160
年我计划它我说好吧现在什么都没有

1431
00:57:18,160 --> 00:57:20,559
运行让我继续并

1432
00:57:20,559 --> 00:57:22,089
选择 一种计划，因为我

1433
00:57:22,089 --> 00:57:23,950
自己运行并开始运行，

1434
00:57:23,950 --> 00:57:25,299
然后这个其他查询现在显示我

1435
00:57:25,299 --> 00:57:27,670
不想回去修改

1436
00:57:27,670 --> 00:57:28,990
其他查询计划说嘿现在你

1437
00:57:28,990 --> 00:57:30,039
也在运行另一个查询

1438
00:57:30,039 --> 00:57:33,329
同时，这太难了，

1439
00:57:39,280 --> 00:57:43,130
我的评论是，有时您会在

1440
00:57:43,130 --> 00:57:45,859
数据仓库中看到，因此数据库

1441
00:57:45,859 --> 00:57:49,040
系统本身可以支持模式

1442
00:57:49,040 --> 00:57:51,170
强制执行完整性约束外

1443
00:57:51,170 --> 00:57:52,820
键主键引用完整性

1444
00:57:52,820 --> 00:57:55,099
和类似的东西它可以支持

1445
00:57:55,099 --> 00:57:58,760
那些但应用程序开发

1446
00:57:58,760 --> 00:58:00,530
人员构建的人 数据仓库可能会

1447
00:58:00,530 --> 00:58:02,089
说我不想支付

1448
00:58:02,089 --> 00:58:03,619
检查外键的罚款让我关闭所有

1449
00:58:03,619 --> 00:58:22,670
这个问题是我在

1450
00:58:22,670 --> 00:58:27,530
上一张幻灯片中说的，通常大多数无

1451
00:58:27,530 --> 00:58:32,150
共享实际上共享磁盘

1452
00:58:32,150 --> 00:58:36,680
通知分布式OLAP数据库不

1453
00:58:36,680 --> 00:58:39,079
支持查询容错或查询

1454
00:58:39,079 --> 00:58:42,290
查询弹性，如果查询如果

1455
00:58:42,290 --> 00:58:44,660
他们知道崩溃，那是

1456
00:58:44,660 --> 00:58:46,190
在查询执行中途执行查询的响应，

1457
00:58:46,190 --> 00:58:50,180
他们不是 能够

1458
00:58:50,180 --> 00:58:52,460
恢复它曾经或计算过的那个查询的敌人结果

1459
00:58:52,460 --> 00:58:55,700
，然后

1460
00:58:55,700 --> 00:58:57,020
在它停止的地方选择查询

1461
00:58:57,020 --> 00:58:58,280
一般他们只是通过一个错误杀死了整个事情

1462
00:58:58,280 --> 00:58:59,990
，或者可能

1463
00:58:59,990 --> 00:59:03,020
为你默默地重新启动它，这

1464
00:59:03,020 --> 00:59:05,030
与日志记录无关，并且 恢复我们绝对

1465
00:59:05,030 --> 00:59:07,160
仍然需要登录恢复我们仍然

1466
00:59:07,160 --> 00:59:10,369
这样做这是更多

1467
00:59:10,369 --> 00:59:12,349
关于在查询运行时我可以在进行时

1468
00:59:12,349 --> 00:59:14,569
拍摄快照以便我

1469
00:59:14,569 --> 00:59:16,430
可以接听我可以

1470
00:59:16,430 --> 00:59:17,540
在查询运行的中途接听 如果我知道 Goes

1471
00:59:17,540 --> 00:59:20,060
Down 并且我在我所做的声明中

1472
00:59:20,060 --> 00:59:22,220
是，据我所知，

1473
00:59:22,220 --> 00:59:24,380
大多数分布式 OLAP 系统不

1474
00:59:24,380 --> 00:59:26,480
支持该查询弹性，因为

1475
00:59:26,480 --> 00:59:28,970
获取检查点

1476
00:59:28,970 --> 00:59:37,609
中间结果的快照是昂贵的日志记录

1477
00:59:37,609 --> 00:59:41,500
什么日志记录

1478
00:59:41,880 --> 00:59:45,910
什么数据库查询我们仍然是

1479
00:59:45,910 --> 00:59:50,200
所有D的错误

1480
00:59:50,200 --> 00:59:51,430
，我们之前讨论过的D和酸的东西

1481
00:59:51,430 --> 00:59:54,310
我们仍然在做我们仍然

1482
00:59:54,310 --> 00:59:56,830
确保如果我们从

1483
00:59:56,830 --> 00:59:58,390
外部世界直到我们的数据库，我们

1484
00:59:58,390 --> 01:00:02,140
不想丢失它，所以他们

1485
01:00:02,140 --> 01:00:03,780
将再次提供持久性保证

1486
01:00:03,780 --> 01:00:06,760
我是我有一百 PB 的

1487
01:00:06,760 --> 01:00:08,620
沃尔玛他们不想丢失这些

1488
01:00:08,620 --> 01:00:10,960
数据好吧，他们的日子 将

1489
01:00:10,960 --> 01:00:24,880
保证他们不会当你

1490
01:00:24,880 --> 01:00:26,410
再次说操作时你是什么意思，

1491
01:00:26,410 --> 01:00:28,930
比如 UH nup date 或者我们很奇怪 e

1492
01:00:28,930 --> 01:00:38,080
我就像一个选择查询让我们带我们

1493
01:00:38,080 --> 01:00:40,000
走吧让我们坐下之后伙计

1494
01:00:40,000 --> 01:00:42,670
我会通过这个 我认为

1495
01:00:42,670 --> 01:00:49,300
你在这里遗漏了一些东西，所以

1496
01:00:49,300 --> 01:00:50,830
他的问题是

1497
01:00:50,830 --> 01:00:53,170
当我做这些来运送它

1498
01:00:53,170 --> 01:00:55,480
时我实际上发送了什么，我是发送整个元组还是

1499
01:00:55,480 --> 01:00:57,670
我发送他们发送一个

1500
01:00:57,670 --> 01:01:00,040
标识符，我总是说答案

1501
01:01:00,040 --> 01:01:02,890
是 您至少

1502
01:01:02,890 --> 01:01:04,450
发送的

1503
01:01:04,450 --> 01:01:05,710
是计算连接所需的最少量信息

1504
01:01:05,710 --> 01:01:08,530
，然后在最坏的

1505
01:01:08,530 --> 01:01:10,170
情况下发送整个元组

1506
01:01:10,170 --> 01:01:13,480
，通常再次发送

1507
01:01:13,480 --> 01:01:16,030
高端 好的分布式数据库

1508
01:01:16,030 --> 01:01:18,730
进行分析将最大限度地减少

1509
01:01:18,730 --> 01:01:21,880
您实际需要的数据量，因此

1510
01:01:21,880 --> 01:01:24,580
它们很小，将

1511
01:01:24,580 --> 01:01:26,200
使用所谓的半连接

1512
01:01:26,200 --> 01:01:30,190
调用查询 半连接就像常规连接，但

1513
01:01:30,190 --> 01:01:32,590
我们的想法是我们并不是真的 将

1514
01:01:32,590 --> 01:01:35,980
在右表

1515
01:01:35,980 --> 01:01:38,590
或内表上进行连接，我们只会

1516
01:01:38,590 --> 01:01:40,890
检查我们是否敢于连接

1517
01:01:40,890 --> 01:01:44,920
元组匹配，以便查询优化器

1518
01:01:44,920 --> 01:01:47,950
可以识别它可能不需要

1519
01:01:47,950 --> 01:01:50,320
所有旧的任何囚犯可能不需要 需要任何

1520
01:01:50,320 --> 01:01:51,910
值或属性来自

1521
01:01:51,910 --> 01:01:54,890
内部表的列

1522
01:01:54,890 --> 01:01:57,109
，因此它可以

1523
01:01:57,109 --> 01:01:59,900
像进行存在检查一样重写查询，

1524
01:01:59,900 --> 01:02:02,240
并将中间人信息

1525
01:02:02,240 --> 01:02:04,789
来回发送他知道进行半连接而

1526
01:02:04,789 --> 01:02:08,480
不是再次复制整个元组，例如

1527
01:02:08,480 --> 01:02:09,740
一个自然连接你会切断你会

1528
01:02:09,740 --> 01:02:11,240
做连接然后输出将是

1529
01:02:11,240 --> 01:02:13,880
组合中的所有结果

1530
01:02:13,880 --> 01:02:16,099
或连接到右侧

1531
01:02:16,099 --> 01:02:18,680
和左侧表上的连接和半连接它

1532
01:02:18,680 --> 01:02:19,970
只是需要计算的属性

1533
01:02:19,970 --> 01:02:24,410
从外部表加入，所以

1534
01:02:24,410 --> 01:02:26,569
在这种情况下，这里说我有一个这样的查询，

1535
01:02:26,569 --> 01:02:29,960
从中选择我们的 ID 正在

1536
01:02:29,960 --> 01:02:32,119
对 s 进行外部联接，我们将只

1537
01:02:32,119 --> 01:02:34,490
匹配我的 IDE 哦，然后这是一个

1538
01:02:34,490 --> 01:02:35,569
写得很差的查询，因为它们是

1539
01:02:35,569 --> 01:02:37,160
基本上是说我们的 ID 不为

1540
01:02:37,160 --> 01:02:41,809
空然后匹配 s 上的内容，所以如果

1541
01:02:41,809 --> 01:02:44,029
我们没有进行半连接，我们要么必须

1542
01:02:44,029 --> 01:02:48,010
在此处复制 s 或在此处

1543
01:02:48,010 --> 01:02:50,000
再次复制 R，我们将复制整个元组

1544
01:02:50,000 --> 01:02:52,160
，这将很昂贵 但是我们可以

1545
01:02:52,160 --> 01:02:53,720
将这个查询重写为这样，

1546
01:02:53,720 --> 01:02:55,010
我们只检查

1547
01:02:55,010 --> 01:02:58,670
s 中是否存在一个与我们的 ID 具有相同想法的元组

1548
01:02:58,670 --> 01:03:02,390
，然后如果这是真的

1549
01:03:02,390 --> 01:03:04,549
那么我们就吐出我们所有匹配的 ID

1550
01:03:04,549 --> 01:03:06,619
，所以在这种情况下 在这里，

1551
01:03:06,619 --> 01:03:08,059
我唯一需要发送的可能

1552
01:03:08,059 --> 01:03:10,160
只是我们的 ID，因为这是

1553
01:03:10,160 --> 01:03:11,599
我计算此连接所需的最少信息，

1554
01:03:11,599 --> 01:03:21,230
因此

1555
01:03:21,230 --> 01:03:23,059
Claude hours 和 Paulo 等某些系统实际上有

1556
01:03:23,059 --> 01:03:25,430
一个显式的 semi join 关键字，您可以

1557
01:03:25,430 --> 01:03:27,829
给它 否则你可以尝试

1558
01:03:27,829 --> 01:03:30,500
用它来伪造它存在于高处 终端系统可以

1559
01:03:30,500 --> 01:03:32,480
检查以尝试再次将您的查询重写

1560
01:03:32,480 --> 01:03:34,880
为半连接它的一部分是

1561
01:03:34,880 --> 01:03:36,049
弄清楚我需要在不同笔记之间传输的数据并将

1562
01:03:36,049 --> 01:03:37,160


1563
01:03:37,160 --> 01:03:39,170
其包含

1564
01:03:39,170 --> 01:03:40,579
在优化器成本模型的成本计算中或

1565
01:03:40,579 --> 01:03:42,500
决定可能有多少数据

1566
01:03:42,500 --> 01:03:44,089
作为一个计划在不同节点之间传输

1567
01:03:44,089 --> 01:03:49,970
比另一个更好，所以

1568
01:03:49,970 --> 01:03:53,930
我可以说我可以说从我们的半

1569
01:03:53,930 --> 01:03:58,220
连接中选择我们的 ID 显式续集，它

1570
01:03:58,220 --> 01:03:59,690
说嘿，你正在做一个半连接，

1571
01:03:59,690 --> 01:04:03,200
或者我可以把它改写成这样 大多数系统

1572
01:04:03,200 --> 01:04:04,160
你必须这样做，因为他们

1573
01:04:04,160 --> 01:04:05,420
没有我不认为半加入

1574
01:04:05,420 --> 01:04:07,720
续集的标准

1575
01:04:10,890 --> 01:04:12,969
问题谁做谁做这项工作

1576
01:04:12,969 --> 01:04:14,049
和这个例子这里是

1577
01:04:14,049 --> 01:04:19,420
应用程序程序员高端

1578
01:04:19,420 --> 01:04:21,099
企业系统 查询

1579
01:04:21,099 --> 01:04:22,660
优化器可以弄清楚如何

1580
01:04:22,660 --> 01:04:24,910
潜在地为你重写这个他们

1581
01:04:24,910 --> 01:04:30,160
可以为你做到这一点哦，你的

1582
01:04:30,160 --> 01:04:32,049
问题是查询优化器

1583
01:04:32,049 --> 01:04:38,489
另一个节点就像你介意的节点

1584
01:04:41,099 --> 01:04:43,690
一样，所以这就像 您认为无关紧要的分区

1585
01:04:43,690 --> 01:04:47,079


1586
01:04:47,079 --> 01:04:47,979
无关紧要 查询优化器

1587
01:04:47,979 --> 01:04:49,569
在此处运行此节点或另一个节点

1588
01:04:49,569 --> 01:04:50,229
无关紧要

1589
01:04:50,229 --> 01:04:51,849
在这里进行更多讨论 这

1590
01:04:51,849 --> 01:04:54,130
有点像半关节的语义，

1591
01:04:54,130 --> 01:04:55,529


1592
01:04:55,529 --> 01:04:59,769
因此从 从关系代数的角度来看，它

1593
01:04:59,769 --> 01:05:01,269
只是看起来像这样我加入了 R 和 s

1594
01:05:01,269 --> 01:05:04,029
然后输出这是半

1595
01:05:04,029 --> 01:05:06,579
联合运算符输出将只是

1596
01:05:06,579 --> 01:05:09,700
皮肤成为 ID 是我用来

1597
01:05:09,700 --> 01:05:12,309
计算关节的 ID 而没有

1598
01:05:12,309 --> 01:05:18,390
来自 内表所以很清楚，

1599
01:05:18,390 --> 01:05:23,920
有一个家庭有一个问题，

1600
01:05:23,920 --> 01:05:28,209
所以我们有十分钟的时间，所以正如我

1601
01:05:28,209 --> 01:05:30,130
所说，这是关于

1602
01:05:30,130 --> 01:05:34,479


1603
01:05:34,479 --> 01:05:38,109
调优问题中的主要设计决策的速成课程和一个

1604
01:05:38,109 --> 01:05:40,779
小数据库，如果 你

1605
01:05:40,779 --> 01:05:42,400
不会构建一个你知道的不自由的

1606
01:05:42,400 --> 01:05:43,599
数据库最小根系统实际上

1607
01:05:43,599 --> 01:05:44,680
在系统的内部工作

1608
01:05:44,680 --> 01:05:46,630
你只想成为他们的用户

1609
01:05:46,630 --> 01:05:48,039
你要处理的主要问题

1610
01:05:48,039 --> 01:05:50,349
是分区键如何 以

1611
01:05:50,349 --> 01:05:53,109
这样的方式选择 您的大多数连接都

1612
01:05:53,109 --> 01:05:54,819
可以在本地节点上运行，而

1613
01:05:54,819 --> 01:05:57,640
无需进行广播或我们的 shuffle 以及那里

1614
01:05:57,640 --> 01:06:00,160
的各种系统，

1615
01:06:00,160 --> 01:06:01,930
大多数企业人员都有

1616
01:06:01,930 --> 01:06:03,190
工具来帮助您

1617
01:06:03,190 --> 01:06:07,959
尝试为您解决这些问题，好吧，让我们

1618
01:06:07,959 --> 01:06:12,459
谈谈 关于 Claudius 的所以

1619
01:06:12,459 --> 01:06:15,390
comp 云数据库的定义有点模糊

1620
01:06:15,390 --> 01:06:18,950
没有双关语的

1621
01:06:18,950 --> 01:06:21,450
意思是通常的意思是如果某些

1622
01:06:21,450 --> 01:06:23,070
供应商向您

1623
01:06:23,070 --> 01:06:26,010
提供来自 dbaas 的所谓数据库即服务的

1624
01:06:26,010 --> 01:06:28,170
想法是您向亚马逊提供

1625
01:06:28,170 --> 01:06:30,090
您的信用卡和 他们会说

1626
01:06:30,090 --> 01:06:32,580
这是您的 JDBC 或没有 DBC 连接

1627
01:06:32,580 --> 01:06:35,460
端口号和主机名，

1628
01:06:35,460 --> 01:06:37,050
您应该开始将查询推入其中

1629
01:06:37,050 --> 01:06:39,840
，您不必担心如何

1630
01:06:39,840 --> 01:06:41,550
管理节点，您不必担心如何

1631
01:06:41,550 --> 01:06:44,190
进行备份他们负责 所有这些都是

1632
01:06:44,190 --> 01:06:47,820
为了你，所以我之前已经

1633
01:06:47,820 --> 01:06:50,790
提到了这一点，但是在

1634
01:06:50,790 --> 01:06:52,800
这些主要的云供应商中

1635
01:06:52,800 --> 01:06:55,050
，像亚马逊、谷歌和微软一样控制整个堆栈的人之间

1636
01:06:55,050 --> 01:06:57,810
的

1637
01:06:57,810 --> 01:07:00,720
界限 是共享磁盘系统

1638
01:07:00,720 --> 01:07:02,430
与无共享系统

1639
01:07:02,430 --> 01:07:04,290
开始变得非常模糊，因为

1640
01:07:04,290 --> 01:07:06,480
它们可以在系统堆栈

1641
01:07:06,480 --> 01:07:08,190
的不同层之间向上和向下推送数据库逻辑，

1642
01:07:08,190 --> 01:07:10,800


1643
01:07:10,800 --> 01:07:13,200
而除非您控制硬件，否则您通常无法做到

1644
01:07:13,200 --> 01:07:16,130
你自己所以例如

1645
01:07:16,130 --> 01:07:18,060
亚马逊有一个叫做 Aurora 的东西

1646
01:07:18,060 --> 01:07:20,820
Aurora 是我

1647
01:07:20,820 --> 01:07:22,920
在 Postgres 中的续集的共享磁盘版本，但他们实际上

1648
01:07:22,920 --> 01:07:25,680


1649
01:07:25,680 --> 01:07:28,620


1650
01:07:28,620 --> 01:07:32,160
在共享磁盘级别再次将事务管理推入 EBS 中的存储层，所以

1651
01:07:32,160 --> 01:07:34,410
现在它不是纯粹的 共享磁盘

1652
01:07:34,410 --> 01:07:36,030
系统开始看起来

1653
01:07:36,030 --> 01:07:40,590
更像是一个不共享的系统

1654
01:07:40,590 --> 01:07:43,440
所以我认为在接下来的十年中

1655
01:07:43,440 --> 01:07:45,150
我认为云系统将收到

1656
01:07:45,150 --> 01:07:46,440
您看到云系统中最具创新性的尘埃

1657
01:07:46,440 --> 01:07:48,030
我认为它

1658
01:07:48,030 --> 01:07:49,110
真的真的 有趣的是，他们

1659
01:07:49,110 --> 01:07:53,310
可以做些什么，所以我想我

1660
01:07:53,310 --> 01:07:55,740
真的讨论过这个，一般来说，

1661
01:07:55,740 --> 01:07:58,200
云系统可以是托管

1662
01:07:58,200 --> 01:08:00,060
数据库或云原生数据库，所以

1663
01:08:00,060 --> 01:08:01,710
男人 过时的数据库将只是采用

1664
01:08:01,710 --> 01:08:03,450
现成的数据库，该系统是

1665
01:08:03,450 --> 01:08:05,160
为在专用硬件上运行而编写的

1666
01:08:05,160 --> 01:08:07,080
，现在您只是

1667
01:08:07,080 --> 01:08:09,450
将它作为服务运行，使用

1668
01:08:09,450 --> 01:08:12,120
我的 Seco 使用 Postgres，然后将

1669
01:08:12,120 --> 01:08:14,550
其放入一个 ec2 实例，然后让

1670
01:08:14,550 --> 01:08:16,830
人们连接到它，他们不

1671
01:08:16,830 --> 01:08:19,200
知道也不关心您正在

1672
01:08:19,200 --> 01:08:20,729
为他们管理 ec2 他们可以自己完成，

1673
01:08:20,729 --> 01:08:23,760
但您只是提供一个

1674
01:08:23,760 --> 01:08:24,899
服务来完成所有备份和其他

1675
01:08:24,899 --> 01:08:28,229
管理他们的东西 所以大多数

1676
01:08:28,229 --> 01:08:29,520
时候当你看到当你得到一个云

1677
01:08:29,520 --> 01:08:31,080
数据库 它将是

1678
01:08:31,080 --> 01:08:32,290
第一个

1679
01:08:32,290 --> 01:08:35,540
现在有一些系统虽然

1680
01:08:35,540 --> 01:08:36,859
他们将自己称为

1681
01:08:36,859 --> 01:08:38,479
云原生数据互联网系统和

1682
01:08:38,479 --> 01:08:41,139
这些 它们被设计为

1683
01:08:41,139 --> 01:08:43,279
在云环境中运行，

1684
01:08:43,279 --> 01:08:44,599
通常它们将成为共享

1685
01:08:44,599 --> 01:08:47,089
磁盘架构，因为他们不

1686
01:08:47,089 --> 01:08:48,380
希望实际上必须构建您知道

1687
01:08:48,380 --> 01:08:50,960
复制 EBS 或 s3，因此它们将构建

1688
01:08:50,960 --> 01:08:52,929
在 现有

1689
01:08:52,929 --> 01:08:54,859
存储 这些云供应商

1690
01:08:54,859 --> 01:08:56,540
为您提供的基础架构，他们在其上

1691
01:08:56,540 --> 01:08:58,189
提供计算层 您知道

1692
01:08:58,189 --> 01:08:59,630
Stefan 做查询计划 您仍然

1693
01:08:59,630 --> 01:09:01,429
需要执行我们

1694
01:09:01,429 --> 01:09:03,109
之前讨论过的所有容错工作，但他们

1695
01:09:03,109 --> 01:09:04,639
实际上并不担心如何 你知道将东西持久化

1696
01:09:04,639 --> 01:09:06,948
到磁盘，他们只是让云

1697
01:09:06,948 --> 01:09:12,618
供应商为你提供，所以

1698
01:09:12,618 --> 01:09:14,299
现在还有一类新的系统将

1699
01:09:14,299 --> 01:09:18,009
自己标记为正在服务是的，

1700
01:09:24,399 --> 01:09:27,618
是的，问题是它会是什么样的，

1701
01:09:27,618 --> 01:09:28,759
它是什么真正的区别在这里

1702
01:09:28,759 --> 01:09:30,880
所以这个 将是一个经理 这将

1703
01:09:30,880 --> 01:09:34,549
只是使用我的序列示例 我拿了我的

1704
01:09:34,549 --> 01:09:36,408
续集 我没有在没有对其进行

1705
01:09:36,408 --> 01:09:38,149
任何更改的情况下运行它 我在

1706
01:09:38,149 --> 01:09:41,658
容器中运行它或在虚拟机中运行它，它

1707
01:09:41,658 --> 01:09:43,488
与我将运行的软件相同 在我的

1708
01:09:43,488 --> 01:09:45,618
本地机器上，但刚才我

1709
01:09:45,618 --> 01:09:48,069
在一个你知道的云中运行它

1710
01:09:48,069 --> 01:09:52,279
，然后是旧的，

1711
01:09:52,279 --> 01:09:54,259
然后服务提供商也会为你做

1712
01:09:54,259 --> 01:09:55,730
备份和恢复以及所有其他的

1713
01:09:55,730 --> 01:09:57,320
事情，这就像 我正在

1714
01:09:57,320 --> 01:09:58,670
建造一个 新的数据库系统从零开始，

1715
01:09:58,670 --> 01:10:00,889
或者我采用现有的数据库系统并对

1716
01:10:00,889 --> 01:10:03,409
它进行重大更改以设计

1717
01:10:03,409 --> 01:10:07,219
在云环境中工作，因此在这里

1718
01:10:07,219 --> 01:10:08,690
运行我的周期我的 Seco

1719
01:10:08,690 --> 01:10:09,710
一无所知，但 s3

1720
01:10:09,710 --> 01:10:11,690
对性能影响一无所知

1721
01:10:11,690 --> 01:10:13,250
你们中的一些人知道阅读 PBS 和诸如此类的东西

1722
01:10:13,250 --> 01:10:14,690
，只有一个磁盘，它具有这些

1723
01:10:14,690 --> 01:10:16,909
属性，就像哦，我已经

1724
01:10:16,909 --> 01:10:18,170
设计了系统的明确性，可以

1725
01:10:18,170 --> 01:10:19,820
在 s/3 s/3 上工作，这些保证

1726
01:10:19,820 --> 01:10:21,679
为我提供了这些

1727
01:10:21,679 --> 01:10:23,420
信息现在渗透的属性

1728
01:10:23,420 --> 01:10:25,730
整个系统就像我的查询优化器成本

1729
01:10:25,730 --> 01:10:27,469
模型可以推理你知道什么

1730
01:10:27,469 --> 01:10:28,909
是写入 s3 的速度或者你知道

1731
01:10:28,909 --> 01:10:30,440
你可以做什么嵌套你不能在 EBS 上做这样的

1732
01:10:30,440 --> 01:10:31,040


1733
01:10:31,040 --> 01:10:36,230
事情，所以有

1734
01:10:36,230 --> 01:10:37,730
一个流行语 现在是

1735
01:10:37,730 --> 01:10:38,270
无服务器的，

1736
01:10:38,270 --> 01:10:39,980
所以当然有服务器列表

1737
01:10:39,980 --> 01:10:43,340
数据库，所以

1738
01:10:43,340 --> 01:10:44,840
一切都一样，我们

1739
01:10:44,840 --> 01:10:45,650
之前讨论

1740
01:10:45,650 --> 01:10:48,260
过的只是这个想法是当

1741
01:10:48,260 --> 01:10:50,570
你的机器空闲时，你的数据有

1742
01:10:50,570 --> 01:10:51,500
连接 空闲是因为您的

1743
01:10:51,500 --> 01:10:53,110
应用程序不再发送查询，

1744
01:10:53,110 --> 01:10:56,020
他们将尝试进行更深入的

1745
01:10:56,020 --> 01:10:58,670
了解，或者您知道不会为

1746
01:10:58,670 --> 01:11:01,430
您实际上没有使用的硬件付费，所以

1747
01:11:01,430 --> 01:11:04,310
假设我再次拥有一个托管数据库

1748
01:11:04,310 --> 01:11:05,840
系统我有一个节点它是 运行

1749
01:11:05,840 --> 01:11:09,320
我的续集，所以我为

1750
01:11:09,320 --> 01:11:11,450
实例付费，我为存储付费，我

1751
01:11:11,450 --> 01:11:12,860
必须将它配置为

1752
01:11:12,860 --> 01:11:14,840
一直运行，所以我的应用程序

1753
01:11:14,840 --> 01:11:16,310
向这个人发送查询，你知道并得到

1754
01:11:16,310 --> 01:11:19,040
结果，但现在如果我的 如果我的

1755
01:11:19,040 --> 01:11:20,660
应用程序进入睡眠状态或走开

1756
01:11:20,660 --> 01:11:24,590
去洗手间做任何事情 然后我

1757
01:11:24,590 --> 01:11:26,870
为这些资源付费 我

1758
01:11:26,870 --> 01:11:28,910
实际上并没有正确使用，因为我必须

1759
01:11:28,910 --> 01:11:30,140
提供提供 ec2 实例的硬权限

1760
01:11:30,140 --> 01:11:31,700
我提供了 EBS

1761
01:11:31,700 --> 01:11:34,460
存储权限，所以我 正在为运行的东西付费，但

1762
01:11:34,460 --> 01:11:35,840
实际上并没有做

1763
01:11:35,840 --> 01:11:39,140
任何事情，所以无服务器数据库的想法

1764
01:11:39,140 --> 01:11:41,510
是它几乎总是一个共享

1765
01:11:41,510 --> 01:11:45,500
磁盘架构，我可以做

1766
01:11:45,500 --> 01:11:47,450
我以前的所有查询，但现在

1767
01:11:47,450 --> 01:11:50,600
当我睡觉时 我退役

1768
01:11:50,600 --> 01:11:53,360
了事情的计算方面，这会消失，

1769
01:11:53,360 --> 01:11:55,340
但在我这样做之前，我基本上拍摄

1770
01:11:55,340 --> 01:11:57,140
了哪些页面是我的缓冲

1771
01:11:57,140 --> 01:11:59,600
池的快照我采取了一个检查点然后记录

1772
01:11:59,600 --> 01:12:00,890
所有页面ID或我的缓冲池中的内容

1773
01:12:00,890 --> 01:12:04,130
将其写出共享磁盘然后杀死

1774
01:12:04,130 --> 01:12:06,740
关闭我的电脑，所以现在

1775
01:12:06,740 --> 01:12:08,990
我唯一需要支付的费用就是存储

1776
01:12:08,990 --> 01:12:11,000
费用，让我的数据在磁盘上处于空闲状态

1777
01:12:11,000 --> 01:12:14,450
，然后如果我醒来并

1778
01:12:14,450 --> 01:12:15,770
回来执行查询，

1779
01:12:15,770 --> 01:12:17,150
我们要做的第一件事就是

1780
01:12:17,150 --> 01:12:19,250
在我上次关闭

1781
01:12:19,250 --> 01:12:21,350
缓冲池中的内容并让它尝试

1782
01:12:21,350 --> 01:12:23,390
将其取出并使其好像我

1783
01:12:23,390 --> 01:12:26,320
一直在运行之前一样

1784
01:12:27,070 --> 01:12:29,090
好所以这是一种方法，如果您

1785
01:12:29,090 --> 01:12:31,250
假设 只有一个

1786
01:12:31,250 --> 01:12:33,220
客户我在一个节点上运行

1787
01:12:33,220 --> 01:12:35,570
另一个常见的设置是你在一个节点上运行

1788
01:12:35,570 --> 01:12:36,830
多个客户或多个租户

1789
01:12:36,830 --> 01:12:38,780
，然后你只是

1790
01:12:38,780 --> 01:12:40,250
意识到这个客户有

1791
01:12:40,250 --> 01:12:41,690
一段时间没有让我查询然后我

1792
01:12:41,690 --> 01:12:43,700
写出来 其缓冲缓冲池页面

1793
01:12:43,700 --> 01:12:48,220
内容 o  ut 在磁盘之前是

1794
01:12:54,780 --> 01:12:58,330
所以这个问题是为什么我做这个

1795
01:12:58,330 --> 01:13:00,610
部分厨师为什么在你知道我为什么关心这个之前我实际上

1796
01:13:00,610 --> 01:13:02,200
将 buffle Blade 页面内容写到

1797
01:13:02,200 --> 01:13:05,050
磁盘

1798
01:13:05,050 --> 01:13:08,770
因为你想让它

1799
01:13:08,770 --> 01:13:10,330
看起来最像 昂贵的事情是

1800
01:13:10,330 --> 01:13:12,820
从磁盘获取东西，所以理想情况下，我

1801
01:13:12,820 --> 01:13:15,670
想让你知道我的查询，下一个

1802
01:13:15,670 --> 01:13:17,680
查询会在一分钟后

1803
01:13:17,680 --> 01:13:19,270


1804
01:13:19,270 --> 01:13:21,400


1805
01:13:21,400 --> 01:13:24,340
出现 加热我所有的

1806
01:13:24,340 --> 01:13:27,220
数据，我正在记忆中，所以你

1807
01:13:27,220 --> 01:13:28,990
记录了所有这些信息，这样当

1808
01:13:28,990 --> 01:13:30,610
你一分钟后再次回来时，它

1809
01:13:30,610 --> 01:13:31,960
看起来仍然在运行

1810
01:13:31,960 --> 01:13:33,520
，你不喜欢你仍然支付了

1811
01:13:33,520 --> 01:13:35,770
罚款，你必须这样做 获取它，但

1812
01:13:35,770 --> 01:13:36,940
您不必等待获取

1813
01:13:36,940 --> 01:13:39,130
所有内容，尝试可能预取

1814
01:13:39,130 --> 01:13:39,810
一些

1815
01:13:39,810 --> 01:13:41,800
您在缓存中用奶精预热的东西

1816
01:13:41,800 --> 01:13:44,050
是的，每个数据库

1817
01:13:44,050 --> 01:13:45,430
系统在您调用关闭时都会这样做，

1818
01:13:45,430 --> 01:13:46,960
就像正确击倒一样 他们已经

1819
01:13:46,960 --> 01:14:00,670
在做 是正确的，所以他的问题是，如果

1820
01:14:00,670 --> 01:14:03,310
我没有很好地完成这一步，这

1821
01:14:03,310 --> 01:14:05,620
仍然有效，是的，它会得到纠正，它会很

1822
01:14:05,620 --> 01:14:07,720
慢，这只是一种

1823
01:14:07,720 --> 01:14:21,610
优化，可以

1824
01:14:21,610 --> 01:14:23,170
像我们一样加热香烟中的缓存 只是

1825
01:14:23,170 --> 01:14:24,460
存储棉花，我们只是

1826
01:14:24,460 --> 01:14:26,320
轻松地翻页，当时我们在缓冲池中

1827
01:14:26,320 --> 01:14:29,230
处于关闭状态，

1828
01:14:29,230 --> 01:14:31,810
然后出现第一个查询，

1829
01:14:31,810 --> 01:14:33,130
然后说第一个查询说给我第一

1830
01:14:33,130 --> 01:14:35,830
页 二三它说哦我还有

1831
01:14:35,830 --> 01:14:37,330
四五六七八九也在

1832
01:14:37,330 --> 01:14:38,890
那里让我去拿他们

1833
01:14:38,890 --> 01:14:45,070
拿诺兰是的这个问题她的问题是

1834
01:14:45,070 --> 01:14:46,780


1835
01:14:46,780 --> 01:14:49,840
像服务器列表中那样无国籍是什么感觉通常

1836
01:14:49,840 --> 01:14:52,480
人们的意思是我的 服务是无状态的，但

1837
01:14:52,480 --> 01:14:57,130
它不是不对的，所以如果

1838
01:14:57,130 --> 01:14:59,610
从最终用户的角度来看它是服务，这

1839
01:14:59,610 --> 01:15:01,750
意味着我不必说为

1840
01:15:01,750 --> 01:15:03,760
我提供这台机器，所以很多

1841
01:15:03,760 --> 01:15:05,380
云供应商他们没有做

1842
01:15:05,380 --> 01:15:06,220
服务架构

1843
01:15:06,220 --> 01:15:07,900
你基本上说

1844
01:15:07,900 --> 01:15:09,760
我想成为关键我不知道我

1845
01:15:09,760 --> 01:15:11,469
想为此付出代价 如果您不使用这些专用资源

1846
01:15:11,469 --> 01:15:13,000
，我将随时可用，

1847
01:15:13,000 --> 01:15:14,020
他们会

1848
01:15:14,020 --> 01:15:17,290
向您收费，他们很高兴，但如果

1849
01:15:17,290 --> 01:15:18,670
我的意思是我每分钟有一个查询，我

1850
01:15:18,670 --> 01:15:19,659
不想给我，你知道我

1851
01:15:19,659 --> 01:15:21,219
不想配置整台机器只是为了

1852
01:15:21,219 --> 01:15:24,190
每小时发送 X 60 个查询，而在

1853
01:15:24,190 --> 01:15:25,630
这种架构中，我仍然可以让我的

1854
01:15:25,630 --> 01:15:27,219
数据库仍然像它一直在

1855
01:15:27,219 --> 01:15:28,929
运行一样，但我没有支付待处理的费用，

1856
01:15:28,929 --> 01:15:30,730
所以我支付或不支付我 按查询支付，

1857
01:15:30,730 --> 01:15:33,190
加上我在这里存储的任何东西

1858
01:15:33,190 --> 01:15:39,130
，所以这个领域的主要供应商

1859
01:15:39,130 --> 01:15:42,159
将是亚马逊有一个服务器

1860
01:15:42,159 --> 01:15:44,560
这个版本的我的续集然后动物

1861
01:15:44,560 --> 01:15:46,600
数据库是一个独立的数据库启动

1862
01:15:46,600 --> 01:15:49,900
，亚马逊会这样做 尝试所有

1863
01:15:49,900 --> 01:15:51,070
这些人都在

1864
01:15:51,070 --> 01:15:52,449
做这件事，你杀死了

1865
01:15:52,449 --> 01:15:54,190
机器他们只是认识到这个

1866
01:15:54,190 --> 01:15:55,690
客户没有发送查询

1867
01:15:55,690 --> 01:15:58,030
，然后他们把所有东西都

1868
01:15:58,030 --> 01:16:00,640
写到磁盘上，这样 Azure 就可以做到这一点，然后

1869
01:16:00,640 --> 01:16:04,449
谷歌我认为是这些 图标太

1870
01:16:04,449 --> 01:16:05,500
没用了，因为这个好像没有

1871
01:16:05,500 --> 01:16:06,520
说名字 我知道并且我第二个意思

1872
01:16:06,520 --> 01:16:08,699
是我认为它是 Google fire store

1873
01:16:08,699 --> 01:16:11,560
所以不是扳手或 bigquery 的东西

1874
01:16:11,560 --> 01:16:15,460
它只适用于 fire store 所以

1875
01:16:15,460 --> 01:16:16,780
另一个有趣的事情

1876
01:16:16,780 --> 01:16:19,300
是你可以构建一个

1877
01:16:19,300 --> 01:16:22,120
数据库系统而不必编写

1878
01:16:22,120 --> 01:16:26,340
每个 自己制作系统的一部分，所以

1879
01:16:26,340 --> 01:16:28,960
现在有足够多的开源软件

1880
01:16:28,960 --> 01:16:31,449
或服务

1881
01:16:31,449 --> 01:16:32,739
，你可以将

1882
01:16:32,739 --> 01:16:34,449
这些东西拼凑在一起，创建一个新的

1883
01:16:34,449 --> 01:16:36,429
云数据库，而无需

1884
01:16:36,429 --> 01:16:38,560
从头开始编写所有内容，所以我们已经

1885
01:16:38,560 --> 01:16:40,390
讨论过 就像我说的，她的问题

1886
01:16:40,390 --> 01:16:41,530
是什么是云原生数据库，

1887
01:16:41,530 --> 01:16:43,090
它是一个你假设你

1888
01:16:43,090 --> 01:16:44,620
可以写你知道你写的硫磺是

1889
01:16:44,620 --> 01:16:46,420
为了假设你正在写入 s3

1890
01:16:46,420 --> 01:16:48,520
并且你将它的保证或

1891
01:16:48,520 --> 01:16:50,699
性能影响纳入设计

1892
01:16:50,699 --> 01:16:52,690
所以这将是一个例子，

1893
01:16:52,690 --> 01:16:54,010
你不是你知道磁盘

1894
01:16:54,010 --> 01:16:56,320
管理器的人，你只是让 s3 为你处理，

1895
01:16:56,320 --> 01:16:57,940
你可能不必正确地编写你的

1896
01:16:57,940 --> 01:17:00,040
目录

1897
01:17:00,040 --> 01:17:01,840
可以获得元数据服务

1898
01:17:01,840 --> 01:17:03,670
通过这些不同类型

1899
01:17:03,670 --> 01:17:05,739
的软件获得元数据作为服务 您可能无法管理您的

1900
01:17:05,739 --> 01:17:07,929
集群 您可以依赖 kubernetes 或

1901
01:17:07,929 --> 01:17:09,640
yarn 或

1902
01:17:09,640 --> 01:17:11,650
供应商必须为您处理所有这些的其他工具

1903
01:17:11,650 --> 01:17:13,989
，然后您可能不会 甚至必须构建

1904
01:17:13,989 --> 01:17:16,270
自己的查询优化器，因此

1905
01:17:16,270 --> 01:17:18,489
实际上有一些开源

1906
01:17:18,489 --> 01:17:21,590
类型的优化器作为

1907
01:17:21,590 --> 01:17:23,840
服务运行在单独的节点上，您

1908
01:17:23,840 --> 01:17:25,159
只需向它提供一堆 XML 或 JSON

1909
01:17:25,159 --> 01:17:26,780
元数据即可说明我的数据是什么

1910
01:17:26,780 --> 01:17:28,340
样的 这是我的查询 计划看起来

1911
01:17:28,340 --> 01:17:30,139
像然后单独的机器

1912
01:17:30,139 --> 01:17:33,219
将紧缩它并

1913
01:17:33,219 --> 01:17:35,420
为您吐出一个可能优化的计划我

1914
01:17:35,420 --> 01:17:36,770
不知道这些东西

1915
01:17:36,770 --> 01:17:39,170
实际上有多好我实际上已经有任何

1916
01:17:39,170 --> 01:17:41,570
研究来评估它们但我们

1917
01:17:41,570 --> 01:17:42,920
看了 当我们构建我们的

1918
01:17:42,920 --> 01:17:45,170
系统时，Orca 我们传递了它，因为

1919
01:17:45,170 --> 01:17:47,270
当时的文档很糟糕

1920
01:17:47,270 --> 01:17:49,340
Cal 用 Java 编写的引用所以

1921
01:17:49,340 --> 01:17:52,340
这对我们来说也是一个非初学者

1922
01:17:52,340 --> 01:17:55,480


1923
01:17:55,480 --> 01:18:00,080
直到

1924
01:18:00,080 --> 01:18:01,670
最近，几乎每个数据库分钟

1925
01:18:01,670 --> 01:18:03,469
系统都有自己专有的

1926
01:18:03,469 --> 01:18:07,699
二进制文件格式，这意味着就像我的

1927
01:18:07,699 --> 01:18:09,020
续集将一堆文件写入磁盘一样，

1928
01:18:09,020 --> 01:18:11,090
您无法将这些文件很好地读入 Oracle，

1929
01:18:11,090 --> 01:18:12,409
因为 Oracle 有自己的 文件

1930
01:18:12,409 --> 01:18:14,420
格式当你构建时你能做同样的事情

1931
01:18:14,420 --> 01:18:16,280
把你的项目放在 bus tub

1932
01:18:16,280 --> 01:18:18,739
总线集线器有自己的页面格式，

1933
01:18:18,739 --> 01:18:21,560
其他人无法读取所以

1934
01:18:21,560 --> 01:18:23,449
如果你在云

1935
01:18:23,449 --> 01:18:24,619
环境中，现在这是有问题的 一堆

1936
01:18:24,619 --> 01:18:27,050
不同的服务，可能想要

1937
01:18:27,050 --> 01:18:29,119
共享数据，就像一堆数据我

1938
01:18:29,119 --> 01:18:30,710
想生成我的旧数据库，

1939
01:18:30,710 --> 01:18:32,210
也许我想通过 spark 运行这些数据，

1940
01:18:32,210 --> 01:18:34,130
或者通过

1941
01:18:34,130 --> 01:18:36,889
Vertica 或其他一些 Shiva 数据库学习这些数据，

1942
01:18:36,889 --> 01:18:38,449
所以现在就在那里 如果一切都

1943
01:18:38,449 --> 01:18:40,550
基于饼图格式，那么您可以

1944
01:18:40,550 --> 01:18:42,020
从一个系统中获取数据并将其

1945
01:18:42,020 --> 01:18:44,239
放入另一个系统的唯一方法是制作副本

1946
01:18:44,239 --> 01:18:46,580
并将其放入这些人类

1947
01:18:46,580 --> 01:18:49,250
可读的文本可读格式之一，等等

1948
01:18:49,250 --> 01:18:51,290
现在相反的是，有

1949
01:18:51,290 --> 01:18:53,239
许多

1950
01:18:53,239 --> 01:18:55,010
云供应商或分布式

1951
01:18:55,010 --> 01:18:57,469
数据库或数据科学生态系统

1952
01:18:57,469 --> 01:19:00,469
工具现在支持这些开源二进制格式，我

1953
01:19:00,469 --> 01:19:02,630
可以直接将其用于 s3 或 EBS 或我的

1954
01:19:02,630 --> 01:19:04,429
分布式文件系统中的一堆这些

1955
01:19:04,429 --> 01:19:06,199
文件 这种格式可能会让我的

1956
01:19:06,199 --> 01:19:08,150
数据由系统生成，然后我可以将

1957
01:19:08,150 --> 01:19:09,860
它们吸入并将它们读入另一个

1958
01:19:09,860 --> 01:19:11,060
数据库，而无需进行任何

1959
01:19:11,060 --> 01:19:15,139
不稳定或转换，所以其中

1960
01:19:15,139 --> 01:19:16,969
一些您可能听说过，但这些

1961
01:19:16,969 --> 01:19:19,400
只是这些 一个主要的

1962
01:19:19,400 --> 01:19:21,409
Parkay Knork 应用了两个最常见

1963
01:19:21,409 --> 01:19:21,770
的

1964
01:19:21,770 --> 01:19:24,080
Parkay Kemetic 阶梯和推特，或者

1965
01:19:24,080 --> 01:19:26,719
从蜂巢中出来，然后再次想到

1966
01:19:26,719 --> 01:19:28,159
这些就像二进制列存储

1967
01:19:28,159 --> 01:19:30,530
格式，不与任何

1968
01:19:30,530 --> 01:19:32,540
太平洋数据系统绑定，就像

1969
01:19:32,540 --> 01:19:34,159
任何人都可以修改的开放规范

1970
01:19:34,159 --> 01:19:35,390
他们的数据库系统 Armada

1971
01:19:35,390 --> 01:19:37,370
通过他们的应用程序本地读取这些数据

1972
01:19:37,370 --> 01:19:40,820
Carbon 数据实际上是 2016 年更新的数据

1973
01:19:40,820 --> 01:19:44,210
我认为这就像

1974
01:19:44,210 --> 01:19:45,710
兽人和来自我们的停车场 t of

1975
01:19:45,710 --> 01:19:49,520
Hawaii in China iceberg

1976
01:19:49,520 --> 01:19:52,910
是来自 Netflix 的另一个新产品，我最近刚

1977
01:19:52,910 --> 01:19:55,430
收到一个我已经深入研究过的人的通知，

1978
01:19:55,430 --> 01:19:56,960
但他们

1979
01:19:56,960 --> 01:19:59,150
声称他们可以支持模式演变，

1980
01:19:59,150 --> 01:20:01,370
就像我可以改变列一样，你

1981
01:20:01,370 --> 01:20:02,690
知道改变模因改变 列

1982
01:20:02,690 --> 01:20:04,820
类型这些其他人可以这些其他

1983
01:20:04,820 --> 01:20:06,530
人只读的方式就像我创建

1984
01:20:06,530 --> 01:20:08,180
文件然后我冻结它并且我无法

1985
01:20:08,180 --> 01:20:10,850
返回并更改它们hd5通常不

1986
01:20:10,850 --> 01:20:13,850
用于云系统或

1987
01:20:13,850 --> 01:20:15,380
传统的硅谷

1988
01:20:15,380 --> 01:20:17,750
科技公司的数据库 这

1989
01:20:17,750 --> 01:20:20,270
主要是在科学界的 HPC 中找到的

1990
01:20:20,270 --> 01:20:22,610
这就像一个 Rea 数据，就像

1991
01:20:22,610 --> 01:20:24,380
你可以让你知道你的

1992
01:20:24,380 --> 01:20:26,600
粒子对撞机可以很好地吐出

1993
01:20:26,600 --> 01:20:27,970
一堆这种类型的文件，

1994
01:20:27,970 --> 01:20:31,070
然后箭头是一个 -

1995
01:20:31,070 --> 01:20:35,030
来自 pandas 和 gem IO 的内存列格式，

1996
01:20:35,030 --> 01:20:36,530
认为这就像 parkade

1997
01:20:36,530 --> 01:20:39,140
orc 但它用于内存数据，所以我们的

1998
01:20:39,140 --> 01:20:40,760
数据在卡内基梅隆大学更多地构建

1999
01:20:40,760 --> 01:20:42,950
我们的本地存储格式

2000
01:20:42,950 --> 01:20:44,960
实际上是箭头 所以你可以

2001
01:20:44,960 --> 01:20:47,210
把我们的数据系统生成的数据转储

2002
01:20:47,210 --> 01:20:49,790
出来，然后把它送入熊猫或其他任何

2003
01:20:49,790 --> 01:20:51,110
东西我不知道你想要

2004
01:20:51,110 --> 01:20:53,570
任何读取箭头格式的东西所以我认为

2005
01:20:53,570 --> 01:20:55,430
这是正确的方法

2006
01:20:55,430 --> 01:20:56,240
到最低

2007
01:20:56,240 --> 01:20:58,400
公分母，就像你知道

2008
01:20:58,400 --> 01:20:59,900
压缩方案一样，所有这些

2009
01:20:59,900 --> 01:21:03,590
不同的这些格式可能不是

2010
01:21:03,590 --> 01:21:05,240
所有可能的应用程序的最佳选择，

2011
01:21:05,240 --> 01:21:06,950
当然如果你编写一个自定义的，你

2012
01:21:06,950 --> 01:21:07,700
可能会得到更好的

2013
01:21:07,700 --> 01:21:09,860
压缩或更好的性能，

2014
01:21:09,860 --> 01:21:12,070
但这提供了 你的互操作性没问题，

2015
01:21:12,070 --> 01:21:17,380
所以只是完成重叠，

2016
01:21:17,380 --> 01:21:20,180
这意味着如果你

2017
01:21:20,180 --> 01:21:22,280
需要需要扩展的分析数据库，那么

2018
01:21:22,280 --> 01:21:24,260
你有钱，因为你正在获得

2019
01:21:24,260 --> 01:21:26,270
正确的数据，人们实际上使用

2020
01:21:26,270 --> 01:21:27,920
你拥有的任何应用程序并且你实际上

2021
01:21:27,920 --> 01:21:29,840
能够处理 但是你

2022
01:21:29,840 --> 01:21:31,040
得到的数据越多，你就会遇到更多的问题，

2023
01:21:31,040 --> 01:21:32,150
因为因为这两个 tivity

2024
01:21:32,150 --> 01:21:34,010
数据库你知道所有

2025
01:21:34,010 --> 01:21:35,450
额外的管理问题和

2026
01:21:35,450 --> 01:21:36,680
问题 女士，您拥有

2027
01:21:36,680 --> 01:21:38,750
分布式系统，您确实必须

2028
01:21:38,750 --> 01:21:41,540
考虑所有问题，所以这是上次的问题，

2029
01:21:41,540 --> 01:21:43,490
我可以说出

2030
01:21:43,490 --> 01:21:46,390
一些有趣的内容，或者

2031
01:21:46,729 --> 01:21:48,919
现在这些内容不好，但是您可以查看的

2032
01:21:48,919 --> 01:21:51,800
主要系统是

2033
01:21:51,800 --> 01:21:54,499
什么？ 红船和

2034
01:21:54,499 --> 01:21:56,590
雪花是两个玩家的关键

2035
01:21:56,590 --> 01:21:59,389
甲骨文、微软和谷歌也

2036
01:21:59,389 --> 01:22:01,550
有自己的太平洋服务 我认为

2037
01:22:01,550 --> 01:22:03,559
这两个可能是最大

2038
01:22:03,559 --> 01:22:06,139
的，所以如果你想在云上运行，就可以运行

2039
01:22:06,139 --> 01:22:08,139
在运行的前提

2040
01:22:08,139 --> 01:22:10,999
下，我实际上非常

2041
01:22:10,999 --> 01:22:13,219
感兴趣的是 click house，因此它

2042
01:22:13,219 --> 01:22:14,899
分布在

2043
01:22:14,899 --> 01:22:16,610
来自 Yandex 家伙的俄罗斯以外的内存列存储系统中

2044
01:22:16,610 --> 01:22:19,099
，当您阅读他们的网页时

2045
01:22:19,099 --> 01:22:20,329
，他们支持的内容列表

2046
01:22:20,329 --> 01:22:22,489
实际上很棒，并且

2047
01:22:22,489 --> 01:22:27,979
presto 是开源的，运行在 SPARC 之上，我

2048
01:22:27,979 --> 01:22:30,709
认为 Hadoop 拼接机器是

2049
01:22:30,709 --> 01:22:33,320
HBase 加上 SPARC greenplum 是 Postgres 的第四个

2050
01:22:33,320 --> 01:22:36,619
版本，有人

2051
01:22:36,619 --> 01:22:38,389
发布了它，它是 2000 年代的一家初创公司，

2052
01:22:38,389 --> 01:22:41,780
他们得到了 bo  EMC 应该 EMC

2053
01:22:41,780 --> 01:22:42,979
说我们不想成为一家基于数据的

2054
01:22:42,979 --> 01:22:44,809
公司，所以他们与 VMware 合并

2055
01:22:44,809 --> 01:22:47,090
成为关键，但在 5 月开源

2056
01:22:47,090 --> 01:22:50,570
了 Vertica 由我的顾问

2057
01:22:50,570 --> 01:22:52,880
在我回到新英格兰时创立，

2058
01:22:52,880 --> 01:22:55,760
他们被惠普收购 这家伙在

2059
01:22:55,760 --> 01:22:58,699
几周前或学期前来过一次演讲，

2060
01:22:58,699 --> 01:23:01,429
所以思考这个问题的方式就像

2061
01:23:01,429 --> 01:23:04,459
如果你没有钱从这里开始如果

2062
01:23:04,459 --> 01:23:06,739
你有钱你可以从这里开始

2063
01:23:06,739 --> 01:23:08,899
就像 Oracle 数据和撕裂数据超级

2064
01:23:08,899 --> 01:23:11,149
超级昂贵一样 Exadata 我不

2065
01:23:11,149 --> 01:23:12,289
认为你能以

2066
01:23:12,289 --> 01:23:13,550
低于你所知道的 200 万美元的价格购买一台机器，

2067
01:23:13,550 --> 01:23:16,389
因为你正在购买定制硬件，

2068
01:23:16,389 --> 01:23:22,489
好吧，如果你

2069
01:23:22,489 --> 01:23:23,780
不想走这条路，它会设置一个完整的

2070
01:23:23,780 --> 01:23:25,760
分布式数据库，还有一个更新的

2071
01:23:25,760 --> 01:23:27,320
系统，我对

2072
01:23:27,320 --> 01:23:30,949
称为duck DB 感到非常兴奋 它在欧洲之外

2073
01:23:30,949 --> 01:23:34,519
认为这个duck DB 就像用于分析的续集灯，

2074
01:23:34,519 --> 01:23:36,349
因此您可以将其作为

2075
01:23:36,349 --> 01:23:37,880
嵌入式数据库运行 它实际上您可以

2076
01:23:37,880 --> 01:23:38,989
通过像终端这样的续集连接到它，

2077
01:23:38,989 --> 01:23:41,179
但它是一个 立柱 重新排名

2078
01:23:41,179 --> 01:23:43,639
并且可以做你可以用你在

2079
01:23:43,639 --> 01:23:45,139
这里可以做的同样的方式进行分析，所以

2080
01:23:45,139 --> 01:23:47,329
如果你的数据可以放在一个单节点

2081
01:23:47,329 --> 01:23:49,280
鸭子 PD 可能是正确的事情，

2082
01:23:49,280 --> 01:23:53,990
它是开源的，

2083
01:23:53,990 --> 01:23:56,270
所以这就是主要材料

2084
01:23:56,270 --> 01:23:59,930


2085
01:23:59,930 --> 01:24:01,340
在假期后的下一学期我们将有一位

2086
01:24:01,340 --> 01:24:02,810
来自甲骨文的演讲嘉宾，我们将再次进行

2087
01:24:02,810 --> 01:24:04,490
最终审查和周三的百花香

2088
01:24:04,490 --> 01:24:07,130
会议，因此此时

2089
01:24:07,130 --> 01:24:09,650
您应该再次有足够的信心

2090
01:24:09,650 --> 01:24:11,060
走出去 世界和

2091
01:24:11,060 --> 01:24:12,800
管理器数据库或用户数据库 并且

2092
01:24:12,800 --> 01:24:14,810
足够了解您是否

2093
01:24:14,810 --> 01:24:16,220
知道您正在使用的系统

2094
01:24:16,220 --> 01:24:18,050
正在提出好主意 好吧

2095
01:24:18,050 --> 01:24:19,790
我们已经涵盖了很多你们

2096
01:24:19,790 --> 01:25:08,330
希望你们好吧好吧不知道

2097
01:25:08,330 --> 01:25:11,020
你可以 't

